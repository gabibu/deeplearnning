{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Linear Image Classifier\n",
    "\n",
    "In this exercise you will implement a linear image classifier while getting familiar with `numpy` and the benefits of vectorized operations in Python. This exercise has 3 parts:\n",
    "\n",
    "1. Python warmup: working with images, refresher on classes and objects.\n",
    "2. Implementing loss functions, calculating gradients and implementing gradient descent.\n",
    "3. Training and evaluating several classifiers.\n",
    "\n",
    "## Submission guidelines:\n",
    "\n",
    "Your zip should include the following files only:\n",
    "```\n",
    "- HW2.pdf\n",
    "- HW2.ipynb\n",
    "- functions/\n",
    "    - classifier.py\n",
    "    - losses.py\n",
    "```\n",
    "Name the file `ex2_ID.zip` if you submit alone of `ex2_ID1_ID2.zip` if you submit in pairs. Do **not** include the data. \n",
    "\n",
    "## Read the following instructions carefully:\n",
    "\n",
    "1. This jupyter notebook contains all the step by step instructions needed for this exercise.\n",
    "1. Write **efficient vectorized** code whenever instructed. \n",
    "1. You should add as many tests as you see fit. Tests will not be graded nor checked.\n",
    "1. Do not change the functions we provided you. \n",
    "1. Write your functions in the instructed python modules only. All the logic you write is imported and used using this jupyter notebook. You are allowed to add functions as long as they are located in the python modules and are imported properly.\n",
    "1. You are allowed to use functions and methods from the [Python Standard Library](https://docs.python.org/3/library/) and [numpy](https://www.numpy.org/devdocs/reference/) only.\n",
    "1. Your code must run without errors. Use `python 3` and at least `numpy 1.15.4`. Before submitting the exercise, restart the kernel and run the notebook from start to finish to make sure everything works. \n",
    "1. Answers to qualitative questions should be written in **markdown** cells (with $\\LaTeX$ support)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functions.classifier import LinearPerceptron\n",
    "from functions.classifier import LogisticRegression\n",
    "from functions.losses import perceptron_loss_vectorized\n",
    "from functions.losses import perceptron_loss_naive\n",
    "from functions.losses import binary_cross_entropy\n",
    "from functions.losses import grad_check\n",
    "\n",
    "# specify the way plots behave in jupyter notebook\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (8.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# auto-reloading extenrnal modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:  3.7.4\n",
      "Numpy version:  1.16.4\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(\"Python version: \", platform.python_version())\n",
    "print(\"Numpy version: \", np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "The next few cells will download and extract CIFAR-10 into `datasets/cifar10/`. The CIFAR-10 dataset consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images. The dataset is divided into five training batches and one test batch, each with 10,000 images. The test batch contains exactly 1,000 randomly-selected images from each class.\n",
    "\n",
    "We have included several image processing functions. Notice the following in particular: we created an additional validation dataset you need to use for hyperparameter optimization (learning rate and L2 regularization). We subtracted the mean from all the images in order to ignore illumination conditions while keeping the content of the image. Next, we flattened the images from a tensor of shape (32x32x3) to a vector with 3072 features (pixel values) so we would be able to use a simple matrix multiplication. Finally, we concatenated each image vector with an additional feature to account for the bias. This is known as the bias trick. \n",
    "\n",
    "Make sure you understand this image processing pipeline before diving into the rest of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has apparently already been downloaded and unpacked.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_cifar10\n",
    "URL = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "PATH = 'datasets/cifar10/' # the script will create required directories\n",
    "load_cifar10.maybe_download_and_extract(URL, PATH) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3073)\n",
      "(1000, 3073)\n",
      "(1000, 3073)\n"
     ]
    }
   ],
   "source": [
    "CIFAR10_PATH = os.path.join(PATH, 'cifar-10-batches-py')\n",
    "X_train, y_train, X_test, y_test = load_cifar10.load(CIFAR10_PATH) # load the entire data\n",
    "\n",
    "# taking only two classes from the dataset\n",
    "X_train = X_train[np.logical_or(y_train == 0, y_train == 1)]\n",
    "y_train = y_train[np.logical_or(y_train == 0, y_train == 1)]\n",
    "X_test = X_test[np.logical_or(y_test == 0, y_test == 1)]\n",
    "y_test = y_test[np.logical_or(y_test == 0, y_test == 1)]\n",
    "\n",
    "# define a splitting for the data\n",
    "num_training = 10000\n",
    "num_validation = 1000\n",
    "num_testing = 1000\n",
    "\n",
    "# add a validation dataset for hyperparameter optimization\n",
    "mask = range(num_training)\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "mask = range(num_validation)\n",
    "X_val = X_test[mask]\n",
    "y_val = y_test[mask]\n",
    "mask = range(num_validation, num_validation+num_testing)\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]\n",
    "\n",
    "# float64\n",
    "X_train = X_train.astype(np.float64)\n",
    "X_val = X_val.astype(np.float64)\n",
    "X_test = X_test.astype(np.float64)\n",
    "\n",
    "# subtract the mean from all the images in the batch\n",
    "mean_image = np.mean(X_train, axis=0)\n",
    "X_train -= mean_image\n",
    "X_val -= mean_image\n",
    "X_test -= mean_image\n",
    "\n",
    "# flatten all the images in the batch (make sure you understand why this is needed)\n",
    "X_train = np.reshape(X_train, newshape=(X_train.shape[0], -1))\n",
    "X_val = np.reshape(X_val, newshape=(X_val.shape[0], -1)) \n",
    "X_test = np.reshape(X_test, newshape=(X_test.shape[0], -1)) \n",
    "\n",
    "# add a bias term to all images in the batch\n",
    "X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))]) \n",
    "X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))]) \n",
    "X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))]) \n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "classes = ('plane', 'car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          car           car         plane           car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:11: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_batch(X, y, n):\n",
    "    rand_items = np.random.randint(0, X.shape[0], size=n)\n",
    "    images = X[rand_items]\n",
    "    labels = y[rand_items]\n",
    "    return X, y\n",
    "\n",
    "def make_random_grid(x, y, n=4):\n",
    "    rand_items = np.random.randint(0, x.shape[0], size=n)\n",
    "    images = x[rand_items]\n",
    "    labels = y[rand_items]\n",
    "    grid = np.hstack((np.asarray((vec_2_img(i) + mean_image), dtype=np.int) for i in images))\n",
    "    print(' '.join('%13s' % classes[labels[j]] for j in range(4)))\n",
    "    return grid\n",
    "\n",
    "def vec_2_img(x):\n",
    "    x = np.reshape(x[:-1], (32, 32, 3))\n",
    "    return x\n",
    "\n",
    "X_batch, y_batch = get_batch(X_test, y_test, 4)\n",
    "plt.imshow(make_random_grid(X_batch, y_batch));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear classifier: mapping images to scores\n",
    "\n",
    "During this exercise, we will maintain a python class with basic functionality (such as training the model). the linear classifiers we will build (perceptron, logistic regression) will inherit some functionality from that class and will change several functions (such as the loss function, for example). Open the file `functions/classifier.py` and make sure you understand the code. You might find this [short classes in python tutorial](https://www.hackerearth.com/practice/python/object-oriented-programming/classes-and-objects-i/tutorial/) useful.\n",
    "\n",
    "## Linear perceptron\n",
    "Our first linear classifier will include a linear function that maps images to scores:\n",
    "\n",
    "$$\n",
    "f(x_i; W, b) = W\\cdot x_i + b\n",
    "$$\n",
    "\n",
    "As you learned in class, this linear classifier takes an input image $x_i$ and outputs a class score. Your goal is to **learn** the parameters $W$ and $b$ to best classify the images according to the provided labels. The linear perceptron is set up so that the perceptron learn to map the correct class for each image such that it will have a score higher than the incorrect class. In this exercise, we will define our Linear perceptron to have two outputs - one outputs for each class.      \n",
    "\n",
    "Open the file `functions/classifier.py`. The constructor of the `LinearPerceptron` class takes as input the dataset and labels in order to create appropriate parameters. Notice we are using the bias trick and only use the matrix `w` for convenience. Since we already have a (random) model, we can start predicting classes on images. Complete the method `predict` in the `LinearPerceptron` class. **(2.5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LinearPerceptron(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          car         plane           car         plane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:11: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_batch, y_batch = get_batch(X_train, y_train, 4)\n",
    "plt.imshow(make_random_grid(X_batch, y_batch));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        plane           car         plane         plane\n"
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "print(' '.join('%13s' % classes[y_pred[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Complete the class method `calc_accuracy` in `functions/classifier.py`. Explain why the accuracy on the training dataset (remember, the model is not trained yet) is around 50%. **(2.5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy:  [0.4704]\n"
     ]
    }
   ],
   "source": [
    "print(\"model accuracy: \", classifier.calc_accuracy(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hinge loss (30 points)\n",
    "\n",
    "Your code for this section will all be written inside `functions/losses.py`. In this section, we write and test code outside the classes for convenience. Notice the loss method for each class is just a call for the loss function written in `losses.py`. Once you are finished with implementation, everything should work.\n",
    "\n",
    "First, complete the function `perceptron_loss_naive`. This function takes as input the weights, data, labels and a regularization term and outputs the calculated loss as a single number and the gradients with respect to W."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.randn(3073, 2) * 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.816776\n",
      "CPU times: user 13.2 ms, sys: 1.28 ms, total: 14.5 ms\n",
      "Wall time: 13.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loss_naive, grad_naive = perceptron_loss_naive(W, X_val, y_val)\n",
    "print ('loss: %f' % (loss_naive, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are provided with a gradient checking function called `grad_check` in `functions/losses.py`. The following cells test your implementation of the loss value and gradient. Errors should be below $10^{-8}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: -6.060511 analytic: -6.060511, relative error: 4.484043e-12\n",
      "numerical: -4.099380 analytic: -4.099380, relative error: 1.355327e-12\n",
      "numerical: -0.981590 analytic: -0.981590, relative error: 2.313270e-12\n",
      "numerical: -5.075406 analytic: -5.075406, relative error: 1.341348e-13\n",
      "numerical: 1.028618 analytic: 1.028618, relative error: 1.040856e-11\n",
      "numerical: 5.290649 analytic: 5.290649, relative error: 1.200035e-11\n",
      "numerical: 2.334474 analytic: 2.334474, relative error: 7.736694e-13\n",
      "numerical: -6.060991 analytic: -6.060991, relative error: 4.869602e-12\n",
      "numerical: -5.009046 analytic: -5.009046, relative error: 2.693413e-12\n",
      "numerical: 9.520549 analytic: 9.520549, relative error: 1.080399e-12\n"
     ]
    }
   ],
   "source": [
    "loss, grad = perceptron_loss_naive(W, X_val, y_val)\n",
    "f = lambda w: perceptron_loss_naive(w, X_val, y_val)[0]\n",
    "grad_numerical = grad_check(f, W, grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your code works, complete the function `perceptron_loss_vectorized` and compare the results of the two functions using the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.816776\n",
      "difference: 0.000000\n",
      "CPU times: user 14.5 ms, sys: 1.78 ms, total: 16.3 ms\n",
      "Wall time: 11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loss_vectorized, grad_vectorized = perceptron_loss_vectorized(W, X_val, y_val)\n",
    "print ('loss: %f' % (loss, ))\n",
    "\n",
    "difference = np.linalg.norm(grad_naive - grad_vectorized)\n",
    "print ('difference: %f' % difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have obtained an efficient function for loss and gradient calculation and we can now train our network. Complete the function `train` in `functions/classifier.py`. This function should be implemented in the `LinearClassifier` class. (**10 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 1500: loss 567.003661\n",
      "iteration 100 / 1500: loss 696.298451\n",
      "iteration 200 / 1500: loss 600.695164\n",
      "iteration 300 / 1500: loss 659.117602\n",
      "iteration 400 / 1500: loss 661.002926\n",
      "iteration 500 / 1500: loss 548.582472\n",
      "iteration 600 / 1500: loss 589.677598\n",
      "iteration 700 / 1500: loss 584.249174\n",
      "iteration 800 / 1500: loss 603.406284\n",
      "iteration 900 / 1500: loss 703.661724\n",
      "iteration 1000 / 1500: loss 477.738859\n",
      "iteration 1100 / 1500: loss 684.492812\n",
      "iteration 1200 / 1500: loss 621.274364\n",
      "iteration 1300 / 1500: loss 610.388993\n",
      "iteration 1400 / 1500: loss 653.240904\n",
      "CPU times: user 4.37 s, sys: 176 ms, total: 4.54 s\n",
      "Wall time: 2.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "perceptron = LinearPerceptron(X_train, y_train)\n",
    "loss_history = perceptron.train(X_train, y_train, \n",
    "                         learning_rate=1e-7,\n",
    "                         num_iters=1500,\n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Loss value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  [0.477]\n",
      "Testing accuracy:  [0.497]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: \", perceptron.calc_accuracy(X_train, y_train))\n",
    "print(\"Testing accuracy: \", perceptron.calc_accuracy(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization\n",
    "\n",
    "Your model should have improved from 50% accuracy to ~75% accuracy in a matter of seconds. Now, use the validation set to tune hyperparameters by training different models (using the training dataset) and evaluating the performance using the validation dataset. Save the results in a dictionary mapping tuples of the form `(learning_rate, batch_size)` to tuples of the form `(training_accuracy, validation_accuracy)`. Finally, you should evaluate the best model on the testing dataset. \n",
    "\n",
    "Note: When changing the batch_size, change the number of iterations accordingly such that the number of epochs on the data stays roughly the same. A reasonable ratio is 600 iterations for a batch size of 200. \n",
    "\n",
    "If you are carful you should reach ~83% accuracy on the validation dataset.\n",
    "\n",
    "Use a small value for the number of iterations as you develop your code. Once you are confident that everything works, run it again for more iterations. Finally, explain the results - what can you learn from the hyper parameters that yields the best results? Why do you think that is the case? **(5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 120000: loss 0.000000\n",
      "iteration 100 / 120000: loss 0.000000\n",
      "iteration 200 / 120000: loss 0.000000\n",
      "iteration 300 / 120000: loss 0.000000\n",
      "iteration 400 / 120000: loss 0.000000\n",
      "iteration 500 / 120000: loss 0.000000\n",
      "iteration 600 / 120000: loss 862.847664\n",
      "iteration 700 / 120000: loss 0.000000\n",
      "iteration 800 / 120000: loss 0.000000\n",
      "iteration 900 / 120000: loss 0.000000\n",
      "iteration 1000 / 120000: loss 0.000000\n",
      "iteration 1100 / 120000: loss 0.000000\n",
      "iteration 1200 / 120000: loss 0.000000\n",
      "iteration 1300 / 120000: loss 0.000000\n",
      "iteration 1400 / 120000: loss 0.000000\n",
      "iteration 1500 / 120000: loss 0.000000\n",
      "iteration 1600 / 120000: loss 512.181336\n",
      "iteration 1700 / 120000: loss 0.000000\n",
      "iteration 1800 / 120000: loss 2147.166099\n",
      "iteration 1900 / 120000: loss 0.000000\n",
      "iteration 2000 / 120000: loss 0.000000\n",
      "iteration 2100 / 120000: loss 0.000000\n",
      "iteration 2200 / 120000: loss 0.000000\n",
      "iteration 2300 / 120000: loss 1010.789232\n",
      "iteration 2400 / 120000: loss 0.000000\n",
      "iteration 2500 / 120000: loss 0.000000\n",
      "iteration 2600 / 120000: loss 152.707103\n",
      "iteration 2700 / 120000: loss 0.000000\n",
      "iteration 2800 / 120000: loss 0.000000\n",
      "iteration 2900 / 120000: loss 450.443150\n",
      "iteration 3000 / 120000: loss 0.000000\n",
      "iteration 3100 / 120000: loss 0.000000\n",
      "iteration 3200 / 120000: loss 0.000000\n",
      "iteration 3300 / 120000: loss 140.413396\n",
      "iteration 3400 / 120000: loss 0.000000\n",
      "iteration 3500 / 120000: loss 0.000000\n",
      "iteration 3600 / 120000: loss 0.000000\n",
      "iteration 3700 / 120000: loss 0.000000\n",
      "iteration 3800 / 120000: loss 0.000000\n",
      "iteration 3900 / 120000: loss 0.000000\n",
      "iteration 4000 / 120000: loss 0.000000\n",
      "iteration 4100 / 120000: loss 0.000000\n",
      "iteration 4200 / 120000: loss 0.000000\n",
      "iteration 4300 / 120000: loss 0.000000\n",
      "iteration 4400 / 120000: loss 0.000000\n",
      "iteration 4500 / 120000: loss 34.262108\n",
      "iteration 4600 / 120000: loss 0.000000\n",
      "iteration 4700 / 120000: loss 0.000000\n",
      "iteration 4800 / 120000: loss 0.000000\n",
      "iteration 4900 / 120000: loss 0.000000\n",
      "iteration 5000 / 120000: loss 815.276516\n",
      "iteration 5100 / 120000: loss 0.000000\n",
      "iteration 5200 / 120000: loss 544.147502\n",
      "iteration 5300 / 120000: loss 0.000000\n",
      "iteration 5400 / 120000: loss 0.000000\n",
      "iteration 5500 / 120000: loss 476.436347\n",
      "iteration 5600 / 120000: loss 1522.801711\n",
      "iteration 5700 / 120000: loss 0.000000\n",
      "iteration 5800 / 120000: loss 166.973809\n",
      "iteration 5900 / 120000: loss 0.000000\n",
      "iteration 6000 / 120000: loss 0.000000\n",
      "iteration 6100 / 120000: loss 0.000000\n",
      "iteration 6200 / 120000: loss 0.000000\n",
      "iteration 6300 / 120000: loss 723.238641\n",
      "iteration 6400 / 120000: loss 1669.412260\n",
      "iteration 6500 / 120000: loss 644.075023\n",
      "iteration 6600 / 120000: loss 738.846261\n",
      "iteration 6700 / 120000: loss 0.000000\n",
      "iteration 6800 / 120000: loss 0.000000\n",
      "iteration 6900 / 120000: loss 0.000000\n",
      "iteration 7000 / 120000: loss 0.000000\n",
      "iteration 7100 / 120000: loss 0.000000\n",
      "iteration 7200 / 120000: loss 0.000000\n",
      "iteration 7300 / 120000: loss 0.000000\n",
      "iteration 7400 / 120000: loss 0.000000\n",
      "iteration 7500 / 120000: loss 482.548781\n",
      "iteration 7600 / 120000: loss 0.000000\n",
      "iteration 7700 / 120000: loss 0.000000\n",
      "iteration 7800 / 120000: loss 0.000000\n",
      "iteration 7900 / 120000: loss 0.000000\n",
      "iteration 8000 / 120000: loss 0.000000\n",
      "iteration 8100 / 120000: loss 1536.733773\n",
      "iteration 8200 / 120000: loss 1472.104265\n",
      "iteration 8300 / 120000: loss 892.087891\n",
      "iteration 8400 / 120000: loss 0.000000\n",
      "iteration 8500 / 120000: loss 0.000000\n",
      "iteration 8600 / 120000: loss 214.819217\n",
      "iteration 8700 / 120000: loss 155.062440\n",
      "iteration 8800 / 120000: loss 353.825945\n",
      "iteration 8900 / 120000: loss 0.000000\n",
      "iteration 9000 / 120000: loss 0.000000\n",
      "iteration 9100 / 120000: loss 0.000000\n",
      "iteration 9200 / 120000: loss 140.089960\n",
      "iteration 9300 / 120000: loss 850.165318\n",
      "iteration 9400 / 120000: loss 0.000000\n",
      "iteration 9500 / 120000: loss 0.000000\n",
      "iteration 9600 / 120000: loss 0.000000\n",
      "iteration 9700 / 120000: loss 0.000000\n",
      "iteration 9800 / 120000: loss 0.000000\n",
      "iteration 9900 / 120000: loss 0.000000\n",
      "iteration 10000 / 120000: loss 2177.732644\n",
      "iteration 10100 / 120000: loss 0.000000\n",
      "iteration 10200 / 120000: loss 60.278946\n",
      "iteration 10300 / 120000: loss 0.000000\n",
      "iteration 10400 / 120000: loss 0.000000\n",
      "iteration 10500 / 120000: loss 0.000000\n",
      "iteration 10600 / 120000: loss 995.801785\n",
      "iteration 10700 / 120000: loss 1368.373985\n",
      "iteration 10800 / 120000: loss 0.000000\n",
      "iteration 10900 / 120000: loss 0.000000\n",
      "iteration 11000 / 120000: loss 0.000000\n",
      "iteration 11100 / 120000: loss 0.000000\n",
      "iteration 11200 / 120000: loss 0.000000\n",
      "iteration 11300 / 120000: loss 0.000000\n",
      "iteration 11400 / 120000: loss 0.000000\n",
      "iteration 11500 / 120000: loss 0.000000\n",
      "iteration 11600 / 120000: loss 470.169759\n",
      "iteration 11700 / 120000: loss 612.493869\n",
      "iteration 11800 / 120000: loss 0.000000\n",
      "iteration 11900 / 120000: loss 1231.174387\n",
      "iteration 12000 / 120000: loss 0.000000\n",
      "iteration 12100 / 120000: loss 0.000000\n",
      "iteration 12200 / 120000: loss 559.083401\n",
      "iteration 12300 / 120000: loss 0.000000\n",
      "iteration 12400 / 120000: loss 125.813841\n",
      "iteration 12500 / 120000: loss 0.000000\n",
      "iteration 12600 / 120000: loss 0.000000\n",
      "iteration 12700 / 120000: loss 0.000000\n",
      "iteration 12800 / 120000: loss 370.601340\n",
      "iteration 12900 / 120000: loss 0.000000\n",
      "iteration 13000 / 120000: loss 0.000000\n",
      "iteration 13100 / 120000: loss 0.000000\n",
      "iteration 13200 / 120000: loss 0.000000\n",
      "iteration 13300 / 120000: loss 0.000000\n",
      "iteration 13400 / 120000: loss 0.000000\n",
      "iteration 13500 / 120000: loss 0.000000\n",
      "iteration 13600 / 120000: loss 0.000000\n",
      "iteration 13700 / 120000: loss 0.000000\n",
      "iteration 13800 / 120000: loss 0.000000\n",
      "iteration 13900 / 120000: loss 0.000000\n",
      "iteration 14000 / 120000: loss 0.000000\n",
      "iteration 14100 / 120000: loss 0.000000\n",
      "iteration 14200 / 120000: loss 750.084367\n",
      "iteration 14300 / 120000: loss 1902.027600\n",
      "iteration 14400 / 120000: loss 415.991553\n",
      "iteration 14500 / 120000: loss 0.000000\n",
      "iteration 14600 / 120000: loss 2292.452939\n",
      "iteration 14700 / 120000: loss 0.000000\n",
      "iteration 14800 / 120000: loss 480.562383\n",
      "iteration 14900 / 120000: loss 1125.323482\n",
      "iteration 15000 / 120000: loss 0.000000\n",
      "iteration 15100 / 120000: loss 1234.800130\n",
      "iteration 15200 / 120000: loss 0.000000\n",
      "iteration 15300 / 120000: loss 0.000000\n",
      "iteration 15400 / 120000: loss 0.000000\n",
      "iteration 15500 / 120000: loss 0.000000\n",
      "iteration 15600 / 120000: loss 0.000000\n",
      "iteration 15700 / 120000: loss 43.757866\n",
      "iteration 15800 / 120000: loss 0.000000\n",
      "iteration 15900 / 120000: loss 0.000000\n",
      "iteration 16000 / 120000: loss 443.086470\n",
      "iteration 16100 / 120000: loss 0.000000\n",
      "iteration 16200 / 120000: loss 1159.716049\n",
      "iteration 16300 / 120000: loss 0.000000\n",
      "iteration 16400 / 120000: loss 0.000000\n",
      "iteration 16500 / 120000: loss 0.000000\n",
      "iteration 16600 / 120000: loss 0.000000\n",
      "iteration 16700 / 120000: loss 325.087292\n",
      "iteration 16800 / 120000: loss 0.000000\n",
      "iteration 16900 / 120000: loss 9.420781\n",
      "iteration 17000 / 120000: loss 1002.269835\n",
      "iteration 17100 / 120000: loss 137.624622\n",
      "iteration 17200 / 120000: loss 0.000000\n",
      "iteration 17300 / 120000: loss 0.000000\n",
      "iteration 17400 / 120000: loss 0.000000\n",
      "iteration 17500 / 120000: loss 0.000000\n",
      "iteration 17600 / 120000: loss 2279.762046\n",
      "iteration 17700 / 120000: loss 0.000000\n",
      "iteration 17800 / 120000: loss 0.000000\n",
      "iteration 17900 / 120000: loss 0.000000\n",
      "iteration 18000 / 120000: loss 1604.318979\n",
      "iteration 18100 / 120000: loss 1991.867110\n",
      "iteration 18200 / 120000: loss 0.000000\n",
      "iteration 18300 / 120000: loss 0.000000\n",
      "iteration 18400 / 120000: loss 0.000000\n",
      "iteration 18500 / 120000: loss 0.000000\n",
      "iteration 18600 / 120000: loss 0.000000\n",
      "iteration 18700 / 120000: loss 0.000000\n",
      "iteration 18800 / 120000: loss 0.000000\n",
      "iteration 18900 / 120000: loss 0.000000\n",
      "iteration 19000 / 120000: loss 875.176764\n",
      "iteration 19100 / 120000: loss 0.000000\n",
      "iteration 19200 / 120000: loss 0.000000\n",
      "iteration 19300 / 120000: loss 0.000000\n",
      "iteration 19400 / 120000: loss 0.000000\n",
      "iteration 19500 / 120000: loss 0.000000\n",
      "iteration 19600 / 120000: loss 0.000000\n",
      "iteration 19700 / 120000: loss 48.595051\n",
      "iteration 19800 / 120000: loss 1680.336739\n",
      "iteration 19900 / 120000: loss 0.000000\n",
      "iteration 20000 / 120000: loss 81.852525\n",
      "iteration 20100 / 120000: loss 0.000000\n",
      "iteration 20200 / 120000: loss 0.000000\n",
      "iteration 20300 / 120000: loss 113.211119\n",
      "iteration 20400 / 120000: loss 220.231011\n",
      "iteration 20500 / 120000: loss 712.414827\n",
      "iteration 20600 / 120000: loss 0.000000\n",
      "iteration 20700 / 120000: loss 0.000000\n",
      "iteration 20800 / 120000: loss 0.000000\n",
      "iteration 20900 / 120000: loss 0.000000\n",
      "iteration 21000 / 120000: loss 0.000000\n",
      "iteration 21100 / 120000: loss 0.000000\n",
      "iteration 21200 / 120000: loss 0.000000\n",
      "iteration 21300 / 120000: loss 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 21400 / 120000: loss 1705.301481\n",
      "iteration 21500 / 120000: loss 0.000000\n",
      "iteration 21600 / 120000: loss 418.933676\n",
      "iteration 21700 / 120000: loss 431.222503\n",
      "iteration 21800 / 120000: loss 0.000000\n",
      "iteration 21900 / 120000: loss 0.000000\n",
      "iteration 22000 / 120000: loss 0.000000\n",
      "iteration 22100 / 120000: loss 0.000000\n",
      "iteration 22200 / 120000: loss 0.000000\n",
      "iteration 22300 / 120000: loss 0.000000\n",
      "iteration 22400 / 120000: loss 0.000000\n",
      "iteration 22500 / 120000: loss 0.000000\n",
      "iteration 22600 / 120000: loss 0.000000\n",
      "iteration 22700 / 120000: loss 203.248383\n",
      "iteration 22800 / 120000: loss 0.000000\n",
      "iteration 22900 / 120000: loss 1136.613498\n",
      "iteration 23000 / 120000: loss 770.531108\n",
      "iteration 23100 / 120000: loss 908.672395\n",
      "iteration 23200 / 120000: loss 216.455331\n",
      "iteration 23300 / 120000: loss 0.000000\n",
      "iteration 23400 / 120000: loss 0.000000\n",
      "iteration 23500 / 120000: loss 0.000000\n",
      "iteration 23600 / 120000: loss 0.000000\n",
      "iteration 23700 / 120000: loss 0.000000\n",
      "iteration 23800 / 120000: loss 0.000000\n",
      "iteration 23900 / 120000: loss 0.000000\n",
      "iteration 24000 / 120000: loss 0.000000\n",
      "iteration 24100 / 120000: loss 0.000000\n",
      "iteration 24200 / 120000: loss 0.000000\n",
      "iteration 24300 / 120000: loss 1163.247580\n",
      "iteration 24400 / 120000: loss 0.000000\n",
      "iteration 24500 / 120000: loss 0.000000\n",
      "iteration 24600 / 120000: loss 354.980637\n",
      "iteration 24700 / 120000: loss 0.000000\n",
      "iteration 24800 / 120000: loss 0.000000\n",
      "iteration 24900 / 120000: loss 0.000000\n",
      "iteration 25000 / 120000: loss 0.000000\n",
      "iteration 25100 / 120000: loss 0.000000\n",
      "iteration 25200 / 120000: loss 442.950320\n",
      "iteration 25300 / 120000: loss 0.000000\n",
      "iteration 25400 / 120000: loss 6.703822\n",
      "iteration 25500 / 120000: loss 0.000000\n",
      "iteration 25600 / 120000: loss 0.000000\n",
      "iteration 25700 / 120000: loss 0.000000\n",
      "iteration 25800 / 120000: loss 0.000000\n",
      "iteration 25900 / 120000: loss 0.000000\n",
      "iteration 26000 / 120000: loss 0.000000\n",
      "iteration 26100 / 120000: loss 0.000000\n",
      "iteration 26200 / 120000: loss 0.000000\n",
      "iteration 26300 / 120000: loss 0.000000\n",
      "iteration 26400 / 120000: loss 0.000000\n",
      "iteration 26500 / 120000: loss 508.581616\n",
      "iteration 26600 / 120000: loss 0.000000\n",
      "iteration 26700 / 120000: loss 0.000000\n",
      "iteration 26800 / 120000: loss 1350.456088\n",
      "iteration 26900 / 120000: loss 0.000000\n",
      "iteration 27000 / 120000: loss 0.000000\n",
      "iteration 27100 / 120000: loss 127.923237\n",
      "iteration 27200 / 120000: loss 0.000000\n",
      "iteration 27300 / 120000: loss 0.000000\n",
      "iteration 27400 / 120000: loss 0.000000\n",
      "iteration 27500 / 120000: loss 0.000000\n",
      "iteration 27600 / 120000: loss 0.000000\n",
      "iteration 27700 / 120000: loss 0.000000\n",
      "iteration 27800 / 120000: loss 0.000000\n",
      "iteration 27900 / 120000: loss 0.000000\n",
      "iteration 28000 / 120000: loss 0.000000\n",
      "iteration 28100 / 120000: loss 0.000000\n",
      "iteration 28200 / 120000: loss 0.000000\n",
      "iteration 28300 / 120000: loss 1171.102081\n",
      "iteration 28400 / 120000: loss 1486.667439\n",
      "iteration 28500 / 120000: loss 0.000000\n",
      "iteration 28600 / 120000: loss 0.000000\n",
      "iteration 28700 / 120000: loss 211.489280\n",
      "iteration 28800 / 120000: loss 0.000000\n",
      "iteration 28900 / 120000: loss 0.000000\n",
      "iteration 29000 / 120000: loss 0.000000\n",
      "iteration 29100 / 120000: loss 270.625578\n",
      "iteration 29200 / 120000: loss 1302.922310\n",
      "iteration 29300 / 120000: loss 0.000000\n",
      "iteration 29400 / 120000: loss 0.000000\n",
      "iteration 29500 / 120000: loss 1056.868259\n",
      "iteration 29600 / 120000: loss 698.209379\n",
      "iteration 29700 / 120000: loss 0.000000\n",
      "iteration 29800 / 120000: loss 0.000000\n",
      "iteration 29900 / 120000: loss 0.000000\n",
      "iteration 30000 / 120000: loss 0.000000\n",
      "iteration 30100 / 120000: loss 629.589301\n",
      "iteration 30200 / 120000: loss 0.000000\n",
      "iteration 30300 / 120000: loss 0.000000\n",
      "iteration 30400 / 120000: loss 981.770389\n",
      "iteration 30500 / 120000: loss 0.000000\n",
      "iteration 30600 / 120000: loss 0.000000\n",
      "iteration 30700 / 120000: loss 349.453468\n",
      "iteration 30800 / 120000: loss 0.000000\n",
      "iteration 30900 / 120000: loss 57.914763\n",
      "iteration 31000 / 120000: loss 0.000000\n",
      "iteration 31100 / 120000: loss 736.483130\n",
      "iteration 31200 / 120000: loss 0.000000\n",
      "iteration 31300 / 120000: loss 0.000000\n",
      "iteration 31400 / 120000: loss 312.072885\n",
      "iteration 31500 / 120000: loss 344.272316\n",
      "iteration 31600 / 120000: loss 0.000000\n",
      "iteration 31700 / 120000: loss 0.000000\n",
      "iteration 31800 / 120000: loss 405.212549\n",
      "iteration 31900 / 120000: loss 0.000000\n",
      "iteration 32000 / 120000: loss 723.453060\n",
      "iteration 32100 / 120000: loss 107.028264\n",
      "iteration 32200 / 120000: loss 0.000000\n",
      "iteration 32300 / 120000: loss 0.000000\n",
      "iteration 32400 / 120000: loss 0.000000\n",
      "iteration 32500 / 120000: loss 0.000000\n",
      "iteration 32600 / 120000: loss 2588.908052\n",
      "iteration 32700 / 120000: loss 0.000000\n",
      "iteration 32800 / 120000: loss 537.891040\n",
      "iteration 32900 / 120000: loss 188.448703\n",
      "iteration 33000 / 120000: loss 0.000000\n",
      "iteration 33100 / 120000: loss 0.000000\n",
      "iteration 33200 / 120000: loss 0.000000\n",
      "iteration 33300 / 120000: loss 0.000000\n",
      "iteration 33400 / 120000: loss 565.871204\n",
      "iteration 33500 / 120000: loss 266.066237\n",
      "iteration 33600 / 120000: loss 254.777637\n",
      "iteration 33700 / 120000: loss 0.000000\n",
      "iteration 33800 / 120000: loss 0.000000\n",
      "iteration 33900 / 120000: loss 0.000000\n",
      "iteration 34000 / 120000: loss 92.505595\n",
      "iteration 34100 / 120000: loss 0.000000\n",
      "iteration 34200 / 120000: loss 74.179602\n",
      "iteration 34300 / 120000: loss 0.000000\n",
      "iteration 34400 / 120000: loss 0.000000\n",
      "iteration 34500 / 120000: loss 0.000000\n",
      "iteration 34600 / 120000: loss 0.000000\n",
      "iteration 34700 / 120000: loss 0.000000\n",
      "iteration 34800 / 120000: loss 0.000000\n",
      "iteration 34900 / 120000: loss 0.000000\n",
      "iteration 35000 / 120000: loss 207.885263\n",
      "iteration 35100 / 120000: loss 0.000000\n",
      "iteration 35200 / 120000: loss 1069.353887\n",
      "iteration 35300 / 120000: loss 0.000000\n",
      "iteration 35400 / 120000: loss 0.000000\n",
      "iteration 35500 / 120000: loss 1291.116541\n",
      "iteration 35600 / 120000: loss 1246.270158\n",
      "iteration 35700 / 120000: loss 0.000000\n",
      "iteration 35800 / 120000: loss 0.000000\n",
      "iteration 35900 / 120000: loss 295.080766\n",
      "iteration 36000 / 120000: loss 0.000000\n",
      "iteration 36100 / 120000: loss 0.000000\n",
      "iteration 36200 / 120000: loss 0.000000\n",
      "iteration 36300 / 120000: loss 0.000000\n",
      "iteration 36400 / 120000: loss 0.000000\n",
      "iteration 36500 / 120000: loss 313.502332\n",
      "iteration 36600 / 120000: loss 0.000000\n",
      "iteration 36700 / 120000: loss 0.000000\n",
      "iteration 36800 / 120000: loss 0.000000\n",
      "iteration 36900 / 120000: loss 0.000000\n",
      "iteration 37000 / 120000: loss 0.000000\n",
      "iteration 37100 / 120000: loss 109.833732\n",
      "iteration 37200 / 120000: loss 0.000000\n",
      "iteration 37300 / 120000: loss 0.000000\n",
      "iteration 37400 / 120000: loss 0.000000\n",
      "iteration 37500 / 120000: loss 0.000000\n",
      "iteration 37600 / 120000: loss 0.000000\n",
      "iteration 37700 / 120000: loss 0.000000\n",
      "iteration 37800 / 120000: loss 813.207361\n",
      "iteration 37900 / 120000: loss 0.000000\n",
      "iteration 38000 / 120000: loss 0.000000\n",
      "iteration 38100 / 120000: loss 300.196216\n",
      "iteration 38200 / 120000: loss 0.000000\n",
      "iteration 38300 / 120000: loss 0.000000\n",
      "iteration 38400 / 120000: loss 0.000000\n",
      "iteration 38500 / 120000: loss 0.000000\n",
      "iteration 38600 / 120000: loss 439.340931\n",
      "iteration 38700 / 120000: loss 0.000000\n",
      "iteration 38800 / 120000: loss 79.579744\n",
      "iteration 38900 / 120000: loss 0.000000\n",
      "iteration 39000 / 120000: loss 0.000000\n",
      "iteration 39100 / 120000: loss 0.000000\n",
      "iteration 39200 / 120000: loss 642.024729\n",
      "iteration 39300 / 120000: loss 667.798726\n",
      "iteration 39400 / 120000: loss 0.000000\n",
      "iteration 39500 / 120000: loss 1447.600367\n",
      "iteration 39600 / 120000: loss 713.337048\n",
      "iteration 39700 / 120000: loss 1080.138427\n",
      "iteration 39800 / 120000: loss 0.000000\n",
      "iteration 39900 / 120000: loss 0.000000\n",
      "iteration 40000 / 120000: loss 0.000000\n",
      "iteration 40100 / 120000: loss 802.683975\n",
      "iteration 40200 / 120000: loss 510.917269\n",
      "iteration 40300 / 120000: loss 0.000000\n",
      "iteration 40400 / 120000: loss 828.366907\n",
      "iteration 40500 / 120000: loss 0.000000\n",
      "iteration 40600 / 120000: loss 0.000000\n",
      "iteration 40700 / 120000: loss 0.000000\n",
      "iteration 40800 / 120000: loss 0.000000\n",
      "iteration 40900 / 120000: loss 1562.972103\n",
      "iteration 41000 / 120000: loss 0.000000\n",
      "iteration 41100 / 120000: loss 0.000000\n",
      "iteration 41200 / 120000: loss 0.000000\n",
      "iteration 41300 / 120000: loss 0.000000\n",
      "iteration 41400 / 120000: loss 97.663202\n",
      "iteration 41500 / 120000: loss 77.008083\n",
      "iteration 41600 / 120000: loss 0.000000\n",
      "iteration 41700 / 120000: loss 0.000000\n",
      "iteration 41800 / 120000: loss 0.000000\n",
      "iteration 41900 / 120000: loss 0.000000\n",
      "iteration 42000 / 120000: loss 0.000000\n",
      "iteration 42100 / 120000: loss 0.000000\n",
      "iteration 42200 / 120000: loss 0.000000\n",
      "iteration 42300 / 120000: loss 0.000000\n",
      "iteration 42400 / 120000: loss 0.000000\n",
      "iteration 42500 / 120000: loss 1329.423223\n",
      "iteration 42600 / 120000: loss 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 42700 / 120000: loss 0.000000\n",
      "iteration 42800 / 120000: loss 55.415691\n",
      "iteration 42900 / 120000: loss 0.000000\n",
      "iteration 43000 / 120000: loss 888.778748\n",
      "iteration 43100 / 120000: loss 0.000000\n",
      "iteration 43200 / 120000: loss 674.243157\n",
      "iteration 43300 / 120000: loss 0.000000\n",
      "iteration 43400 / 120000: loss 0.000000\n",
      "iteration 43500 / 120000: loss 0.000000\n",
      "iteration 43600 / 120000: loss 423.460443\n",
      "iteration 43700 / 120000: loss 0.000000\n",
      "iteration 43800 / 120000: loss 0.000000\n",
      "iteration 43900 / 120000: loss 345.756284\n",
      "iteration 44000 / 120000: loss 357.145134\n",
      "iteration 44100 / 120000: loss 0.000000\n",
      "iteration 44200 / 120000: loss 0.000000\n",
      "iteration 44300 / 120000: loss 0.000000\n",
      "iteration 44400 / 120000: loss 0.000000\n",
      "iteration 44500 / 120000: loss 0.000000\n",
      "iteration 44600 / 120000: loss 0.000000\n",
      "iteration 44700 / 120000: loss 0.000000\n",
      "iteration 44800 / 120000: loss 0.000000\n",
      "iteration 44900 / 120000: loss 0.000000\n",
      "iteration 45000 / 120000: loss 0.000000\n",
      "iteration 45100 / 120000: loss 0.000000\n",
      "iteration 45200 / 120000: loss 0.000000\n",
      "iteration 45300 / 120000: loss 777.143004\n",
      "iteration 45400 / 120000: loss 0.000000\n",
      "iteration 45500 / 120000: loss 0.000000\n",
      "iteration 45600 / 120000: loss 0.000000\n",
      "iteration 45700 / 120000: loss 0.000000\n",
      "iteration 45800 / 120000: loss 0.000000\n",
      "iteration 45900 / 120000: loss 0.000000\n",
      "iteration 46000 / 120000: loss 0.000000\n",
      "iteration 46100 / 120000: loss 344.316523\n",
      "iteration 46200 / 120000: loss 0.000000\n",
      "iteration 46300 / 120000: loss 279.962420\n",
      "iteration 46400 / 120000: loss 0.000000\n",
      "iteration 46500 / 120000: loss 6.659950\n",
      "iteration 46600 / 120000: loss 0.000000\n",
      "iteration 46700 / 120000: loss 238.996143\n",
      "iteration 46800 / 120000: loss 0.000000\n",
      "iteration 46900 / 120000: loss 216.527419\n",
      "iteration 47000 / 120000: loss 394.495630\n",
      "iteration 47100 / 120000: loss 1634.592438\n",
      "iteration 47200 / 120000: loss 0.000000\n",
      "iteration 47300 / 120000: loss 0.000000\n",
      "iteration 47400 / 120000: loss 0.000000\n",
      "iteration 47500 / 120000: loss 0.000000\n",
      "iteration 47600 / 120000: loss 987.277670\n",
      "iteration 47700 / 120000: loss 158.673612\n",
      "iteration 47800 / 120000: loss 1521.062381\n",
      "iteration 47900 / 120000: loss 0.000000\n",
      "iteration 48000 / 120000: loss 0.000000\n",
      "iteration 48100 / 120000: loss 0.000000\n",
      "iteration 48200 / 120000: loss 0.000000\n",
      "iteration 48300 / 120000: loss 1511.562025\n",
      "iteration 48400 / 120000: loss 0.000000\n",
      "iteration 48500 / 120000: loss 0.000000\n",
      "iteration 48600 / 120000: loss 0.000000\n",
      "iteration 48700 / 120000: loss 1020.316585\n",
      "iteration 48800 / 120000: loss 0.000000\n",
      "iteration 48900 / 120000: loss 271.937624\n",
      "iteration 49000 / 120000: loss 0.000000\n",
      "iteration 49100 / 120000: loss 0.000000\n",
      "iteration 49200 / 120000: loss 0.000000\n",
      "iteration 49300 / 120000: loss 0.000000\n",
      "iteration 49400 / 120000: loss 681.634165\n",
      "iteration 49500 / 120000: loss 1700.799293\n",
      "iteration 49600 / 120000: loss 85.186231\n",
      "iteration 49700 / 120000: loss 326.778683\n",
      "iteration 49800 / 120000: loss 552.309879\n",
      "iteration 49900 / 120000: loss 208.319852\n",
      "iteration 50000 / 120000: loss 399.054211\n",
      "iteration 50100 / 120000: loss 262.218279\n",
      "iteration 50200 / 120000: loss 0.000000\n",
      "iteration 50300 / 120000: loss 0.000000\n",
      "iteration 50400 / 120000: loss 0.000000\n",
      "iteration 50500 / 120000: loss 0.000000\n",
      "iteration 50600 / 120000: loss 0.000000\n",
      "iteration 50700 / 120000: loss 1217.769051\n",
      "iteration 50800 / 120000: loss 11.596196\n",
      "iteration 50900 / 120000: loss 0.000000\n",
      "iteration 51000 / 120000: loss 82.808690\n",
      "iteration 51100 / 120000: loss 0.000000\n",
      "iteration 51200 / 120000: loss 0.000000\n",
      "iteration 51300 / 120000: loss 0.000000\n",
      "iteration 51400 / 120000: loss 0.000000\n",
      "iteration 51500 / 120000: loss 0.000000\n",
      "iteration 51600 / 120000: loss 246.795758\n",
      "iteration 51700 / 120000: loss 0.000000\n",
      "iteration 51800 / 120000: loss 307.079810\n",
      "iteration 51900 / 120000: loss 338.497194\n",
      "iteration 52000 / 120000: loss 0.000000\n",
      "iteration 52100 / 120000: loss 0.000000\n",
      "iteration 52200 / 120000: loss 0.000000\n",
      "iteration 52300 / 120000: loss 0.000000\n",
      "iteration 52400 / 120000: loss 0.000000\n",
      "iteration 52500 / 120000: loss 0.000000\n",
      "iteration 52600 / 120000: loss 0.000000\n",
      "iteration 52700 / 120000: loss 358.082764\n",
      "iteration 52800 / 120000: loss 0.000000\n",
      "iteration 52900 / 120000: loss 0.000000\n",
      "iteration 53000 / 120000: loss 0.000000\n",
      "iteration 53100 / 120000: loss 966.109200\n",
      "iteration 53200 / 120000: loss 1038.639935\n",
      "iteration 53300 / 120000: loss 0.000000\n",
      "iteration 53400 / 120000: loss 0.000000\n",
      "iteration 53500 / 120000: loss 567.641482\n",
      "iteration 53600 / 120000: loss 147.005350\n",
      "iteration 53700 / 120000: loss 2308.293663\n",
      "iteration 53800 / 120000: loss 0.000000\n",
      "iteration 53900 / 120000: loss 0.000000\n",
      "iteration 54000 / 120000: loss 0.000000\n",
      "iteration 54100 / 120000: loss 0.000000\n",
      "iteration 54200 / 120000: loss 1244.971787\n",
      "iteration 54300 / 120000: loss 563.448459\n",
      "iteration 54400 / 120000: loss 0.000000\n",
      "iteration 54500 / 120000: loss 0.000000\n",
      "iteration 54600 / 120000: loss 0.000000\n",
      "iteration 54700 / 120000: loss 0.000000\n",
      "iteration 54800 / 120000: loss 906.552529\n",
      "iteration 54900 / 120000: loss 492.384595\n",
      "iteration 55000 / 120000: loss 2106.403885\n",
      "iteration 55100 / 120000: loss 0.000000\n",
      "iteration 55200 / 120000: loss 0.000000\n",
      "iteration 55300 / 120000: loss 0.000000\n",
      "iteration 55400 / 120000: loss 0.000000\n",
      "iteration 55500 / 120000: loss 0.000000\n",
      "iteration 55600 / 120000: loss 1557.822647\n",
      "iteration 55700 / 120000: loss 0.000000\n",
      "iteration 55800 / 120000: loss 0.000000\n",
      "iteration 55900 / 120000: loss 0.000000\n",
      "iteration 56000 / 120000: loss 0.000000\n",
      "iteration 56100 / 120000: loss 710.232467\n",
      "iteration 56200 / 120000: loss 0.000000\n",
      "iteration 56300 / 120000: loss 0.000000\n",
      "iteration 56400 / 120000: loss 0.000000\n",
      "iteration 56500 / 120000: loss 882.413642\n",
      "iteration 56600 / 120000: loss 0.000000\n",
      "iteration 56700 / 120000: loss 0.000000\n",
      "iteration 56800 / 120000: loss 0.000000\n",
      "iteration 56900 / 120000: loss 705.960697\n",
      "iteration 57000 / 120000: loss 0.000000\n",
      "iteration 57100 / 120000: loss 1424.710314\n",
      "iteration 57200 / 120000: loss 1150.119356\n",
      "iteration 57300 / 120000: loss 0.000000\n",
      "iteration 57400 / 120000: loss 500.575334\n",
      "iteration 57500 / 120000: loss 2500.195832\n",
      "iteration 57600 / 120000: loss 0.000000\n",
      "iteration 57700 / 120000: loss 0.000000\n",
      "iteration 57800 / 120000: loss 0.000000\n",
      "iteration 57900 / 120000: loss 0.000000\n",
      "iteration 58000 / 120000: loss 0.000000\n",
      "iteration 58100 / 120000: loss 0.000000\n",
      "iteration 58200 / 120000: loss 0.000000\n",
      "iteration 58300 / 120000: loss 0.000000\n",
      "iteration 58400 / 120000: loss 0.000000\n",
      "iteration 58500 / 120000: loss 0.000000\n",
      "iteration 58600 / 120000: loss 291.970753\n",
      "iteration 58700 / 120000: loss 2173.639472\n",
      "iteration 58800 / 120000: loss 0.000000\n",
      "iteration 58900 / 120000: loss 0.000000\n",
      "iteration 59000 / 120000: loss 0.000000\n",
      "iteration 59100 / 120000: loss 0.000000\n",
      "iteration 59200 / 120000: loss 0.000000\n",
      "iteration 59300 / 120000: loss 2547.393699\n",
      "iteration 59400 / 120000: loss 0.000000\n",
      "iteration 59500 / 120000: loss 685.618634\n",
      "iteration 59600 / 120000: loss 0.000000\n",
      "iteration 59700 / 120000: loss 0.000000\n",
      "iteration 59800 / 120000: loss 0.000000\n",
      "iteration 59900 / 120000: loss 945.535006\n",
      "iteration 60000 / 120000: loss 0.000000\n",
      "iteration 60100 / 120000: loss 0.000000\n",
      "iteration 60200 / 120000: loss 275.511014\n",
      "iteration 60300 / 120000: loss 0.000000\n",
      "iteration 60400 / 120000: loss 0.000000\n",
      "iteration 60500 / 120000: loss 0.000000\n",
      "iteration 60600 / 120000: loss 127.973459\n",
      "iteration 60700 / 120000: loss 0.000000\n",
      "iteration 60800 / 120000: loss 0.000000\n",
      "iteration 60900 / 120000: loss 0.000000\n",
      "iteration 61000 / 120000: loss 325.654396\n",
      "iteration 61100 / 120000: loss 0.000000\n",
      "iteration 61200 / 120000: loss 0.000000\n",
      "iteration 61300 / 120000: loss 492.952306\n",
      "iteration 61400 / 120000: loss 0.000000\n",
      "iteration 61500 / 120000: loss 808.429474\n",
      "iteration 61600 / 120000: loss 173.996861\n",
      "iteration 61700 / 120000: loss 0.000000\n",
      "iteration 61800 / 120000: loss 0.000000\n",
      "iteration 61900 / 120000: loss 0.000000\n",
      "iteration 62000 / 120000: loss 0.000000\n",
      "iteration 62100 / 120000: loss 919.085416\n",
      "iteration 62200 / 120000: loss 0.000000\n",
      "iteration 62300 / 120000: loss 0.000000\n",
      "iteration 62400 / 120000: loss 0.000000\n",
      "iteration 62500 / 120000: loss 0.000000\n",
      "iteration 62600 / 120000: loss 7.637982\n",
      "iteration 62700 / 120000: loss 0.000000\n",
      "iteration 62800 / 120000: loss 0.000000\n",
      "iteration 62900 / 120000: loss 35.029268\n",
      "iteration 63000 / 120000: loss 1813.229416\n",
      "iteration 63100 / 120000: loss 43.555638\n",
      "iteration 63200 / 120000: loss 435.665659\n",
      "iteration 63300 / 120000: loss 0.000000\n",
      "iteration 63400 / 120000: loss 0.000000\n",
      "iteration 63500 / 120000: loss 0.000000\n",
      "iteration 63600 / 120000: loss 0.000000\n",
      "iteration 63700 / 120000: loss 226.522014\n",
      "iteration 63800 / 120000: loss 0.000000\n",
      "iteration 63900 / 120000: loss 0.000000\n",
      "iteration 64000 / 120000: loss 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 64100 / 120000: loss 0.000000\n",
      "iteration 64200 / 120000: loss 0.000000\n",
      "iteration 64300 / 120000: loss 456.742529\n",
      "iteration 64400 / 120000: loss 31.261694\n",
      "iteration 64500 / 120000: loss 562.271317\n",
      "iteration 64600 / 120000: loss 0.000000\n",
      "iteration 64700 / 120000: loss 458.093639\n",
      "iteration 64800 / 120000: loss 553.988699\n",
      "iteration 64900 / 120000: loss 0.000000\n",
      "iteration 65000 / 120000: loss 0.000000\n",
      "iteration 65100 / 120000: loss 0.000000\n",
      "iteration 65200 / 120000: loss 0.000000\n",
      "iteration 65300 / 120000: loss 906.012150\n",
      "iteration 65400 / 120000: loss 0.000000\n",
      "iteration 65500 / 120000: loss 0.000000\n",
      "iteration 65600 / 120000: loss 101.198879\n",
      "iteration 65700 / 120000: loss 0.000000\n",
      "iteration 65800 / 120000: loss 0.000000\n",
      "iteration 65900 / 120000: loss 83.332784\n",
      "iteration 66000 / 120000: loss 840.770045\n",
      "iteration 66100 / 120000: loss 0.000000\n",
      "iteration 66200 / 120000: loss 0.000000\n",
      "iteration 66300 / 120000: loss 0.000000\n",
      "iteration 66400 / 120000: loss 34.767832\n",
      "iteration 66500 / 120000: loss 1786.156314\n",
      "iteration 66600 / 120000: loss 0.000000\n",
      "iteration 66700 / 120000: loss 1051.453726\n",
      "iteration 66800 / 120000: loss 0.000000\n",
      "iteration 66900 / 120000: loss 0.000000\n",
      "iteration 67000 / 120000: loss 0.000000\n",
      "iteration 67100 / 120000: loss 0.000000\n",
      "iteration 67200 / 120000: loss 0.000000\n",
      "iteration 67300 / 120000: loss 0.000000\n",
      "iteration 67400 / 120000: loss 0.000000\n",
      "iteration 67500 / 120000: loss 0.000000\n",
      "iteration 67600 / 120000: loss 486.314840\n",
      "iteration 67700 / 120000: loss 0.000000\n",
      "iteration 67800 / 120000: loss 0.000000\n",
      "iteration 67900 / 120000: loss 0.000000\n",
      "iteration 68000 / 120000: loss 0.000000\n",
      "iteration 68100 / 120000: loss 0.000000\n",
      "iteration 68200 / 120000: loss 117.223079\n",
      "iteration 68300 / 120000: loss 0.000000\n",
      "iteration 68400 / 120000: loss 13.529234\n",
      "iteration 68500 / 120000: loss 1401.925809\n",
      "iteration 68600 / 120000: loss 0.000000\n",
      "iteration 68700 / 120000: loss 0.000000\n",
      "iteration 68800 / 120000: loss 462.031338\n",
      "iteration 68900 / 120000: loss 0.000000\n",
      "iteration 69000 / 120000: loss 81.441259\n",
      "iteration 69100 / 120000: loss 177.257568\n",
      "iteration 69200 / 120000: loss 0.000000\n",
      "iteration 69300 / 120000: loss 0.000000\n",
      "iteration 69400 / 120000: loss 479.142733\n",
      "iteration 69500 / 120000: loss 0.000000\n",
      "iteration 69600 / 120000: loss 0.000000\n",
      "iteration 69700 / 120000: loss 799.087782\n",
      "iteration 69800 / 120000: loss 0.000000\n",
      "iteration 69900 / 120000: loss 0.000000\n",
      "iteration 70000 / 120000: loss 0.000000\n",
      "iteration 70100 / 120000: loss 0.000000\n",
      "iteration 70200 / 120000: loss 0.000000\n",
      "iteration 70300 / 120000: loss 671.942802\n",
      "iteration 70400 / 120000: loss 0.000000\n",
      "iteration 70500 / 120000: loss 251.833106\n",
      "iteration 70600 / 120000: loss 0.000000\n",
      "iteration 70700 / 120000: loss 0.000000\n",
      "iteration 70800 / 120000: loss 608.321647\n",
      "iteration 70900 / 120000: loss 0.000000\n",
      "iteration 71000 / 120000: loss 574.964780\n",
      "iteration 71100 / 120000: loss 0.000000\n",
      "iteration 71200 / 120000: loss 0.000000\n",
      "iteration 71300 / 120000: loss 0.000000\n",
      "iteration 71400 / 120000: loss 0.000000\n",
      "iteration 71500 / 120000: loss 0.000000\n",
      "iteration 71600 / 120000: loss 171.440652\n",
      "iteration 71700 / 120000: loss 0.000000\n",
      "iteration 71800 / 120000: loss 0.000000\n",
      "iteration 71900 / 120000: loss 0.000000\n",
      "iteration 72000 / 120000: loss 675.301418\n",
      "iteration 72100 / 120000: loss 0.000000\n",
      "iteration 72200 / 120000: loss 60.117776\n",
      "iteration 72300 / 120000: loss 0.000000\n",
      "iteration 72400 / 120000: loss 0.000000\n",
      "iteration 72500 / 120000: loss 0.000000\n",
      "iteration 72600 / 120000: loss 0.000000\n",
      "iteration 72700 / 120000: loss 0.000000\n",
      "iteration 72800 / 120000: loss 0.000000\n",
      "iteration 72900 / 120000: loss 0.000000\n",
      "iteration 73000 / 120000: loss 0.000000\n",
      "iteration 73100 / 120000: loss 624.947579\n",
      "iteration 73200 / 120000: loss 0.000000\n",
      "iteration 73300 / 120000: loss 821.015493\n",
      "iteration 73400 / 120000: loss 0.000000\n",
      "iteration 73500 / 120000: loss 0.000000\n",
      "iteration 73600 / 120000: loss 1465.271213\n",
      "iteration 73700 / 120000: loss 0.000000\n",
      "iteration 73800 / 120000: loss 0.000000\n",
      "iteration 73900 / 120000: loss 0.000000\n",
      "iteration 74000 / 120000: loss 0.000000\n",
      "iteration 74100 / 120000: loss 0.000000\n",
      "iteration 74200 / 120000: loss 949.690959\n",
      "iteration 74300 / 120000: loss 0.000000\n",
      "iteration 74400 / 120000: loss 80.871686\n",
      "iteration 74500 / 120000: loss 526.518783\n",
      "iteration 74600 / 120000: loss 104.059923\n",
      "iteration 74700 / 120000: loss 0.000000\n",
      "iteration 74800 / 120000: loss 237.504430\n",
      "iteration 74900 / 120000: loss 0.000000\n",
      "iteration 75000 / 120000: loss 0.000000\n",
      "iteration 75100 / 120000: loss 0.000000\n",
      "iteration 75200 / 120000: loss 0.000000\n",
      "iteration 75300 / 120000: loss 0.000000\n",
      "iteration 75400 / 120000: loss 0.000000\n",
      "iteration 75500 / 120000: loss 249.668360\n",
      "iteration 75600 / 120000: loss 676.361917\n",
      "iteration 75700 / 120000: loss 0.000000\n",
      "iteration 75800 / 120000: loss 0.000000\n",
      "iteration 75900 / 120000: loss 1142.088339\n",
      "iteration 76000 / 120000: loss 0.000000\n",
      "iteration 76100 / 120000: loss 0.000000\n",
      "iteration 76200 / 120000: loss 0.000000\n",
      "iteration 76300 / 120000: loss 0.000000\n",
      "iteration 76400 / 120000: loss 0.000000\n",
      "iteration 76500 / 120000: loss 0.000000\n",
      "iteration 76600 / 120000: loss 0.000000\n",
      "iteration 76700 / 120000: loss 0.000000\n",
      "iteration 76800 / 120000: loss 0.000000\n",
      "iteration 76900 / 120000: loss 0.000000\n",
      "iteration 77000 / 120000: loss 0.000000\n",
      "iteration 77100 / 120000: loss 0.000000\n",
      "iteration 77200 / 120000: loss 0.000000\n",
      "iteration 77300 / 120000: loss 0.000000\n",
      "iteration 77400 / 120000: loss 462.560273\n",
      "iteration 77500 / 120000: loss 0.000000\n",
      "iteration 77600 / 120000: loss 0.000000\n",
      "iteration 77700 / 120000: loss 0.000000\n",
      "iteration 77800 / 120000: loss 0.000000\n",
      "iteration 77900 / 120000: loss 0.000000\n",
      "iteration 78000 / 120000: loss 0.000000\n",
      "iteration 78100 / 120000: loss 0.000000\n",
      "iteration 78200 / 120000: loss 0.000000\n",
      "iteration 78300 / 120000: loss 331.775540\n",
      "iteration 78400 / 120000: loss 490.934077\n",
      "iteration 78500 / 120000: loss 341.273218\n",
      "iteration 78600 / 120000: loss 1155.965564\n",
      "iteration 78700 / 120000: loss 0.000000\n",
      "iteration 78800 / 120000: loss 0.000000\n",
      "iteration 78900 / 120000: loss 80.346911\n",
      "iteration 79000 / 120000: loss 0.000000\n",
      "iteration 79100 / 120000: loss 684.986532\n",
      "iteration 79200 / 120000: loss 221.299373\n",
      "iteration 79300 / 120000: loss 0.000000\n",
      "iteration 79400 / 120000: loss 0.000000\n",
      "iteration 79500 / 120000: loss 0.000000\n",
      "iteration 79600 / 120000: loss 0.000000\n",
      "iteration 79700 / 120000: loss 0.000000\n",
      "iteration 79800 / 120000: loss 933.743686\n",
      "iteration 79900 / 120000: loss 1217.086963\n",
      "iteration 80000 / 120000: loss 0.000000\n",
      "iteration 80100 / 120000: loss 742.529502\n",
      "iteration 80200 / 120000: loss 225.398791\n",
      "iteration 80300 / 120000: loss 0.000000\n",
      "iteration 80400 / 120000: loss 632.786416\n",
      "iteration 80500 / 120000: loss 0.000000\n",
      "iteration 80600 / 120000: loss 294.416344\n",
      "iteration 80700 / 120000: loss 0.000000\n",
      "iteration 80800 / 120000: loss 0.000000\n",
      "iteration 80900 / 120000: loss 0.000000\n",
      "iteration 81000 / 120000: loss 0.000000\n",
      "iteration 81100 / 120000: loss 1421.872900\n",
      "iteration 81200 / 120000: loss 0.000000\n",
      "iteration 81300 / 120000: loss 0.000000\n",
      "iteration 81400 / 120000: loss 185.357681\n",
      "iteration 81500 / 120000: loss 0.000000\n",
      "iteration 81600 / 120000: loss 0.000000\n",
      "iteration 81700 / 120000: loss 0.000000\n",
      "iteration 81800 / 120000: loss 0.000000\n",
      "iteration 81900 / 120000: loss 0.000000\n",
      "iteration 82000 / 120000: loss 348.937607\n",
      "iteration 82100 / 120000: loss 570.277133\n",
      "iteration 82200 / 120000: loss 0.000000\n",
      "iteration 82300 / 120000: loss 0.000000\n",
      "iteration 82400 / 120000: loss 0.000000\n",
      "iteration 82500 / 120000: loss 1373.215606\n",
      "iteration 82600 / 120000: loss 0.000000\n",
      "iteration 82700 / 120000: loss 242.840333\n",
      "iteration 82800 / 120000: loss 1313.352279\n",
      "iteration 82900 / 120000: loss 0.000000\n",
      "iteration 83000 / 120000: loss 607.397872\n",
      "iteration 83100 / 120000: loss 0.000000\n",
      "iteration 83200 / 120000: loss 889.497928\n",
      "iteration 83300 / 120000: loss 0.000000\n",
      "iteration 83400 / 120000: loss 475.322068\n",
      "iteration 83500 / 120000: loss 0.000000\n",
      "iteration 83600 / 120000: loss 936.427374\n",
      "iteration 83700 / 120000: loss 0.000000\n",
      "iteration 83800 / 120000: loss 0.000000\n",
      "iteration 83900 / 120000: loss 0.000000\n",
      "iteration 84000 / 120000: loss 111.328067\n",
      "iteration 84100 / 120000: loss 0.000000\n",
      "iteration 84200 / 120000: loss 0.000000\n",
      "iteration 84300 / 120000: loss 0.000000\n",
      "iteration 84400 / 120000: loss 1957.914933\n",
      "iteration 84500 / 120000: loss 0.000000\n",
      "iteration 84600 / 120000: loss 0.000000\n",
      "iteration 84700 / 120000: loss 548.536937\n",
      "iteration 84800 / 120000: loss 900.501858\n",
      "iteration 84900 / 120000: loss 23.857929\n",
      "iteration 85000 / 120000: loss 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 85100 / 120000: loss 0.000000\n",
      "iteration 85200 / 120000: loss 676.140094\n",
      "iteration 85300 / 120000: loss 0.000000\n",
      "iteration 85400 / 120000: loss 447.338455\n",
      "iteration 85500 / 120000: loss 384.573266\n",
      "iteration 85600 / 120000: loss 0.000000\n",
      "iteration 85700 / 120000: loss 0.000000\n",
      "iteration 85800 / 120000: loss 461.877467\n",
      "iteration 85900 / 120000: loss 0.000000\n",
      "iteration 86000 / 120000: loss 0.000000\n",
      "iteration 86100 / 120000: loss 449.822149\n",
      "iteration 86200 / 120000: loss 0.000000\n",
      "iteration 86300 / 120000: loss 0.000000\n",
      "iteration 86400 / 120000: loss 837.110438\n",
      "iteration 86500 / 120000: loss 0.000000\n",
      "iteration 86600 / 120000: loss 277.506196\n",
      "iteration 86700 / 120000: loss 0.000000\n",
      "iteration 86800 / 120000: loss 313.477635\n",
      "iteration 86900 / 120000: loss 142.352021\n",
      "iteration 87000 / 120000: loss 100.580975\n",
      "iteration 87100 / 120000: loss 0.000000\n",
      "iteration 87200 / 120000: loss 0.000000\n",
      "iteration 87300 / 120000: loss 0.000000\n",
      "iteration 87400 / 120000: loss 0.000000\n",
      "iteration 87500 / 120000: loss 0.000000\n",
      "iteration 87600 / 120000: loss 364.668517\n",
      "iteration 87700 / 120000: loss 0.000000\n",
      "iteration 87800 / 120000: loss 0.000000\n",
      "iteration 87900 / 120000: loss 0.000000\n",
      "iteration 88000 / 120000: loss 185.687770\n",
      "iteration 88100 / 120000: loss 0.000000\n",
      "iteration 88200 / 120000: loss 0.000000\n",
      "iteration 88300 / 120000: loss 639.662804\n",
      "iteration 88400 / 120000: loss 0.000000\n",
      "iteration 88500 / 120000: loss 0.000000\n",
      "iteration 88600 / 120000: loss 0.000000\n",
      "iteration 88700 / 120000: loss 0.000000\n",
      "iteration 88800 / 120000: loss 0.000000\n",
      "iteration 88900 / 120000: loss 1929.590174\n",
      "iteration 89000 / 120000: loss 1525.581121\n",
      "iteration 89100 / 120000: loss 0.000000\n",
      "iteration 89200 / 120000: loss 0.000000\n",
      "iteration 89300 / 120000: loss 0.000000\n",
      "iteration 89400 / 120000: loss 906.442525\n",
      "iteration 89500 / 120000: loss 0.000000\n",
      "iteration 89600 / 120000: loss 26.924560\n",
      "iteration 89700 / 120000: loss 0.000000\n",
      "iteration 89800 / 120000: loss 76.975711\n",
      "iteration 89900 / 120000: loss 0.000000\n",
      "iteration 90000 / 120000: loss 0.000000\n",
      "iteration 90100 / 120000: loss 0.000000\n",
      "iteration 90200 / 120000: loss 1434.491565\n",
      "iteration 90300 / 120000: loss 97.780334\n",
      "iteration 90400 / 120000: loss 0.000000\n",
      "iteration 90500 / 120000: loss 578.490982\n",
      "iteration 90600 / 120000: loss 707.884385\n",
      "iteration 90700 / 120000: loss 0.000000\n",
      "iteration 90800 / 120000: loss 0.000000\n",
      "iteration 90900 / 120000: loss 0.000000\n",
      "iteration 91000 / 120000: loss 245.095635\n",
      "iteration 91100 / 120000: loss 0.000000\n",
      "iteration 91200 / 120000: loss 0.000000\n",
      "iteration 91300 / 120000: loss 0.000000\n",
      "iteration 91400 / 120000: loss 0.000000\n",
      "iteration 91500 / 120000: loss 0.000000\n",
      "iteration 91600 / 120000: loss 0.000000\n",
      "iteration 91700 / 120000: loss 0.000000\n",
      "iteration 91800 / 120000: loss 0.000000\n",
      "iteration 91900 / 120000: loss 0.000000\n",
      "iteration 92000 / 120000: loss 260.235581\n",
      "iteration 92100 / 120000: loss 0.000000\n",
      "iteration 92200 / 120000: loss 0.000000\n",
      "iteration 92300 / 120000: loss 0.000000\n",
      "iteration 92400 / 120000: loss 467.102070\n",
      "iteration 92500 / 120000: loss 0.000000\n",
      "iteration 92600 / 120000: loss 25.234955\n",
      "iteration 92700 / 120000: loss 46.834824\n",
      "iteration 92800 / 120000: loss 0.000000\n",
      "iteration 92900 / 120000: loss 0.000000\n",
      "iteration 93000 / 120000: loss 0.000000\n",
      "iteration 93100 / 120000: loss 0.000000\n",
      "iteration 93200 / 120000: loss 395.854434\n",
      "iteration 93300 / 120000: loss 0.000000\n",
      "iteration 93400 / 120000: loss 1270.068755\n",
      "iteration 93500 / 120000: loss 298.042216\n",
      "iteration 93600 / 120000: loss 0.000000\n",
      "iteration 93700 / 120000: loss 234.573729\n",
      "iteration 93800 / 120000: loss 0.000000\n",
      "iteration 93900 / 120000: loss 866.368885\n",
      "iteration 94000 / 120000: loss 825.682326\n",
      "iteration 94100 / 120000: loss 0.000000\n",
      "iteration 94200 / 120000: loss 211.540757\n",
      "iteration 94300 / 120000: loss 0.000000\n",
      "iteration 94400 / 120000: loss 0.000000\n",
      "iteration 94500 / 120000: loss 0.000000\n",
      "iteration 94600 / 120000: loss 0.000000\n",
      "iteration 94700 / 120000: loss 1404.265341\n",
      "iteration 94800 / 120000: loss 1150.209718\n",
      "iteration 94900 / 120000: loss 340.433834\n",
      "iteration 95000 / 120000: loss 0.000000\n",
      "iteration 95100 / 120000: loss 0.000000\n",
      "iteration 95200 / 120000: loss 0.000000\n",
      "iteration 95300 / 120000: loss 0.000000\n",
      "iteration 95400 / 120000: loss 0.000000\n",
      "iteration 95500 / 120000: loss 0.000000\n",
      "iteration 95600 / 120000: loss 639.189706\n",
      "iteration 95700 / 120000: loss 0.000000\n",
      "iteration 95800 / 120000: loss 0.000000\n",
      "iteration 95900 / 120000: loss 8.164837\n",
      "iteration 96000 / 120000: loss 0.000000\n",
      "iteration 96100 / 120000: loss 0.000000\n",
      "iteration 96200 / 120000: loss 0.000000\n",
      "iteration 96300 / 120000: loss 228.300478\n",
      "iteration 96400 / 120000: loss 0.000000\n",
      "iteration 96500 / 120000: loss 0.000000\n",
      "iteration 96600 / 120000: loss 0.000000\n",
      "iteration 96700 / 120000: loss 0.000000\n",
      "iteration 96800 / 120000: loss 627.055422\n",
      "iteration 96900 / 120000: loss 0.000000\n",
      "iteration 97000 / 120000: loss 242.700264\n",
      "iteration 97100 / 120000: loss 0.000000\n",
      "iteration 97200 / 120000: loss 0.000000\n",
      "iteration 97300 / 120000: loss 0.000000\n",
      "iteration 97400 / 120000: loss 0.000000\n",
      "iteration 97500 / 120000: loss 698.436985\n",
      "iteration 97600 / 120000: loss 0.000000\n",
      "iteration 97700 / 120000: loss 247.312300\n",
      "iteration 97800 / 120000: loss 0.000000\n",
      "iteration 97900 / 120000: loss 440.595999\n",
      "iteration 98000 / 120000: loss 0.000000\n",
      "iteration 98100 / 120000: loss 376.252533\n",
      "iteration 98200 / 120000: loss 0.000000\n",
      "iteration 98300 / 120000: loss 12.899115\n",
      "iteration 98400 / 120000: loss 0.000000\n",
      "iteration 98500 / 120000: loss 0.000000\n",
      "iteration 98600 / 120000: loss 0.000000\n",
      "iteration 98700 / 120000: loss 0.000000\n",
      "iteration 98800 / 120000: loss 0.000000\n",
      "iteration 98900 / 120000: loss 0.000000\n",
      "iteration 99000 / 120000: loss 289.327297\n",
      "iteration 99100 / 120000: loss 345.457293\n",
      "iteration 99200 / 120000: loss 0.000000\n",
      "iteration 99300 / 120000: loss 0.000000\n",
      "iteration 99400 / 120000: loss 0.000000\n",
      "iteration 99500 / 120000: loss 0.000000\n",
      "iteration 99600 / 120000: loss 177.106043\n",
      "iteration 99700 / 120000: loss 406.756236\n",
      "iteration 99800 / 120000: loss 0.000000\n",
      "iteration 99900 / 120000: loss 0.000000\n",
      "iteration 100000 / 120000: loss 0.000000\n",
      "iteration 100100 / 120000: loss 267.999203\n",
      "iteration 100200 / 120000: loss 1189.011665\n",
      "iteration 100300 / 120000: loss 626.636100\n",
      "iteration 100400 / 120000: loss 0.000000\n",
      "iteration 100500 / 120000: loss 0.000000\n",
      "iteration 100600 / 120000: loss 144.034033\n",
      "iteration 100700 / 120000: loss 0.000000\n",
      "iteration 100800 / 120000: loss 0.000000\n",
      "iteration 100900 / 120000: loss 0.000000\n",
      "iteration 101000 / 120000: loss 0.000000\n",
      "iteration 101100 / 120000: loss 0.000000\n",
      "iteration 101200 / 120000: loss 0.000000\n",
      "iteration 101300 / 120000: loss 0.000000\n",
      "iteration 101400 / 120000: loss 0.000000\n",
      "iteration 101500 / 120000: loss 762.788018\n",
      "iteration 101600 / 120000: loss 0.000000\n",
      "iteration 101700 / 120000: loss 0.000000\n",
      "iteration 101800 / 120000: loss 0.000000\n",
      "iteration 101900 / 120000: loss 0.000000\n",
      "iteration 102000 / 120000: loss 0.000000\n",
      "iteration 102100 / 120000: loss 0.000000\n",
      "iteration 102200 / 120000: loss 0.000000\n",
      "iteration 102300 / 120000: loss 0.000000\n",
      "iteration 102400 / 120000: loss 1032.743837\n",
      "iteration 102500 / 120000: loss 0.000000\n",
      "iteration 102600 / 120000: loss 0.000000\n",
      "iteration 102700 / 120000: loss 200.045869\n",
      "iteration 102800 / 120000: loss 0.000000\n",
      "iteration 102900 / 120000: loss 0.000000\n",
      "iteration 103000 / 120000: loss 0.000000\n",
      "iteration 103100 / 120000: loss 0.000000\n",
      "iteration 103200 / 120000: loss 0.000000\n",
      "iteration 103300 / 120000: loss 0.000000\n",
      "iteration 103400 / 120000: loss 423.069340\n",
      "iteration 103500 / 120000: loss 0.000000\n",
      "iteration 103600 / 120000: loss 0.000000\n",
      "iteration 103700 / 120000: loss 761.431330\n",
      "iteration 103800 / 120000: loss 0.000000\n",
      "iteration 103900 / 120000: loss 0.000000\n",
      "iteration 104000 / 120000: loss 0.000000\n",
      "iteration 104100 / 120000: loss 382.791972\n",
      "iteration 104200 / 120000: loss 0.000000\n",
      "iteration 104300 / 120000: loss 0.000000\n",
      "iteration 104400 / 120000: loss 0.000000\n",
      "iteration 104500 / 120000: loss 0.000000\n",
      "iteration 104600 / 120000: loss 0.000000\n",
      "iteration 104700 / 120000: loss 0.000000\n",
      "iteration 104800 / 120000: loss 0.000000\n",
      "iteration 104900 / 120000: loss 0.000000\n",
      "iteration 105000 / 120000: loss 392.001283\n",
      "iteration 105100 / 120000: loss 1154.849314\n",
      "iteration 105200 / 120000: loss 0.000000\n",
      "iteration 105300 / 120000: loss 0.000000\n",
      "iteration 105400 / 120000: loss 0.000000\n",
      "iteration 105500 / 120000: loss 0.000000\n",
      "iteration 105600 / 120000: loss 0.000000\n",
      "iteration 105700 / 120000: loss 0.000000\n",
      "iteration 105800 / 120000: loss 2225.345893\n",
      "iteration 105900 / 120000: loss 0.000000\n",
      "iteration 106000 / 120000: loss 0.000000\n",
      "iteration 106100 / 120000: loss 0.000000\n",
      "iteration 106200 / 120000: loss 946.063817\n",
      "iteration 106300 / 120000: loss 0.000000\n",
      "iteration 106400 / 120000: loss 0.000000\n",
      "iteration 106500 / 120000: loss 0.000000\n",
      "iteration 106600 / 120000: loss 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 106700 / 120000: loss 0.000000\n",
      "iteration 106800 / 120000: loss 0.000000\n",
      "iteration 106900 / 120000: loss 0.000000\n",
      "iteration 107000 / 120000: loss 0.000000\n",
      "iteration 107100 / 120000: loss 1593.077640\n",
      "iteration 107200 / 120000: loss 0.000000\n",
      "iteration 107300 / 120000: loss 0.000000\n",
      "iteration 107400 / 120000: loss 0.000000\n",
      "iteration 107500 / 120000: loss 630.415869\n",
      "iteration 107600 / 120000: loss 0.000000\n",
      "iteration 107700 / 120000: loss 0.000000\n",
      "iteration 107800 / 120000: loss 461.766364\n",
      "iteration 107900 / 120000: loss 0.000000\n",
      "iteration 108000 / 120000: loss 0.000000\n",
      "iteration 108100 / 120000: loss 0.000000\n",
      "iteration 108200 / 120000: loss 592.187707\n",
      "iteration 108300 / 120000: loss 0.000000\n",
      "iteration 108400 / 120000: loss 0.000000\n",
      "iteration 108500 / 120000: loss 0.000000\n",
      "iteration 108600 / 120000: loss 0.000000\n",
      "iteration 108700 / 120000: loss 0.000000\n",
      "iteration 108800 / 120000: loss 0.000000\n",
      "iteration 108900 / 120000: loss 0.000000\n",
      "iteration 109000 / 120000: loss 200.040984\n",
      "iteration 109100 / 120000: loss 0.000000\n",
      "iteration 109200 / 120000: loss 0.000000\n",
      "iteration 109300 / 120000: loss 0.000000\n",
      "iteration 109400 / 120000: loss 746.216044\n",
      "iteration 109500 / 120000: loss 701.945648\n",
      "iteration 109600 / 120000: loss 0.000000\n",
      "iteration 109700 / 120000: loss 0.000000\n",
      "iteration 109800 / 120000: loss 0.000000\n",
      "iteration 109900 / 120000: loss 487.830561\n",
      "iteration 110000 / 120000: loss 0.000000\n",
      "iteration 110100 / 120000: loss 2449.362878\n",
      "iteration 110200 / 120000: loss 0.000000\n",
      "iteration 110300 / 120000: loss 0.000000\n",
      "iteration 110400 / 120000: loss 0.000000\n",
      "iteration 110500 / 120000: loss 0.000000\n",
      "iteration 110600 / 120000: loss 0.000000\n",
      "iteration 110700 / 120000: loss 0.000000\n",
      "iteration 110800 / 120000: loss 0.000000\n",
      "iteration 110900 / 120000: loss 0.000000\n",
      "iteration 111000 / 120000: loss 0.000000\n",
      "iteration 111100 / 120000: loss 22.232350\n",
      "iteration 111200 / 120000: loss 0.000000\n",
      "iteration 111300 / 120000: loss 0.000000\n",
      "iteration 111400 / 120000: loss 863.235697\n",
      "iteration 111500 / 120000: loss 0.000000\n",
      "iteration 111600 / 120000: loss 1056.196976\n",
      "iteration 111700 / 120000: loss 0.000000\n",
      "iteration 111800 / 120000: loss 0.000000\n",
      "iteration 111900 / 120000: loss 0.000000\n",
      "iteration 112000 / 120000: loss 0.000000\n",
      "iteration 112100 / 120000: loss 0.000000\n",
      "iteration 112200 / 120000: loss 0.000000\n",
      "iteration 112300 / 120000: loss 0.000000\n",
      "iteration 112400 / 120000: loss 0.000000\n",
      "iteration 112500 / 120000: loss 0.000000\n",
      "iteration 112600 / 120000: loss 196.935551\n",
      "iteration 112700 / 120000: loss 0.000000\n",
      "iteration 112800 / 120000: loss 0.000000\n",
      "iteration 112900 / 120000: loss 0.000000\n",
      "iteration 113000 / 120000: loss 0.000000\n",
      "iteration 113100 / 120000: loss 0.000000\n",
      "iteration 113200 / 120000: loss 0.000000\n",
      "iteration 113300 / 120000: loss 0.000000\n",
      "iteration 113400 / 120000: loss 143.509385\n",
      "iteration 113500 / 120000: loss 0.000000\n",
      "iteration 113600 / 120000: loss 0.000000\n",
      "iteration 113700 / 120000: loss 0.000000\n",
      "iteration 113800 / 120000: loss 0.000000\n",
      "iteration 113900 / 120000: loss 0.000000\n",
      "iteration 114000 / 120000: loss 0.000000\n",
      "iteration 114100 / 120000: loss 352.470670\n",
      "iteration 114200 / 120000: loss 0.000000\n",
      "iteration 114300 / 120000: loss 0.000000\n",
      "iteration 114400 / 120000: loss 0.000000\n",
      "iteration 114500 / 120000: loss 0.000000\n",
      "iteration 114600 / 120000: loss 672.349381\n",
      "iteration 114700 / 120000: loss 0.000000\n",
      "iteration 114800 / 120000: loss 0.000000\n",
      "iteration 114900 / 120000: loss 0.000000\n",
      "iteration 115000 / 120000: loss 1554.077320\n",
      "iteration 115100 / 120000: loss 40.815941\n",
      "iteration 115200 / 120000: loss 0.000000\n",
      "iteration 115300 / 120000: loss 0.000000\n",
      "iteration 115400 / 120000: loss 654.990916\n",
      "iteration 115500 / 120000: loss 0.000000\n",
      "iteration 115600 / 120000: loss 0.000000\n",
      "iteration 115700 / 120000: loss 0.000000\n",
      "iteration 115800 / 120000: loss 1150.831030\n",
      "iteration 115900 / 120000: loss 0.000000\n",
      "iteration 116000 / 120000: loss 758.307737\n",
      "iteration 116100 / 120000: loss 908.232487\n",
      "iteration 116200 / 120000: loss 261.545221\n",
      "iteration 116300 / 120000: loss 0.000000\n",
      "iteration 116400 / 120000: loss 0.000000\n",
      "iteration 116500 / 120000: loss 0.000000\n",
      "iteration 116600 / 120000: loss 0.000000\n",
      "iteration 116700 / 120000: loss 1040.500760\n",
      "iteration 116800 / 120000: loss 0.000000\n",
      "iteration 116900 / 120000: loss 0.000000\n",
      "iteration 117000 / 120000: loss 0.000000\n",
      "iteration 117100 / 120000: loss 0.000000\n",
      "iteration 117200 / 120000: loss 460.436200\n",
      "iteration 117300 / 120000: loss 2546.236965\n",
      "iteration 117400 / 120000: loss 0.000000\n",
      "iteration 117500 / 120000: loss 196.576263\n",
      "iteration 117600 / 120000: loss 0.000000\n",
      "iteration 117700 / 120000: loss 0.000000\n",
      "iteration 117800 / 120000: loss 0.000000\n",
      "iteration 117900 / 120000: loss 0.000000\n",
      "iteration 118000 / 120000: loss 955.787348\n",
      "iteration 118100 / 120000: loss 0.000000\n",
      "iteration 118200 / 120000: loss 0.000000\n",
      "iteration 118300 / 120000: loss 235.033070\n",
      "iteration 118400 / 120000: loss 386.644425\n",
      "iteration 118500 / 120000: loss 0.000000\n",
      "iteration 118600 / 120000: loss 808.855344\n",
      "iteration 118700 / 120000: loss 49.885743\n",
      "iteration 118800 / 120000: loss 0.000000\n",
      "iteration 118900 / 120000: loss 0.000000\n",
      "iteration 119000 / 120000: loss 88.374563\n",
      "iteration 119100 / 120000: loss 31.516797\n",
      "iteration 119200 / 120000: loss 0.000000\n",
      "iteration 119300 / 120000: loss 0.000000\n",
      "iteration 119400 / 120000: loss 296.050871\n",
      "iteration 119500 / 120000: loss 693.837176\n",
      "iteration 119600 / 120000: loss 176.250779\n",
      "iteration 119700 / 120000: loss 0.000000\n",
      "iteration 119800 / 120000: loss 0.000000\n",
      "iteration 119900 / 120000: loss 0.000000\n",
      "iteration 0 / 1200: loss 547.399364\n",
      "iteration 100 / 1200: loss 420.903997\n",
      "iteration 200 / 1200: loss 447.746551\n",
      "iteration 300 / 1200: loss 437.138467\n",
      "iteration 400 / 1200: loss 447.752949\n",
      "iteration 500 / 1200: loss 417.315286\n",
      "iteration 600 / 1200: loss 398.858852\n",
      "iteration 700 / 1200: loss 483.042495\n",
      "iteration 800 / 1200: loss 354.229532\n",
      "iteration 900 / 1200: loss 340.521963\n",
      "iteration 1000 / 1200: loss 350.287056\n",
      "iteration 1100 / 1200: loss 402.462391\n",
      "iteration 0 / 600: loss 251.657417\n",
      "iteration 100 / 600: loss 322.297956\n",
      "iteration 200 / 600: loss 398.278352\n",
      "iteration 300 / 600: loss 401.009773\n",
      "iteration 400 / 600: loss 345.049272\n",
      "iteration 500 / 600: loss 346.460802\n",
      "iteration 0 / 240: loss 463.716299\n",
      "iteration 100 / 240: loss 381.047034\n",
      "iteration 200 / 240: loss 422.256323\n",
      "iteration 0 / 12: loss 808.715533\n",
      "iteration 0 / 120000: loss 0.000000\n",
      "iteration 100 / 120000: loss 926.081736\n",
      "iteration 200 / 120000: loss 1800.725973\n",
      "iteration 300 / 120000: loss 0.000000\n",
      "iteration 400 / 120000: loss 195.845672\n",
      "iteration 500 / 120000: loss 0.000000\n",
      "iteration 600 / 120000: loss 377.706698\n",
      "iteration 700 / 120000: loss 0.000000\n",
      "iteration 800 / 120000: loss 261.771843\n",
      "iteration 900 / 120000: loss 0.000000\n",
      "iteration 1000 / 120000: loss 1252.876785\n",
      "iteration 1100 / 120000: loss 577.460366\n",
      "iteration 1200 / 120000: loss 0.000000\n",
      "iteration 1300 / 120000: loss 0.000000\n",
      "iteration 1400 / 120000: loss 88.893836\n",
      "iteration 1500 / 120000: loss 948.284859\n",
      "iteration 1600 / 120000: loss 30.827877\n",
      "iteration 1700 / 120000: loss 0.000000\n",
      "iteration 1800 / 120000: loss 0.000000\n",
      "iteration 1900 / 120000: loss 0.000000\n",
      "iteration 2000 / 120000: loss 428.353054\n",
      "iteration 2100 / 120000: loss 0.000000\n",
      "iteration 2200 / 120000: loss 0.000000\n",
      "iteration 2300 / 120000: loss 0.000000\n",
      "iteration 2400 / 120000: loss 0.000000\n",
      "iteration 2500 / 120000: loss 0.000000\n",
      "iteration 2600 / 120000: loss 0.000000\n",
      "iteration 2700 / 120000: loss 0.000000\n",
      "iteration 2800 / 120000: loss 121.485857\n",
      "iteration 2900 / 120000: loss 117.854934\n",
      "iteration 3000 / 120000: loss 0.000000\n",
      "iteration 3100 / 120000: loss 0.000000\n",
      "iteration 3200 / 120000: loss 0.000000\n",
      "iteration 3300 / 120000: loss 0.000000\n",
      "iteration 3400 / 120000: loss 306.917912\n",
      "iteration 3500 / 120000: loss 225.543793\n",
      "iteration 3600 / 120000: loss 0.000000\n",
      "iteration 3700 / 120000: loss 893.020232\n",
      "iteration 3800 / 120000: loss 0.000000\n",
      "iteration 3900 / 120000: loss 872.566283\n",
      "iteration 4000 / 120000: loss 0.000000\n",
      "iteration 4100 / 120000: loss 0.000000\n",
      "iteration 4200 / 120000: loss 175.516089\n",
      "iteration 4300 / 120000: loss 0.000000\n",
      "iteration 4400 / 120000: loss 78.680316\n",
      "iteration 4500 / 120000: loss 283.827788\n",
      "iteration 4600 / 120000: loss 0.000000\n",
      "iteration 4700 / 120000: loss 0.000000\n",
      "iteration 4800 / 120000: loss 0.000000\n",
      "iteration 4900 / 120000: loss 0.000000\n",
      "iteration 5000 / 120000: loss 0.000000\n",
      "iteration 5100 / 120000: loss 0.000000\n",
      "iteration 5200 / 120000: loss 0.000000\n",
      "iteration 5300 / 120000: loss 0.000000\n",
      "iteration 5400 / 120000: loss 0.000000\n",
      "iteration 5500 / 120000: loss 0.000000\n",
      "iteration 5600 / 120000: loss 0.000000\n",
      "iteration 5700 / 120000: loss 0.000000\n",
      "iteration 5800 / 120000: loss 0.000000\n",
      "iteration 5900 / 120000: loss 0.000000\n",
      "iteration 6000 / 120000: loss 0.000000\n",
      "iteration 6100 / 120000: loss 0.000000\n",
      "iteration 6200 / 120000: loss 0.000000\n",
      "iteration 6300 / 120000: loss 0.000000\n",
      "iteration 6400 / 120000: loss 0.000000\n",
      "iteration 6500 / 120000: loss 0.000000\n",
      "iteration 6600 / 120000: loss 64.524205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 6700 / 120000: loss 0.000000\n",
      "iteration 6800 / 120000: loss 0.000000\n",
      "iteration 6900 / 120000: loss 0.000000\n",
      "iteration 7000 / 120000: loss 1363.679844\n",
      "iteration 7100 / 120000: loss 0.000000\n",
      "iteration 7200 / 120000: loss 0.000000\n",
      "iteration 7300 / 120000: loss 0.000000\n",
      "iteration 7400 / 120000: loss 0.000000\n",
      "iteration 7500 / 120000: loss 0.000000\n",
      "iteration 7600 / 120000: loss 0.000000\n",
      "iteration 7700 / 120000: loss 29.004709\n",
      "iteration 7800 / 120000: loss 0.000000\n",
      "iteration 7900 / 120000: loss 0.000000\n",
      "iteration 8000 / 120000: loss 770.622360\n",
      "iteration 8100 / 120000: loss 0.000000\n",
      "iteration 8200 / 120000: loss 0.000000\n",
      "iteration 8300 / 120000: loss 0.000000\n",
      "iteration 8400 / 120000: loss 214.296158\n",
      "iteration 8500 / 120000: loss 174.705809\n",
      "iteration 8600 / 120000: loss 0.000000\n",
      "iteration 8700 / 120000: loss 0.000000\n",
      "iteration 8800 / 120000: loss 0.000000\n",
      "iteration 8900 / 120000: loss 0.000000\n",
      "iteration 9000 / 120000: loss 0.000000\n",
      "iteration 9100 / 120000: loss 0.000000\n",
      "iteration 9200 / 120000: loss 666.098228\n",
      "iteration 9300 / 120000: loss 0.000000\n",
      "iteration 9400 / 120000: loss 255.456211\n",
      "iteration 9500 / 120000: loss 0.000000\n",
      "iteration 9600 / 120000: loss 0.000000\n",
      "iteration 9700 / 120000: loss 0.000000\n",
      "iteration 9800 / 120000: loss 0.000000\n",
      "iteration 9900 / 120000: loss 0.000000\n",
      "iteration 10000 / 120000: loss 161.559059\n",
      "iteration 10100 / 120000: loss 600.822015\n",
      "iteration 10200 / 120000: loss 0.000000\n",
      "iteration 10300 / 120000: loss 1692.544260\n",
      "iteration 10400 / 120000: loss 1333.787805\n",
      "iteration 10500 / 120000: loss 673.584154\n",
      "iteration 10600 / 120000: loss 61.613945\n",
      "iteration 10700 / 120000: loss 0.000000\n",
      "iteration 10800 / 120000: loss 0.000000\n",
      "iteration 10900 / 120000: loss 3.445686\n",
      "iteration 11000 / 120000: loss 482.898622\n",
      "iteration 11100 / 120000: loss 0.000000\n",
      "iteration 11200 / 120000: loss 0.000000\n",
      "iteration 11300 / 120000: loss 326.616694\n",
      "iteration 11400 / 120000: loss 493.198057\n",
      "iteration 11500 / 120000: loss 81.716359\n",
      "iteration 11600 / 120000: loss 0.000000\n",
      "iteration 11700 / 120000: loss 0.000000\n",
      "iteration 11800 / 120000: loss 0.000000\n",
      "iteration 11900 / 120000: loss 0.000000\n",
      "iteration 12000 / 120000: loss 0.000000\n",
      "iteration 12100 / 120000: loss 0.000000\n",
      "iteration 12200 / 120000: loss 0.000000\n",
      "iteration 12300 / 120000: loss 0.000000\n",
      "iteration 12400 / 120000: loss 0.000000\n",
      "iteration 12500 / 120000: loss 0.000000\n",
      "iteration 12600 / 120000: loss 0.000000\n",
      "iteration 12700 / 120000: loss 0.000000\n",
      "iteration 12800 / 120000: loss 0.000000\n",
      "iteration 12900 / 120000: loss 0.000000\n",
      "iteration 13000 / 120000: loss 127.246809\n",
      "iteration 13100 / 120000: loss 0.000000\n",
      "iteration 13200 / 120000: loss 0.000000\n",
      "iteration 13300 / 120000: loss 0.000000\n",
      "iteration 13400 / 120000: loss 0.000000\n",
      "iteration 13500 / 120000: loss 0.000000\n",
      "iteration 13600 / 120000: loss 408.736572\n",
      "iteration 13700 / 120000: loss 0.000000\n",
      "iteration 13800 / 120000: loss 0.000000\n",
      "iteration 13900 / 120000: loss 516.568435\n",
      "iteration 14000 / 120000: loss 1224.085056\n",
      "iteration 14100 / 120000: loss 291.837420\n",
      "iteration 14200 / 120000: loss 0.000000\n",
      "iteration 14300 / 120000: loss 0.000000\n",
      "iteration 14400 / 120000: loss 0.000000\n",
      "iteration 14500 / 120000: loss 0.000000\n",
      "iteration 14600 / 120000: loss 0.000000\n",
      "iteration 14700 / 120000: loss 0.000000\n",
      "iteration 14800 / 120000: loss 0.000000\n",
      "iteration 14900 / 120000: loss 154.327083\n",
      "iteration 15000 / 120000: loss 334.153883\n",
      "iteration 15100 / 120000: loss 0.000000\n",
      "iteration 15200 / 120000: loss 0.000000\n",
      "iteration 15300 / 120000: loss 0.000000\n",
      "iteration 15400 / 120000: loss 781.856570\n",
      "iteration 15500 / 120000: loss 423.267470\n",
      "iteration 15600 / 120000: loss 0.000000\n",
      "iteration 15700 / 120000: loss 219.868672\n",
      "iteration 15800 / 120000: loss 0.000000\n",
      "iteration 15900 / 120000: loss 0.000000\n",
      "iteration 16000 / 120000: loss 0.000000\n",
      "iteration 16100 / 120000: loss 0.000000\n",
      "iteration 16200 / 120000: loss 0.000000\n",
      "iteration 16300 / 120000: loss 0.000000\n",
      "iteration 16400 / 120000: loss 0.000000\n",
      "iteration 16500 / 120000: loss 0.000000\n",
      "iteration 16600 / 120000: loss 240.055839\n",
      "iteration 16700 / 120000: loss 598.248200\n",
      "iteration 16800 / 120000: loss 0.000000\n",
      "iteration 16900 / 120000: loss 0.000000\n",
      "iteration 17000 / 120000: loss 0.000000\n",
      "iteration 17100 / 120000: loss 0.000000\n",
      "iteration 17200 / 120000: loss 0.000000\n",
      "iteration 17300 / 120000: loss 0.000000\n",
      "iteration 17400 / 120000: loss 152.178639\n",
      "iteration 17500 / 120000: loss 0.000000\n",
      "iteration 17600 / 120000: loss 0.000000\n",
      "iteration 17700 / 120000: loss 0.000000\n",
      "iteration 17800 / 120000: loss 0.000000\n",
      "iteration 17900 / 120000: loss 783.446843\n",
      "iteration 18000 / 120000: loss 0.000000\n",
      "iteration 18100 / 120000: loss 0.000000\n",
      "iteration 18200 / 120000: loss 0.000000\n",
      "iteration 18300 / 120000: loss 0.000000\n",
      "iteration 18400 / 120000: loss 0.000000\n",
      "iteration 18500 / 120000: loss 0.000000\n",
      "iteration 18600 / 120000: loss 0.000000\n",
      "iteration 18700 / 120000: loss 0.000000\n",
      "iteration 18800 / 120000: loss 95.854693\n",
      "iteration 18900 / 120000: loss 0.000000\n",
      "iteration 19000 / 120000: loss 0.000000\n",
      "iteration 19100 / 120000: loss 0.000000\n",
      "iteration 19200 / 120000: loss 0.000000\n",
      "iteration 19300 / 120000: loss 720.015653\n",
      "iteration 19400 / 120000: loss 0.000000\n",
      "iteration 19500 / 120000: loss 0.000000\n",
      "iteration 19600 / 120000: loss 168.607745\n",
      "iteration 19700 / 120000: loss 488.570939\n",
      "iteration 19800 / 120000: loss 0.000000\n",
      "iteration 19900 / 120000: loss 0.000000\n",
      "iteration 20000 / 120000: loss 0.000000\n",
      "iteration 20100 / 120000: loss 0.000000\n",
      "iteration 20200 / 120000: loss 0.000000\n",
      "iteration 20300 / 120000: loss 0.000000\n",
      "iteration 20400 / 120000: loss 0.000000\n",
      "iteration 20500 / 120000: loss 1011.473875\n",
      "iteration 20600 / 120000: loss 0.000000\n",
      "iteration 20700 / 120000: loss 279.460132\n",
      "iteration 20800 / 120000: loss 0.000000\n",
      "iteration 20900 / 120000: loss 0.000000\n",
      "iteration 21000 / 120000: loss 0.000000\n",
      "iteration 21100 / 120000: loss 0.000000\n",
      "iteration 21200 / 120000: loss 0.000000\n",
      "iteration 21300 / 120000: loss 0.000000\n",
      "iteration 21400 / 120000: loss 0.000000\n",
      "iteration 21500 / 120000: loss 0.000000\n",
      "iteration 21600 / 120000: loss 0.000000\n",
      "iteration 21700 / 120000: loss 668.876616\n",
      "iteration 21800 / 120000: loss 0.000000\n",
      "iteration 21900 / 120000: loss 842.277327\n",
      "iteration 22000 / 120000: loss 0.000000\n",
      "iteration 22100 / 120000: loss 0.000000\n",
      "iteration 22200 / 120000: loss 0.000000\n",
      "iteration 22300 / 120000: loss 0.000000\n",
      "iteration 22400 / 120000: loss 0.000000\n",
      "iteration 22500 / 120000: loss 0.000000\n",
      "iteration 22600 / 120000: loss 0.000000\n",
      "iteration 22700 / 120000: loss 0.000000\n",
      "iteration 22800 / 120000: loss 0.000000\n",
      "iteration 22900 / 120000: loss 0.000000\n",
      "iteration 23000 / 120000: loss 0.000000\n",
      "iteration 23100 / 120000: loss 0.000000\n",
      "iteration 23200 / 120000: loss 0.000000\n",
      "iteration 23300 / 120000: loss 0.000000\n",
      "iteration 23400 / 120000: loss 0.000000\n",
      "iteration 23500 / 120000: loss 315.443233\n",
      "iteration 23600 / 120000: loss 0.000000\n",
      "iteration 23700 / 120000: loss 0.000000\n",
      "iteration 23800 / 120000: loss 28.463079\n",
      "iteration 23900 / 120000: loss 877.657552\n",
      "iteration 24000 / 120000: loss 0.000000\n",
      "iteration 24100 / 120000: loss 0.000000\n",
      "iteration 24200 / 120000: loss 0.000000\n",
      "iteration 24300 / 120000: loss 0.000000\n",
      "iteration 24400 / 120000: loss 0.000000\n",
      "iteration 24500 / 120000: loss 0.000000\n",
      "iteration 24600 / 120000: loss 0.000000\n",
      "iteration 24700 / 120000: loss 0.000000\n",
      "iteration 24800 / 120000: loss 20.707515\n",
      "iteration 24900 / 120000: loss 173.878914\n",
      "iteration 25000 / 120000: loss 272.392673\n",
      "iteration 25100 / 120000: loss 0.000000\n",
      "iteration 25200 / 120000: loss 292.769850\n",
      "iteration 25300 / 120000: loss 0.000000\n",
      "iteration 25400 / 120000: loss 0.000000\n",
      "iteration 25500 / 120000: loss 783.470921\n",
      "iteration 25600 / 120000: loss 441.351856\n",
      "iteration 25700 / 120000: loss 95.463865\n",
      "iteration 25800 / 120000: loss 0.000000\n",
      "iteration 25900 / 120000: loss 103.800600\n",
      "iteration 26000 / 120000: loss 0.000000\n",
      "iteration 26100 / 120000: loss 69.783806\n",
      "iteration 26200 / 120000: loss 0.000000\n",
      "iteration 26300 / 120000: loss 0.000000\n",
      "iteration 26400 / 120000: loss 0.000000\n",
      "iteration 26500 / 120000: loss 240.945522\n",
      "iteration 26600 / 120000: loss 0.000000\n",
      "iteration 26700 / 120000: loss 0.000000\n",
      "iteration 26800 / 120000: loss 0.000000\n",
      "iteration 26900 / 120000: loss 98.054911\n",
      "iteration 27000 / 120000: loss 0.000000\n",
      "iteration 27100 / 120000: loss 489.317186\n",
      "iteration 27200 / 120000: loss 0.000000\n",
      "iteration 27300 / 120000: loss 323.103983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 27400 / 120000: loss 0.000000\n",
      "iteration 27500 / 120000: loss 0.000000\n",
      "iteration 27600 / 120000: loss 11.592741\n",
      "iteration 27700 / 120000: loss 0.000000\n",
      "iteration 27800 / 120000: loss 0.000000\n",
      "iteration 27900 / 120000: loss 274.903035\n",
      "iteration 28000 / 120000: loss 0.000000\n",
      "iteration 28100 / 120000: loss 0.000000\n",
      "iteration 28200 / 120000: loss 0.000000\n",
      "iteration 28300 / 120000: loss 0.000000\n",
      "iteration 28400 / 120000: loss 0.000000\n",
      "iteration 28500 / 120000: loss 0.000000\n",
      "iteration 28600 / 120000: loss 587.227565\n",
      "iteration 28700 / 120000: loss 492.381295\n",
      "iteration 28800 / 120000: loss 0.000000\n",
      "iteration 28900 / 120000: loss 494.455507\n",
      "iteration 29000 / 120000: loss 429.735237\n",
      "iteration 29100 / 120000: loss 0.000000\n",
      "iteration 29200 / 120000: loss 0.000000\n",
      "iteration 29300 / 120000: loss 0.000000\n",
      "iteration 29400 / 120000: loss 142.638376\n",
      "iteration 29500 / 120000: loss 0.000000\n",
      "iteration 29600 / 120000: loss 0.000000\n",
      "iteration 29700 / 120000: loss 0.000000\n",
      "iteration 29800 / 120000: loss 0.000000\n",
      "iteration 29900 / 120000: loss 0.000000\n",
      "iteration 30000 / 120000: loss 0.000000\n",
      "iteration 30100 / 120000: loss 159.784016\n",
      "iteration 30200 / 120000: loss 0.000000\n",
      "iteration 30300 / 120000: loss 0.000000\n",
      "iteration 30400 / 120000: loss 75.350209\n",
      "iteration 30500 / 120000: loss 75.813145\n",
      "iteration 30600 / 120000: loss 0.000000\n",
      "iteration 30700 / 120000: loss 355.404622\n",
      "iteration 30800 / 120000: loss 0.000000\n",
      "iteration 30900 / 120000: loss 682.865155\n",
      "iteration 31000 / 120000: loss 0.000000\n",
      "iteration 31100 / 120000: loss 0.000000\n",
      "iteration 31200 / 120000: loss 0.000000\n",
      "iteration 31300 / 120000: loss 0.000000\n",
      "iteration 31400 / 120000: loss 50.452035\n",
      "iteration 31500 / 120000: loss 0.000000\n",
      "iteration 31600 / 120000: loss 0.000000\n",
      "iteration 31700 / 120000: loss 0.000000\n",
      "iteration 31800 / 120000: loss 0.000000\n",
      "iteration 31900 / 120000: loss 0.000000\n",
      "iteration 32000 / 120000: loss 0.000000\n",
      "iteration 32100 / 120000: loss 0.000000\n",
      "iteration 32200 / 120000: loss 0.000000\n",
      "iteration 32300 / 120000: loss 0.000000\n",
      "iteration 32400 / 120000: loss 0.000000\n",
      "iteration 32500 / 120000: loss 0.000000\n",
      "iteration 32600 / 120000: loss 39.049908\n",
      "iteration 32700 / 120000: loss 0.000000\n",
      "iteration 32800 / 120000: loss 0.000000\n",
      "iteration 32900 / 120000: loss 0.000000\n",
      "iteration 33000 / 120000: loss 0.000000\n",
      "iteration 33100 / 120000: loss 171.558633\n",
      "iteration 33200 / 120000: loss 0.000000\n",
      "iteration 33300 / 120000: loss 0.000000\n",
      "iteration 33400 / 120000: loss 0.000000\n",
      "iteration 33500 / 120000: loss 0.000000\n",
      "iteration 33600 / 120000: loss 0.000000\n",
      "iteration 33700 / 120000: loss 470.289986\n",
      "iteration 33800 / 120000: loss 0.000000\n",
      "iteration 33900 / 120000: loss 172.732331\n",
      "iteration 34000 / 120000: loss 46.150845\n",
      "iteration 34100 / 120000: loss 426.590895\n",
      "iteration 34200 / 120000: loss 0.000000\n",
      "iteration 34300 / 120000: loss 0.000000\n",
      "iteration 34400 / 120000: loss 593.111389\n",
      "iteration 34500 / 120000: loss 34.995839\n",
      "iteration 34600 / 120000: loss 0.000000\n",
      "iteration 34700 / 120000: loss 0.000000\n",
      "iteration 34800 / 120000: loss 0.000000\n",
      "iteration 34900 / 120000: loss 0.000000\n",
      "iteration 35000 / 120000: loss 0.000000\n",
      "iteration 35100 / 120000: loss 0.000000\n",
      "iteration 35200 / 120000: loss 0.000000\n",
      "iteration 35300 / 120000: loss 0.000000\n",
      "iteration 35400 / 120000: loss 0.000000\n",
      "iteration 35500 / 120000: loss 0.000000\n",
      "iteration 35600 / 120000: loss 0.000000\n",
      "iteration 35700 / 120000: loss 0.000000\n",
      "iteration 35800 / 120000: loss 0.000000\n",
      "iteration 35900 / 120000: loss 0.000000\n",
      "iteration 36000 / 120000: loss 0.000000\n",
      "iteration 36100 / 120000: loss 700.179757\n",
      "iteration 36200 / 120000: loss 0.000000\n",
      "iteration 36300 / 120000: loss 0.000000\n",
      "iteration 36400 / 120000: loss 203.415436\n",
      "iteration 36500 / 120000: loss 0.000000\n",
      "iteration 36600 / 120000: loss 0.000000\n",
      "iteration 36700 / 120000: loss 0.000000\n",
      "iteration 36800 / 120000: loss 0.000000\n",
      "iteration 36900 / 120000: loss 0.000000\n",
      "iteration 37000 / 120000: loss 0.000000\n",
      "iteration 37100 / 120000: loss 0.000000\n",
      "iteration 37200 / 120000: loss 0.000000\n",
      "iteration 37300 / 120000: loss 0.000000\n",
      "iteration 37400 / 120000: loss 0.000000\n",
      "iteration 37500 / 120000: loss 0.000000\n",
      "iteration 37600 / 120000: loss 0.000000\n",
      "iteration 37700 / 120000: loss 470.213425\n",
      "iteration 37800 / 120000: loss 78.384049\n",
      "iteration 37900 / 120000: loss 0.000000\n",
      "iteration 38000 / 120000: loss 0.000000\n",
      "iteration 38100 / 120000: loss 0.000000\n",
      "iteration 38200 / 120000: loss 0.000000\n",
      "iteration 38300 / 120000: loss 219.136027\n",
      "iteration 38400 / 120000: loss 0.000000\n",
      "iteration 38500 / 120000: loss 0.000000\n",
      "iteration 38600 / 120000: loss 0.000000\n",
      "iteration 38700 / 120000: loss 0.000000\n",
      "iteration 38800 / 120000: loss 211.310298\n",
      "iteration 38900 / 120000: loss 0.000000\n",
      "iteration 39000 / 120000: loss 0.000000\n",
      "iteration 39100 / 120000: loss 0.000000\n",
      "iteration 39200 / 120000: loss 0.000000\n",
      "iteration 39300 / 120000: loss 0.000000\n",
      "iteration 39400 / 120000: loss 534.601587\n",
      "iteration 39500 / 120000: loss 0.000000\n",
      "iteration 39600 / 120000: loss 0.000000\n",
      "iteration 39700 / 120000: loss 0.000000\n",
      "iteration 39800 / 120000: loss 0.000000\n",
      "iteration 39900 / 120000: loss 0.000000\n",
      "iteration 40000 / 120000: loss 0.000000\n",
      "iteration 40100 / 120000: loss 0.000000\n",
      "iteration 40200 / 120000: loss 0.000000\n",
      "iteration 40300 / 120000: loss 0.000000\n",
      "iteration 40400 / 120000: loss 962.570039\n",
      "iteration 40500 / 120000: loss 0.000000\n",
      "iteration 40600 / 120000: loss 0.000000\n",
      "iteration 40700 / 120000: loss 0.000000\n",
      "iteration 40800 / 120000: loss 0.000000\n",
      "iteration 40900 / 120000: loss 0.000000\n",
      "iteration 41000 / 120000: loss 0.000000\n",
      "iteration 41100 / 120000: loss 19.918033\n",
      "iteration 41200 / 120000: loss 0.000000\n",
      "iteration 41300 / 120000: loss 0.000000\n",
      "iteration 41400 / 120000: loss 0.000000\n",
      "iteration 41500 / 120000: loss 0.000000\n",
      "iteration 41600 / 120000: loss 61.225868\n",
      "iteration 41700 / 120000: loss 0.000000\n",
      "iteration 41800 / 120000: loss 0.000000\n",
      "iteration 41900 / 120000: loss 0.000000\n",
      "iteration 42000 / 120000: loss 0.000000\n",
      "iteration 42100 / 120000: loss 0.000000\n",
      "iteration 42200 / 120000: loss 13.312809\n",
      "iteration 42300 / 120000: loss 0.000000\n",
      "iteration 42400 / 120000: loss 37.995323\n",
      "iteration 42500 / 120000: loss 0.000000\n",
      "iteration 42600 / 120000: loss 89.773116\n",
      "iteration 42700 / 120000: loss 531.507284\n",
      "iteration 42800 / 120000: loss 0.000000\n",
      "iteration 42900 / 120000: loss 0.000000\n",
      "iteration 43000 / 120000: loss 0.000000\n",
      "iteration 43100 / 120000: loss 0.000000\n",
      "iteration 43200 / 120000: loss 0.000000\n",
      "iteration 43300 / 120000: loss 0.000000\n",
      "iteration 43400 / 120000: loss 0.000000\n",
      "iteration 43500 / 120000: loss 0.000000\n",
      "iteration 43600 / 120000: loss 285.577543\n",
      "iteration 43700 / 120000: loss 14.804459\n",
      "iteration 43800 / 120000: loss 0.000000\n",
      "iteration 43900 / 120000: loss 0.000000\n",
      "iteration 44000 / 120000: loss 782.768195\n",
      "iteration 44100 / 120000: loss 0.000000\n",
      "iteration 44200 / 120000: loss 0.000000\n",
      "iteration 44300 / 120000: loss 0.000000\n",
      "iteration 44400 / 120000: loss 0.000000\n",
      "iteration 44500 / 120000: loss 0.000000\n",
      "iteration 44600 / 120000: loss 0.000000\n",
      "iteration 44700 / 120000: loss 0.000000\n",
      "iteration 44800 / 120000: loss 0.000000\n",
      "iteration 44900 / 120000: loss 0.000000\n",
      "iteration 45000 / 120000: loss 0.000000\n",
      "iteration 45100 / 120000: loss 0.000000\n",
      "iteration 45200 / 120000: loss 0.000000\n",
      "iteration 45300 / 120000: loss 0.000000\n",
      "iteration 45400 / 120000: loss 220.186217\n",
      "iteration 45500 / 120000: loss 0.000000\n",
      "iteration 45600 / 120000: loss 0.000000\n",
      "iteration 45700 / 120000: loss 0.000000\n",
      "iteration 45800 / 120000: loss 0.000000\n",
      "iteration 45900 / 120000: loss 0.000000\n",
      "iteration 46000 / 120000: loss 0.000000\n",
      "iteration 46100 / 120000: loss 132.770360\n",
      "iteration 46200 / 120000: loss 0.000000\n",
      "iteration 46300 / 120000: loss 150.169470\n",
      "iteration 46400 / 120000: loss 0.000000\n",
      "iteration 46500 / 120000: loss 0.000000\n",
      "iteration 46600 / 120000: loss 0.000000\n",
      "iteration 46700 / 120000: loss 0.000000\n",
      "iteration 46800 / 120000: loss 77.406119\n",
      "iteration 46900 / 120000: loss 582.768239\n",
      "iteration 47000 / 120000: loss 0.000000\n",
      "iteration 47100 / 120000: loss 386.903846\n",
      "iteration 47200 / 120000: loss 323.936261\n",
      "iteration 47300 / 120000: loss 0.000000\n",
      "iteration 47400 / 120000: loss 0.000000\n",
      "iteration 47500 / 120000: loss 0.000000\n",
      "iteration 47600 / 120000: loss 0.000000\n",
      "iteration 47700 / 120000: loss 88.470420\n",
      "iteration 47800 / 120000: loss 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 47900 / 120000: loss 0.000000\n",
      "iteration 48000 / 120000: loss 85.451273\n",
      "iteration 48100 / 120000: loss 0.000000\n",
      "iteration 48200 / 120000: loss 0.000000\n",
      "iteration 48300 / 120000: loss 0.000000\n",
      "iteration 48400 / 120000: loss 0.000000\n",
      "iteration 48500 / 120000: loss 0.000000\n",
      "iteration 48600 / 120000: loss 0.000000\n",
      "iteration 48700 / 120000: loss 0.000000\n",
      "iteration 48800 / 120000: loss 177.898434\n",
      "iteration 48900 / 120000: loss 0.000000\n",
      "iteration 49000 / 120000: loss 0.000000\n",
      "iteration 49100 / 120000: loss 0.000000\n",
      "iteration 49200 / 120000: loss 0.000000\n",
      "iteration 49300 / 120000: loss 0.000000\n",
      "iteration 49400 / 120000: loss 0.000000\n",
      "iteration 49500 / 120000: loss 0.000000\n",
      "iteration 49600 / 120000: loss 131.499936\n",
      "iteration 49700 / 120000: loss 417.190927\n",
      "iteration 49800 / 120000: loss 563.482673\n",
      "iteration 49900 / 120000: loss 0.000000\n",
      "iteration 50000 / 120000: loss 0.000000\n",
      "iteration 50100 / 120000: loss 0.000000\n",
      "iteration 50200 / 120000: loss 0.000000\n",
      "iteration 50300 / 120000: loss 0.000000\n",
      "iteration 50400 / 120000: loss 0.000000\n",
      "iteration 50500 / 120000: loss 0.000000\n",
      "iteration 50600 / 120000: loss 0.000000\n",
      "iteration 50700 / 120000: loss 0.000000\n",
      "iteration 50800 / 120000: loss 301.899757\n",
      "iteration 50900 / 120000: loss 0.000000\n",
      "iteration 51000 / 120000: loss 0.000000\n",
      "iteration 51100 / 120000: loss 0.000000\n",
      "iteration 51200 / 120000: loss 431.005002\n",
      "iteration 51300 / 120000: loss 0.000000\n",
      "iteration 51400 / 120000: loss 0.000000\n",
      "iteration 51500 / 120000: loss 0.000000\n",
      "iteration 51600 / 120000: loss 0.000000\n",
      "iteration 51700 / 120000: loss 197.956229\n",
      "iteration 51800 / 120000: loss 0.000000\n",
      "iteration 51900 / 120000: loss 0.000000\n",
      "iteration 52000 / 120000: loss 0.000000\n",
      "iteration 52100 / 120000: loss 266.298685\n",
      "iteration 52200 / 120000: loss 0.000000\n",
      "iteration 52300 / 120000: loss 0.000000\n",
      "iteration 52400 / 120000: loss 0.000000\n",
      "iteration 52500 / 120000: loss 0.000000\n",
      "iteration 52600 / 120000: loss 82.419600\n",
      "iteration 52700 / 120000: loss 0.000000\n",
      "iteration 52800 / 120000: loss 41.282731\n",
      "iteration 52900 / 120000: loss 0.000000\n",
      "iteration 53000 / 120000: loss 326.669875\n",
      "iteration 53100 / 120000: loss 0.000000\n",
      "iteration 53200 / 120000: loss 0.000000\n",
      "iteration 53300 / 120000: loss 132.904173\n",
      "iteration 53400 / 120000: loss 63.987747\n",
      "iteration 53500 / 120000: loss 0.000000\n",
      "iteration 53600 / 120000: loss 0.000000\n",
      "iteration 53700 / 120000: loss 0.000000\n",
      "iteration 53800 / 120000: loss 0.000000\n",
      "iteration 53900 / 120000: loss 0.000000\n",
      "iteration 54000 / 120000: loss 0.000000\n",
      "iteration 54100 / 120000: loss 0.000000\n",
      "iteration 54200 / 120000: loss 0.000000\n",
      "iteration 54300 / 120000: loss 0.000000\n",
      "iteration 54400 / 120000: loss 0.000000\n",
      "iteration 54500 / 120000: loss 0.000000\n",
      "iteration 54600 / 120000: loss 0.000000\n",
      "iteration 54700 / 120000: loss 0.000000\n",
      "iteration 54800 / 120000: loss 0.000000\n",
      "iteration 54900 / 120000: loss 0.000000\n",
      "iteration 55000 / 120000: loss 309.163468\n",
      "iteration 55100 / 120000: loss 0.000000\n",
      "iteration 55200 / 120000: loss 78.313391\n",
      "iteration 55300 / 120000: loss 0.000000\n",
      "iteration 55400 / 120000: loss 0.000000\n",
      "iteration 55500 / 120000: loss 210.029765\n",
      "iteration 55600 / 120000: loss 0.000000\n",
      "iteration 55700 / 120000: loss 0.000000\n",
      "iteration 55800 / 120000: loss 0.000000\n",
      "iteration 55900 / 120000: loss 842.267336\n",
      "iteration 56000 / 120000: loss 0.000000\n",
      "iteration 56100 / 120000: loss 0.000000\n",
      "iteration 56200 / 120000: loss 21.322002\n",
      "iteration 56300 / 120000: loss 230.805939\n",
      "iteration 56400 / 120000: loss 317.458662\n",
      "iteration 56500 / 120000: loss 0.000000\n",
      "iteration 56600 / 120000: loss 0.000000\n",
      "iteration 56700 / 120000: loss 0.000000\n",
      "iteration 56800 / 120000: loss 0.000000\n",
      "iteration 56900 / 120000: loss 0.000000\n",
      "iteration 57000 / 120000: loss 0.991939\n",
      "iteration 57100 / 120000: loss 0.000000\n",
      "iteration 57200 / 120000: loss 0.000000\n",
      "iteration 57300 / 120000: loss 0.000000\n",
      "iteration 57400 / 120000: loss 0.000000\n",
      "iteration 57500 / 120000: loss 74.966927\n",
      "iteration 57600 / 120000: loss 0.000000\n",
      "iteration 57700 / 120000: loss 269.598938\n",
      "iteration 57800 / 120000: loss 0.000000\n",
      "iteration 57900 / 120000: loss 0.000000\n",
      "iteration 58000 / 120000: loss 210.825855\n",
      "iteration 58100 / 120000: loss 225.333954\n",
      "iteration 58200 / 120000: loss 0.000000\n",
      "iteration 58300 / 120000: loss 96.373656\n",
      "iteration 58400 / 120000: loss 343.194223\n",
      "iteration 58500 / 120000: loss 0.000000\n",
      "iteration 58600 / 120000: loss 0.000000\n",
      "iteration 58700 / 120000: loss 0.000000\n",
      "iteration 58800 / 120000: loss 0.000000\n",
      "iteration 58900 / 120000: loss 0.000000\n",
      "iteration 59000 / 120000: loss 0.000000\n",
      "iteration 59100 / 120000: loss 0.000000\n",
      "iteration 59200 / 120000: loss 0.000000\n",
      "iteration 59300 / 120000: loss 0.000000\n",
      "iteration 59400 / 120000: loss 0.000000\n",
      "iteration 59500 / 120000: loss 0.000000\n",
      "iteration 59600 / 120000: loss 0.000000\n",
      "iteration 59700 / 120000: loss 530.763200\n",
      "iteration 59800 / 120000: loss 0.000000\n",
      "iteration 59900 / 120000: loss 0.000000\n",
      "iteration 60000 / 120000: loss 0.000000\n",
      "iteration 60100 / 120000: loss 124.541922\n",
      "iteration 60200 / 120000: loss 0.000000\n",
      "iteration 60300 / 120000: loss 0.000000\n",
      "iteration 60400 / 120000: loss 0.000000\n",
      "iteration 60500 / 120000: loss 0.000000\n",
      "iteration 60600 / 120000: loss 574.769696\n",
      "iteration 60700 / 120000: loss 0.000000\n",
      "iteration 60800 / 120000: loss 0.000000\n",
      "iteration 60900 / 120000: loss 0.000000\n",
      "iteration 61000 / 120000: loss 0.000000\n",
      "iteration 61100 / 120000: loss 134.127829\n",
      "iteration 61200 / 120000: loss 0.000000\n",
      "iteration 61300 / 120000: loss 0.000000\n",
      "iteration 61400 / 120000: loss 135.144519\n",
      "iteration 61500 / 120000: loss 0.000000\n",
      "iteration 61600 / 120000: loss 0.000000\n",
      "iteration 61700 / 120000: loss 0.000000\n",
      "iteration 61800 / 120000: loss 121.583469\n",
      "iteration 61900 / 120000: loss 424.731746\n",
      "iteration 62000 / 120000: loss 0.000000\n",
      "iteration 62100 / 120000: loss 0.000000\n",
      "iteration 62200 / 120000: loss 0.000000\n",
      "iteration 62300 / 120000: loss 95.483670\n",
      "iteration 62400 / 120000: loss 0.000000\n",
      "iteration 62500 / 120000: loss 0.000000\n",
      "iteration 62600 / 120000: loss 154.677334\n",
      "iteration 62700 / 120000: loss 0.000000\n",
      "iteration 62800 / 120000: loss 0.000000\n",
      "iteration 62900 / 120000: loss 532.356204\n",
      "iteration 63000 / 120000: loss 0.000000\n",
      "iteration 63100 / 120000: loss 91.796841\n",
      "iteration 63200 / 120000: loss 0.000000\n",
      "iteration 63300 / 120000: loss 0.000000\n",
      "iteration 63400 / 120000: loss 0.000000\n",
      "iteration 63500 / 120000: loss 0.000000\n",
      "iteration 63600 / 120000: loss 0.000000\n",
      "iteration 63700 / 120000: loss 145.388292\n",
      "iteration 63800 / 120000: loss 0.000000\n",
      "iteration 63900 / 120000: loss 0.000000\n",
      "iteration 64000 / 120000: loss 0.000000\n",
      "iteration 64100 / 120000: loss 0.705371\n",
      "iteration 64200 / 120000: loss 377.844706\n",
      "iteration 64300 / 120000: loss 0.000000\n",
      "iteration 64400 / 120000: loss 193.346238\n",
      "iteration 64500 / 120000: loss 0.000000\n",
      "iteration 64600 / 120000: loss 414.940244\n",
      "iteration 64700 / 120000: loss 176.699336\n",
      "iteration 64800 / 120000: loss 0.000000\n",
      "iteration 64900 / 120000: loss 0.000000\n",
      "iteration 65000 / 120000: loss 202.126422\n",
      "iteration 65100 / 120000: loss 0.000000\n",
      "iteration 65200 / 120000: loss 0.000000\n",
      "iteration 65300 / 120000: loss 117.439026\n",
      "iteration 65400 / 120000: loss 0.000000\n",
      "iteration 65500 / 120000: loss 206.256599\n",
      "iteration 65600 / 120000: loss 0.000000\n",
      "iteration 65700 / 120000: loss 251.550465\n",
      "iteration 65800 / 120000: loss 0.000000\n",
      "iteration 65900 / 120000: loss 0.000000\n",
      "iteration 66000 / 120000: loss 0.000000\n",
      "iteration 66100 / 120000: loss 0.000000\n",
      "iteration 66200 / 120000: loss 0.000000\n",
      "iteration 66300 / 120000: loss 0.000000\n",
      "iteration 66400 / 120000: loss 0.000000\n",
      "iteration 66500 / 120000: loss 0.000000\n",
      "iteration 66600 / 120000: loss 0.000000\n",
      "iteration 66700 / 120000: loss 340.205262\n",
      "iteration 66800 / 120000: loss 0.000000\n",
      "iteration 66900 / 120000: loss 26.974931\n",
      "iteration 67000 / 120000: loss 0.000000\n",
      "iteration 67100 / 120000: loss 0.000000\n",
      "iteration 67200 / 120000: loss 0.000000\n",
      "iteration 67300 / 120000: loss 0.000000\n",
      "iteration 67400 / 120000: loss 705.797614\n",
      "iteration 67500 / 120000: loss 0.000000\n",
      "iteration 67600 / 120000: loss 0.000000\n",
      "iteration 67700 / 120000: loss 36.383387\n",
      "iteration 67800 / 120000: loss 0.000000\n",
      "iteration 67900 / 120000: loss 39.477469\n",
      "iteration 68000 / 120000: loss 0.000000\n",
      "iteration 68100 / 120000: loss 0.000000\n",
      "iteration 68200 / 120000: loss 0.000000\n",
      "iteration 68300 / 120000: loss 0.000000\n",
      "iteration 68400 / 120000: loss 0.000000\n",
      "iteration 68500 / 120000: loss 0.000000\n",
      "iteration 68600 / 120000: loss 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 68700 / 120000: loss 0.000000\n",
      "iteration 68800 / 120000: loss 170.479571\n",
      "iteration 68900 / 120000: loss 0.000000\n",
      "iteration 69000 / 120000: loss 0.000000\n",
      "iteration 69100 / 120000: loss 0.000000\n",
      "iteration 69200 / 120000: loss 88.132440\n",
      "iteration 69300 / 120000: loss 0.000000\n",
      "iteration 69400 / 120000: loss 0.000000\n",
      "iteration 69500 / 120000: loss 0.000000\n",
      "iteration 69600 / 120000: loss 0.000000\n",
      "iteration 69700 / 120000: loss 0.000000\n",
      "iteration 69800 / 120000: loss 0.000000\n",
      "iteration 69900 / 120000: loss 0.000000\n",
      "iteration 70000 / 120000: loss 0.000000\n",
      "iteration 70100 / 120000: loss 0.000000\n",
      "iteration 70200 / 120000: loss 0.000000\n",
      "iteration 70300 / 120000: loss 0.000000\n",
      "iteration 70400 / 120000: loss 0.000000\n",
      "iteration 70500 / 120000: loss 0.000000\n",
      "iteration 70600 / 120000: loss 0.000000\n",
      "iteration 70700 / 120000: loss 0.000000\n",
      "iteration 70800 / 120000: loss 0.000000\n",
      "iteration 70900 / 120000: loss 0.000000\n",
      "iteration 71000 / 120000: loss 0.000000\n",
      "iteration 71100 / 120000: loss 0.000000\n",
      "iteration 71200 / 120000: loss 0.000000\n",
      "iteration 71300 / 120000: loss 0.000000\n",
      "iteration 71400 / 120000: loss 219.428559\n",
      "iteration 71500 / 120000: loss 38.451240\n",
      "iteration 71600 / 120000: loss 0.000000\n",
      "iteration 71700 / 120000: loss 0.000000\n",
      "iteration 71800 / 120000: loss 0.000000\n",
      "iteration 71900 / 120000: loss 0.000000\n",
      "iteration 72000 / 120000: loss 0.000000\n",
      "iteration 72100 / 120000: loss 0.000000\n",
      "iteration 72200 / 120000: loss 0.000000\n",
      "iteration 72300 / 120000: loss 123.898848\n",
      "iteration 72400 / 120000: loss 0.000000\n",
      "iteration 72500 / 120000: loss 0.000000\n",
      "iteration 72600 / 120000: loss 0.000000\n",
      "iteration 72700 / 120000: loss 0.000000\n",
      "iteration 72800 / 120000: loss 0.000000\n",
      "iteration 72900 / 120000: loss 519.992329\n",
      "iteration 73000 / 120000: loss 0.000000\n",
      "iteration 73100 / 120000: loss 0.000000\n",
      "iteration 73200 / 120000: loss 0.000000\n",
      "iteration 73300 / 120000: loss 857.438824\n",
      "iteration 73400 / 120000: loss 0.000000\n",
      "iteration 73500 / 120000: loss 0.000000\n",
      "iteration 73600 / 120000: loss 16.642002\n",
      "iteration 73700 / 120000: loss 0.000000\n",
      "iteration 73800 / 120000: loss 0.000000\n",
      "iteration 73900 / 120000: loss 0.000000\n",
      "iteration 74000 / 120000: loss 0.000000\n",
      "iteration 74100 / 120000: loss 0.000000\n",
      "iteration 74200 / 120000: loss 0.000000\n",
      "iteration 74300 / 120000: loss 337.832416\n",
      "iteration 74400 / 120000: loss 0.000000\n",
      "iteration 74500 / 120000: loss 0.000000\n",
      "iteration 74600 / 120000: loss 0.000000\n",
      "iteration 74700 / 120000: loss 0.000000\n",
      "iteration 74800 / 120000: loss 0.000000\n",
      "iteration 74900 / 120000: loss 0.000000\n",
      "iteration 75000 / 120000: loss 0.000000\n",
      "iteration 75100 / 120000: loss 0.000000\n",
      "iteration 75200 / 120000: loss 0.000000\n",
      "iteration 75300 / 120000: loss 0.000000\n",
      "iteration 75400 / 120000: loss 0.000000\n",
      "iteration 75500 / 120000: loss 64.314422\n",
      "iteration 75600 / 120000: loss 0.000000\n",
      "iteration 75700 / 120000: loss 0.000000\n",
      "iteration 75800 / 120000: loss 156.690733\n",
      "iteration 75900 / 120000: loss 34.712488\n",
      "iteration 76000 / 120000: loss 0.000000\n",
      "iteration 76100 / 120000: loss 0.000000\n",
      "iteration 76200 / 120000: loss 0.000000\n",
      "iteration 76300 / 120000: loss 0.000000\n",
      "iteration 76400 / 120000: loss 0.000000\n",
      "iteration 76500 / 120000: loss 0.000000\n",
      "iteration 76600 / 120000: loss 0.000000\n",
      "iteration 76700 / 120000: loss 0.000000\n",
      "iteration 76800 / 120000: loss 0.000000\n",
      "iteration 76900 / 120000: loss 137.382560\n",
      "iteration 77000 / 120000: loss 0.000000\n",
      "iteration 77100 / 120000: loss 0.000000\n",
      "iteration 77200 / 120000: loss 0.000000\n",
      "iteration 77300 / 120000: loss 0.000000\n",
      "iteration 77400 / 120000: loss 0.000000\n",
      "iteration 77500 / 120000: loss 0.000000\n",
      "iteration 77600 / 120000: loss 0.000000\n",
      "iteration 77700 / 120000: loss 0.000000\n",
      "iteration 77800 / 120000: loss 0.000000\n",
      "iteration 77900 / 120000: loss 0.000000\n",
      "iteration 78000 / 120000: loss 0.000000\n",
      "iteration 78100 / 120000: loss 0.000000\n",
      "iteration 78200 / 120000: loss 0.000000\n",
      "iteration 78300 / 120000: loss 0.000000\n",
      "iteration 78400 / 120000: loss 0.000000\n",
      "iteration 78500 / 120000: loss 0.000000\n",
      "iteration 78600 / 120000: loss 0.000000\n",
      "iteration 78700 / 120000: loss 0.000000\n",
      "iteration 78800 / 120000: loss 0.000000\n",
      "iteration 78900 / 120000: loss 7.375242\n",
      "iteration 79000 / 120000: loss 0.000000\n",
      "iteration 79100 / 120000: loss 0.000000\n",
      "iteration 79200 / 120000: loss 361.148820\n",
      "iteration 79300 / 120000: loss 108.588255\n",
      "iteration 79400 / 120000: loss 0.000000\n",
      "iteration 79500 / 120000: loss 0.000000\n",
      "iteration 79600 / 120000: loss 0.000000\n",
      "iteration 79700 / 120000: loss 46.852948\n",
      "iteration 79800 / 120000: loss 0.000000\n",
      "iteration 79900 / 120000: loss 0.000000\n",
      "iteration 80000 / 120000: loss 432.599122\n",
      "iteration 80100 / 120000: loss 87.415617\n",
      "iteration 80200 / 120000: loss 0.000000\n",
      "iteration 80300 / 120000: loss 336.245195\n",
      "iteration 80400 / 120000: loss 263.546881\n",
      "iteration 80500 / 120000: loss 0.000000\n",
      "iteration 80600 / 120000: loss 438.579843\n",
      "iteration 80700 / 120000: loss 0.000000\n",
      "iteration 80800 / 120000: loss 0.000000\n",
      "iteration 80900 / 120000: loss 0.000000\n",
      "iteration 81000 / 120000: loss 0.000000\n",
      "iteration 81100 / 120000: loss 0.000000\n",
      "iteration 81200 / 120000: loss 0.000000\n",
      "iteration 81300 / 120000: loss 0.000000\n",
      "iteration 81400 / 120000: loss 0.000000\n",
      "iteration 81500 / 120000: loss 0.000000\n",
      "iteration 81600 / 120000: loss 0.000000\n",
      "iteration 81700 / 120000: loss 0.000000\n",
      "iteration 81800 / 120000: loss 0.000000\n",
      "iteration 81900 / 120000: loss 0.000000\n",
      "iteration 82000 / 120000: loss 116.263634\n",
      "iteration 82100 / 120000: loss 0.000000\n",
      "iteration 82200 / 120000: loss 0.000000\n",
      "iteration 82300 / 120000: loss 0.000000\n",
      "iteration 82400 / 120000: loss 0.000000\n",
      "iteration 82500 / 120000: loss 62.720397\n",
      "iteration 82600 / 120000: loss 0.000000\n",
      "iteration 82700 / 120000: loss 0.000000\n",
      "iteration 82800 / 120000: loss 0.000000\n",
      "iteration 82900 / 120000: loss 0.000000\n",
      "iteration 83000 / 120000: loss 0.000000\n",
      "iteration 83100 / 120000: loss 0.000000\n",
      "iteration 83200 / 120000: loss 0.000000\n",
      "iteration 83300 / 120000: loss 0.000000\n",
      "iteration 83400 / 120000: loss 104.348415\n",
      "iteration 83500 / 120000: loss 0.000000\n",
      "iteration 83600 / 120000: loss 0.000000\n",
      "iteration 83700 / 120000: loss 0.000000\n",
      "iteration 83800 / 120000: loss 0.000000\n",
      "iteration 83900 / 120000: loss 0.000000\n",
      "iteration 84000 / 120000: loss 0.000000\n",
      "iteration 84100 / 120000: loss 0.000000\n",
      "iteration 84200 / 120000: loss 0.000000\n",
      "iteration 84300 / 120000: loss 0.000000\n",
      "iteration 84400 / 120000: loss 0.000000\n",
      "iteration 84500 / 120000: loss 0.000000\n",
      "iteration 84600 / 120000: loss 0.000000\n",
      "iteration 84700 / 120000: loss 0.000000\n",
      "iteration 84800 / 120000: loss 171.157049\n",
      "iteration 84900 / 120000: loss 0.000000\n",
      "iteration 85000 / 120000: loss 0.000000\n",
      "iteration 85100 / 120000: loss 16.285357\n",
      "iteration 85200 / 120000: loss 172.517713\n",
      "iteration 85300 / 120000: loss 0.000000\n",
      "iteration 85400 / 120000: loss 0.000000\n",
      "iteration 85500 / 120000: loss 0.000000\n",
      "iteration 85600 / 120000: loss 114.816212\n",
      "iteration 85700 / 120000: loss 457.771026\n",
      "iteration 85800 / 120000: loss 0.000000\n",
      "iteration 85900 / 120000: loss 0.000000\n",
      "iteration 86000 / 120000: loss 0.000000\n",
      "iteration 86100 / 120000: loss 17.135546\n",
      "iteration 86200 / 120000: loss 0.000000\n",
      "iteration 86300 / 120000: loss 68.170912\n",
      "iteration 86400 / 120000: loss 0.000000\n",
      "iteration 86500 / 120000: loss 0.000000\n",
      "iteration 86600 / 120000: loss 0.000000\n",
      "iteration 86700 / 120000: loss 266.890747\n",
      "iteration 86800 / 120000: loss 0.000000\n",
      "iteration 86900 / 120000: loss 0.000000\n",
      "iteration 87000 / 120000: loss 0.000000\n",
      "iteration 87100 / 120000: loss 303.514009\n",
      "iteration 87200 / 120000: loss 0.000000\n",
      "iteration 87300 / 120000: loss 0.000000\n",
      "iteration 87400 / 120000: loss 0.000000\n",
      "iteration 87500 / 120000: loss 0.000000\n",
      "iteration 87600 / 120000: loss 0.000000\n",
      "iteration 87700 / 120000: loss 0.000000\n",
      "iteration 87800 / 120000: loss 425.587345\n",
      "iteration 87900 / 120000: loss 0.000000\n",
      "iteration 88000 / 120000: loss 0.000000\n",
      "iteration 88100 / 120000: loss 0.000000\n",
      "iteration 88200 / 120000: loss 279.338405\n",
      "iteration 88300 / 120000: loss 0.000000\n",
      "iteration 88400 / 120000: loss 0.000000\n",
      "iteration 88500 / 120000: loss 0.000000\n",
      "iteration 88600 / 120000: loss 0.000000\n",
      "iteration 88700 / 120000: loss 120.310475\n",
      "iteration 88800 / 120000: loss 344.495486\n",
      "iteration 88900 / 120000: loss 4.212023\n",
      "iteration 89000 / 120000: loss 0.000000\n",
      "iteration 89100 / 120000: loss 0.000000\n",
      "iteration 89200 / 120000: loss 0.000000\n",
      "iteration 89300 / 120000: loss 0.000000\n",
      "iteration 89400 / 120000: loss 58.395997\n",
      "iteration 89500 / 120000: loss 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 89600 / 120000: loss 0.000000\n",
      "iteration 89700 / 120000: loss 107.413264\n",
      "iteration 89800 / 120000: loss 0.000000\n",
      "iteration 89900 / 120000: loss 0.000000\n",
      "iteration 90000 / 120000: loss 0.000000\n",
      "iteration 90100 / 120000: loss 0.000000\n",
      "iteration 90200 / 120000: loss 0.000000\n",
      "iteration 90300 / 120000: loss 0.000000\n",
      "iteration 90400 / 120000: loss 0.000000\n",
      "iteration 90500 / 120000: loss 0.000000\n",
      "iteration 90600 / 120000: loss 85.372465\n",
      "iteration 90700 / 120000: loss 0.000000\n",
      "iteration 90800 / 120000: loss 0.000000\n",
      "iteration 90900 / 120000: loss 0.000000\n",
      "iteration 91000 / 120000: loss 0.000000\n",
      "iteration 91100 / 120000: loss 0.000000\n",
      "iteration 91200 / 120000: loss 0.000000\n",
      "iteration 91300 / 120000: loss 0.000000\n",
      "iteration 91400 / 120000: loss 0.000000\n",
      "iteration 91500 / 120000: loss 0.000000\n",
      "iteration 91600 / 120000: loss 0.000000\n",
      "iteration 91700 / 120000: loss 0.000000\n",
      "iteration 91800 / 120000: loss 0.000000\n",
      "iteration 91900 / 120000: loss 426.515011\n",
      "iteration 92000 / 120000: loss 0.000000\n",
      "iteration 92100 / 120000: loss 0.000000\n",
      "iteration 92200 / 120000: loss 0.000000\n",
      "iteration 92300 / 120000: loss 0.000000\n",
      "iteration 92400 / 120000: loss 0.000000\n",
      "iteration 92500 / 120000: loss 0.000000\n",
      "iteration 92600 / 120000: loss 0.000000\n",
      "iteration 92700 / 120000: loss 0.000000\n",
      "iteration 92800 / 120000: loss 0.000000\n",
      "iteration 92900 / 120000: loss 0.000000\n",
      "iteration 93000 / 120000: loss 0.000000\n",
      "iteration 93100 / 120000: loss 0.000000\n",
      "iteration 93200 / 120000: loss 0.000000\n",
      "iteration 93300 / 120000: loss 233.431003\n",
      "iteration 93400 / 120000: loss 0.000000\n",
      "iteration 93500 / 120000: loss 0.000000\n",
      "iteration 93600 / 120000: loss 0.000000\n",
      "iteration 93700 / 120000: loss 0.000000\n",
      "iteration 93800 / 120000: loss 19.172733\n",
      "iteration 93900 / 120000: loss 0.000000\n",
      "iteration 94000 / 120000: loss 0.000000\n",
      "iteration 94100 / 120000: loss 215.454607\n",
      "iteration 94200 / 120000: loss 0.000000\n",
      "iteration 94300 / 120000: loss 0.000000\n",
      "iteration 94400 / 120000: loss 98.801626\n",
      "iteration 94500 / 120000: loss 0.000000\n",
      "iteration 94600 / 120000: loss 0.000000\n",
      "iteration 94700 / 120000: loss 297.798355\n",
      "iteration 94800 / 120000: loss 0.000000\n",
      "iteration 94900 / 120000: loss 0.000000\n",
      "iteration 95000 / 120000: loss 0.000000\n",
      "iteration 95100 / 120000: loss 91.682808\n",
      "iteration 95200 / 120000: loss 0.000000\n",
      "iteration 95300 / 120000: loss 0.000000\n",
      "iteration 95400 / 120000: loss 0.000000\n",
      "iteration 95500 / 120000: loss 0.000000\n",
      "iteration 95600 / 120000: loss 0.000000\n",
      "iteration 95700 / 120000: loss 0.000000\n",
      "iteration 95800 / 120000: loss 0.000000\n",
      "iteration 95900 / 120000: loss 386.079693\n",
      "iteration 96000 / 120000: loss 150.942700\n",
      "iteration 96100 / 120000: loss 14.987107\n",
      "iteration 96200 / 120000: loss 0.000000\n",
      "iteration 96300 / 120000: loss 0.000000\n",
      "iteration 96400 / 120000: loss 0.000000\n",
      "iteration 96500 / 120000: loss 0.000000\n",
      "iteration 96600 / 120000: loss 0.000000\n",
      "iteration 96700 / 120000: loss 120.127263\n",
      "iteration 96800 / 120000: loss 0.000000\n",
      "iteration 96900 / 120000: loss 0.000000\n",
      "iteration 97000 / 120000: loss 445.579510\n",
      "iteration 97100 / 120000: loss 0.000000\n",
      "iteration 97200 / 120000: loss 0.000000\n",
      "iteration 97300 / 120000: loss 0.000000\n",
      "iteration 97400 / 120000: loss 0.000000\n",
      "iteration 97500 / 120000: loss 0.000000\n",
      "iteration 97600 / 120000: loss 0.000000\n",
      "iteration 97700 / 120000: loss 0.000000\n",
      "iteration 97800 / 120000: loss 0.000000\n",
      "iteration 97900 / 120000: loss 0.000000\n",
      "iteration 98000 / 120000: loss 0.000000\n",
      "iteration 98100 / 120000: loss 0.000000\n",
      "iteration 98200 / 120000: loss 0.000000\n",
      "iteration 98300 / 120000: loss 0.000000\n",
      "iteration 98400 / 120000: loss 0.000000\n",
      "iteration 98500 / 120000: loss 0.000000\n",
      "iteration 98600 / 120000: loss 51.860632\n",
      "iteration 98700 / 120000: loss 0.000000\n",
      "iteration 98800 / 120000: loss 0.000000\n",
      "iteration 98900 / 120000: loss 0.000000\n",
      "iteration 99000 / 120000: loss 0.000000\n",
      "iteration 99100 / 120000: loss 0.000000\n",
      "iteration 99200 / 120000: loss 0.000000\n",
      "iteration 99300 / 120000: loss 0.000000\n",
      "iteration 99400 / 120000: loss 0.000000\n",
      "iteration 99500 / 120000: loss 0.000000\n",
      "iteration 99600 / 120000: loss 0.000000\n",
      "iteration 99700 / 120000: loss 159.084011\n",
      "iteration 99800 / 120000: loss 158.110070\n",
      "iteration 99900 / 120000: loss 0.000000\n",
      "iteration 100000 / 120000: loss 163.618998\n",
      "iteration 100100 / 120000: loss 0.000000\n",
      "iteration 100200 / 120000: loss 215.369611\n",
      "iteration 100300 / 120000: loss 0.000000\n",
      "iteration 100400 / 120000: loss 539.423686\n",
      "iteration 100500 / 120000: loss 0.000000\n",
      "iteration 100600 / 120000: loss 0.000000\n",
      "iteration 100700 / 120000: loss 0.000000\n",
      "iteration 100800 / 120000: loss 161.535500\n",
      "iteration 100900 / 120000: loss 278.978705\n",
      "iteration 101000 / 120000: loss 0.000000\n",
      "iteration 101100 / 120000: loss 0.000000\n",
      "iteration 101200 / 120000: loss 0.000000\n",
      "iteration 101300 / 120000: loss 0.000000\n",
      "iteration 101400 / 120000: loss 0.000000\n",
      "iteration 101500 / 120000: loss 192.294712\n",
      "iteration 101600 / 120000: loss 73.019240\n",
      "iteration 101700 / 120000: loss 0.000000\n",
      "iteration 101800 / 120000: loss 0.000000\n",
      "iteration 101900 / 120000: loss 0.000000\n",
      "iteration 102000 / 120000: loss 0.000000\n",
      "iteration 102100 / 120000: loss 309.537938\n",
      "iteration 102200 / 120000: loss 0.000000\n",
      "iteration 102300 / 120000: loss 0.000000\n",
      "iteration 102400 / 120000: loss 0.000000\n",
      "iteration 102500 / 120000: loss 0.000000\n",
      "iteration 102600 / 120000: loss 0.000000\n",
      "iteration 102700 / 120000: loss 0.000000\n",
      "iteration 102800 / 120000: loss 8.457774\n",
      "iteration 102900 / 120000: loss 0.000000\n",
      "iteration 103000 / 120000: loss 0.000000\n",
      "iteration 103100 / 120000: loss 95.511433\n",
      "iteration 103200 / 120000: loss 0.000000\n",
      "iteration 103300 / 120000: loss 423.521043\n",
      "iteration 103400 / 120000: loss 0.000000\n",
      "iteration 103500 / 120000: loss 0.000000\n",
      "iteration 103600 / 120000: loss 0.000000\n",
      "iteration 103700 / 120000: loss 0.000000\n",
      "iteration 103800 / 120000: loss 0.000000\n",
      "iteration 103900 / 120000: loss 0.000000\n",
      "iteration 104000 / 120000: loss 0.000000\n",
      "iteration 104100 / 120000: loss 143.313504\n",
      "iteration 104200 / 120000: loss 0.000000\n",
      "iteration 104300 / 120000: loss 0.000000\n",
      "iteration 104400 / 120000: loss 0.000000\n",
      "iteration 104500 / 120000: loss 0.000000\n",
      "iteration 104600 / 120000: loss 0.000000\n",
      "iteration 104700 / 120000: loss 5.274768\n",
      "iteration 104800 / 120000: loss 212.619167\n",
      "iteration 104900 / 120000: loss 0.000000\n",
      "iteration 105000 / 120000: loss 59.419962\n",
      "iteration 105100 / 120000: loss 0.000000\n",
      "iteration 105200 / 120000: loss 141.705167\n",
      "iteration 105300 / 120000: loss 0.000000\n",
      "iteration 105400 / 120000: loss 0.000000\n",
      "iteration 105500 / 120000: loss 0.000000\n",
      "iteration 105600 / 120000: loss 331.482597\n",
      "iteration 105700 / 120000: loss 0.000000\n",
      "iteration 105800 / 120000: loss 0.000000\n",
      "iteration 105900 / 120000: loss 0.000000\n",
      "iteration 106000 / 120000: loss 0.000000\n",
      "iteration 106100 / 120000: loss 161.249547\n",
      "iteration 106200 / 120000: loss 0.000000\n",
      "iteration 106300 / 120000: loss 0.000000\n",
      "iteration 106400 / 120000: loss 0.000000\n",
      "iteration 106500 / 120000: loss 0.000000\n",
      "iteration 106600 / 120000: loss 0.849017\n",
      "iteration 106700 / 120000: loss 0.000000\n",
      "iteration 106800 / 120000: loss 536.260503\n",
      "iteration 106900 / 120000: loss 227.157824\n",
      "iteration 107000 / 120000: loss 0.000000\n",
      "iteration 107100 / 120000: loss 0.000000\n",
      "iteration 107200 / 120000: loss 0.000000\n",
      "iteration 107300 / 120000: loss 0.000000\n",
      "iteration 107400 / 120000: loss 0.000000\n",
      "iteration 107500 / 120000: loss 0.000000\n",
      "iteration 107600 / 120000: loss 0.000000\n",
      "iteration 107700 / 120000: loss 38.227464\n",
      "iteration 107800 / 120000: loss 0.000000\n",
      "iteration 107900 / 120000: loss 0.000000\n",
      "iteration 108000 / 120000: loss 0.000000\n",
      "iteration 108100 / 120000: loss 0.000000\n",
      "iteration 108200 / 120000: loss 0.000000\n",
      "iteration 108300 / 120000: loss 0.000000\n",
      "iteration 108400 / 120000: loss 0.000000\n",
      "iteration 108500 / 120000: loss 0.000000\n",
      "iteration 108600 / 120000: loss 233.371374\n",
      "iteration 108700 / 120000: loss 0.000000\n",
      "iteration 108800 / 120000: loss 572.327448\n",
      "iteration 108900 / 120000: loss 0.000000\n",
      "iteration 109000 / 120000: loss 0.000000\n",
      "iteration 109100 / 120000: loss 0.000000\n",
      "iteration 109200 / 120000: loss 0.000000\n",
      "iteration 109300 / 120000: loss 0.000000\n",
      "iteration 109400 / 120000: loss 0.000000\n",
      "iteration 109500 / 120000: loss 0.000000\n",
      "iteration 109600 / 120000: loss 0.000000\n",
      "iteration 109700 / 120000: loss 0.000000\n",
      "iteration 109800 / 120000: loss 0.000000\n",
      "iteration 109900 / 120000: loss 0.000000\n",
      "iteration 110000 / 120000: loss 0.000000\n",
      "iteration 110100 / 120000: loss 0.000000\n",
      "iteration 110200 / 120000: loss 118.606845\n",
      "iteration 110300 / 120000: loss 0.000000\n",
      "iteration 110400 / 120000: loss 0.000000\n",
      "iteration 110500 / 120000: loss 0.000000\n",
      "iteration 110600 / 120000: loss 0.000000\n",
      "iteration 110700 / 120000: loss 16.414028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 110800 / 120000: loss 0.000000\n",
      "iteration 110900 / 120000: loss 0.000000\n",
      "iteration 111000 / 120000: loss 280.380761\n",
      "iteration 111100 / 120000: loss 0.000000\n",
      "iteration 111200 / 120000: loss 0.000000\n",
      "iteration 111300 / 120000: loss 0.000000\n",
      "iteration 111400 / 120000: loss 43.939007\n",
      "iteration 111500 / 120000: loss 0.000000\n",
      "iteration 111600 / 120000: loss 0.000000\n",
      "iteration 111700 / 120000: loss 0.000000\n",
      "iteration 111800 / 120000: loss 0.000000\n",
      "iteration 111900 / 120000: loss 0.000000\n",
      "iteration 112000 / 120000: loss 0.000000\n",
      "iteration 112100 / 120000: loss 0.000000\n",
      "iteration 112200 / 120000: loss 256.902049\n",
      "iteration 112300 / 120000: loss 0.000000\n",
      "iteration 112400 / 120000: loss 0.000000\n",
      "iteration 112500 / 120000: loss 0.000000\n",
      "iteration 112600 / 120000: loss 0.000000\n",
      "iteration 112700 / 120000: loss 0.000000\n",
      "iteration 112800 / 120000: loss 0.000000\n",
      "iteration 112900 / 120000: loss 0.000000\n",
      "iteration 113000 / 120000: loss 0.000000\n",
      "iteration 113100 / 120000: loss 0.000000\n",
      "iteration 113200 / 120000: loss 0.000000\n",
      "iteration 113300 / 120000: loss 0.000000\n",
      "iteration 113400 / 120000: loss 0.000000\n",
      "iteration 113500 / 120000: loss 96.225018\n",
      "iteration 113600 / 120000: loss 0.000000\n",
      "iteration 113700 / 120000: loss 0.000000\n",
      "iteration 113800 / 120000: loss 0.000000\n",
      "iteration 113900 / 120000: loss 0.000000\n",
      "iteration 114000 / 120000: loss 0.000000\n",
      "iteration 114100 / 120000: loss 0.000000\n",
      "iteration 114200 / 120000: loss 0.000000\n",
      "iteration 114300 / 120000: loss 91.092442\n",
      "iteration 114400 / 120000: loss 0.000000\n",
      "iteration 114500 / 120000: loss 0.000000\n",
      "iteration 114600 / 120000: loss 66.986844\n",
      "iteration 114700 / 120000: loss 0.000000\n",
      "iteration 114800 / 120000: loss 0.000000\n",
      "iteration 114900 / 120000: loss 0.000000\n",
      "iteration 115000 / 120000: loss 0.000000\n",
      "iteration 115100 / 120000: loss 0.000000\n",
      "iteration 115200 / 120000: loss 0.000000\n",
      "iteration 115300 / 120000: loss 0.000000\n",
      "iteration 115400 / 120000: loss 0.000000\n",
      "iteration 115500 / 120000: loss 0.000000\n",
      "iteration 115600 / 120000: loss 0.000000\n",
      "iteration 115700 / 120000: loss 0.000000\n",
      "iteration 115800 / 120000: loss 0.000000\n",
      "iteration 115900 / 120000: loss 0.000000\n",
      "iteration 116000 / 120000: loss 0.000000\n",
      "iteration 116100 / 120000: loss 210.086305\n",
      "iteration 116200 / 120000: loss 0.000000\n",
      "iteration 116300 / 120000: loss 394.924427\n",
      "iteration 116400 / 120000: loss 0.000000\n",
      "iteration 116500 / 120000: loss 0.000000\n",
      "iteration 116600 / 120000: loss 348.148300\n",
      "iteration 116700 / 120000: loss 0.000000\n",
      "iteration 116800 / 120000: loss 0.000000\n",
      "iteration 116900 / 120000: loss 0.000000\n",
      "iteration 117000 / 120000: loss 0.000000\n",
      "iteration 117100 / 120000: loss 0.000000\n",
      "iteration 117200 / 120000: loss 0.000000\n",
      "iteration 117300 / 120000: loss 0.000000\n",
      "iteration 117400 / 120000: loss 0.000000\n",
      "iteration 117500 / 120000: loss 0.000000\n",
      "iteration 117600 / 120000: loss 0.000000\n",
      "iteration 117700 / 120000: loss 0.000000\n",
      "iteration 117800 / 120000: loss 0.000000\n",
      "iteration 117900 / 120000: loss 0.000000\n",
      "iteration 118000 / 120000: loss 0.000000\n",
      "iteration 118100 / 120000: loss 0.000000\n",
      "iteration 118200 / 120000: loss 0.000000\n",
      "iteration 118300 / 120000: loss 326.239716\n",
      "iteration 118400 / 120000: loss 0.000000\n",
      "iteration 118500 / 120000: loss 133.410410\n",
      "iteration 118600 / 120000: loss 330.374210\n",
      "iteration 118700 / 120000: loss 0.000000\n",
      "iteration 118800 / 120000: loss 0.000000\n",
      "iteration 118900 / 120000: loss 0.000000\n",
      "iteration 119000 / 120000: loss 0.000000\n",
      "iteration 119100 / 120000: loss 0.000000\n",
      "iteration 119200 / 120000: loss 0.000000\n",
      "iteration 119300 / 120000: loss 0.000000\n",
      "iteration 119400 / 120000: loss 0.000000\n",
      "iteration 119500 / 120000: loss 0.000000\n",
      "iteration 119600 / 120000: loss 0.000000\n",
      "iteration 119700 / 120000: loss 0.000000\n",
      "iteration 119800 / 120000: loss 97.791733\n",
      "iteration 119900 / 120000: loss 0.000000\n",
      "iteration 0 / 1200: loss 525.758638\n",
      "iteration 100 / 1200: loss 254.331833\n",
      "iteration 200 / 1200: loss 371.044142\n",
      "iteration 300 / 1200: loss 309.955090\n",
      "iteration 400 / 1200: loss 249.560452\n",
      "iteration 500 / 1200: loss 276.652829\n",
      "iteration 600 / 1200: loss 184.321865\n",
      "iteration 700 / 1200: loss 226.757521\n",
      "iteration 800 / 1200: loss 149.271429\n",
      "iteration 900 / 1200: loss 111.858400\n",
      "iteration 1000 / 1200: loss 189.968160\n",
      "iteration 1100 / 1200: loss 203.912154\n",
      "iteration 0 / 600: loss 420.610870\n",
      "iteration 100 / 600: loss 362.833671\n",
      "iteration 200 / 600: loss 406.081653\n",
      "iteration 300 / 600: loss 337.684743\n",
      "iteration 400 / 600: loss 277.019615\n",
      "iteration 500 / 600: loss 283.058701\n",
      "iteration 0 / 240: loss 390.496052\n",
      "iteration 100 / 240: loss 284.926427\n",
      "iteration 200 / 240: loss 258.732093\n",
      "iteration 0 / 12: loss 366.405131\n",
      "lr 1.000000e-07 batch_size 1.000000e+00 train accuracy: 0.716700 val accuracy: 0.733000\n",
      "lr 1.000000e-07 batch_size 1.000000e+02 train accuracy: 0.523400 val accuracy: 0.552000\n",
      "lr 1.000000e-07 batch_size 2.000000e+02 train accuracy: 0.536900 val accuracy: 0.529000\n",
      "lr 1.000000e-07 batch_size 5.000000e+02 train accuracy: 0.672800 val accuracy: 0.692000\n",
      "lr 1.000000e-07 batch_size 1.000000e+04 train accuracy: 0.386400 val accuracy: 0.381000\n",
      "lr 5.000000e-06 batch_size 1.000000e+00 train accuracy: 0.776600 val accuracy: 0.736000\n",
      "lr 5.000000e-06 batch_size 1.000000e+02 train accuracy: 0.697300 val accuracy: 0.700000\n",
      "lr 5.000000e-06 batch_size 2.000000e+02 train accuracy: 0.623700 val accuracy: 0.634000\n",
      "lr 5.000000e-06 batch_size 5.000000e+02 train accuracy: 0.638700 val accuracy: 0.627000\n",
      "lr 5.000000e-06 batch_size 1.000000e+04 train accuracy: 0.567300 val accuracy: 0.566000\n",
      "best validation accuracy achieved during cross-validation: -1.000000\n",
      "linear perceptron on raw pixels final test set accuracy: 0.591000\n"
     ]
    }
   ],
   "source": [
    "# You are encouraged to experiment with additional values\n",
    "learning_rates = [1e-7, 5e-6]\n",
    "batch_sizes = [1, 100, 200, 500, 10000]\n",
    "\n",
    "results = {}\n",
    "best_val = -1   # The highest validation accuracy that we have seen so far.\n",
    "best_perceptron = None # The LinearPerceptron object that achieved the highest validation rate.\n",
    "\n",
    "################################################################################\n",
    "#                            START OF YOUR CODE                                #\n",
    "################################################################################\n",
    "epochs = 200*600/X_train.shape[0]\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        num_iters = int(epochs*X_train.shape[0]/bs)\n",
    "        lp = LinearPerceptron(X_train, y_train)\n",
    "        _ = lp.train(X_train, y_train, learning_rate=lr, num_iters=num_iters,batch_size=bs,verbose=True)\n",
    "        val_accuracy = lp.calc_accuracy(X_val, y_val)\n",
    "        train_accuracy = lp.calc_accuracy(X_train, y_train)\n",
    "        results[(lr, bs)] = (train_accuracy,val_accuracy)\n",
    "        \n",
    "        if val_accuracy > best_val:\n",
    "            best_val = val_accuracy\n",
    "            best_perceptron = lp\n",
    "            \n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, batch_size in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, batch_size)]\n",
    "    print ('lr %e batch_size %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, batch_size, train_accuracy, val_accuracy))\n",
    "\n",
    "\n",
    "print ('best validation accuracy achieved during cross-validation: %f' % best_val)\n",
    "\n",
    "test_accuracy = best_perceptron.calc_accuracy(X_test, y_test)\n",
    "print ('linear perceptron on raw pixels final test set accuracy: %f' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = best_perceptron.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 2)\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "classes = ['plane', 'car']\n",
    "for i in range(2):\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "Another choice for a binary classifier is the binary logistic regression classifier. Unlike the perceptron which treats the outputs as uncalibrated and possibly difficult to interpret scores for each class, the binary logistic regression classifier gives a slightly more intuitive output in the form of normalized class probabilities. In this classifier, the function mapping $f(x_i; W, b) = W\\cdot x_i + b$ stays unchanged but we now interpret these scores as the unnormalized log probabilities for each class and replace the hinge loss with a cross-entropy loss. In this exercise, we will define our binary logistic regression classifier to have one input.       \n",
    "\n",
    "Open the file `functions/classifier.py`. The constructor of the `LogisticRegression` class takes as input the dataset and labels in order to create appropriate parameters. Notice we are using the bias trick and only use the matrix `w` for convenience. Since we already have a (random) model, we can start predicting classes on images. Complete the method `predict` in the `LogisticRegression` class - remember you need to implement the sigmoid function before you can obtain predictions using your classifier. (**2.5 points**)\n",
    "\n",
    "**Important note**: values passed to the `sigmoid` function can be arbitrarily large or small. When we take the exponent of such values, we might encounter extreme values that might *overflow*. This is known as numerical instability and you should always take care when you use exponent in your functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(X_train, y_train)\n",
    "y_pred = logistic.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        plane           car           car         plane\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:11: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_batch, y_batch = get_batch(X_train, y_train, 4)\n",
    "plt.imshow(make_random_grid(X_batch, y_batch));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        plane           car           car           car\n"
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "print(' '.join('%13s' % classes[y_pred[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Complete the class method `calc_accuracy` in the `LinearClassifier` located in `functions/classifier.py`. (**2.5 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model accuracy:  [0.5796]\n"
     ]
    }
   ],
   "source": [
    "print(\"model accuracy: \", logistic.calc_accuracy(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary cross-entropy (30 points)\n",
    "\n",
    "Your code for this section will all be written inside **functions/losses.py**. \n",
    "\n",
    "Complete the function `binary_cross_entropy` using vectorized code. This function takes as input the weights, data, labels and a regularization term and outputs the calculated loss as a single number and the gradients with respect to W. (**10 points**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.randn(3073, 1) * 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 675.952212\n",
      "CPU times: user 11.6 ms, sys: 3.58 ms, total: 15.1 ms\n",
      "Wall time: 16.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "loss_naive, grad_naive = binary_cross_entropy(W, X_val, y_val)\n",
    "print ('loss: %f' % (loss_naive, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: 12254.677088 analytic: 12254.676922, relative error: 6.743897e-09\n",
      "numerical: -2843.607026 analytic: -2843.607107, relative error: 1.417219e-08\n",
      "numerical: 4454.527029 analytic: 4454.526992, relative error: 4.234694e-09\n",
      "numerical: 8577.605982 analytic: 8577.606004, relative error: 1.293165e-09\n",
      "numerical: 11957.008517 analytic: 11957.008528, relative error: 4.560905e-10\n",
      "numerical: 11614.737426 analytic: 11614.737330, relative error: 4.166928e-09\n",
      "numerical: 8755.382205 analytic: 8755.381998, relative error: 1.186841e-08\n",
      "numerical: 13658.173337 analytic: 13658.173215, relative error: 4.458530e-09\n",
      "numerical: 534.284930 analytic: 534.284785, relative error: 1.357876e-07\n",
      "numerical: 8124.478488 analytic: 8124.478271, relative error: 1.336456e-08\n"
     ]
    }
   ],
   "source": [
    "loss, grad = binary_cross_entropy(W, X_val, y_val)\n",
    "f = lambda w: binary_cross_entropy(w, X_val, y_val)[0]\n",
    "grad_numerical = grad_check(f, W, grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If implemented correctly, the training procedure you already implemented should work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 1500: loss 152.995856\n",
      "iteration 100 / 1500: loss 714.079604\n",
      "iteration 200 / 1500: loss 282.805945\n",
      "iteration 300 / 1500: loss 314.450220\n",
      "iteration 400 / 1500: loss 852.251995\n",
      "iteration 500 / 1500: loss 148.653884\n",
      "iteration 600 / 1500: loss 366.819065\n",
      "iteration 700 / 1500: loss 219.586917\n",
      "iteration 800 / 1500: loss 85.142033\n",
      "iteration 900 / 1500: loss 152.118032\n",
      "iteration 1000 / 1500: loss 389.980677\n",
      "iteration 1100 / 1500: loss 643.958543\n",
      "iteration 1200 / 1500: loss 146.844491\n",
      "iteration 1300 / 1500: loss 202.859145\n",
      "iteration 1400 / 1500: loss 836.625430\n",
      "CPU times: user 4.61 s, sys: 324 ms, total: 4.94 s\n",
      "Wall time: 2.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logistic = LogisticRegression(X_train, y_train)\n",
    "loss_history = logistic.train(X_train, y_train, \n",
    "                         learning_rate=1e-7,\n",
    "                         num_iters=1500,\n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.xlabel('Iteration number')\n",
    "plt.ylabel('Loss value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  [0.8053]\n",
      "Testing accuracy:  [0.804]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training accuracy: \", logistic.calc_accuracy(X_train, y_train))\n",
    "print(\"Testing accuracy: \", logistic.calc_accuracy(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization\n",
    "\n",
    "Your model should have improved from 50% accuracy to ~75% accuracy in a matter of seconds. Now, use the validation set to tune hyperparameters by training different models (using the training dataset) and evaluating the performance using the validation dataset. Save the results in a dictionary mapping tuples of the form `(learning_rate, batch_size)` to tuples of the form `(training_accuracy, validation_accuracy)`. Finally, you should evaluate the best model on the testing dataset. \n",
    "\n",
    "Note: When changing the batch_size, change the number of iterations accordingly such that the number of epochs on the data stays roughly the same. A reasonable ratio is 600 iterations for a batch size of 200. \n",
    "\n",
    "If you are carful you should reach ~83% accuracy on the validation dataset.\n",
    "\n",
    "Use a small value for the number of iterations as you develop your code. Once you are confident that everything works, run it again for more iterations. Finally, explain the results - what can you learn from the hyper parameters that yields the best results? Why do you think that is the case? **(5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 120000: loss 0.510205\n",
      "iteration 100 / 120000: loss 0.761476\n",
      "iteration 200 / 120000: loss 1.264493\n",
      "iteration 300 / 120000: loss 1.095027\n",
      "iteration 400 / 120000: loss 1.050029\n",
      "iteration 500 / 120000: loss 0.458279\n",
      "iteration 600 / 120000: loss 0.220641\n",
      "iteration 700 / 120000: loss 0.165147\n",
      "iteration 800 / 120000: loss 0.014918\n",
      "iteration 900 / 120000: loss 1.399836\n",
      "iteration 1000 / 120000: loss 1.058271\n",
      "iteration 1100 / 120000: loss 0.358603\n",
      "iteration 1200 / 120000: loss 0.007780\n",
      "iteration 1300 / 120000: loss 0.158842\n",
      "iteration 1400 / 120000: loss 2.350961\n",
      "iteration 1500 / 120000: loss 0.429368\n",
      "iteration 1600 / 120000: loss 0.268336\n",
      "iteration 1700 / 120000: loss 0.165167\n",
      "iteration 1800 / 120000: loss 0.574513\n",
      "iteration 1900 / 120000: loss 0.504218\n",
      "iteration 2000 / 120000: loss 0.858677\n",
      "iteration 2100 / 120000: loss 0.239370\n",
      "iteration 2200 / 120000: loss 0.231505\n",
      "iteration 2300 / 120000: loss 0.146539\n",
      "iteration 2400 / 120000: loss 0.085568\n",
      "iteration 2500 / 120000: loss 0.835892\n",
      "iteration 2600 / 120000: loss 0.805095\n",
      "iteration 2700 / 120000: loss 0.533660\n",
      "iteration 2800 / 120000: loss 0.488612\n",
      "iteration 2900 / 120000: loss 0.098176\n",
      "iteration 3000 / 120000: loss 0.049053\n",
      "iteration 3100 / 120000: loss 1.453555\n",
      "iteration 3200 / 120000: loss 0.390168\n",
      "iteration 3300 / 120000: loss 0.174802\n",
      "iteration 3400 / 120000: loss 0.346307\n",
      "iteration 3500 / 120000: loss 0.764684\n",
      "iteration 3600 / 120000: loss 0.126081\n",
      "iteration 3700 / 120000: loss 1.304917\n",
      "iteration 3800 / 120000: loss 0.108055\n",
      "iteration 3900 / 120000: loss 0.952841\n",
      "iteration 4000 / 120000: loss 0.057873\n",
      "iteration 4100 / 120000: loss 0.007881\n",
      "iteration 4200 / 120000: loss 0.773503\n",
      "iteration 4300 / 120000: loss 0.032669\n",
      "iteration 4400 / 120000: loss 0.030602\n",
      "iteration 4500 / 120000: loss 0.143108\n",
      "iteration 4600 / 120000: loss 0.027598\n",
      "iteration 4700 / 120000: loss 0.320746\n",
      "iteration 4800 / 120000: loss 0.448294\n",
      "iteration 4900 / 120000: loss 0.001900\n",
      "iteration 5000 / 120000: loss 0.258675\n",
      "iteration 5100 / 120000: loss 0.032198\n",
      "iteration 5200 / 120000: loss 0.087335\n",
      "iteration 5300 / 120000: loss 0.432106\n",
      "iteration 5400 / 120000: loss 2.289241\n",
      "iteration 5500 / 120000: loss 0.042022\n",
      "iteration 5600 / 120000: loss 0.077499\n",
      "iteration 5700 / 120000: loss 0.209606\n",
      "iteration 5800 / 120000: loss 1.433121\n",
      "iteration 5900 / 120000: loss 1.369060\n",
      "iteration 6000 / 120000: loss 0.085359\n",
      "iteration 6100 / 120000: loss 0.010167\n",
      "iteration 6200 / 120000: loss 0.061758\n",
      "iteration 6300 / 120000: loss 0.308524\n",
      "iteration 6400 / 120000: loss 0.001786\n",
      "iteration 6500 / 120000: loss 0.340537\n",
      "iteration 6600 / 120000: loss 0.129597\n",
      "iteration 6700 / 120000: loss 0.146481\n",
      "iteration 6800 / 120000: loss 0.302786\n",
      "iteration 6900 / 120000: loss 0.226288\n",
      "iteration 7000 / 120000: loss 0.216199\n",
      "iteration 7100 / 120000: loss 0.212329\n",
      "iteration 7200 / 120000: loss 0.000600\n",
      "iteration 7300 / 120000: loss 0.662118\n",
      "iteration 7400 / 120000: loss 0.985941\n",
      "iteration 7500 / 120000: loss 0.018888\n",
      "iteration 7600 / 120000: loss 1.017633\n",
      "iteration 7700 / 120000: loss 0.004599\n",
      "iteration 7800 / 120000: loss 0.026787\n",
      "iteration 7900 / 120000: loss 0.646464\n",
      "iteration 8000 / 120000: loss 0.650639\n",
      "iteration 8100 / 120000: loss 0.447067\n",
      "iteration 8200 / 120000: loss 0.139167\n",
      "iteration 8300 / 120000: loss 1.682279\n",
      "iteration 8400 / 120000: loss 0.037927\n",
      "iteration 8500 / 120000: loss 1.883100\n",
      "iteration 8600 / 120000: loss 1.481461\n",
      "iteration 8700 / 120000: loss 0.147008\n",
      "iteration 8800 / 120000: loss 0.275054\n",
      "iteration 8900 / 120000: loss 0.050543\n",
      "iteration 9000 / 120000: loss 0.017239\n",
      "iteration 9100 / 120000: loss 0.143289\n",
      "iteration 9200 / 120000: loss 0.034327\n",
      "iteration 9300 / 120000: loss 0.566346\n",
      "iteration 9400 / 120000: loss 0.832408\n",
      "iteration 9500 / 120000: loss 0.032859\n",
      "iteration 9600 / 120000: loss 0.351048\n",
      "iteration 9700 / 120000: loss 0.064821\n",
      "iteration 9800 / 120000: loss 0.001894\n",
      "iteration 9900 / 120000: loss 0.362914\n",
      "iteration 10000 / 120000: loss 0.006704\n",
      "iteration 10100 / 120000: loss 0.390512\n",
      "iteration 10200 / 120000: loss 0.336049\n",
      "iteration 10300 / 120000: loss 0.488669\n",
      "iteration 10400 / 120000: loss 0.011862\n",
      "iteration 10500 / 120000: loss 0.677737\n",
      "iteration 10600 / 120000: loss 0.189672\n",
      "iteration 10700 / 120000: loss 0.095559\n",
      "iteration 10800 / 120000: loss 0.169879\n",
      "iteration 10900 / 120000: loss 0.175923\n",
      "iteration 11000 / 120000: loss 0.049723\n",
      "iteration 11100 / 120000: loss 3.120766\n",
      "iteration 11200 / 120000: loss 0.438535\n",
      "iteration 11300 / 120000: loss 2.099865\n",
      "iteration 11400 / 120000: loss 0.009190\n",
      "iteration 11500 / 120000: loss 0.493918\n",
      "iteration 11600 / 120000: loss 0.033437\n",
      "iteration 11700 / 120000: loss 0.211295\n",
      "iteration 11800 / 120000: loss 0.321333\n",
      "iteration 11900 / 120000: loss 0.178420\n",
      "iteration 12000 / 120000: loss 0.017475\n",
      "iteration 12100 / 120000: loss 0.348048\n",
      "iteration 12200 / 120000: loss 0.405638\n",
      "iteration 12300 / 120000: loss 0.939831\n",
      "iteration 12400 / 120000: loss 0.090637\n",
      "iteration 12500 / 120000: loss 0.442320\n",
      "iteration 12600 / 120000: loss 0.031700\n",
      "iteration 12700 / 120000: loss 0.034957\n",
      "iteration 12800 / 120000: loss 0.002371\n",
      "iteration 12900 / 120000: loss 0.091202\n",
      "iteration 13000 / 120000: loss 0.122100\n",
      "iteration 13100 / 120000: loss 0.128676\n",
      "iteration 13200 / 120000: loss 0.106805\n",
      "iteration 13300 / 120000: loss 0.117550\n",
      "iteration 13400 / 120000: loss 0.025066\n",
      "iteration 13500 / 120000: loss 1.594090\n",
      "iteration 13600 / 120000: loss 0.001635\n",
      "iteration 13700 / 120000: loss 0.892011\n",
      "iteration 13800 / 120000: loss 0.095263\n",
      "iteration 13900 / 120000: loss 0.356066\n",
      "iteration 14000 / 120000: loss 0.249950\n",
      "iteration 14100 / 120000: loss 0.039648\n",
      "iteration 14200 / 120000: loss 0.020551\n",
      "iteration 14300 / 120000: loss 1.461181\n",
      "iteration 14400 / 120000: loss 0.531961\n",
      "iteration 14500 / 120000: loss 0.021864\n",
      "iteration 14600 / 120000: loss 1.763946\n",
      "iteration 14700 / 120000: loss 0.043664\n",
      "iteration 14800 / 120000: loss 0.066277\n",
      "iteration 14900 / 120000: loss 0.430158\n",
      "iteration 15000 / 120000: loss 0.096603\n",
      "iteration 15100 / 120000: loss 0.077295\n",
      "iteration 15200 / 120000: loss 0.245365\n",
      "iteration 15300 / 120000: loss 0.138772\n",
      "iteration 15400 / 120000: loss 0.383610\n",
      "iteration 15500 / 120000: loss 0.117369\n",
      "iteration 15600 / 120000: loss 0.653171\n",
      "iteration 15700 / 120000: loss 0.012029\n",
      "iteration 15800 / 120000: loss 1.198844\n",
      "iteration 15900 / 120000: loss 0.274687\n",
      "iteration 16000 / 120000: loss 0.049270\n",
      "iteration 16100 / 120000: loss 0.011845\n",
      "iteration 16200 / 120000: loss 0.415016\n",
      "iteration 16300 / 120000: loss 0.623977\n",
      "iteration 16400 / 120000: loss 0.341025\n",
      "iteration 16500 / 120000: loss 0.142332\n",
      "iteration 16600 / 120000: loss 0.006683\n",
      "iteration 16700 / 120000: loss 0.146027\n",
      "iteration 16800 / 120000: loss 0.320854\n",
      "iteration 16900 / 120000: loss 0.385739\n",
      "iteration 17000 / 120000: loss 0.038016\n",
      "iteration 17100 / 120000: loss 1.128109\n",
      "iteration 17200 / 120000: loss 0.012547\n",
      "iteration 17300 / 120000: loss 2.042489\n",
      "iteration 17400 / 120000: loss 3.555510\n",
      "iteration 17500 / 120000: loss 0.042913\n",
      "iteration 17600 / 120000: loss 0.251630\n",
      "iteration 17700 / 120000: loss 0.069902\n",
      "iteration 17800 / 120000: loss 1.177862\n",
      "iteration 17900 / 120000: loss 0.350332\n",
      "iteration 18000 / 120000: loss 0.188576\n",
      "iteration 18100 / 120000: loss 0.055834\n",
      "iteration 18200 / 120000: loss 0.291255\n",
      "iteration 18300 / 120000: loss 0.217475\n",
      "iteration 18400 / 120000: loss 2.620683\n",
      "iteration 18500 / 120000: loss 0.136318\n",
      "iteration 18600 / 120000: loss 0.006598\n",
      "iteration 18700 / 120000: loss 0.189407\n",
      "iteration 18800 / 120000: loss 0.437454\n",
      "iteration 18900 / 120000: loss 0.750516\n",
      "iteration 19000 / 120000: loss 1.003033\n",
      "iteration 19100 / 120000: loss 0.035209\n",
      "iteration 19200 / 120000: loss 0.029672\n",
      "iteration 19300 / 120000: loss 0.025611\n",
      "iteration 19400 / 120000: loss 0.164730\n",
      "iteration 19500 / 120000: loss 0.035385\n",
      "iteration 19600 / 120000: loss 0.108857\n",
      "iteration 19700 / 120000: loss 0.005345\n",
      "iteration 19800 / 120000: loss 0.007946\n",
      "iteration 19900 / 120000: loss 0.703209\n",
      "iteration 20000 / 120000: loss 0.001961\n",
      "iteration 20100 / 120000: loss 0.640034\n",
      "iteration 20200 / 120000: loss 0.162274\n",
      "iteration 20300 / 120000: loss 0.006720\n",
      "iteration 20400 / 120000: loss 0.022368\n",
      "iteration 20500 / 120000: loss 0.151139\n",
      "iteration 20600 / 120000: loss 0.053923\n",
      "iteration 20700 / 120000: loss 0.058072\n",
      "iteration 20800 / 120000: loss 0.004094\n",
      "iteration 20900 / 120000: loss 1.581793\n",
      "iteration 21000 / 120000: loss 0.285352\n",
      "iteration 21100 / 120000: loss 0.091648\n",
      "iteration 21200 / 120000: loss 1.818945\n",
      "iteration 21300 / 120000: loss 0.248253\n",
      "iteration 21400 / 120000: loss 0.007214\n",
      "iteration 21500 / 120000: loss 0.271539\n",
      "iteration 21600 / 120000: loss 0.715072\n",
      "iteration 21700 / 120000: loss 0.062229\n",
      "iteration 21800 / 120000: loss 0.164766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 21900 / 120000: loss 0.246745\n",
      "iteration 22000 / 120000: loss 0.070205\n",
      "iteration 22100 / 120000: loss 1.197329\n",
      "iteration 22200 / 120000: loss 0.277815\n",
      "iteration 22300 / 120000: loss 0.069844\n",
      "iteration 22400 / 120000: loss 0.279978\n",
      "iteration 22500 / 120000: loss 0.467296\n",
      "iteration 22600 / 120000: loss 0.392829\n",
      "iteration 22700 / 120000: loss 0.324019\n",
      "iteration 22800 / 120000: loss 1.008880\n",
      "iteration 22900 / 120000: loss 0.263505\n",
      "iteration 23000 / 120000: loss 0.127649\n",
      "iteration 23100 / 120000: loss 0.030542\n",
      "iteration 23200 / 120000: loss 0.989215\n",
      "iteration 23300 / 120000: loss 0.020384\n",
      "iteration 23400 / 120000: loss 0.249012\n",
      "iteration 23500 / 120000: loss 0.558178\n",
      "iteration 23600 / 120000: loss 0.159513\n",
      "iteration 23700 / 120000: loss 0.010345\n",
      "iteration 23800 / 120000: loss 0.012517\n",
      "iteration 23900 / 120000: loss 0.676055\n",
      "iteration 24000 / 120000: loss 0.341307\n",
      "iteration 24100 / 120000: loss 0.007585\n",
      "iteration 24200 / 120000: loss 0.087348\n",
      "iteration 24300 / 120000: loss 0.200998\n",
      "iteration 24400 / 120000: loss 1.324109\n",
      "iteration 24500 / 120000: loss 0.006434\n",
      "iteration 24600 / 120000: loss 0.003853\n",
      "iteration 24700 / 120000: loss 0.502211\n",
      "iteration 24800 / 120000: loss 0.240068\n",
      "iteration 24900 / 120000: loss 0.007617\n",
      "iteration 25000 / 120000: loss 0.014552\n",
      "iteration 25100 / 120000: loss 0.354115\n",
      "iteration 25200 / 120000: loss 0.028314\n",
      "iteration 25300 / 120000: loss 0.082904\n",
      "iteration 25400 / 120000: loss 0.000377\n",
      "iteration 25500 / 120000: loss 0.259186\n",
      "iteration 25600 / 120000: loss 0.026619\n",
      "iteration 25700 / 120000: loss 2.209030\n",
      "iteration 25800 / 120000: loss 0.454979\n",
      "iteration 25900 / 120000: loss 0.836825\n",
      "iteration 26000 / 120000: loss 0.119036\n",
      "iteration 26100 / 120000: loss 0.269201\n",
      "iteration 26200 / 120000: loss 0.046828\n",
      "iteration 26300 / 120000: loss 0.886687\n",
      "iteration 26400 / 120000: loss 0.203377\n",
      "iteration 26500 / 120000: loss 0.596228\n",
      "iteration 26600 / 120000: loss 0.838672\n",
      "iteration 26700 / 120000: loss 0.026500\n",
      "iteration 26800 / 120000: loss 0.968977\n",
      "iteration 26900 / 120000: loss 2.152422\n",
      "iteration 27000 / 120000: loss 0.010462\n",
      "iteration 27100 / 120000: loss 0.007465\n",
      "iteration 27200 / 120000: loss 0.141407\n",
      "iteration 27300 / 120000: loss 0.034139\n",
      "iteration 27400 / 120000: loss 0.010028\n",
      "iteration 27500 / 120000: loss 0.008002\n",
      "iteration 27600 / 120000: loss 0.007377\n",
      "iteration 27700 / 120000: loss 1.697011\n",
      "iteration 27800 / 120000: loss 1.567101\n",
      "iteration 27900 / 120000: loss 1.196938\n",
      "iteration 28000 / 120000: loss 0.004731\n",
      "iteration 28100 / 120000: loss 0.001979\n",
      "iteration 28200 / 120000: loss 0.096456\n",
      "iteration 28300 / 120000: loss 0.003661\n",
      "iteration 28400 / 120000: loss 0.004557\n",
      "iteration 28500 / 120000: loss 0.615757\n",
      "iteration 28600 / 120000: loss 0.008517\n",
      "iteration 28700 / 120000: loss 0.012772\n",
      "iteration 28800 / 120000: loss 2.046455\n",
      "iteration 28900 / 120000: loss 0.160080\n",
      "iteration 29000 / 120000: loss 0.460461\n",
      "iteration 29100 / 120000: loss 2.508237\n",
      "iteration 29200 / 120000: loss 0.049494\n",
      "iteration 29300 / 120000: loss 2.452017\n",
      "iteration 29400 / 120000: loss 0.049782\n",
      "iteration 29500 / 120000: loss 0.022469\n",
      "iteration 29600 / 120000: loss 1.188082\n",
      "iteration 29700 / 120000: loss 1.182168\n",
      "iteration 29800 / 120000: loss 0.497104\n",
      "iteration 29900 / 120000: loss 0.004733\n",
      "iteration 30000 / 120000: loss 0.214064\n",
      "iteration 30100 / 120000: loss 0.070410\n",
      "iteration 30200 / 120000: loss 0.018447\n",
      "iteration 30300 / 120000: loss 0.363659\n",
      "iteration 30400 / 120000: loss 0.104324\n",
      "iteration 30500 / 120000: loss 0.015646\n",
      "iteration 30600 / 120000: loss 0.032418\n",
      "iteration 30700 / 120000: loss 0.285533\n",
      "iteration 30800 / 120000: loss 0.428037\n",
      "iteration 30900 / 120000: loss 0.253815\n",
      "iteration 31000 / 120000: loss 0.065231\n",
      "iteration 31100 / 120000: loss 0.004199\n",
      "iteration 31200 / 120000: loss 0.003965\n",
      "iteration 31300 / 120000: loss 0.077326\n",
      "iteration 31400 / 120000: loss 0.020587\n",
      "iteration 31500 / 120000: loss 0.216457\n",
      "iteration 31600 / 120000: loss 0.142261\n",
      "iteration 31700 / 120000: loss 0.046672\n",
      "iteration 31800 / 120000: loss 0.000094\n",
      "iteration 31900 / 120000: loss 0.543382\n",
      "iteration 32000 / 120000: loss 0.035346\n",
      "iteration 32100 / 120000: loss 0.001977\n",
      "iteration 32200 / 120000: loss 0.086001\n",
      "iteration 32300 / 120000: loss 0.103944\n",
      "iteration 32400 / 120000: loss 0.079909\n",
      "iteration 32500 / 120000: loss 2.070756\n",
      "iteration 32600 / 120000: loss 0.175562\n",
      "iteration 32700 / 120000: loss 0.444448\n",
      "iteration 32800 / 120000: loss 0.045904\n",
      "iteration 32900 / 120000: loss 1.502437\n",
      "iteration 33000 / 120000: loss 0.153487\n",
      "iteration 33100 / 120000: loss 0.060506\n",
      "iteration 33200 / 120000: loss 0.097306\n",
      "iteration 33300 / 120000: loss 0.242798\n",
      "iteration 33400 / 120000: loss 0.020855\n",
      "iteration 33500 / 120000: loss 0.084884\n",
      "iteration 33600 / 120000: loss 0.084515\n",
      "iteration 33700 / 120000: loss 0.075964\n",
      "iteration 33800 / 120000: loss 0.079813\n",
      "iteration 33900 / 120000: loss 1.274460\n",
      "iteration 34000 / 120000: loss 0.089717\n",
      "iteration 34100 / 120000: loss 0.794891\n",
      "iteration 34200 / 120000: loss 0.012905\n",
      "iteration 34300 / 120000: loss 0.761990\n",
      "iteration 34400 / 120000: loss 0.105322\n",
      "iteration 34500 / 120000: loss 0.536627\n",
      "iteration 34600 / 120000: loss 0.039508\n",
      "iteration 34700 / 120000: loss 1.480100\n",
      "iteration 34800 / 120000: loss 0.310714\n",
      "iteration 34900 / 120000: loss 0.602608\n",
      "iteration 35000 / 120000: loss 0.249667\n",
      "iteration 35100 / 120000: loss 0.140985\n",
      "iteration 35200 / 120000: loss 0.028471\n",
      "iteration 35300 / 120000: loss 0.197296\n",
      "iteration 35400 / 120000: loss 0.114509\n",
      "iteration 35500 / 120000: loss 0.056908\n",
      "iteration 35600 / 120000: loss 0.011414\n",
      "iteration 35700 / 120000: loss 0.840693\n",
      "iteration 35800 / 120000: loss 0.678691\n",
      "iteration 35900 / 120000: loss 0.731115\n",
      "iteration 36000 / 120000: loss 0.023284\n",
      "iteration 36100 / 120000: loss 0.024279\n",
      "iteration 36200 / 120000: loss 0.028433\n",
      "iteration 36300 / 120000: loss 0.070393\n",
      "iteration 36400 / 120000: loss 0.032492\n",
      "iteration 36500 / 120000: loss 0.124553\n",
      "iteration 36600 / 120000: loss 0.011446\n",
      "iteration 36700 / 120000: loss 0.004381\n",
      "iteration 36800 / 120000: loss 0.128016\n",
      "iteration 36900 / 120000: loss 1.103219\n",
      "iteration 37000 / 120000: loss 1.019444\n",
      "iteration 37100 / 120000: loss 0.001904\n",
      "iteration 37200 / 120000: loss 0.460719\n",
      "iteration 37300 / 120000: loss 0.378014\n",
      "iteration 37400 / 120000: loss 0.863007\n",
      "iteration 37500 / 120000: loss 1.089544\n",
      "iteration 37600 / 120000: loss 3.243454\n",
      "iteration 37700 / 120000: loss 0.049943\n",
      "iteration 37800 / 120000: loss 0.643119\n",
      "iteration 37900 / 120000: loss 0.069631\n",
      "iteration 38000 / 120000: loss 0.198245\n",
      "iteration 38100 / 120000: loss 0.234230\n",
      "iteration 38200 / 120000: loss 0.167995\n",
      "iteration 38300 / 120000: loss 3.615294\n",
      "iteration 38400 / 120000: loss 0.400240\n",
      "iteration 38500 / 120000: loss 0.050971\n",
      "iteration 38600 / 120000: loss 0.007452\n",
      "iteration 38700 / 120000: loss 0.091204\n",
      "iteration 38800 / 120000: loss 0.182301\n",
      "iteration 38900 / 120000: loss 0.108435\n",
      "iteration 39000 / 120000: loss 0.034363\n",
      "iteration 39100 / 120000: loss 0.194851\n",
      "iteration 39200 / 120000: loss 0.975413\n",
      "iteration 39300 / 120000: loss 0.464034\n",
      "iteration 39400 / 120000: loss 0.044487\n",
      "iteration 39500 / 120000: loss 0.106007\n",
      "iteration 39600 / 120000: loss 0.044111\n",
      "iteration 39700 / 120000: loss 0.013303\n",
      "iteration 39800 / 120000: loss 1.894090\n",
      "iteration 39900 / 120000: loss 0.073515\n",
      "iteration 40000 / 120000: loss 0.244171\n",
      "iteration 40100 / 120000: loss 0.195315\n",
      "iteration 40200 / 120000: loss 0.005034\n",
      "iteration 40300 / 120000: loss 0.222002\n",
      "iteration 40400 / 120000: loss 0.040780\n",
      "iteration 40500 / 120000: loss 0.260123\n",
      "iteration 40600 / 120000: loss 0.231267\n",
      "iteration 40700 / 120000: loss 0.011683\n",
      "iteration 40800 / 120000: loss 0.009709\n",
      "iteration 40900 / 120000: loss 4.406102\n",
      "iteration 41000 / 120000: loss 0.004101\n",
      "iteration 41100 / 120000: loss 0.613017\n",
      "iteration 41200 / 120000: loss 0.007333\n",
      "iteration 41300 / 120000: loss 3.127237\n",
      "iteration 41400 / 120000: loss 0.073261\n",
      "iteration 41500 / 120000: loss 0.175013\n",
      "iteration 41600 / 120000: loss 0.188171\n",
      "iteration 41700 / 120000: loss 0.141718\n",
      "iteration 41800 / 120000: loss 0.013032\n",
      "iteration 41900 / 120000: loss 0.434727\n",
      "iteration 42000 / 120000: loss 0.126248\n",
      "iteration 42100 / 120000: loss 0.061323\n",
      "iteration 42200 / 120000: loss 0.186984\n",
      "iteration 42300 / 120000: loss 3.223532\n",
      "iteration 42400 / 120000: loss 0.031914\n",
      "iteration 42500 / 120000: loss 1.650227\n",
      "iteration 42600 / 120000: loss 0.410473\n",
      "iteration 42700 / 120000: loss 0.030962\n",
      "iteration 42800 / 120000: loss 0.233091\n",
      "iteration 42900 / 120000: loss 2.595693\n",
      "iteration 43000 / 120000: loss 0.062828\n",
      "iteration 43100 / 120000: loss 0.174810\n",
      "iteration 43200 / 120000: loss 0.098106\n",
      "iteration 43300 / 120000: loss 0.004892\n",
      "iteration 43400 / 120000: loss 0.009991\n",
      "iteration 43500 / 120000: loss 0.786132\n",
      "iteration 43600 / 120000: loss 0.089948\n",
      "iteration 43700 / 120000: loss 0.319286\n",
      "iteration 43800 / 120000: loss 0.577953\n",
      "iteration 43900 / 120000: loss 0.007477\n",
      "iteration 44000 / 120000: loss 0.498064\n",
      "iteration 44100 / 120000: loss 0.258784\n",
      "iteration 44200 / 120000: loss 0.162362\n",
      "iteration 44300 / 120000: loss 1.133617\n",
      "iteration 44400 / 120000: loss 0.122115\n",
      "iteration 44500 / 120000: loss 0.003906\n",
      "iteration 44600 / 120000: loss 0.464976\n",
      "iteration 44700 / 120000: loss 0.029668\n",
      "iteration 44800 / 120000: loss 0.935698\n",
      "iteration 44900 / 120000: loss 0.091239\n",
      "iteration 45000 / 120000: loss 0.206243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 45100 / 120000: loss 1.760650\n",
      "iteration 45200 / 120000: loss 0.020588\n",
      "iteration 45300 / 120000: loss 0.230240\n",
      "iteration 45400 / 120000: loss 0.192414\n",
      "iteration 45500 / 120000: loss 0.391369\n",
      "iteration 45600 / 120000: loss 0.899351\n",
      "iteration 45700 / 120000: loss 0.016213\n",
      "iteration 45800 / 120000: loss 0.048513\n",
      "iteration 45900 / 120000: loss 0.730975\n",
      "iteration 46000 / 120000: loss 0.019370\n",
      "iteration 46100 / 120000: loss 0.713486\n",
      "iteration 46200 / 120000: loss 0.214040\n",
      "iteration 46300 / 120000: loss 1.036266\n",
      "iteration 46400 / 120000: loss 0.155737\n",
      "iteration 46500 / 120000: loss 0.021147\n",
      "iteration 46600 / 120000: loss 1.296038\n",
      "iteration 46700 / 120000: loss 0.089689\n",
      "iteration 46800 / 120000: loss 5.739792\n",
      "iteration 46900 / 120000: loss 0.511687\n",
      "iteration 47000 / 120000: loss 0.171667\n",
      "iteration 47100 / 120000: loss 0.017870\n",
      "iteration 47200 / 120000: loss 0.030824\n",
      "iteration 47300 / 120000: loss 0.010048\n",
      "iteration 47400 / 120000: loss 0.027398\n",
      "iteration 47500 / 120000: loss 0.030220\n",
      "iteration 47600 / 120000: loss 0.376338\n",
      "iteration 47700 / 120000: loss 0.399021\n",
      "iteration 47800 / 120000: loss 0.151309\n",
      "iteration 47900 / 120000: loss 0.266737\n",
      "iteration 48000 / 120000: loss 0.011002\n",
      "iteration 48100 / 120000: loss 0.028349\n",
      "iteration 48200 / 120000: loss 0.131961\n",
      "iteration 48300 / 120000: loss 0.022605\n",
      "iteration 48400 / 120000: loss 0.103083\n",
      "iteration 48500 / 120000: loss 0.036104\n",
      "iteration 48600 / 120000: loss 0.004942\n",
      "iteration 48700 / 120000: loss 0.016381\n",
      "iteration 48800 / 120000: loss 0.012339\n",
      "iteration 48900 / 120000: loss 0.000487\n",
      "iteration 49000 / 120000: loss 0.397368\n",
      "iteration 49100 / 120000: loss 0.228813\n",
      "iteration 49200 / 120000: loss 0.017848\n",
      "iteration 49300 / 120000: loss 0.061834\n",
      "iteration 49400 / 120000: loss 0.083300\n",
      "iteration 49500 / 120000: loss 0.037890\n",
      "iteration 49600 / 120000: loss 0.108496\n",
      "iteration 49700 / 120000: loss 0.414547\n",
      "iteration 49800 / 120000: loss 0.526114\n",
      "iteration 49900 / 120000: loss 0.062551\n",
      "iteration 50000 / 120000: loss 0.997452\n",
      "iteration 50100 / 120000: loss 0.001042\n",
      "iteration 50200 / 120000: loss 0.031937\n",
      "iteration 50300 / 120000: loss 0.008850\n",
      "iteration 50400 / 120000: loss 0.000072\n",
      "iteration 50500 / 120000: loss 0.061660\n",
      "iteration 50600 / 120000: loss 0.014085\n",
      "iteration 50700 / 120000: loss 0.003115\n",
      "iteration 50800 / 120000: loss 0.144142\n",
      "iteration 50900 / 120000: loss 0.046751\n",
      "iteration 51000 / 120000: loss 2.776475\n",
      "iteration 51100 / 120000: loss 2.495078\n",
      "iteration 51200 / 120000: loss 0.086968\n",
      "iteration 51300 / 120000: loss 0.009932\n",
      "iteration 51400 / 120000: loss 1.864827\n",
      "iteration 51500 / 120000: loss 0.127384\n",
      "iteration 51600 / 120000: loss 0.031842\n",
      "iteration 51700 / 120000: loss 0.237871\n",
      "iteration 51800 / 120000: loss 0.104181\n",
      "iteration 51900 / 120000: loss 0.333034\n",
      "iteration 52000 / 120000: loss 0.420379\n",
      "iteration 52100 / 120000: loss 0.999817\n",
      "iteration 52200 / 120000: loss 0.104896\n",
      "iteration 52300 / 120000: loss 0.212395\n",
      "iteration 52400 / 120000: loss 0.335387\n",
      "iteration 52500 / 120000: loss 0.017626\n",
      "iteration 52600 / 120000: loss 0.126925\n",
      "iteration 52700 / 120000: loss 0.011242\n",
      "iteration 52800 / 120000: loss 0.004563\n",
      "iteration 52900 / 120000: loss 0.000523\n",
      "iteration 53000 / 120000: loss 0.724007\n",
      "iteration 53100 / 120000: loss 0.004153\n",
      "iteration 53200 / 120000: loss 0.271486\n",
      "iteration 53300 / 120000: loss 0.362804\n",
      "iteration 53400 / 120000: loss 0.035231\n",
      "iteration 53500 / 120000: loss 0.612965\n",
      "iteration 53600 / 120000: loss 1.662343\n",
      "iteration 53700 / 120000: loss 0.021913\n",
      "iteration 53800 / 120000: loss 0.005959\n",
      "iteration 53900 / 120000: loss 0.008692\n",
      "iteration 54000 / 120000: loss 0.028195\n",
      "iteration 54100 / 120000: loss 0.001814\n",
      "iteration 54200 / 120000: loss 0.283395\n",
      "iteration 54300 / 120000: loss 0.558576\n",
      "iteration 54400 / 120000: loss 0.054221\n",
      "iteration 54500 / 120000: loss 0.788789\n",
      "iteration 54600 / 120000: loss 0.065456\n",
      "iteration 54700 / 120000: loss 0.475595\n",
      "iteration 54800 / 120000: loss 0.148877\n",
      "iteration 54900 / 120000: loss 0.000116\n",
      "iteration 55000 / 120000: loss 0.449711\n",
      "iteration 55100 / 120000: loss 1.190599\n",
      "iteration 55200 / 120000: loss 0.000333\n",
      "iteration 55300 / 120000: loss 0.140874\n",
      "iteration 55400 / 120000: loss 0.054375\n",
      "iteration 55500 / 120000: loss 0.232920\n",
      "iteration 55600 / 120000: loss 0.010234\n",
      "iteration 55700 / 120000: loss 0.177018\n",
      "iteration 55800 / 120000: loss 0.059295\n",
      "iteration 55900 / 120000: loss 0.191021\n",
      "iteration 56000 / 120000: loss 0.083238\n",
      "iteration 56100 / 120000: loss 0.484487\n",
      "iteration 56200 / 120000: loss 0.620505\n",
      "iteration 56300 / 120000: loss 0.085409\n",
      "iteration 56400 / 120000: loss 2.423498\n",
      "iteration 56500 / 120000: loss 3.089125\n",
      "iteration 56600 / 120000: loss 0.094367\n",
      "iteration 56700 / 120000: loss 0.074669\n",
      "iteration 56800 / 120000: loss 1.231140\n",
      "iteration 56900 / 120000: loss 0.185420\n",
      "iteration 57000 / 120000: loss 0.218469\n",
      "iteration 57100 / 120000: loss 0.108976\n",
      "iteration 57200 / 120000: loss 0.061252\n",
      "iteration 57300 / 120000: loss 0.048928\n",
      "iteration 57400 / 120000: loss 0.002207\n",
      "iteration 57500 / 120000: loss 0.002520\n",
      "iteration 57600 / 120000: loss 0.018457\n",
      "iteration 57700 / 120000: loss 0.148768\n",
      "iteration 57800 / 120000: loss 0.521219\n",
      "iteration 57900 / 120000: loss 0.258409\n",
      "iteration 58000 / 120000: loss 0.005557\n",
      "iteration 58100 / 120000: loss 1.039127\n",
      "iteration 58200 / 120000: loss 0.003921\n",
      "iteration 58300 / 120000: loss 0.108868\n",
      "iteration 58400 / 120000: loss 0.000524\n",
      "iteration 58500 / 120000: loss 1.834350\n",
      "iteration 58600 / 120000: loss 0.301992\n",
      "iteration 58700 / 120000: loss 0.204170\n",
      "iteration 58800 / 120000: loss 0.132305\n",
      "iteration 58900 / 120000: loss 0.687753\n",
      "iteration 59000 / 120000: loss 0.016092\n",
      "iteration 59100 / 120000: loss 0.406911\n",
      "iteration 59200 / 120000: loss 0.012470\n",
      "iteration 59300 / 120000: loss 0.014802\n",
      "iteration 59400 / 120000: loss 0.534409\n",
      "iteration 59500 / 120000: loss 0.010097\n",
      "iteration 59600 / 120000: loss 0.010999\n",
      "iteration 59700 / 120000: loss 0.105410\n",
      "iteration 59800 / 120000: loss 2.394027\n",
      "iteration 59900 / 120000: loss 0.209710\n",
      "iteration 60000 / 120000: loss 0.153941\n",
      "iteration 60100 / 120000: loss 0.607036\n",
      "iteration 60200 / 120000: loss 0.021405\n",
      "iteration 60300 / 120000: loss 0.119416\n",
      "iteration 60400 / 120000: loss 0.192435\n",
      "iteration 60500 / 120000: loss 0.552214\n",
      "iteration 60600 / 120000: loss 0.004234\n",
      "iteration 60700 / 120000: loss 0.006915\n",
      "iteration 60800 / 120000: loss 0.003019\n",
      "iteration 60900 / 120000: loss 0.000192\n",
      "iteration 61000 / 120000: loss 0.013626\n",
      "iteration 61100 / 120000: loss 0.014308\n",
      "iteration 61200 / 120000: loss 0.236132\n",
      "iteration 61300 / 120000: loss 0.675920\n",
      "iteration 61400 / 120000: loss 4.862212\n",
      "iteration 61500 / 120000: loss 0.275573\n",
      "iteration 61600 / 120000: loss 0.014680\n",
      "iteration 61700 / 120000: loss 0.192287\n",
      "iteration 61800 / 120000: loss 0.062527\n",
      "iteration 61900 / 120000: loss 0.238519\n",
      "iteration 62000 / 120000: loss 0.004191\n",
      "iteration 62100 / 120000: loss 0.255720\n",
      "iteration 62200 / 120000: loss 1.338635\n",
      "iteration 62300 / 120000: loss 0.149957\n",
      "iteration 62400 / 120000: loss 0.002013\n",
      "iteration 62500 / 120000: loss 0.536610\n",
      "iteration 62600 / 120000: loss 0.121908\n",
      "iteration 62700 / 120000: loss 0.216361\n",
      "iteration 62800 / 120000: loss 0.032728\n",
      "iteration 62900 / 120000: loss 0.322522\n",
      "iteration 63000 / 120000: loss 1.110228\n",
      "iteration 63100 / 120000: loss 0.309980\n",
      "iteration 63200 / 120000: loss 0.010218\n",
      "iteration 63300 / 120000: loss 0.037947\n",
      "iteration 63400 / 120000: loss 0.011917\n",
      "iteration 63500 / 120000: loss 0.164437\n",
      "iteration 63600 / 120000: loss 0.841800\n",
      "iteration 63700 / 120000: loss 0.075223\n",
      "iteration 63800 / 120000: loss 0.016249\n",
      "iteration 63900 / 120000: loss 0.945542\n",
      "iteration 64000 / 120000: loss 0.162758\n",
      "iteration 64100 / 120000: loss 0.229875\n",
      "iteration 64200 / 120000: loss 0.145021\n",
      "iteration 64300 / 120000: loss 0.019455\n",
      "iteration 64400 / 120000: loss 0.004311\n",
      "iteration 64500 / 120000: loss 0.157848\n",
      "iteration 64600 / 120000: loss 0.395216\n",
      "iteration 64700 / 120000: loss 0.000104\n",
      "iteration 64800 / 120000: loss 0.002756\n",
      "iteration 64900 / 120000: loss 1.147658\n",
      "iteration 65000 / 120000: loss 0.405868\n",
      "iteration 65100 / 120000: loss 0.151800\n",
      "iteration 65200 / 120000: loss 0.191542\n",
      "iteration 65300 / 120000: loss 0.981164\n",
      "iteration 65400 / 120000: loss 1.175647\n",
      "iteration 65500 / 120000: loss 1.747928\n",
      "iteration 65600 / 120000: loss 0.011129\n",
      "iteration 65700 / 120000: loss 0.834421\n",
      "iteration 65800 / 120000: loss 0.013896\n",
      "iteration 65900 / 120000: loss 0.000334\n",
      "iteration 66000 / 120000: loss 0.179756\n",
      "iteration 66100 / 120000: loss 0.682785\n",
      "iteration 66200 / 120000: loss 1.607427\n",
      "iteration 66300 / 120000: loss 0.567233\n",
      "iteration 66400 / 120000: loss 0.092415\n",
      "iteration 66500 / 120000: loss 0.039219\n",
      "iteration 66600 / 120000: loss 2.803918\n",
      "iteration 66700 / 120000: loss 0.001079\n",
      "iteration 66800 / 120000: loss 0.032977\n",
      "iteration 66900 / 120000: loss 0.002282\n",
      "iteration 67000 / 120000: loss 0.001733\n",
      "iteration 67100 / 120000: loss 0.230867\n",
      "iteration 67200 / 120000: loss 0.873961\n",
      "iteration 67300 / 120000: loss 0.187395\n",
      "iteration 67400 / 120000: loss 0.069453\n",
      "iteration 67500 / 120000: loss 0.670130\n",
      "iteration 67600 / 120000: loss 0.009076\n",
      "iteration 67700 / 120000: loss 0.117323\n",
      "iteration 67800 / 120000: loss 0.917852\n",
      "iteration 67900 / 120000: loss 0.374733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 68000 / 120000: loss 0.007567\n",
      "iteration 68100 / 120000: loss 0.000803\n",
      "iteration 68200 / 120000: loss 0.076200\n",
      "iteration 68300 / 120000: loss 0.006940\n",
      "iteration 68400 / 120000: loss 0.176687\n",
      "iteration 68500 / 120000: loss 0.008180\n",
      "iteration 68600 / 120000: loss 0.121119\n",
      "iteration 68700 / 120000: loss 2.228628\n",
      "iteration 68800 / 120000: loss 0.666588\n",
      "iteration 68900 / 120000: loss 0.339733\n",
      "iteration 69000 / 120000: loss 0.927941\n",
      "iteration 69100 / 120000: loss 2.357864\n",
      "iteration 69200 / 120000: loss 0.100946\n",
      "iteration 69300 / 120000: loss 0.048354\n",
      "iteration 69400 / 120000: loss 0.000155\n",
      "iteration 69500 / 120000: loss 0.012136\n",
      "iteration 69600 / 120000: loss 0.260576\n",
      "iteration 69700 / 120000: loss 0.064021\n",
      "iteration 69800 / 120000: loss 0.012452\n",
      "iteration 69900 / 120000: loss 1.578661\n",
      "iteration 70000 / 120000: loss 0.260074\n",
      "iteration 70100 / 120000: loss 0.006143\n",
      "iteration 70200 / 120000: loss 0.013298\n",
      "iteration 70300 / 120000: loss 0.534524\n",
      "iteration 70400 / 120000: loss 0.005277\n",
      "iteration 70500 / 120000: loss 2.041054\n",
      "iteration 70600 / 120000: loss 0.591722\n",
      "iteration 70700 / 120000: loss 1.049781\n",
      "iteration 70800 / 120000: loss 0.022714\n",
      "iteration 70900 / 120000: loss 1.141583\n",
      "iteration 71000 / 120000: loss 1.754670\n",
      "iteration 71100 / 120000: loss 0.733572\n",
      "iteration 71200 / 120000: loss 0.013667\n",
      "iteration 71300 / 120000: loss 0.129359\n",
      "iteration 71400 / 120000: loss 0.075946\n",
      "iteration 71500 / 120000: loss 0.052008\n",
      "iteration 71600 / 120000: loss 0.162289\n",
      "iteration 71700 / 120000: loss 0.459145\n",
      "iteration 71800 / 120000: loss 1.343790\n",
      "iteration 71900 / 120000: loss 0.362296\n",
      "iteration 72000 / 120000: loss 0.049108\n",
      "iteration 72100 / 120000: loss 0.030766\n",
      "iteration 72200 / 120000: loss 1.711473\n",
      "iteration 72300 / 120000: loss 0.012603\n",
      "iteration 72400 / 120000: loss 0.027193\n",
      "iteration 72500 / 120000: loss 0.001487\n",
      "iteration 72600 / 120000: loss 0.035863\n",
      "iteration 72700 / 120000: loss 1.724164\n",
      "iteration 72800 / 120000: loss 0.557523\n",
      "iteration 72900 / 120000: loss 0.003095\n",
      "iteration 73000 / 120000: loss 0.058605\n",
      "iteration 73100 / 120000: loss 0.049902\n",
      "iteration 73200 / 120000: loss 0.312001\n",
      "iteration 73300 / 120000: loss 3.080030\n",
      "iteration 73400 / 120000: loss 0.030011\n",
      "iteration 73500 / 120000: loss 0.042921\n",
      "iteration 73600 / 120000: loss 0.056477\n",
      "iteration 73700 / 120000: loss 0.004601\n",
      "iteration 73800 / 120000: loss 0.217778\n",
      "iteration 73900 / 120000: loss 0.079250\n",
      "iteration 74000 / 120000: loss 0.015318\n",
      "iteration 74100 / 120000: loss 0.001143\n",
      "iteration 74200 / 120000: loss 0.452280\n",
      "iteration 74300 / 120000: loss 0.040332\n",
      "iteration 74400 / 120000: loss 0.032929\n",
      "iteration 74500 / 120000: loss 0.005910\n",
      "iteration 74600 / 120000: loss 0.000058\n",
      "iteration 74700 / 120000: loss 0.069949\n",
      "iteration 74800 / 120000: loss 0.019403\n",
      "iteration 74900 / 120000: loss 0.088127\n",
      "iteration 75000 / 120000: loss 0.267427\n",
      "iteration 75100 / 120000: loss 0.031875\n",
      "iteration 75200 / 120000: loss 0.439407\n",
      "iteration 75300 / 120000: loss 0.097456\n",
      "iteration 75400 / 120000: loss 0.036762\n",
      "iteration 75500 / 120000: loss 0.018597\n",
      "iteration 75600 / 120000: loss 0.175097\n",
      "iteration 75700 / 120000: loss 0.069019\n",
      "iteration 75800 / 120000: loss 3.347420\n",
      "iteration 75900 / 120000: loss 0.003966\n",
      "iteration 76000 / 120000: loss 1.289075\n",
      "iteration 76100 / 120000: loss 0.143824\n",
      "iteration 76200 / 120000: loss 1.130105\n",
      "iteration 76300 / 120000: loss 0.093490\n",
      "iteration 76400 / 120000: loss 0.563896\n",
      "iteration 76500 / 120000: loss 0.003818\n",
      "iteration 76600 / 120000: loss 0.037764\n",
      "iteration 76700 / 120000: loss 0.314531\n",
      "iteration 76800 / 120000: loss 0.202145\n",
      "iteration 76900 / 120000: loss 4.324378\n",
      "iteration 77000 / 120000: loss 1.039336\n",
      "iteration 77100 / 120000: loss 0.289883\n",
      "iteration 77200 / 120000: loss 0.017934\n",
      "iteration 77300 / 120000: loss 0.173097\n",
      "iteration 77400 / 120000: loss 0.080484\n",
      "iteration 77500 / 120000: loss 2.967941\n",
      "iteration 77600 / 120000: loss 0.116522\n",
      "iteration 77700 / 120000: loss 0.013001\n",
      "iteration 77800 / 120000: loss 0.007266\n",
      "iteration 77900 / 120000: loss 2.317244\n",
      "iteration 78000 / 120000: loss 0.915910\n",
      "iteration 78100 / 120000: loss 0.781624\n",
      "iteration 78200 / 120000: loss 0.699657\n",
      "iteration 78300 / 120000: loss 0.055746\n",
      "iteration 78400 / 120000: loss 0.215593\n",
      "iteration 78500 / 120000: loss 1.034038\n",
      "iteration 78600 / 120000: loss 0.678346\n",
      "iteration 78700 / 120000: loss 1.712480\n",
      "iteration 78800 / 120000: loss 0.021894\n",
      "iteration 78900 / 120000: loss 0.721637\n",
      "iteration 79000 / 120000: loss 6.881194\n",
      "iteration 79100 / 120000: loss 0.383296\n",
      "iteration 79200 / 120000: loss 0.015025\n",
      "iteration 79300 / 120000: loss 0.006931\n",
      "iteration 79400 / 120000: loss 0.073378\n",
      "iteration 79500 / 120000: loss 0.015643\n",
      "iteration 79600 / 120000: loss 0.422839\n",
      "iteration 79700 / 120000: loss 0.026029\n",
      "iteration 79800 / 120000: loss 0.022333\n",
      "iteration 79900 / 120000: loss 0.027867\n",
      "iteration 80000 / 120000: loss 0.031111\n",
      "iteration 80100 / 120000: loss 1.650433\n",
      "iteration 80200 / 120000: loss 0.114663\n",
      "iteration 80300 / 120000: loss 1.157781\n",
      "iteration 80400 / 120000: loss 0.060283\n",
      "iteration 80500 / 120000: loss 0.159213\n",
      "iteration 80600 / 120000: loss 0.824747\n",
      "iteration 80700 / 120000: loss 0.146311\n",
      "iteration 80800 / 120000: loss 0.373950\n",
      "iteration 80900 / 120000: loss 0.005304\n",
      "iteration 81000 / 120000: loss 0.052643\n",
      "iteration 81100 / 120000: loss 0.230485\n",
      "iteration 81200 / 120000: loss 0.112483\n",
      "iteration 81300 / 120000: loss 0.050672\n",
      "iteration 81400 / 120000: loss 0.021109\n",
      "iteration 81500 / 120000: loss 0.000654\n",
      "iteration 81600 / 120000: loss 0.254337\n",
      "iteration 81700 / 120000: loss 0.349688\n",
      "iteration 81800 / 120000: loss 0.062675\n",
      "iteration 81900 / 120000: loss 0.147957\n",
      "iteration 82000 / 120000: loss 0.510094\n",
      "iteration 82100 / 120000: loss 0.270684\n",
      "iteration 82200 / 120000: loss 0.132056\n",
      "iteration 82300 / 120000: loss 0.142922\n",
      "iteration 82400 / 120000: loss 0.397624\n",
      "iteration 82500 / 120000: loss 0.095366\n",
      "iteration 82600 / 120000: loss 0.726779\n",
      "iteration 82700 / 120000: loss 0.318271\n",
      "iteration 82800 / 120000: loss 0.817980\n",
      "iteration 82900 / 120000: loss 0.814124\n",
      "iteration 83000 / 120000: loss 0.000059\n",
      "iteration 83100 / 120000: loss 2.128411\n",
      "iteration 83200 / 120000: loss 0.695211\n",
      "iteration 83300 / 120000: loss 0.086623\n",
      "iteration 83400 / 120000: loss 0.534979\n",
      "iteration 83500 / 120000: loss 1.002336\n",
      "iteration 83600 / 120000: loss 0.270528\n",
      "iteration 83700 / 120000: loss 0.140662\n",
      "iteration 83800 / 120000: loss 0.055690\n",
      "iteration 83900 / 120000: loss 0.064057\n",
      "iteration 84000 / 120000: loss 0.055610\n",
      "iteration 84100 / 120000: loss 0.014254\n",
      "iteration 84200 / 120000: loss 0.690104\n",
      "iteration 84300 / 120000: loss 0.707868\n",
      "iteration 84400 / 120000: loss 0.073765\n",
      "iteration 84500 / 120000: loss 0.221249\n",
      "iteration 84600 / 120000: loss 0.929065\n",
      "iteration 84700 / 120000: loss 0.000023\n",
      "iteration 84800 / 120000: loss 0.005989\n",
      "iteration 84900 / 120000: loss 0.043736\n",
      "iteration 85000 / 120000: loss 0.000870\n",
      "iteration 85100 / 120000: loss 0.181337\n",
      "iteration 85200 / 120000: loss 0.960458\n",
      "iteration 85300 / 120000: loss 0.061550\n",
      "iteration 85400 / 120000: loss 0.066232\n",
      "iteration 85500 / 120000: loss 0.030388\n",
      "iteration 85600 / 120000: loss 0.361413\n",
      "iteration 85700 / 120000: loss 0.000308\n",
      "iteration 85800 / 120000: loss 0.002308\n",
      "iteration 85900 / 120000: loss 0.022604\n",
      "iteration 86000 / 120000: loss 0.167411\n",
      "iteration 86100 / 120000: loss 0.041966\n",
      "iteration 86200 / 120000: loss 0.029445\n",
      "iteration 86300 / 120000: loss 0.192520\n",
      "iteration 86400 / 120000: loss 0.120842\n",
      "iteration 86500 / 120000: loss 0.605230\n",
      "iteration 86600 / 120000: loss 0.111301\n",
      "iteration 86700 / 120000: loss 0.117101\n",
      "iteration 86800 / 120000: loss 1.337432\n",
      "iteration 86900 / 120000: loss 0.152266\n",
      "iteration 87000 / 120000: loss 0.014762\n",
      "iteration 87100 / 120000: loss 0.008573\n",
      "iteration 87200 / 120000: loss 0.137052\n",
      "iteration 87300 / 120000: loss 0.336035\n",
      "iteration 87400 / 120000: loss 0.783072\n",
      "iteration 87500 / 120000: loss 0.149577\n",
      "iteration 87600 / 120000: loss 0.188135\n",
      "iteration 87700 / 120000: loss 0.508002\n",
      "iteration 87800 / 120000: loss 0.006709\n",
      "iteration 87900 / 120000: loss 0.005002\n",
      "iteration 88000 / 120000: loss 0.011824\n",
      "iteration 88100 / 120000: loss 1.466548\n",
      "iteration 88200 / 120000: loss 0.398033\n",
      "iteration 88300 / 120000: loss 0.052500\n",
      "iteration 88400 / 120000: loss 0.524529\n",
      "iteration 88500 / 120000: loss 0.182300\n",
      "iteration 88600 / 120000: loss 0.844031\n",
      "iteration 88700 / 120000: loss 0.001632\n",
      "iteration 88800 / 120000: loss 0.033752\n",
      "iteration 88900 / 120000: loss 1.253971\n",
      "iteration 89000 / 120000: loss 0.012852\n",
      "iteration 89100 / 120000: loss 0.128779\n",
      "iteration 89200 / 120000: loss 1.523026\n",
      "iteration 89300 / 120000: loss 0.047372\n",
      "iteration 89400 / 120000: loss 0.237468\n",
      "iteration 89500 / 120000: loss 0.024625\n",
      "iteration 89600 / 120000: loss 0.991457\n",
      "iteration 89700 / 120000: loss 0.011529\n",
      "iteration 89800 / 120000: loss 0.013069\n",
      "iteration 89900 / 120000: loss 1.193104\n",
      "iteration 90000 / 120000: loss 0.151724\n",
      "iteration 90100 / 120000: loss 0.192993\n",
      "iteration 90200 / 120000: loss 0.003897\n",
      "iteration 90300 / 120000: loss 0.024887\n",
      "iteration 90400 / 120000: loss 0.095009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 90500 / 120000: loss 0.472099\n",
      "iteration 90600 / 120000: loss 0.182840\n",
      "iteration 90700 / 120000: loss 0.002511\n",
      "iteration 90800 / 120000: loss 0.213720\n",
      "iteration 90900 / 120000: loss 1.627729\n",
      "iteration 91000 / 120000: loss 0.081091\n",
      "iteration 91100 / 120000: loss 0.118228\n",
      "iteration 91200 / 120000: loss 0.001774\n",
      "iteration 91300 / 120000: loss 0.252197\n",
      "iteration 91400 / 120000: loss 0.436149\n",
      "iteration 91500 / 120000: loss 0.122146\n",
      "iteration 91600 / 120000: loss 2.388886\n",
      "iteration 91700 / 120000: loss 1.366912\n",
      "iteration 91800 / 120000: loss 0.281909\n",
      "iteration 91900 / 120000: loss 0.179741\n",
      "iteration 92000 / 120000: loss 0.238409\n",
      "iteration 92100 / 120000: loss 0.165569\n",
      "iteration 92200 / 120000: loss 0.160778\n",
      "iteration 92300 / 120000: loss 1.588679\n",
      "iteration 92400 / 120000: loss 0.080259\n",
      "iteration 92500 / 120000: loss 0.018966\n",
      "iteration 92600 / 120000: loss 1.553794\n",
      "iteration 92700 / 120000: loss 0.241759\n",
      "iteration 92800 / 120000: loss 0.073708\n",
      "iteration 92900 / 120000: loss 0.006512\n",
      "iteration 93000 / 120000: loss 0.043600\n",
      "iteration 93100 / 120000: loss 0.081747\n",
      "iteration 93200 / 120000: loss 0.060150\n",
      "iteration 93300 / 120000: loss 1.252587\n",
      "iteration 93400 / 120000: loss 0.037021\n",
      "iteration 93500 / 120000: loss 0.632031\n",
      "iteration 93600 / 120000: loss 0.207475\n",
      "iteration 93700 / 120000: loss 1.800123\n",
      "iteration 93800 / 120000: loss 0.388247\n",
      "iteration 93900 / 120000: loss 3.241588\n",
      "iteration 94000 / 120000: loss 1.407407\n",
      "iteration 94100 / 120000: loss 0.102761\n",
      "iteration 94200 / 120000: loss 0.006215\n",
      "iteration 94300 / 120000: loss 0.766316\n",
      "iteration 94400 / 120000: loss 0.728998\n",
      "iteration 94500 / 120000: loss 0.020997\n",
      "iteration 94600 / 120000: loss 0.035669\n",
      "iteration 94700 / 120000: loss 0.042444\n",
      "iteration 94800 / 120000: loss 0.550792\n",
      "iteration 94900 / 120000: loss 0.001469\n",
      "iteration 95000 / 120000: loss 1.872540\n",
      "iteration 95100 / 120000: loss 0.004264\n",
      "iteration 95200 / 120000: loss 0.006080\n",
      "iteration 95300 / 120000: loss 0.003485\n",
      "iteration 95400 / 120000: loss 0.363822\n",
      "iteration 95500 / 120000: loss 0.012747\n",
      "iteration 95600 / 120000: loss 4.283434\n",
      "iteration 95700 / 120000: loss 0.207002\n",
      "iteration 95800 / 120000: loss 0.162218\n",
      "iteration 95900 / 120000: loss 0.401661\n",
      "iteration 96000 / 120000: loss 0.429767\n",
      "iteration 96100 / 120000: loss 0.710809\n",
      "iteration 96200 / 120000: loss 0.025487\n",
      "iteration 96300 / 120000: loss 1.508314\n",
      "iteration 96400 / 120000: loss 0.082988\n",
      "iteration 96500 / 120000: loss 0.140466\n",
      "iteration 96600 / 120000: loss 0.021113\n",
      "iteration 96700 / 120000: loss 0.737407\n",
      "iteration 96800 / 120000: loss 0.086218\n",
      "iteration 96900 / 120000: loss 0.233917\n",
      "iteration 97000 / 120000: loss 0.002856\n",
      "iteration 97100 / 120000: loss 0.192508\n",
      "iteration 97200 / 120000: loss 0.001598\n",
      "iteration 97300 / 120000: loss 1.382634\n",
      "iteration 97400 / 120000: loss 0.116891\n",
      "iteration 97500 / 120000: loss 2.255003\n",
      "iteration 97600 / 120000: loss 0.070355\n",
      "iteration 97700 / 120000: loss 0.119306\n",
      "iteration 97800 / 120000: loss 0.229311\n",
      "iteration 97900 / 120000: loss 0.295618\n",
      "iteration 98000 / 120000: loss 0.056254\n",
      "iteration 98100 / 120000: loss 0.036431\n",
      "iteration 98200 / 120000: loss 0.032408\n",
      "iteration 98300 / 120000: loss 0.012010\n",
      "iteration 98400 / 120000: loss 1.686392\n",
      "iteration 98500 / 120000: loss 0.401630\n",
      "iteration 98600 / 120000: loss 0.014383\n",
      "iteration 98700 / 120000: loss 0.162087\n",
      "iteration 98800 / 120000: loss 2.066969\n",
      "iteration 98900 / 120000: loss 0.008300\n",
      "iteration 99000 / 120000: loss 0.039225\n",
      "iteration 99100 / 120000: loss 0.011821\n",
      "iteration 99200 / 120000: loss 0.000432\n",
      "iteration 99300 / 120000: loss 0.275529\n",
      "iteration 99400 / 120000: loss 0.157950\n",
      "iteration 99500 / 120000: loss 0.152289\n",
      "iteration 99600 / 120000: loss 0.268797\n",
      "iteration 99700 / 120000: loss 0.090096\n",
      "iteration 99800 / 120000: loss 0.039358\n",
      "iteration 99900 / 120000: loss 0.058353\n",
      "iteration 100000 / 120000: loss 0.014734\n",
      "iteration 100100 / 120000: loss 0.003105\n",
      "iteration 100200 / 120000: loss 0.013044\n",
      "iteration 100300 / 120000: loss 0.001223\n",
      "iteration 100400 / 120000: loss 0.016545\n",
      "iteration 100500 / 120000: loss 0.062841\n",
      "iteration 100600 / 120000: loss 3.099051\n",
      "iteration 100700 / 120000: loss 0.003370\n",
      "iteration 100800 / 120000: loss 1.105123\n",
      "iteration 100900 / 120000: loss 0.180371\n",
      "iteration 101000 / 120000: loss 0.141365\n",
      "iteration 101100 / 120000: loss 0.683114\n",
      "iteration 101200 / 120000: loss 0.002751\n",
      "iteration 101300 / 120000: loss 0.009457\n",
      "iteration 101400 / 120000: loss 0.053923\n",
      "iteration 101500 / 120000: loss 0.018754\n",
      "iteration 101600 / 120000: loss 0.000999\n",
      "iteration 101700 / 120000: loss 0.151893\n",
      "iteration 101800 / 120000: loss 0.007168\n",
      "iteration 101900 / 120000: loss 0.005572\n",
      "iteration 102000 / 120000: loss 0.005874\n",
      "iteration 102100 / 120000: loss 0.614790\n",
      "iteration 102200 / 120000: loss 0.103429\n",
      "iteration 102300 / 120000: loss 0.023970\n",
      "iteration 102400 / 120000: loss 1.250699\n",
      "iteration 102500 / 120000: loss 0.096835\n",
      "iteration 102600 / 120000: loss 0.014926\n",
      "iteration 102700 / 120000: loss 0.518142\n",
      "iteration 102800 / 120000: loss 0.024872\n",
      "iteration 102900 / 120000: loss 3.658408\n",
      "iteration 103000 / 120000: loss 0.334080\n",
      "iteration 103100 / 120000: loss 0.021034\n",
      "iteration 103200 / 120000: loss 1.161606\n",
      "iteration 103300 / 120000: loss 0.038232\n",
      "iteration 103400 / 120000: loss 0.024106\n",
      "iteration 103500 / 120000: loss 0.022298\n",
      "iteration 103600 / 120000: loss 0.407001\n",
      "iteration 103700 / 120000: loss 0.048740\n",
      "iteration 103800 / 120000: loss 0.000513\n",
      "iteration 103900 / 120000: loss 0.012235\n",
      "iteration 104000 / 120000: loss 0.275941\n",
      "iteration 104100 / 120000: loss 0.003025\n",
      "iteration 104200 / 120000: loss 0.081954\n",
      "iteration 104300 / 120000: loss 0.010493\n",
      "iteration 104400 / 120000: loss 0.517336\n",
      "iteration 104500 / 120000: loss 0.008061\n",
      "iteration 104600 / 120000: loss 0.000583\n",
      "iteration 104700 / 120000: loss 0.050918\n",
      "iteration 104800 / 120000: loss 0.000450\n",
      "iteration 104900 / 120000: loss 0.664227\n",
      "iteration 105000 / 120000: loss 0.046874\n",
      "iteration 105100 / 120000: loss 0.916043\n",
      "iteration 105200 / 120000: loss 0.005988\n",
      "iteration 105300 / 120000: loss 0.613823\n",
      "iteration 105400 / 120000: loss 0.329528\n",
      "iteration 105500 / 120000: loss 0.450715\n",
      "iteration 105600 / 120000: loss 0.308872\n",
      "iteration 105700 / 120000: loss 0.098445\n",
      "iteration 105800 / 120000: loss 0.182933\n",
      "iteration 105900 / 120000: loss 0.094251\n",
      "iteration 106000 / 120000: loss 0.596328\n",
      "iteration 106100 / 120000: loss 1.426380\n",
      "iteration 106200 / 120000: loss 0.721228\n",
      "iteration 106300 / 120000: loss 0.325010\n",
      "iteration 106400 / 120000: loss 1.143137\n",
      "iteration 106500 / 120000: loss 0.377036\n",
      "iteration 106600 / 120000: loss 0.004970\n",
      "iteration 106700 / 120000: loss 0.001740\n",
      "iteration 106800 / 120000: loss 0.017838\n",
      "iteration 106900 / 120000: loss 0.000556\n",
      "iteration 107000 / 120000: loss 0.714286\n",
      "iteration 107100 / 120000: loss 0.805258\n",
      "iteration 107200 / 120000: loss 0.095884\n",
      "iteration 107300 / 120000: loss 0.145706\n",
      "iteration 107400 / 120000: loss 0.005751\n",
      "iteration 107500 / 120000: loss 0.018370\n",
      "iteration 107600 / 120000: loss 0.009676\n",
      "iteration 107700 / 120000: loss 0.761787\n",
      "iteration 107800 / 120000: loss 0.621329\n",
      "iteration 107900 / 120000: loss 2.741740\n",
      "iteration 108000 / 120000: loss 1.330439\n",
      "iteration 108100 / 120000: loss 4.328110\n",
      "iteration 108200 / 120000: loss 0.144135\n",
      "iteration 108300 / 120000: loss 0.064968\n",
      "iteration 108400 / 120000: loss 0.005991\n",
      "iteration 108500 / 120000: loss 2.056122\n",
      "iteration 108600 / 120000: loss 0.005505\n",
      "iteration 108700 / 120000: loss 0.522303\n",
      "iteration 108800 / 120000: loss 0.014329\n",
      "iteration 108900 / 120000: loss 1.658241\n",
      "iteration 109000 / 120000: loss 0.028652\n",
      "iteration 109100 / 120000: loss 0.048471\n",
      "iteration 109200 / 120000: loss 0.568821\n",
      "iteration 109300 / 120000: loss 0.074048\n",
      "iteration 109400 / 120000: loss 0.004467\n",
      "iteration 109500 / 120000: loss 0.002004\n",
      "iteration 109600 / 120000: loss 0.023590\n",
      "iteration 109700 / 120000: loss 0.018545\n",
      "iteration 109800 / 120000: loss 0.073456\n",
      "iteration 109900 / 120000: loss 0.647214\n",
      "iteration 110000 / 120000: loss 0.261344\n",
      "iteration 110100 / 120000: loss 0.215089\n",
      "iteration 110200 / 120000: loss 0.002392\n",
      "iteration 110300 / 120000: loss 0.057328\n",
      "iteration 110400 / 120000: loss 0.182184\n",
      "iteration 110500 / 120000: loss 0.000495\n",
      "iteration 110600 / 120000: loss 0.210327\n",
      "iteration 110700 / 120000: loss 0.062400\n",
      "iteration 110800 / 120000: loss 0.009075\n",
      "iteration 110900 / 120000: loss 0.019095\n",
      "iteration 111000 / 120000: loss 0.009822\n",
      "iteration 111100 / 120000: loss 0.028249\n",
      "iteration 111200 / 120000: loss 3.157184\n",
      "iteration 111300 / 120000: loss 0.004313\n",
      "iteration 111400 / 120000: loss 1.199493\n",
      "iteration 111500 / 120000: loss 0.055056\n",
      "iteration 111600 / 120000: loss 0.376885\n",
      "iteration 111700 / 120000: loss 0.039545\n",
      "iteration 111800 / 120000: loss 0.001771\n",
      "iteration 111900 / 120000: loss 0.077184\n",
      "iteration 112000 / 120000: loss 0.635698\n",
      "iteration 112100 / 120000: loss 0.220141\n",
      "iteration 112200 / 120000: loss 0.139623\n",
      "iteration 112300 / 120000: loss 0.000154\n",
      "iteration 112400 / 120000: loss 0.403605\n",
      "iteration 112500 / 120000: loss 0.067951\n",
      "iteration 112600 / 120000: loss 0.105980\n",
      "iteration 112700 / 120000: loss 0.075508\n",
      "iteration 112800 / 120000: loss 0.735606\n",
      "iteration 112900 / 120000: loss 0.094661\n",
      "iteration 113000 / 120000: loss 0.053166\n",
      "iteration 113100 / 120000: loss 1.169401\n",
      "iteration 113200 / 120000: loss 0.051778\n",
      "iteration 113300 / 120000: loss 0.016058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 113400 / 120000: loss 0.394229\n",
      "iteration 113500 / 120000: loss 0.408935\n",
      "iteration 113600 / 120000: loss 0.609569\n",
      "iteration 113700 / 120000: loss 0.282871\n",
      "iteration 113800 / 120000: loss 0.022774\n",
      "iteration 113900 / 120000: loss 0.011573\n",
      "iteration 114000 / 120000: loss 0.115105\n",
      "iteration 114100 / 120000: loss 0.194266\n",
      "iteration 114200 / 120000: loss 0.270040\n",
      "iteration 114300 / 120000: loss 0.014443\n",
      "iteration 114400 / 120000: loss 0.129603\n",
      "iteration 114500 / 120000: loss 0.398395\n",
      "iteration 114600 / 120000: loss 0.009019\n",
      "iteration 114700 / 120000: loss 0.086377\n",
      "iteration 114800 / 120000: loss 0.541309\n",
      "iteration 114900 / 120000: loss 0.000049\n",
      "iteration 115000 / 120000: loss 0.511357\n",
      "iteration 115100 / 120000: loss 0.014335\n",
      "iteration 115200 / 120000: loss 0.012475\n",
      "iteration 115300 / 120000: loss 0.403257\n",
      "iteration 115400 / 120000: loss 0.183823\n",
      "iteration 115500 / 120000: loss 0.024390\n",
      "iteration 115600 / 120000: loss 0.226284\n",
      "iteration 115700 / 120000: loss 0.062490\n",
      "iteration 115800 / 120000: loss 0.548540\n",
      "iteration 115900 / 120000: loss 0.006947\n",
      "iteration 116000 / 120000: loss 0.105027\n",
      "iteration 116100 / 120000: loss 0.067330\n",
      "iteration 116200 / 120000: loss 0.003586\n",
      "iteration 116300 / 120000: loss 0.022329\n",
      "iteration 116400 / 120000: loss 0.004045\n",
      "iteration 116500 / 120000: loss 0.792061\n",
      "iteration 116600 / 120000: loss 0.030175\n",
      "iteration 116700 / 120000: loss 2.598640\n",
      "iteration 116800 / 120000: loss 0.002912\n",
      "iteration 116900 / 120000: loss 2.050181\n",
      "iteration 117000 / 120000: loss 0.024245\n",
      "iteration 117100 / 120000: loss 0.036123\n",
      "iteration 117200 / 120000: loss 0.028040\n",
      "iteration 117300 / 120000: loss 0.009404\n",
      "iteration 117400 / 120000: loss 0.021401\n",
      "iteration 117500 / 120000: loss 0.001160\n",
      "iteration 117600 / 120000: loss 0.032343\n",
      "iteration 117700 / 120000: loss 0.194632\n",
      "iteration 117800 / 120000: loss 0.316920\n",
      "iteration 117900 / 120000: loss 0.000022\n",
      "iteration 118000 / 120000: loss 0.585776\n",
      "iteration 118100 / 120000: loss 1.750088\n",
      "iteration 118200 / 120000: loss 0.000436\n",
      "iteration 118300 / 120000: loss 0.003430\n",
      "iteration 118400 / 120000: loss 1.211097\n",
      "iteration 118500 / 120000: loss 0.031509\n",
      "iteration 118600 / 120000: loss 1.942861\n",
      "iteration 118700 / 120000: loss 0.002125\n",
      "iteration 118800 / 120000: loss 0.074778\n",
      "iteration 118900 / 120000: loss 1.794918\n",
      "iteration 119000 / 120000: loss 0.306794\n",
      "iteration 119100 / 120000: loss 1.336616\n",
      "iteration 119200 / 120000: loss 0.304285\n",
      "iteration 119300 / 120000: loss 0.049268\n",
      "iteration 119400 / 120000: loss 0.005756\n",
      "iteration 119500 / 120000: loss 0.064002\n",
      "iteration 119600 / 120000: loss 0.385771\n",
      "iteration 119700 / 120000: loss 0.065048\n",
      "iteration 119800 / 120000: loss 0.289757\n",
      "iteration 119900 / 120000: loss 0.021893\n",
      "(lr, bs) = (1e-07, 1)\n",
      "(val_accuracy,train_accuracy, best_val) = (array([0.409]), array([0.8265]), -1)\n",
      "iteration 0 / 1200: loss 70.239184\n",
      "iteration 100 / 1200: loss 108.209865\n",
      "iteration 200 / 1200: loss 98.932519\n",
      "iteration 300 / 1200: loss 80.242810\n",
      "iteration 400 / 1200: loss 97.993315\n",
      "iteration 500 / 1200: loss 52.844740\n",
      "iteration 600 / 1200: loss 67.998473\n",
      "iteration 700 / 1200: loss 268.731486\n",
      "iteration 800 / 1200: loss 193.409030\n",
      "iteration 900 / 1200: loss 57.942141\n",
      "iteration 1000 / 1200: loss 106.569323\n",
      "iteration 1100 / 1200: loss 39.704116\n",
      "(lr, bs) = (1e-07, 100)\n",
      "(val_accuracy,train_accuracy, best_val) = (array([0.314]), array([0.6798]), array([0.409]))\n",
      "iteration 0 / 600: loss 151.678525\n",
      "iteration 100 / 600: loss 309.186008\n",
      "iteration 200 / 600: loss 152.694696\n",
      "iteration 300 / 600: loss 645.254515\n",
      "iteration 400 / 600: loss 160.073414\n",
      "iteration 500 / 600: loss 393.235007\n",
      "(lr, bs) = (1e-07, 200)\n",
      "(val_accuracy,train_accuracy, best_val) = (array([0.382]), array([0.8224]), array([0.409]))\n",
      "iteration 0 / 240: loss 349.401101\n",
      "iteration 100 / 240: loss 3286.733627\n",
      "iteration 200 / 240: loss 1213.645472\n",
      "(lr, bs) = (1e-07, 500)\n",
      "(val_accuracy,train_accuracy, best_val) = (array([0.399]), array([0.822]), array([0.409]))\n",
      "iteration 0 / 120: loss 686.079691\n",
      "iteration 100 / 120: loss 12602.186916\n",
      "(lr, bs) = (1e-07, 1000)\n",
      "(val_accuracy,train_accuracy, best_val) = (array([0.318]), array([0.6961]), array([0.409]))\n",
      "iteration 0 / 12: loss 6811.043182\n",
      "(lr, bs) = (1e-07, 10000)\n",
      "(val_accuracy,train_accuracy, best_val) = (array([0.404]), array([0.7932]), array([0.409]))\n",
      "iteration 0 / 120000: loss 0.554214\n",
      "iteration 100 / 120000: loss 0.000000\n",
      "iteration 200 / 120000: loss 0.000000\n",
      "iteration 300 / 120000: loss 0.000215\n",
      "iteration 400 / 120000: loss 58.124724\n",
      "iteration 500 / 120000: loss 0.000000\n",
      "iteration 600 / 120000: loss 0.000000\n",
      "iteration 700 / 120000: loss 0.000113\n",
      "iteration 800 / 120000: loss 0.000000\n",
      "iteration 900 / 120000: loss 0.102390\n",
      "iteration 1000 / 120000: loss 0.000000\n",
      "iteration 1100 / 120000: loss 0.000000\n",
      "iteration 1200 / 120000: loss 0.000000\n",
      "iteration 1300 / 120000: loss 0.001476\n",
      "iteration 1400 / 120000: loss 0.000001\n",
      "iteration 1500 / 120000: loss 20.532640\n",
      "iteration 1600 / 120000: loss 0.000000\n",
      "iteration 1700 / 120000: loss 0.000000\n",
      "iteration 1800 / 120000: loss 0.000000\n",
      "iteration 1900 / 120000: loss 0.000000\n",
      "iteration 2000 / 120000: loss 34.999899\n",
      "iteration 2100 / 120000: loss 0.000000\n",
      "iteration 2200 / 120000: loss 0.000000\n",
      "iteration 2300 / 120000: loss 0.000000\n",
      "iteration 2400 / 120000: loss 0.000000\n",
      "iteration 2500 / 120000: loss 0.000000\n",
      "iteration 2600 / 120000: loss 37.891596\n",
      "iteration 2700 / 120000: loss 0.000000\n",
      "iteration 2800 / 120000: loss 0.000000\n",
      "iteration 2900 / 120000: loss 0.000000\n",
      "iteration 3000 / 120000: loss 0.000000\n",
      "iteration 3100 / 120000: loss 33.294372\n",
      "iteration 3200 / 120000: loss 0.000000\n",
      "iteration 3300 / 120000: loss 0.000000\n",
      "iteration 3400 / 120000: loss 0.000000\n",
      "iteration 3500 / 120000: loss 15.245614\n",
      "iteration 3600 / 120000: loss 0.000000\n",
      "iteration 3700 / 120000: loss 0.000000\n",
      "iteration 3800 / 120000: loss 9.363067\n",
      "iteration 3900 / 120000: loss 2.325736\n",
      "iteration 4000 / 120000: loss 0.000000\n",
      "iteration 4100 / 120000: loss 5.011090\n",
      "iteration 4200 / 120000: loss 0.000000\n",
      "iteration 4300 / 120000: loss 0.000000\n",
      "iteration 4400 / 120000: loss 26.306042\n",
      "iteration 4500 / 120000: loss 4.396831\n",
      "iteration 4600 / 120000: loss 0.000000\n",
      "iteration 4700 / 120000: loss 8.562070\n",
      "iteration 4800 / 120000: loss 0.000000\n",
      "iteration 4900 / 120000: loss 0.000000\n",
      "iteration 5000 / 120000: loss 41.056874\n",
      "iteration 5100 / 120000: loss 91.576762\n",
      "iteration 5200 / 120000: loss 0.000000\n",
      "iteration 5300 / 120000: loss 0.000000\n",
      "iteration 5400 / 120000: loss 24.053866\n",
      "iteration 5500 / 120000: loss 118.364180\n",
      "iteration 5600 / 120000: loss 0.000000\n",
      "iteration 5700 / 120000: loss 0.000000\n",
      "iteration 5800 / 120000: loss 0.000000\n",
      "iteration 5900 / 120000: loss 0.000000\n",
      "iteration 6000 / 120000: loss 0.187532\n",
      "iteration 6100 / 120000: loss 39.812198\n",
      "iteration 6200 / 120000: loss 45.075726\n",
      "iteration 6300 / 120000: loss 31.596198\n",
      "iteration 6400 / 120000: loss 0.000000\n",
      "iteration 6500 / 120000: loss 0.000000\n",
      "iteration 6600 / 120000: loss 0.000000\n",
      "iteration 6700 / 120000: loss 18.691320\n",
      "iteration 6800 / 120000: loss 0.000000\n",
      "iteration 6900 / 120000: loss 0.000000\n",
      "iteration 7000 / 120000: loss 59.463398\n",
      "iteration 7100 / 120000: loss 0.000000\n",
      "iteration 7200 / 120000: loss 0.000000\n",
      "iteration 7300 / 120000: loss 3.616141\n",
      "iteration 7400 / 120000: loss 0.000000\n",
      "iteration 7500 / 120000: loss 0.000000\n",
      "iteration 7600 / 120000: loss 46.953980\n",
      "iteration 7700 / 120000: loss 0.000000\n",
      "iteration 7800 / 120000: loss 0.000000\n",
      "iteration 7900 / 120000: loss 0.000000\n",
      "iteration 8000 / 120000: loss 52.161967\n",
      "iteration 8100 / 120000: loss 0.000000\n",
      "iteration 8200 / 120000: loss 0.000000\n",
      "iteration 8300 / 120000: loss 0.000000\n",
      "iteration 8400 / 120000: loss 0.000000\n",
      "iteration 8500 / 120000: loss 0.000000\n",
      "iteration 8600 / 120000: loss 0.000001\n",
      "iteration 8700 / 120000: loss 0.000000\n",
      "iteration 8800 / 120000: loss 0.000000\n",
      "iteration 8900 / 120000: loss 0.000000\n",
      "iteration 9000 / 120000: loss 0.000000\n",
      "iteration 9100 / 120000: loss 0.000000\n",
      "iteration 9200 / 120000: loss 0.000000\n",
      "iteration 9300 / 120000: loss 0.000000\n",
      "iteration 9400 / 120000: loss 0.000000\n",
      "iteration 9500 / 120000: loss 0.000000\n",
      "iteration 9600 / 120000: loss 57.934331\n",
      "iteration 9700 / 120000: loss 16.650575\n",
      "iteration 9800 / 120000: loss 0.000000\n",
      "iteration 9900 / 120000: loss 0.000000\n",
      "iteration 10000 / 120000: loss 0.000000\n",
      "iteration 10100 / 120000: loss 0.000000\n",
      "iteration 10200 / 120000: loss 0.000000\n",
      "iteration 10300 / 120000: loss 74.298558\n",
      "iteration 10400 / 120000: loss 0.000000\n",
      "iteration 10500 / 120000: loss 0.000000\n",
      "iteration 10600 / 120000: loss 0.000000\n",
      "iteration 10700 / 120000: loss 0.000000\n",
      "iteration 10800 / 120000: loss 0.000000\n",
      "iteration 10900 / 120000: loss 10.374309\n",
      "iteration 11000 / 120000: loss 9.920578\n",
      "iteration 11100 / 120000: loss 0.000000\n",
      "iteration 11200 / 120000: loss 16.491594\n",
      "iteration 11300 / 120000: loss 0.000000\n",
      "iteration 11400 / 120000: loss 0.000000\n",
      "iteration 11500 / 120000: loss 0.000000\n",
      "iteration 11600 / 120000: loss 0.000000\n",
      "iteration 11700 / 120000: loss 0.000014\n",
      "iteration 11800 / 120000: loss 0.000000\n",
      "iteration 11900 / 120000: loss 0.000017\n",
      "iteration 12000 / 120000: loss 0.000014\n",
      "iteration 12100 / 120000: loss 0.000000\n",
      "iteration 12200 / 120000: loss 0.000000\n",
      "iteration 12300 / 120000: loss 5.029857\n",
      "iteration 12400 / 120000: loss 0.000000\n",
      "iteration 12500 / 120000: loss 0.000017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 12600 / 120000: loss 0.000000\n",
      "iteration 12700 / 120000: loss 0.077495\n",
      "iteration 12800 / 120000: loss 0.000000\n",
      "iteration 12900 / 120000: loss 0.000356\n",
      "iteration 13000 / 120000: loss 0.080557\n",
      "iteration 13100 / 120000: loss 0.000000\n",
      "iteration 13200 / 120000: loss 0.000000\n",
      "iteration 13300 / 120000: loss 29.302869\n",
      "iteration 13400 / 120000: loss 26.409406\n",
      "iteration 13500 / 120000: loss 69.060391\n",
      "iteration 13600 / 120000: loss 95.540490\n",
      "iteration 13700 / 120000: loss 0.000000\n",
      "iteration 13800 / 120000: loss 0.000000\n",
      "iteration 13900 / 120000: loss 0.000000\n",
      "iteration 14000 / 120000: loss 0.000000\n",
      "iteration 14100 / 120000: loss 0.000000\n",
      "iteration 14200 / 120000: loss 0.000000\n",
      "iteration 14300 / 120000: loss 0.000000\n",
      "iteration 14400 / 120000: loss 0.000000\n",
      "iteration 14500 / 120000: loss 0.000000\n",
      "iteration 14600 / 120000: loss 0.000000\n",
      "iteration 14700 / 120000: loss 0.000000\n",
      "iteration 14800 / 120000: loss 84.946586\n",
      "iteration 14900 / 120000: loss 26.384528\n",
      "iteration 15000 / 120000: loss 0.000000\n",
      "iteration 15100 / 120000: loss 69.528108\n",
      "iteration 15200 / 120000: loss 0.000000\n",
      "iteration 15300 / 120000: loss 0.000000\n",
      "iteration 15400 / 120000: loss 0.000000\n",
      "iteration 15500 / 120000: loss 25.150313\n",
      "iteration 15600 / 120000: loss 7.567847\n",
      "iteration 15700 / 120000: loss 0.000000\n",
      "iteration 15800 / 120000: loss 0.000000\n",
      "iteration 15900 / 120000: loss 0.000000\n",
      "iteration 16000 / 120000: loss 0.000000\n",
      "iteration 16100 / 120000: loss 0.000000\n",
      "iteration 16200 / 120000: loss 10.332168\n",
      "iteration 16300 / 120000: loss 0.000000\n",
      "iteration 16400 / 120000: loss 0.000000\n",
      "iteration 16500 / 120000: loss 0.000000\n",
      "iteration 16600 / 120000: loss 0.000000\n",
      "iteration 16700 / 120000: loss 0.000000\n",
      "iteration 16800 / 120000: loss 8.550018\n",
      "iteration 16900 / 120000: loss 0.000106\n",
      "iteration 17000 / 120000: loss 0.000000\n",
      "iteration 17100 / 120000: loss 0.000000\n",
      "iteration 17200 / 120000: loss 0.000000\n",
      "iteration 17300 / 120000: loss 0.000000\n",
      "iteration 17400 / 120000: loss 0.000000\n",
      "iteration 17500 / 120000: loss 6.616014\n",
      "iteration 17600 / 120000: loss 0.000000\n",
      "iteration 17700 / 120000: loss 0.000000\n",
      "iteration 17800 / 120000: loss 1.401249\n",
      "iteration 17900 / 120000: loss 0.005788\n",
      "iteration 18000 / 120000: loss 0.000000\n",
      "iteration 18100 / 120000: loss 22.546513\n",
      "iteration 18200 / 120000: loss 0.000000\n",
      "iteration 18300 / 120000: loss 0.000000\n",
      "iteration 18400 / 120000: loss 0.000000\n",
      "iteration 18500 / 120000: loss 0.000000\n",
      "iteration 18600 / 120000: loss 0.000000\n",
      "iteration 18700 / 120000: loss 0.000000\n",
      "iteration 18800 / 120000: loss 0.000000\n",
      "iteration 18900 / 120000: loss 0.000000\n",
      "iteration 19000 / 120000: loss 0.000000\n",
      "iteration 19100 / 120000: loss 82.877592\n",
      "iteration 19200 / 120000: loss 0.000000\n",
      "iteration 19300 / 120000: loss 0.000000\n",
      "iteration 19400 / 120000: loss 34.840418\n",
      "iteration 19500 / 120000: loss 0.000000\n",
      "iteration 19600 / 120000: loss 0.000000\n",
      "iteration 19700 / 120000: loss 0.000000\n",
      "iteration 19800 / 120000: loss 0.000000\n",
      "iteration 19900 / 120000: loss 53.186490\n",
      "iteration 20000 / 120000: loss 0.000000\n",
      "iteration 20100 / 120000: loss 0.000000\n",
      "iteration 20200 / 120000: loss 0.000000\n",
      "iteration 20300 / 120000: loss 0.000000\n",
      "iteration 20400 / 120000: loss 0.000000\n",
      "iteration 20500 / 120000: loss 0.000000\n",
      "iteration 20600 / 120000: loss 0.000000\n",
      "iteration 20700 / 120000: loss 14.548842\n",
      "iteration 20800 / 120000: loss 1.128278\n",
      "iteration 20900 / 120000: loss 0.000000\n",
      "iteration 21000 / 120000: loss 36.219308\n",
      "iteration 21100 / 120000: loss 0.000000\n",
      "iteration 21200 / 120000: loss 0.000000\n",
      "iteration 21300 / 120000: loss 0.000000\n",
      "iteration 21400 / 120000: loss 18.250115\n",
      "iteration 21500 / 120000: loss 0.000080\n",
      "iteration 21600 / 120000: loss 0.000000\n",
      "iteration 21700 / 120000: loss 0.000000\n",
      "iteration 21800 / 120000: loss 0.000000\n",
      "iteration 21900 / 120000: loss 0.000000\n",
      "iteration 22000 / 120000: loss 0.000000\n",
      "iteration 22100 / 120000: loss 0.000000\n",
      "iteration 22200 / 120000: loss 0.000000\n",
      "iteration 22300 / 120000: loss 0.000022\n",
      "iteration 22400 / 120000: loss 0.000001\n",
      "iteration 22500 / 120000: loss 0.000000\n",
      "iteration 22600 / 120000: loss 0.000000\n",
      "iteration 22700 / 120000: loss 6.730810\n",
      "iteration 22800 / 120000: loss 0.000000\n",
      "iteration 22900 / 120000: loss 1.009447\n",
      "iteration 23000 / 120000: loss 28.303471\n",
      "iteration 23100 / 120000: loss 0.000000\n",
      "iteration 23200 / 120000: loss 0.000000\n",
      "iteration 23300 / 120000: loss 0.067903\n",
      "iteration 23400 / 120000: loss 0.000000\n",
      "iteration 23500 / 120000: loss 0.000000\n",
      "iteration 23600 / 120000: loss 0.000000\n",
      "iteration 23700 / 120000: loss 7.416520\n",
      "iteration 23800 / 120000: loss 41.351187\n",
      "iteration 23900 / 120000: loss 0.000000\n",
      "iteration 24000 / 120000: loss 0.000000\n",
      "iteration 24100 / 120000: loss 0.000000\n",
      "iteration 24200 / 120000: loss 0.856448\n",
      "iteration 24300 / 120000: loss 0.000000\n",
      "iteration 24400 / 120000: loss 0.054173\n",
      "iteration 24500 / 120000: loss 0.000001\n",
      "iteration 24600 / 120000: loss 0.000000\n",
      "iteration 24700 / 120000: loss 0.000002\n",
      "iteration 24800 / 120000: loss 0.000000\n",
      "iteration 24900 / 120000: loss 0.000000\n",
      "iteration 25000 / 120000: loss 27.633853\n",
      "iteration 25100 / 120000: loss 0.000000\n",
      "iteration 25200 / 120000: loss 2.412928\n",
      "iteration 25300 / 120000: loss 0.000000\n",
      "iteration 25400 / 120000: loss 0.000000\n",
      "iteration 25500 / 120000: loss 0.000000\n",
      "iteration 25600 / 120000: loss 0.000000\n",
      "iteration 25700 / 120000: loss 0.000000\n",
      "iteration 25800 / 120000: loss 0.000000\n",
      "iteration 25900 / 120000: loss 0.000000\n",
      "iteration 26000 / 120000: loss 0.000000\n",
      "iteration 26100 / 120000: loss 55.340990\n",
      "iteration 26200 / 120000: loss 0.000000\n",
      "iteration 26300 / 120000: loss 0.000000\n",
      "iteration 26400 / 120000: loss 0.000000\n",
      "iteration 26500 / 120000: loss 0.000000\n",
      "iteration 26600 / 120000: loss 44.440339\n",
      "iteration 26700 / 120000: loss 0.000000\n",
      "iteration 26800 / 120000: loss 0.000000\n",
      "iteration 26900 / 120000: loss 59.046447\n",
      "iteration 27000 / 120000: loss 0.000375\n",
      "iteration 27100 / 120000: loss 0.000000\n",
      "iteration 27200 / 120000: loss 39.843408\n",
      "iteration 27300 / 120000: loss 0.000000\n",
      "iteration 27400 / 120000: loss 0.000000\n",
      "iteration 27500 / 120000: loss 16.166471\n",
      "iteration 27600 / 120000: loss 19.561240\n",
      "iteration 27700 / 120000: loss 0.000000\n",
      "iteration 27800 / 120000: loss 0.000000\n",
      "iteration 27900 / 120000: loss 0.000000\n",
      "iteration 28000 / 120000: loss 0.000000\n",
      "iteration 28100 / 120000: loss 0.000000\n",
      "iteration 28200 / 120000: loss 5.470860\n",
      "iteration 28300 / 120000: loss 0.000000\n",
      "iteration 28400 / 120000: loss 4.205349\n",
      "iteration 28500 / 120000: loss 0.000000\n",
      "iteration 28600 / 120000: loss 0.000000\n",
      "iteration 28700 / 120000: loss 0.000000\n",
      "iteration 28800 / 120000: loss 0.000000\n",
      "iteration 28900 / 120000: loss 0.000000\n",
      "iteration 29000 / 120000: loss 0.000000\n",
      "iteration 29100 / 120000: loss 0.000000\n",
      "iteration 29200 / 120000: loss 0.000000\n",
      "iteration 29300 / 120000: loss 0.000000\n",
      "iteration 29400 / 120000: loss 0.000000\n",
      "iteration 29500 / 120000: loss 0.000000\n",
      "iteration 29600 / 120000: loss 0.000000\n",
      "iteration 29700 / 120000: loss 0.000000\n",
      "iteration 29800 / 120000: loss 0.596837\n",
      "iteration 29900 / 120000: loss 0.000000\n",
      "iteration 30000 / 120000: loss 0.000000\n",
      "iteration 30100 / 120000: loss 0.000000\n",
      "iteration 30200 / 120000: loss 0.000000\n",
      "iteration 30300 / 120000: loss 0.000000\n",
      "iteration 30400 / 120000: loss 0.000000\n",
      "iteration 30500 / 120000: loss 0.000000\n",
      "iteration 30600 / 120000: loss 0.000000\n",
      "iteration 30700 / 120000: loss 0.000114\n",
      "iteration 30800 / 120000: loss 0.000000\n",
      "iteration 30900 / 120000: loss 0.000000\n",
      "iteration 31000 / 120000: loss 0.021041\n",
      "iteration 31100 / 120000: loss 2.703449\n",
      "iteration 31200 / 120000: loss 0.000000\n",
      "iteration 31300 / 120000: loss 0.000260\n",
      "iteration 31400 / 120000: loss 0.000000\n",
      "iteration 31500 / 120000: loss 0.000000\n",
      "iteration 31600 / 120000: loss 0.000000\n",
      "iteration 31700 / 120000: loss 0.000000\n",
      "iteration 31800 / 120000: loss 91.941379\n",
      "iteration 31900 / 120000: loss 0.000000\n",
      "iteration 32000 / 120000: loss 0.000000\n",
      "iteration 32100 / 120000: loss 0.000834\n",
      "iteration 32200 / 120000: loss 0.000000\n",
      "iteration 32300 / 120000: loss 0.000000\n",
      "iteration 32400 / 120000: loss 0.000000\n",
      "iteration 32500 / 120000: loss 0.867489\n",
      "iteration 32600 / 120000: loss 0.000000\n",
      "iteration 32700 / 120000: loss 36.690012\n",
      "iteration 32800 / 120000: loss 21.854923\n",
      "iteration 32900 / 120000: loss 0.000000\n",
      "iteration 33000 / 120000: loss 0.000000\n",
      "iteration 33100 / 120000: loss 0.000000\n",
      "iteration 33200 / 120000: loss 0.000000\n",
      "iteration 33300 / 120000: loss 0.000000\n",
      "iteration 33400 / 120000: loss 0.659454\n",
      "iteration 33500 / 120000: loss 0.000000\n",
      "iteration 33600 / 120000: loss 0.000000\n",
      "iteration 33700 / 120000: loss 5.872398\n",
      "iteration 33800 / 120000: loss 0.000000\n",
      "iteration 33900 / 120000: loss 0.000000\n",
      "iteration 34000 / 120000: loss 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 34100 / 120000: loss 0.000000\n",
      "iteration 34200 / 120000: loss 0.000000\n",
      "iteration 34300 / 120000: loss 0.000000\n",
      "iteration 34400 / 120000: loss 0.000000\n",
      "iteration 34500 / 120000: loss 28.946522\n",
      "iteration 34600 / 120000: loss 0.000000\n",
      "iteration 34700 / 120000: loss 23.871638\n",
      "iteration 34800 / 120000: loss 0.000000\n",
      "iteration 34900 / 120000: loss 0.000000\n",
      "iteration 35000 / 120000: loss 0.000000\n",
      "iteration 35100 / 120000: loss 0.000000\n",
      "iteration 35200 / 120000: loss 0.014745\n",
      "iteration 35300 / 120000: loss 0.000000\n",
      "iteration 35400 / 120000: loss 0.000000\n",
      "iteration 35500 / 120000: loss 0.000000\n",
      "iteration 35600 / 120000: loss 0.000000\n",
      "iteration 35700 / 120000: loss 13.919396\n",
      "iteration 35800 / 120000: loss 0.000000\n",
      "iteration 35900 / 120000: loss 0.000000\n",
      "iteration 36000 / 120000: loss 0.000000\n",
      "iteration 36100 / 120000: loss 0.000161\n",
      "iteration 36200 / 120000: loss 0.000000\n",
      "iteration 36300 / 120000: loss 0.000000\n",
      "iteration 36400 / 120000: loss 0.000000\n",
      "iteration 36500 / 120000: loss 0.000000\n",
      "iteration 36600 / 120000: loss 0.000000\n",
      "iteration 36700 / 120000: loss 0.000000\n",
      "iteration 36800 / 120000: loss 0.000000\n",
      "iteration 36900 / 120000: loss 0.000000\n",
      "iteration 37000 / 120000: loss 115.476980\n",
      "iteration 37100 / 120000: loss 18.959905\n",
      "iteration 37200 / 120000: loss 0.000000\n",
      "iteration 37300 / 120000: loss 4.033620\n",
      "iteration 37400 / 120000: loss 45.477600\n",
      "iteration 37500 / 120000: loss 0.000000\n",
      "iteration 37600 / 120000: loss 28.552001\n",
      "iteration 37700 / 120000: loss 0.000000\n",
      "iteration 37800 / 120000: loss 25.753933\n",
      "iteration 37900 / 120000: loss 99.259723\n",
      "iteration 38000 / 120000: loss 0.000000\n",
      "iteration 38100 / 120000: loss 0.000000\n",
      "iteration 38200 / 120000: loss 0.000001\n",
      "iteration 38300 / 120000: loss 98.328941\n",
      "iteration 38400 / 120000: loss 0.000000\n",
      "iteration 38500 / 120000: loss 19.295373\n",
      "iteration 38600 / 120000: loss 0.000000\n",
      "iteration 38700 / 120000: loss 0.000000\n",
      "iteration 38800 / 120000: loss 0.000000\n",
      "iteration 38900 / 120000: loss 0.000000\n",
      "iteration 39000 / 120000: loss 9.277970\n",
      "iteration 39100 / 120000: loss 0.000000\n",
      "iteration 39200 / 120000: loss 0.198149\n",
      "iteration 39300 / 120000: loss 6.189553\n",
      "iteration 39400 / 120000: loss 0.000000\n",
      "iteration 39500 / 120000: loss 0.000000\n",
      "iteration 39600 / 120000: loss 0.000000\n",
      "iteration 39700 / 120000: loss 0.000000\n",
      "iteration 39800 / 120000: loss 0.000000\n",
      "iteration 39900 / 120000: loss 129.240332\n",
      "iteration 40000 / 120000: loss 0.000000\n",
      "iteration 40100 / 120000: loss 0.000067\n",
      "iteration 40200 / 120000: loss 0.000000\n",
      "iteration 40300 / 120000: loss 0.000000\n",
      "iteration 40400 / 120000: loss 0.000000\n",
      "iteration 40500 / 120000: loss 0.000000\n",
      "iteration 40600 / 120000: loss 0.000000\n",
      "iteration 40700 / 120000: loss 22.923030\n",
      "iteration 40800 / 120000: loss 62.917297\n",
      "iteration 40900 / 120000: loss 0.000000\n",
      "iteration 41000 / 120000: loss 0.000000\n",
      "iteration 41100 / 120000: loss 0.000951\n",
      "iteration 41200 / 120000: loss 0.000000\n",
      "iteration 41300 / 120000: loss 27.281612\n",
      "iteration 41400 / 120000: loss 28.335699\n",
      "iteration 41500 / 120000: loss 32.194656\n",
      "iteration 41600 / 120000: loss 2.371444\n",
      "iteration 41700 / 120000: loss 35.832940\n",
      "iteration 41800 / 120000: loss 0.000000\n",
      "iteration 41900 / 120000: loss 0.000000\n",
      "iteration 42000 / 120000: loss 0.000000\n",
      "iteration 42100 / 120000: loss 10.236498\n",
      "iteration 42200 / 120000: loss 0.000000\n",
      "iteration 42300 / 120000: loss 0.000000\n",
      "iteration 42400 / 120000: loss 0.000000\n",
      "iteration 42500 / 120000: loss 0.950658\n",
      "iteration 42600 / 120000: loss 0.000000\n",
      "iteration 42700 / 120000: loss 93.821302\n",
      "iteration 42800 / 120000: loss 0.000000\n",
      "iteration 42900 / 120000: loss 0.000000\n",
      "iteration 43000 / 120000: loss 0.000000\n",
      "iteration 43100 / 120000: loss 0.000000\n",
      "iteration 43200 / 120000: loss 6.027472\n",
      "iteration 43300 / 120000: loss 26.652541\n",
      "iteration 43400 / 120000: loss 0.000000\n",
      "iteration 43500 / 120000: loss 0.000000\n",
      "iteration 43600 / 120000: loss 0.000000\n",
      "iteration 43700 / 120000: loss 24.120709\n",
      "iteration 43800 / 120000: loss 0.000000\n",
      "iteration 43900 / 120000: loss 45.685428\n",
      "iteration 44000 / 120000: loss 0.000000\n",
      "iteration 44100 / 120000: loss 0.000000\n",
      "iteration 44200 / 120000: loss 0.000000\n",
      "iteration 44300 / 120000: loss 0.000000\n",
      "iteration 44400 / 120000: loss 36.063167\n",
      "iteration 44500 / 120000: loss 9.796787\n",
      "iteration 44600 / 120000: loss 0.000000\n",
      "iteration 44700 / 120000: loss 0.000000\n",
      "iteration 44800 / 120000: loss 0.000000\n",
      "iteration 44900 / 120000: loss 129.602370\n",
      "iteration 45000 / 120000: loss 0.000000\n",
      "iteration 45100 / 120000: loss 0.018742\n",
      "iteration 45200 / 120000: loss 0.000000\n",
      "iteration 45300 / 120000: loss 0.000000\n",
      "iteration 45400 / 120000: loss 0.000000\n",
      "iteration 45500 / 120000: loss 45.511552\n",
      "iteration 45600 / 120000: loss 0.000000\n",
      "iteration 45700 / 120000: loss 0.000000\n",
      "iteration 45800 / 120000: loss 0.000000\n",
      "iteration 45900 / 120000: loss 0.000006\n",
      "iteration 46000 / 120000: loss 28.827332\n",
      "iteration 46100 / 120000: loss 0.000000\n",
      "iteration 46200 / 120000: loss 0.000000\n",
      "iteration 46300 / 120000: loss 0.000000\n",
      "iteration 46400 / 120000: loss 0.003939\n",
      "iteration 46500 / 120000: loss 0.000000\n",
      "iteration 46600 / 120000: loss 0.004324\n",
      "iteration 46700 / 120000: loss 46.695904\n",
      "iteration 46800 / 120000: loss 0.672016\n",
      "iteration 46900 / 120000: loss 56.960214\n",
      "iteration 47000 / 120000: loss 0.000000\n",
      "iteration 47100 / 120000: loss 3.732671\n",
      "iteration 47200 / 120000: loss 0.000000\n",
      "iteration 47300 / 120000: loss 34.341023\n",
      "iteration 47400 / 120000: loss 30.713083\n",
      "iteration 47500 / 120000: loss 0.000000\n",
      "iteration 47600 / 120000: loss 0.000000\n",
      "iteration 47700 / 120000: loss 0.000000\n",
      "iteration 47800 / 120000: loss 0.000289\n",
      "iteration 47900 / 120000: loss 61.456980\n",
      "iteration 48000 / 120000: loss 0.000000\n",
      "iteration 48100 / 120000: loss 0.000001\n",
      "iteration 48200 / 120000: loss 0.000000\n",
      "iteration 48300 / 120000: loss 15.564821\n",
      "iteration 48400 / 120000: loss 0.000000\n",
      "iteration 48500 / 120000: loss 0.000000\n",
      "iteration 48600 / 120000: loss 0.000000\n",
      "iteration 48700 / 120000: loss 0.000000\n",
      "iteration 48800 / 120000: loss 0.000000\n",
      "iteration 48900 / 120000: loss 0.688536\n",
      "iteration 49000 / 120000: loss 0.000000\n",
      "iteration 49100 / 120000: loss 0.000000\n",
      "iteration 49200 / 120000: loss 13.576558\n",
      "iteration 49300 / 120000: loss 0.000000\n",
      "iteration 49400 / 120000: loss 0.000000\n",
      "iteration 49500 / 120000: loss 0.000000\n",
      "iteration 49600 / 120000: loss 0.001458\n",
      "iteration 49700 / 120000: loss 0.000000\n",
      "iteration 49800 / 120000: loss 0.000000\n",
      "iteration 49900 / 120000: loss 0.000000\n",
      "iteration 50000 / 120000: loss 0.000000\n",
      "iteration 50100 / 120000: loss 36.316666\n",
      "iteration 50200 / 120000: loss 16.769470\n",
      "iteration 50300 / 120000: loss 0.000000\n",
      "iteration 50400 / 120000: loss 0.000000\n",
      "iteration 50500 / 120000: loss 5.372361\n",
      "iteration 50600 / 120000: loss 0.000000\n",
      "iteration 50700 / 120000: loss 0.000024\n",
      "iteration 50800 / 120000: loss 0.002875\n",
      "iteration 50900 / 120000: loss 2.995685\n",
      "iteration 51000 / 120000: loss 0.000000\n",
      "iteration 51100 / 120000: loss 0.000000\n",
      "iteration 51200 / 120000: loss 0.023470\n",
      "iteration 51300 / 120000: loss 0.000000\n",
      "iteration 51400 / 120000: loss 0.000000\n",
      "iteration 51500 / 120000: loss 0.009322\n",
      "iteration 51600 / 120000: loss 62.561944\n",
      "iteration 51700 / 120000: loss 0.000000\n",
      "iteration 51800 / 120000: loss 0.000000\n",
      "iteration 51900 / 120000: loss 0.000000\n",
      "iteration 52000 / 120000: loss 0.026083\n",
      "iteration 52100 / 120000: loss 0.000000\n",
      "iteration 52200 / 120000: loss 0.000000\n",
      "iteration 52300 / 120000: loss 0.000000\n",
      "iteration 52400 / 120000: loss 12.544561\n",
      "iteration 52500 / 120000: loss 0.000000\n",
      "iteration 52600 / 120000: loss 95.209766\n",
      "iteration 52700 / 120000: loss 1.837612\n",
      "iteration 52800 / 120000: loss 0.000000\n",
      "iteration 52900 / 120000: loss 0.000000\n",
      "iteration 53000 / 120000: loss 0.000000\n",
      "iteration 53100 / 120000: loss 0.000000\n",
      "iteration 53200 / 120000: loss 0.000000\n",
      "iteration 53300 / 120000: loss 0.000000\n",
      "iteration 53400 / 120000: loss 0.000000\n",
      "iteration 53500 / 120000: loss 0.000000\n",
      "iteration 53600 / 120000: loss 0.002245\n",
      "iteration 53700 / 120000: loss 0.016118\n",
      "iteration 53800 / 120000: loss 0.000000\n",
      "iteration 53900 / 120000: loss 0.000000\n",
      "iteration 54000 / 120000: loss 63.422165\n",
      "iteration 54100 / 120000: loss 13.804546\n",
      "iteration 54200 / 120000: loss 0.000000\n",
      "iteration 54300 / 120000: loss 0.000001\n",
      "iteration 54400 / 120000: loss 0.000000\n",
      "iteration 54500 / 120000: loss 0.000000\n",
      "iteration 54600 / 120000: loss 0.000000\n",
      "iteration 54700 / 120000: loss 0.000109\n",
      "iteration 54800 / 120000: loss 75.501523\n",
      "iteration 54900 / 120000: loss 0.000000\n",
      "iteration 55000 / 120000: loss 0.000000\n",
      "iteration 55100 / 120000: loss 93.373498\n",
      "iteration 55200 / 120000: loss 0.000000\n",
      "iteration 55300 / 120000: loss 0.000000\n",
      "iteration 55400 / 120000: loss 0.000000\n",
      "iteration 55500 / 120000: loss 35.554903\n",
      "iteration 55600 / 120000: loss 0.000000\n",
      "iteration 55700 / 120000: loss 0.000000\n",
      "iteration 55800 / 120000: loss 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 55900 / 120000: loss 0.001135\n",
      "iteration 56000 / 120000: loss 9.088777\n",
      "iteration 56100 / 120000: loss 0.000000\n",
      "iteration 56200 / 120000: loss 8.056406\n",
      "iteration 56300 / 120000: loss 34.420329\n",
      "iteration 56400 / 120000: loss 34.243888\n",
      "iteration 56500 / 120000: loss 0.210814\n",
      "iteration 56600 / 120000: loss 0.000866\n",
      "iteration 56700 / 120000: loss 0.000000\n",
      "iteration 56800 / 120000: loss 9.278233\n",
      "iteration 56900 / 120000: loss 0.000000\n",
      "iteration 57000 / 120000: loss 0.000000\n",
      "iteration 57100 / 120000: loss 0.000000\n",
      "iteration 57200 / 120000: loss 0.000000\n",
      "iteration 57300 / 120000: loss 0.000000\n",
      "iteration 57400 / 120000: loss 0.000000\n",
      "iteration 57500 / 120000: loss 6.662219\n",
      "iteration 57600 / 120000: loss 0.000000\n",
      "iteration 57700 / 120000: loss 38.281565\n",
      "iteration 57800 / 120000: loss 0.000000\n",
      "iteration 57900 / 120000: loss 0.000000\n",
      "iteration 58000 / 120000: loss 23.165877\n",
      "iteration 58100 / 120000: loss 0.000000\n",
      "iteration 58200 / 120000: loss 0.000000\n",
      "iteration 58300 / 120000: loss 0.000000\n",
      "iteration 58400 / 120000: loss 17.332368\n",
      "iteration 58500 / 120000: loss 0.000000\n",
      "iteration 58600 / 120000: loss 34.715830\n",
      "iteration 58700 / 120000: loss 38.861243\n",
      "iteration 58800 / 120000: loss 0.550780\n",
      "iteration 58900 / 120000: loss 0.000000\n",
      "iteration 59000 / 120000: loss 0.000000\n",
      "iteration 59100 / 120000: loss 0.000000\n",
      "iteration 59200 / 120000: loss 0.000000\n",
      "iteration 59300 / 120000: loss 0.000000\n",
      "iteration 59400 / 120000: loss 0.000000\n",
      "iteration 59500 / 120000: loss 0.000000\n",
      "iteration 59600 / 120000: loss 0.000000\n",
      "iteration 59700 / 120000: loss 6.467339\n",
      "iteration 59800 / 120000: loss 0.000000\n",
      "iteration 59900 / 120000: loss 0.000000\n",
      "iteration 60000 / 120000: loss 0.016383\n",
      "iteration 60100 / 120000: loss 0.000000\n",
      "iteration 60200 / 120000: loss 0.000000\n",
      "iteration 60300 / 120000: loss 0.000000\n",
      "iteration 60400 / 120000: loss 0.000000\n",
      "iteration 60500 / 120000: loss 0.000000\n",
      "iteration 60600 / 120000: loss 0.000000\n",
      "iteration 60700 / 120000: loss 51.001229\n",
      "iteration 60800 / 120000: loss 3.815513\n",
      "iteration 60900 / 120000: loss 0.000017\n",
      "iteration 61000 / 120000: loss 0.000000\n",
      "iteration 61100 / 120000: loss 13.671181\n",
      "iteration 61200 / 120000: loss 0.005002\n",
      "iteration 61300 / 120000: loss 104.930854\n",
      "iteration 61400 / 120000: loss 0.046325\n",
      "iteration 61500 / 120000: loss 0.000000\n",
      "iteration 61600 / 120000: loss 0.000000\n",
      "iteration 61700 / 120000: loss 0.000000\n",
      "iteration 61800 / 120000: loss 0.000000\n",
      "iteration 61900 / 120000: loss 0.000000\n",
      "iteration 62000 / 120000: loss 0.000180\n",
      "iteration 62100 / 120000: loss 0.000007\n",
      "iteration 62200 / 120000: loss 0.000000\n",
      "iteration 62300 / 120000: loss 0.000000\n",
      "iteration 62400 / 120000: loss 0.000000\n",
      "iteration 62500 / 120000: loss 60.596642\n",
      "iteration 62600 / 120000: loss 0.000000\n",
      "iteration 62700 / 120000: loss 0.000000\n",
      "iteration 62800 / 120000: loss 0.000000\n",
      "iteration 62900 / 120000: loss 0.000000\n",
      "iteration 63000 / 120000: loss 0.000012\n",
      "iteration 63100 / 120000: loss 17.050196\n",
      "iteration 63200 / 120000: loss 0.000000\n",
      "iteration 63300 / 120000: loss 0.007945\n",
      "iteration 63400 / 120000: loss 0.000000\n",
      "iteration 63500 / 120000: loss 0.000000\n",
      "iteration 63600 / 120000: loss 33.612347\n",
      "iteration 63700 / 120000: loss 0.000000\n",
      "iteration 63800 / 120000: loss 45.377009\n",
      "iteration 63900 / 120000: loss 28.145832\n",
      "iteration 64000 / 120000: loss 0.000000\n",
      "iteration 64100 / 120000: loss 0.047533\n",
      "iteration 64200 / 120000: loss 0.000000\n",
      "iteration 64300 / 120000: loss 0.000000\n",
      "iteration 64400 / 120000: loss 0.000000\n",
      "iteration 64500 / 120000: loss 0.000000\n",
      "iteration 64600 / 120000: loss 0.000000\n",
      "iteration 64700 / 120000: loss 0.000000\n",
      "iteration 64800 / 120000: loss 0.000000\n",
      "iteration 64900 / 120000: loss 59.429538\n",
      "iteration 65000 / 120000: loss 0.000000\n",
      "iteration 65100 / 120000: loss 9.616656\n",
      "iteration 65200 / 120000: loss 29.917776\n",
      "iteration 65300 / 120000: loss 25.614103\n",
      "iteration 65400 / 120000: loss 26.179306\n",
      "iteration 65500 / 120000: loss 0.000011\n",
      "iteration 65600 / 120000: loss 0.000000\n",
      "iteration 65700 / 120000: loss 0.000000\n",
      "iteration 65800 / 120000: loss 0.000000\n",
      "iteration 65900 / 120000: loss 24.446901\n",
      "iteration 66000 / 120000: loss 0.249625\n",
      "iteration 66100 / 120000: loss 0.000000\n",
      "iteration 66200 / 120000: loss 0.000000\n",
      "iteration 66300 / 120000: loss 30.160946\n",
      "iteration 66400 / 120000: loss 0.000000\n",
      "iteration 66500 / 120000: loss 0.000000\n",
      "iteration 66600 / 120000: loss 0.000000\n",
      "iteration 66700 / 120000: loss 0.000000\n",
      "iteration 66800 / 120000: loss 4.796798\n",
      "iteration 66900 / 120000: loss 0.000000\n",
      "iteration 67000 / 120000: loss 0.006495\n",
      "iteration 67100 / 120000: loss 0.000000\n",
      "iteration 67200 / 120000: loss 0.000000\n",
      "iteration 67300 / 120000: loss 0.000000\n",
      "iteration 67400 / 120000: loss 0.000000\n",
      "iteration 67500 / 120000: loss 0.000000\n",
      "iteration 67600 / 120000: loss 0.000125\n",
      "iteration 67700 / 120000: loss 0.000000\n",
      "iteration 67800 / 120000: loss 55.607896\n",
      "iteration 67900 / 120000: loss 0.000000\n",
      "iteration 68000 / 120000: loss 71.006952\n",
      "iteration 68100 / 120000: loss 0.000000\n",
      "iteration 68200 / 120000: loss 0.000000\n",
      "iteration 68300 / 120000: loss 0.000000\n",
      "iteration 68400 / 120000: loss 0.000000\n",
      "iteration 68500 / 120000: loss 0.000000\n",
      "iteration 68600 / 120000: loss 0.000003\n",
      "iteration 68700 / 120000: loss 0.000000\n",
      "iteration 68800 / 120000: loss 0.000000\n",
      "iteration 68900 / 120000: loss 40.533870\n",
      "iteration 69000 / 120000: loss 0.000000\n",
      "iteration 69100 / 120000: loss 0.000000\n",
      "iteration 69200 / 120000: loss 5.466427\n",
      "iteration 69300 / 120000: loss 0.000000\n",
      "iteration 69400 / 120000: loss 0.000000\n",
      "iteration 69500 / 120000: loss 15.107745\n",
      "iteration 69600 / 120000: loss 0.000000\n",
      "iteration 69700 / 120000: loss 0.000000\n",
      "iteration 69800 / 120000: loss 0.000001\n",
      "iteration 69900 / 120000: loss 0.000000\n",
      "iteration 70000 / 120000: loss 0.000000\n",
      "iteration 70100 / 120000: loss 0.000000\n",
      "iteration 70200 / 120000: loss 0.000000\n",
      "iteration 70300 / 120000: loss 0.000000\n",
      "iteration 70400 / 120000: loss 3.852235\n",
      "iteration 70500 / 120000: loss 21.964500\n",
      "iteration 70600 / 120000: loss 0.000000\n",
      "iteration 70700 / 120000: loss 0.000000\n",
      "iteration 70800 / 120000: loss 0.000000\n",
      "iteration 70900 / 120000: loss 0.000000\n",
      "iteration 71000 / 120000: loss 28.240412\n",
      "iteration 71100 / 120000: loss 0.000000\n",
      "iteration 71200 / 120000: loss 11.844220\n",
      "iteration 71300 / 120000: loss 0.000000\n",
      "iteration 71400 / 120000: loss 0.000000\n",
      "iteration 71500 / 120000: loss 0.000000\n",
      "iteration 71600 / 120000: loss 0.000000\n",
      "iteration 71700 / 120000: loss 0.000000\n",
      "iteration 71800 / 120000: loss 0.000000\n",
      "iteration 71900 / 120000: loss 0.000000\n",
      "iteration 72000 / 120000: loss 0.000000\n",
      "iteration 72100 / 120000: loss 0.000000\n",
      "iteration 72200 / 120000: loss 0.000000\n",
      "iteration 72300 / 120000: loss 0.000000\n",
      "iteration 72400 / 120000: loss 0.000049\n",
      "iteration 72500 / 120000: loss 0.000000\n",
      "iteration 72600 / 120000: loss 0.000000\n",
      "iteration 72700 / 120000: loss 0.000000\n",
      "iteration 72800 / 120000: loss 0.000000\n",
      "iteration 72900 / 120000: loss 0.000000\n",
      "iteration 73000 / 120000: loss 3.298118\n",
      "iteration 73100 / 120000: loss 12.216259\n",
      "iteration 73200 / 120000: loss 0.745182\n",
      "iteration 73300 / 120000: loss 0.000000\n",
      "iteration 73400 / 120000: loss 0.000000\n",
      "iteration 73500 / 120000: loss 32.456690\n",
      "iteration 73600 / 120000: loss 0.000000\n",
      "iteration 73700 / 120000: loss 0.000000\n",
      "iteration 73800 / 120000: loss 0.000000\n",
      "iteration 73900 / 120000: loss 38.561177\n",
      "iteration 74000 / 120000: loss 41.183018\n",
      "iteration 74100 / 120000: loss 0.000000\n",
      "iteration 74200 / 120000: loss 0.000000\n",
      "iteration 74300 / 120000: loss 0.000000\n",
      "iteration 74400 / 120000: loss 0.000000\n",
      "iteration 74500 / 120000: loss 0.000000\n",
      "iteration 74600 / 120000: loss 0.000000\n",
      "iteration 74700 / 120000: loss 0.275860\n",
      "iteration 74800 / 120000: loss 0.000000\n",
      "iteration 74900 / 120000: loss 0.000002\n",
      "iteration 75000 / 120000: loss 0.000000\n",
      "iteration 75100 / 120000: loss 0.036862\n",
      "iteration 75200 / 120000: loss 0.000000\n",
      "iteration 75300 / 120000: loss 0.000000\n",
      "iteration 75400 / 120000: loss 32.686251\n",
      "iteration 75500 / 120000: loss 0.000000\n",
      "iteration 75600 / 120000: loss 0.000000\n",
      "iteration 75700 / 120000: loss 0.000000\n",
      "iteration 75800 / 120000: loss 0.000000\n",
      "iteration 75900 / 120000: loss 0.000000\n",
      "iteration 76000 / 120000: loss 0.000000\n",
      "iteration 76100 / 120000: loss 0.000000\n",
      "iteration 76200 / 120000: loss 13.112642\n",
      "iteration 76300 / 120000: loss 0.000000\n",
      "iteration 76400 / 120000: loss 0.000000\n",
      "iteration 76500 / 120000: loss 39.503546\n",
      "iteration 76600 / 120000: loss 1.408905\n",
      "iteration 76700 / 120000: loss 0.000000\n",
      "iteration 76800 / 120000: loss 124.993698\n",
      "iteration 76900 / 120000: loss 12.845270\n",
      "iteration 77000 / 120000: loss 0.000000\n",
      "iteration 77100 / 120000: loss 0.000000\n",
      "iteration 77200 / 120000: loss 15.043061\n",
      "iteration 77300 / 120000: loss 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 77400 / 120000: loss 55.589749\n",
      "iteration 77500 / 120000: loss 0.000000\n",
      "iteration 77600 / 120000: loss 0.000000\n",
      "iteration 77700 / 120000: loss 32.177837\n",
      "iteration 77800 / 120000: loss 0.000000\n",
      "iteration 77900 / 120000: loss 39.082530\n",
      "iteration 78000 / 120000: loss 0.000000\n",
      "iteration 78100 / 120000: loss 0.001716\n",
      "iteration 78200 / 120000: loss 0.000000\n",
      "iteration 78300 / 120000: loss 0.000000\n",
      "iteration 78400 / 120000: loss 0.000000\n",
      "iteration 78500 / 120000: loss 28.487019\n",
      "iteration 78600 / 120000: loss 0.000000\n",
      "iteration 78700 / 120000: loss 0.000000\n",
      "iteration 78800 / 120000: loss 30.033931\n",
      "iteration 78900 / 120000: loss 0.000001\n",
      "iteration 79000 / 120000: loss 66.991094\n",
      "iteration 79100 / 120000: loss 0.000000\n",
      "iteration 79200 / 120000: loss 0.000000\n",
      "iteration 79300 / 120000: loss 0.000000\n",
      "iteration 79400 / 120000: loss 0.000000\n",
      "iteration 79500 / 120000: loss 0.000000\n",
      "iteration 79600 / 120000: loss 0.000000\n",
      "iteration 79700 / 120000: loss 0.000005\n",
      "iteration 79800 / 120000: loss 0.000000\n",
      "iteration 79900 / 120000: loss 0.000000\n",
      "iteration 80000 / 120000: loss 0.000000\n",
      "iteration 80100 / 120000: loss 0.000000\n",
      "iteration 80200 / 120000: loss 0.000000\n",
      "iteration 80300 / 120000: loss 0.000000\n",
      "iteration 80400 / 120000: loss 0.000000\n",
      "iteration 80500 / 120000: loss 0.000000\n",
      "iteration 80600 / 120000: loss 0.000000\n",
      "iteration 80700 / 120000: loss 0.000000\n",
      "iteration 80800 / 120000: loss 0.000000\n",
      "iteration 80900 / 120000: loss 75.260765\n",
      "iteration 81000 / 120000: loss 29.930859\n",
      "iteration 81100 / 120000: loss 0.000000\n",
      "iteration 81200 / 120000: loss 0.401485\n",
      "iteration 81300 / 120000: loss 0.000000\n",
      "iteration 81400 / 120000: loss 0.000000\n",
      "iteration 81500 / 120000: loss 48.460180\n",
      "iteration 81600 / 120000: loss 0.000000\n",
      "iteration 81700 / 120000: loss 0.000000\n",
      "iteration 81800 / 120000: loss 0.000000\n",
      "iteration 81900 / 120000: loss 0.000000\n",
      "iteration 82000 / 120000: loss 0.000000\n",
      "iteration 82100 / 120000: loss 0.000000\n",
      "iteration 82200 / 120000: loss 0.000000\n",
      "iteration 82300 / 120000: loss 0.000000\n",
      "iteration 82400 / 120000: loss 0.000000\n",
      "iteration 82500 / 120000: loss 0.000000\n",
      "iteration 82600 / 120000: loss 0.000000\n",
      "iteration 82700 / 120000: loss 0.000000\n",
      "iteration 82800 / 120000: loss 2.819169\n",
      "iteration 82900 / 120000: loss 0.000000\n",
      "iteration 83000 / 120000: loss 0.000000\n",
      "iteration 83100 / 120000: loss 0.000000\n",
      "iteration 83200 / 120000: loss 0.000000\n",
      "iteration 83300 / 120000: loss 18.519714\n",
      "iteration 83400 / 120000: loss 0.000000\n",
      "iteration 83500 / 120000: loss 0.000000\n",
      "iteration 83600 / 120000: loss 0.000000\n",
      "iteration 83700 / 120000: loss 23.635119\n",
      "iteration 83800 / 120000: loss 53.861551\n",
      "iteration 83900 / 120000: loss 0.014030\n",
      "iteration 84000 / 120000: loss 0.000000\n",
      "iteration 84100 / 120000: loss 0.000000\n",
      "iteration 84200 / 120000: loss 0.196105\n",
      "iteration 84300 / 120000: loss 0.000000\n",
      "iteration 84400 / 120000: loss 0.000000\n",
      "iteration 84500 / 120000: loss 0.000000\n",
      "iteration 84600 / 120000: loss 0.000000\n",
      "iteration 84700 / 120000: loss 0.000000\n",
      "iteration 84800 / 120000: loss 0.000000\n",
      "iteration 84900 / 120000: loss 0.000000\n",
      "iteration 85000 / 120000: loss 47.170459\n",
      "iteration 85100 / 120000: loss 0.003811\n",
      "iteration 85200 / 120000: loss 0.000000\n",
      "iteration 85300 / 120000: loss 85.912135\n",
      "iteration 85400 / 120000: loss 0.000000\n",
      "iteration 85500 / 120000: loss 0.000000\n",
      "iteration 85600 / 120000: loss 0.000000\n",
      "iteration 85700 / 120000: loss 0.000000\n",
      "iteration 85800 / 120000: loss 0.381588\n",
      "iteration 85900 / 120000: loss 0.000000\n",
      "iteration 86000 / 120000: loss 39.223064\n",
      "iteration 86100 / 120000: loss 0.000000\n",
      "iteration 86200 / 120000: loss 0.000000\n",
      "iteration 86300 / 120000: loss 0.000000\n",
      "iteration 86400 / 120000: loss 0.000000\n",
      "iteration 86500 / 120000: loss 0.000000\n",
      "iteration 86600 / 120000: loss 26.561791\n",
      "iteration 86700 / 120000: loss 0.000000\n",
      "iteration 86800 / 120000: loss 42.650550\n",
      "iteration 86900 / 120000: loss 0.000000\n",
      "iteration 87000 / 120000: loss 0.000000\n",
      "iteration 87100 / 120000: loss 53.039038\n",
      "iteration 87200 / 120000: loss 2.997719\n",
      "iteration 87300 / 120000: loss 0.000000\n",
      "iteration 87400 / 120000: loss 0.000053\n",
      "iteration 87500 / 120000: loss 0.000011\n",
      "iteration 87600 / 120000: loss 0.000000\n",
      "iteration 87700 / 120000: loss 0.000000\n",
      "iteration 87800 / 120000: loss 0.000000\n",
      "iteration 87900 / 120000: loss 0.000000\n",
      "iteration 88000 / 120000: loss 0.003965\n",
      "iteration 88100 / 120000: loss 0.000208\n",
      "iteration 88200 / 120000: loss 23.948405\n",
      "iteration 88300 / 120000: loss 21.457300\n",
      "iteration 88400 / 120000: loss 0.000000\n",
      "iteration 88500 / 120000: loss 11.945968\n",
      "iteration 88600 / 120000: loss 0.000000\n",
      "iteration 88700 / 120000: loss 0.000000\n",
      "iteration 88800 / 120000: loss 4.842721\n",
      "iteration 88900 / 120000: loss 21.231149\n",
      "iteration 89000 / 120000: loss 0.000622\n",
      "iteration 89100 / 120000: loss 0.000000\n",
      "iteration 89200 / 120000: loss 0.000000\n",
      "iteration 89300 / 120000: loss 0.300325\n",
      "iteration 89400 / 120000: loss 0.000000\n",
      "iteration 89500 / 120000: loss 82.558927\n",
      "iteration 89600 / 120000: loss 6.769596\n",
      "iteration 89700 / 120000: loss 0.000000\n",
      "iteration 89800 / 120000: loss 0.000000\n",
      "iteration 89900 / 120000: loss 0.000000\n",
      "iteration 90000 / 120000: loss 0.000000\n",
      "iteration 90100 / 120000: loss 0.000000\n",
      "iteration 90200 / 120000: loss 13.784236\n",
      "iteration 90300 / 120000: loss 0.000000\n",
      "iteration 90400 / 120000: loss 0.000000\n",
      "iteration 90500 / 120000: loss 14.537714\n",
      "iteration 90600 / 120000: loss 0.000000\n",
      "iteration 90700 / 120000: loss 9.604892\n",
      "iteration 90800 / 120000: loss 0.000000\n",
      "iteration 90900 / 120000: loss 0.000000\n",
      "iteration 91000 / 120000: loss 0.000000\n",
      "iteration 91100 / 120000: loss 0.000000\n",
      "iteration 91200 / 120000: loss 0.000000\n",
      "iteration 91300 / 120000: loss 16.159087\n",
      "iteration 91400 / 120000: loss 9.590079\n",
      "iteration 91500 / 120000: loss 0.000000\n",
      "iteration 91600 / 120000: loss 0.000000\n",
      "iteration 91700 / 120000: loss 0.000000\n",
      "iteration 91800 / 120000: loss 0.000000\n",
      "iteration 91900 / 120000: loss 0.000000\n",
      "iteration 92000 / 120000: loss 0.000000\n",
      "iteration 92100 / 120000: loss 0.000000\n",
      "iteration 92200 / 120000: loss 0.000000\n",
      "iteration 92300 / 120000: loss 0.000000\n",
      "iteration 92400 / 120000: loss 0.000000\n",
      "iteration 92500 / 120000: loss 0.000000\n",
      "iteration 92600 / 120000: loss 0.000000\n",
      "iteration 92700 / 120000: loss 0.000000\n",
      "iteration 92800 / 120000: loss 0.003841\n",
      "iteration 92900 / 120000: loss 0.000000\n",
      "iteration 93000 / 120000: loss 0.000000\n",
      "iteration 93100 / 120000: loss 0.000000\n",
      "iteration 93200 / 120000: loss 0.000000\n",
      "iteration 93300 / 120000: loss 0.000000\n",
      "iteration 93400 / 120000: loss 0.000000\n",
      "iteration 93500 / 120000: loss 0.000000\n",
      "iteration 93600 / 120000: loss 0.000000\n",
      "iteration 93700 / 120000: loss 0.002881\n",
      "iteration 93800 / 120000: loss 0.000000\n",
      "iteration 93900 / 120000: loss 0.000000\n",
      "iteration 94000 / 120000: loss 34.580299\n",
      "iteration 94100 / 120000: loss 0.000000\n",
      "iteration 94200 / 120000: loss 0.000000\n",
      "iteration 94300 / 120000: loss 0.001422\n",
      "iteration 94400 / 120000: loss 0.000000\n",
      "iteration 94500 / 120000: loss 1.469300\n",
      "iteration 94600 / 120000: loss 0.000000\n",
      "iteration 94700 / 120000: loss 0.000000\n",
      "iteration 94800 / 120000: loss 35.462662\n",
      "iteration 94900 / 120000: loss 0.141196\n",
      "iteration 95000 / 120000: loss 0.000000\n",
      "iteration 95100 / 120000: loss 0.000000\n",
      "iteration 95200 / 120000: loss 0.000000\n",
      "iteration 95300 / 120000: loss 0.000000\n",
      "iteration 95400 / 120000: loss 0.000000\n",
      "iteration 95500 / 120000: loss 15.902672\n",
      "iteration 95600 / 120000: loss 0.004432\n",
      "iteration 95700 / 120000: loss 0.025482\n",
      "iteration 95800 / 120000: loss 0.000000\n",
      "iteration 95900 / 120000: loss 14.553449\n",
      "iteration 96000 / 120000: loss 0.000000\n",
      "iteration 96100 / 120000: loss 0.000000\n",
      "iteration 96200 / 120000: loss 0.000000\n",
      "iteration 96300 / 120000: loss 0.000001\n",
      "iteration 96400 / 120000: loss 0.000000\n",
      "iteration 96500 / 120000: loss 0.000000\n",
      "iteration 96600 / 120000: loss 0.002908\n",
      "iteration 96700 / 120000: loss 0.000000\n",
      "iteration 96800 / 120000: loss 0.000000\n",
      "iteration 96900 / 120000: loss 0.000000\n",
      "iteration 97000 / 120000: loss 0.012357\n",
      "iteration 97100 / 120000: loss 0.315530\n",
      "iteration 97200 / 120000: loss 0.000000\n",
      "iteration 97300 / 120000: loss 18.898762\n",
      "iteration 97400 / 120000: loss 0.000000\n",
      "iteration 97500 / 120000: loss 1.327909\n",
      "iteration 97600 / 120000: loss 0.000000\n",
      "iteration 97700 / 120000: loss 0.000000\n",
      "iteration 97800 / 120000: loss 32.541901\n",
      "iteration 97900 / 120000: loss 18.837873\n",
      "iteration 98000 / 120000: loss 0.000000\n",
      "iteration 98100 / 120000: loss 0.000000\n",
      "iteration 98200 / 120000: loss 0.000000\n",
      "iteration 98300 / 120000: loss 0.009902\n",
      "iteration 98400 / 120000: loss 23.426885\n",
      "iteration 98500 / 120000: loss 0.011245\n",
      "iteration 98600 / 120000: loss 50.817906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 98700 / 120000: loss 0.000000\n",
      "iteration 98800 / 120000: loss 0.000000\n",
      "iteration 98900 / 120000: loss 0.006070\n",
      "iteration 99000 / 120000: loss 0.000000\n",
      "iteration 99100 / 120000: loss 0.000000\n",
      "iteration 99200 / 120000: loss 9.836871\n",
      "iteration 99300 / 120000: loss 0.000000\n",
      "iteration 99400 / 120000: loss 0.000000\n",
      "iteration 99500 / 120000: loss 0.000000\n",
      "iteration 99600 / 120000: loss 0.000000\n",
      "iteration 99700 / 120000: loss 0.000000\n",
      "iteration 99800 / 120000: loss 14.723391\n",
      "iteration 99900 / 120000: loss 0.000000\n",
      "iteration 100000 / 120000: loss 0.000000\n",
      "iteration 100100 / 120000: loss 0.000000\n",
      "iteration 100200 / 120000: loss 0.000000\n",
      "iteration 100300 / 120000: loss 0.000000\n",
      "iteration 100400 / 120000: loss 0.000000\n",
      "iteration 100500 / 120000: loss 23.229754\n",
      "iteration 100600 / 120000: loss 0.000084\n",
      "iteration 100700 / 120000: loss 0.000000\n",
      "iteration 100800 / 120000: loss 0.000000\n",
      "iteration 100900 / 120000: loss 9.221116\n",
      "iteration 101000 / 120000: loss 0.000000\n",
      "iteration 101100 / 120000: loss 0.000000\n",
      "iteration 101200 / 120000: loss 0.000000\n",
      "iteration 101300 / 120000: loss 0.000000\n",
      "iteration 101400 / 120000: loss 0.000000\n",
      "iteration 101500 / 120000: loss 28.984937\n",
      "iteration 101600 / 120000: loss 0.000000\n",
      "iteration 101700 / 120000: loss 0.000000\n",
      "iteration 101800 / 120000: loss 0.000000\n",
      "iteration 101900 / 120000: loss 1.261695\n",
      "iteration 102000 / 120000: loss 0.020169\n",
      "iteration 102100 / 120000: loss 35.514168\n",
      "iteration 102200 / 120000: loss 0.000000\n",
      "iteration 102300 / 120000: loss 0.000000\n",
      "iteration 102400 / 120000: loss 0.000000\n",
      "iteration 102500 / 120000: loss 0.000000\n",
      "iteration 102600 / 120000: loss 0.000000\n",
      "iteration 102700 / 120000: loss 0.000000\n",
      "iteration 102800 / 120000: loss 0.000000\n",
      "iteration 102900 / 120000: loss 0.000000\n",
      "iteration 103000 / 120000: loss 0.000000\n",
      "iteration 103100 / 120000: loss 0.000000\n",
      "iteration 103200 / 120000: loss 0.000000\n",
      "iteration 103300 / 120000: loss 0.000195\n",
      "iteration 103400 / 120000: loss 0.000000\n",
      "iteration 103500 / 120000: loss 0.000003\n",
      "iteration 103600 / 120000: loss 0.000000\n",
      "iteration 103700 / 120000: loss 0.000000\n",
      "iteration 103800 / 120000: loss 0.000000\n",
      "iteration 103900 / 120000: loss 0.000000\n",
      "iteration 104000 / 120000: loss 0.000000\n",
      "iteration 104100 / 120000: loss 0.000000\n",
      "iteration 104200 / 120000: loss 0.000000\n",
      "iteration 104300 / 120000: loss 0.001044\n",
      "iteration 104400 / 120000: loss 0.000000\n",
      "iteration 104500 / 120000: loss 0.000000\n",
      "iteration 104600 / 120000: loss 53.819090\n",
      "iteration 104700 / 120000: loss 0.000000\n",
      "iteration 104800 / 120000: loss 0.000000\n",
      "iteration 104900 / 120000: loss 0.000000\n",
      "iteration 105000 / 120000: loss 0.000000\n",
      "iteration 105100 / 120000: loss 16.111092\n",
      "iteration 105200 / 120000: loss 0.000000\n",
      "iteration 105300 / 120000: loss 0.000000\n",
      "iteration 105400 / 120000: loss 48.737200\n",
      "iteration 105500 / 120000: loss 0.000000\n",
      "iteration 105600 / 120000: loss 0.000000\n",
      "iteration 105700 / 120000: loss 0.000000\n",
      "iteration 105800 / 120000: loss 0.000000\n",
      "iteration 105900 / 120000: loss 31.681119\n",
      "iteration 106000 / 120000: loss 0.000001\n",
      "iteration 106100 / 120000: loss 9.783087\n",
      "iteration 106200 / 120000: loss 0.000000\n",
      "iteration 106300 / 120000: loss 0.000000\n",
      "iteration 106400 / 120000: loss 0.000000\n",
      "iteration 106500 / 120000: loss 94.552150\n",
      "iteration 106600 / 120000: loss 0.000000\n",
      "iteration 106700 / 120000: loss 0.000000\n",
      "iteration 106800 / 120000: loss 46.591968\n",
      "iteration 106900 / 120000: loss 0.000000\n",
      "iteration 107000 / 120000: loss 0.000000\n",
      "iteration 107100 / 120000: loss 0.000000\n",
      "iteration 107200 / 120000: loss 0.000000\n",
      "iteration 107300 / 120000: loss 0.000000\n",
      "iteration 107400 / 120000: loss 0.000000\n",
      "iteration 107500 / 120000: loss 67.586962\n",
      "iteration 107600 / 120000: loss 0.000000\n",
      "iteration 107700 / 120000: loss 0.000000\n",
      "iteration 107800 / 120000: loss 5.637402\n",
      "iteration 107900 / 120000: loss 1.474351\n",
      "iteration 108000 / 120000: loss 0.000003\n",
      "iteration 108100 / 120000: loss 0.000096\n",
      "iteration 108200 / 120000: loss 0.000000\n",
      "iteration 108300 / 120000: loss 7.738619\n",
      "iteration 108400 / 120000: loss 0.000000\n",
      "iteration 108500 / 120000: loss 26.548731\n",
      "iteration 108600 / 120000: loss 10.997673\n",
      "iteration 108700 / 120000: loss 1.778678\n",
      "iteration 108800 / 120000: loss 0.000000\n",
      "iteration 108900 / 120000: loss 0.000000\n",
      "iteration 109000 / 120000: loss 0.000000\n",
      "iteration 109100 / 120000: loss 0.000000\n",
      "iteration 109200 / 120000: loss 0.000000\n",
      "iteration 109300 / 120000: loss 0.000000\n",
      "iteration 109400 / 120000: loss 0.000000\n",
      "iteration 109500 / 120000: loss 0.000000\n",
      "iteration 109600 / 120000: loss 0.000000\n",
      "iteration 109700 / 120000: loss 0.000000\n",
      "iteration 109800 / 120000: loss 0.000000\n",
      "iteration 109900 / 120000: loss 0.000000\n",
      "iteration 110000 / 120000: loss 0.000000\n",
      "iteration 110100 / 120000: loss 0.000000\n",
      "iteration 110200 / 120000: loss 0.000000\n",
      "iteration 110300 / 120000: loss 0.000000\n",
      "iteration 110400 / 120000: loss 0.000000\n",
      "iteration 110500 / 120000: loss 0.000000\n",
      "iteration 110600 / 120000: loss 0.000000\n",
      "iteration 110700 / 120000: loss 0.000000\n",
      "iteration 110800 / 120000: loss 0.000000\n",
      "iteration 110900 / 120000: loss 0.000000\n",
      "iteration 111000 / 120000: loss 0.085427\n",
      "iteration 111100 / 120000: loss 0.000000\n",
      "iteration 111200 / 120000: loss 0.000000\n",
      "iteration 111300 / 120000: loss 0.307043\n",
      "iteration 111400 / 120000: loss 0.719976\n",
      "iteration 111500 / 120000: loss 0.000000\n",
      "iteration 111600 / 120000: loss 0.000000\n",
      "iteration 111700 / 120000: loss 0.000000\n",
      "iteration 111800 / 120000: loss 0.000000\n",
      "iteration 111900 / 120000: loss 0.000000\n",
      "iteration 112000 / 120000: loss 0.000000\n",
      "iteration 112100 / 120000: loss 0.000000\n",
      "iteration 112200 / 120000: loss 6.426925\n",
      "iteration 112300 / 120000: loss 2.093564\n",
      "iteration 112400 / 120000: loss 28.720508\n",
      "iteration 112500 / 120000: loss 0.000000\n",
      "iteration 112600 / 120000: loss 0.000000\n",
      "iteration 112700 / 120000: loss 0.000000\n",
      "iteration 112800 / 120000: loss 0.000000\n",
      "iteration 112900 / 120000: loss 0.000000\n",
      "iteration 113000 / 120000: loss 0.000000\n",
      "iteration 113100 / 120000: loss 0.000000\n",
      "iteration 113200 / 120000: loss 0.814834\n",
      "iteration 113300 / 120000: loss 0.000000\n",
      "iteration 113400 / 120000: loss 0.000000\n",
      "iteration 113500 / 120000: loss 43.351598\n",
      "iteration 113600 / 120000: loss 0.000000\n",
      "iteration 113700 / 120000: loss 0.000000\n",
      "iteration 113800 / 120000: loss 0.000000\n",
      "iteration 113900 / 120000: loss 0.000000\n",
      "iteration 114000 / 120000: loss 0.000000\n",
      "iteration 114100 / 120000: loss 27.345527\n",
      "iteration 114200 / 120000: loss 112.057382\n",
      "iteration 114300 / 120000: loss 36.662274\n",
      "iteration 114400 / 120000: loss 20.739084\n",
      "iteration 114500 / 120000: loss 20.650034\n",
      "iteration 114600 / 120000: loss 0.000000\n",
      "iteration 114700 / 120000: loss 0.000000\n",
      "iteration 114800 / 120000: loss 5.778096\n",
      "iteration 114900 / 120000: loss 98.603117\n",
      "iteration 115000 / 120000: loss 0.000000\n",
      "iteration 115100 / 120000: loss 0.000000\n",
      "iteration 115200 / 120000: loss 0.000021\n",
      "iteration 115300 / 120000: loss 0.000000\n",
      "iteration 115400 / 120000: loss 0.000000\n",
      "iteration 115500 / 120000: loss 0.000009\n",
      "iteration 115600 / 120000: loss 0.000000\n",
      "iteration 115700 / 120000: loss 0.000000\n",
      "iteration 115800 / 120000: loss 0.000000\n",
      "iteration 115900 / 120000: loss 0.000000\n",
      "iteration 116000 / 120000: loss 0.000000\n",
      "iteration 116100 / 120000: loss 2.998291\n",
      "iteration 116200 / 120000: loss 0.000000\n",
      "iteration 116300 / 120000: loss 0.000000\n",
      "iteration 116400 / 120000: loss 13.239055\n",
      "iteration 116500 / 120000: loss 18.218964\n",
      "iteration 116600 / 120000: loss 0.000616\n",
      "iteration 116700 / 120000: loss 0.000000\n",
      "iteration 116800 / 120000: loss 0.000000\n",
      "iteration 116900 / 120000: loss 0.000000\n",
      "iteration 117000 / 120000: loss 50.620991\n",
      "iteration 117100 / 120000: loss 0.000000\n",
      "iteration 117200 / 120000: loss 0.000000\n",
      "iteration 117300 / 120000: loss 7.755123\n",
      "iteration 117400 / 120000: loss 41.113681\n",
      "iteration 117500 / 120000: loss 0.060722\n",
      "iteration 117600 / 120000: loss 0.000000\n",
      "iteration 117700 / 120000: loss 34.498693\n",
      "iteration 117800 / 120000: loss 0.000000\n",
      "iteration 117900 / 120000: loss 0.000000\n",
      "iteration 118000 / 120000: loss 60.264614\n",
      "iteration 118100 / 120000: loss 0.000006\n",
      "iteration 118200 / 120000: loss 0.000000\n",
      "iteration 118300 / 120000: loss 0.000000\n",
      "iteration 118400 / 120000: loss 0.000000\n",
      "iteration 118500 / 120000: loss 0.000000\n",
      "iteration 118600 / 120000: loss 0.000000\n",
      "iteration 118700 / 120000: loss 0.000000\n",
      "iteration 118800 / 120000: loss 0.000000\n",
      "iteration 118900 / 120000: loss 0.146423\n",
      "iteration 119000 / 120000: loss 0.000000\n",
      "iteration 119100 / 120000: loss 0.000000\n",
      "iteration 119200 / 120000: loss 0.000000\n",
      "iteration 119300 / 120000: loss 0.000000\n",
      "iteration 119400 / 120000: loss 0.000000\n",
      "iteration 119500 / 120000: loss 0.000000\n",
      "iteration 119600 / 120000: loss 0.000000\n",
      "iteration 119700 / 120000: loss 0.000000\n",
      "iteration 119800 / 120000: loss 16.468039\n",
      "iteration 119900 / 120000: loss 0.000000\n",
      "(lr, bs) = (5e-06, 1)\n",
      "(val_accuracy,train_accuracy, best_val) = (array([0.388]), array([0.8075]), array([0.409]))\n",
      "iteration 0 / 1200: loss 67.514980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100 / 1200: loss 7132.244055\n",
      "iteration 200 / 1200: loss 2707.585265\n",
      "iteration 300 / 1200: loss 3287.510468\n",
      "iteration 400 / 1200: loss inf\n",
      "iteration 500 / 1200: loss 1169.138934\n",
      "iteration 600 / 1200: loss 2109.695660\n",
      "iteration 700 / 1200: loss 2439.770909\n",
      "iteration 800 / 1200: loss 3607.228302\n",
      "iteration 900 / 1200: loss inf\n",
      "iteration 1000 / 1200: loss 2611.966596\n",
      "iteration 1100 / 1200: loss 6855.206217\n",
      "(lr, bs) = (5e-06, 100)\n",
      "(val_accuracy,train_accuracy, best_val) = (array([0.322]), array([0.733]), array([0.409]))\n",
      "iteration 0 / 600: loss 147.262512\n",
      "iteration 100 / 600: loss 8314.501238\n",
      "iteration 200 / 600: loss inf\n",
      "iteration 300 / 600: loss inf\n",
      "iteration 400 / 600: loss inf\n",
      "iteration 500 / 600: loss 12113.607108\n",
      "(lr, bs) = (5e-06, 200)\n",
      "(val_accuracy,train_accuracy, best_val) = (array([0.377]), array([0.8234]), array([0.409]))\n",
      "iteration 0 / 240: loss 375.683764\n",
      "iteration 100 / 240: loss inf\n",
      "iteration 200 / 240: loss inf\n",
      "(lr, bs) = (5e-06, 500)\n",
      "(val_accuracy,train_accuracy, best_val) = (array([0.375]), array([0.7244]), array([0.409]))\n",
      "iteration 0 / 120: loss 766.401735\n",
      "iteration 100 / 120: loss inf\n",
      "(lr, bs) = (5e-06, 1000)\n",
      "(val_accuracy,train_accuracy, best_val) = (array([0.405]), array([0.8193]), array([0.409]))\n",
      "iteration 0 / 12: loss 6773.866134\n",
      "(lr, bs) = (5e-06, 10000)\n",
      "(val_accuracy,train_accuracy, best_val) = (array([0.385]), array([0.7801]), array([0.409]))\n",
      "lr 1.000000e-07 batch_size 1.000000e+00 train accuracy: 0.826500 val accuracy: 0.409000\n",
      "lr 1.000000e-07 batch_size 1.000000e+02 train accuracy: 0.679800 val accuracy: 0.314000\n",
      "lr 1.000000e-07 batch_size 2.000000e+02 train accuracy: 0.822400 val accuracy: 0.382000\n",
      "lr 1.000000e-07 batch_size 5.000000e+02 train accuracy: 0.822000 val accuracy: 0.399000\n",
      "lr 1.000000e-07 batch_size 1.000000e+03 train accuracy: 0.696100 val accuracy: 0.318000\n",
      "lr 1.000000e-07 batch_size 1.000000e+04 train accuracy: 0.793200 val accuracy: 0.404000\n",
      "lr 5.000000e-06 batch_size 1.000000e+00 train accuracy: 0.807500 val accuracy: 0.388000\n",
      "lr 5.000000e-06 batch_size 1.000000e+02 train accuracy: 0.733000 val accuracy: 0.322000\n",
      "lr 5.000000e-06 batch_size 2.000000e+02 train accuracy: 0.823400 val accuracy: 0.377000\n",
      "lr 5.000000e-06 batch_size 5.000000e+02 train accuracy: 0.724400 val accuracy: 0.375000\n",
      "lr 5.000000e-06 batch_size 1.000000e+03 train accuracy: 0.819300 val accuracy: 0.405000\n",
      "lr 5.000000e-06 batch_size 1.000000e+04 train accuracy: 0.780100 val accuracy: 0.385000\n",
      "best validation accuracy achieved during cross-validation: 0.409000\n",
      "Binary logistic regression on raw pixels final test set accuracy: 0.820000\n"
     ]
    }
   ],
   "source": [
    "# You are encouraged to experiment with additional values\n",
    "learning_rates = [1e-7, 5e-6]\n",
    "batch_sizes = [1, 100, 200, 500, 1000, 10000]\n",
    "\n",
    "results = {}\n",
    "best_val = -1   # The highest validation accuracy that we have seen so far.\n",
    "best_logistic = None # The LogisticRegression object that achieved the highest validation rate.\n",
    "\n",
    "################################################################################\n",
    "#                            START OF YOUR CODE                                #\n",
    "################################################################################\n",
    "\n",
    "epochs = 200*600/X_train.shape[0]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        \n",
    "        num_iters = int(epochs*X_train.shape[0]/bs)\n",
    "        lr_classifier = LogisticRegression(X_train, y_train)\n",
    "        \n",
    "        _ = lr_classifier.train(X_train, y_train, learning_rate=lr, num_iters=num_iters,batch_size=bs,verbose=True)\n",
    "        \n",
    "        val_accuracy = lr_classifier.calc_accuracy(X_val, y_val)\n",
    "        train_accuracy = lr_classifier.calc_accuracy(X_train, y_train)\n",
    "        \n",
    "        print('(lr, bs) = {}'.format((lr, bs)))\n",
    "        print('(val_accuracy,train_accuracy, best_val) = {}'.format((val_accuracy, train_accuracy, best_val)))\n",
    "\n",
    "        if val_accuracy > best_val:\n",
    "            best_val = val_accuracy\n",
    "            best_logistic = lr_classifier\n",
    "        results[(lr, bs)] = (train_accuracy,val_accuracy)\n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, batch_size in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, batch_size)]\n",
    "    print ('lr %e batch_size %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, batch_size, train_accuracy, val_accuracy))\n",
    "    \n",
    "print ('best validation accuracy achieved during cross-validation: %f' % best_val)\n",
    "\n",
    "test_accuracy = best_logistic.calc_accuracy(X_test, y_test)\n",
    "print ('Binary logistic regression on raw pixels final test set accuracy: %f' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = best_logistic.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 1)\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "classes = ['car']\n",
    "for i in range(1):\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the possible reasons for the differences in the visualization of the weights in the both cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both models are trying to solve the same problem but they are doing it in diffrenet ways. \n",
    "1. They use diffrent loss function\n",
    "2. Diffrent activation function. \n",
    "\n",
    "The loss functions are similar at the edges but are diffrent in the middle.\n",
    "So they are optimized to lear diffrent things so the weights will look diffrent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus (**10 points**): Regularization is a very important technique in machine learning to prevent overfitting. Mathematically speaking, it adds a regularization term to the loss to penalize larger weights. For this part, implement L2 regularization of the form:\n",
    "$$\n",
    "Loss = Loss + \\lambda \\cdot \\sum_{i=0}^k w_k^2\n",
    "$$\n",
    "Where $\\lambda$ is yet another hyper parameter. Search for an optimal $\\lambda$ (look around 5e4) and don't forget to update the gradient or the regularization won't effect the weights. When you are finished, train a perceptron classifier and visualize the weights. What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr=1e-07 bs=1 regularization_rate=0.0006\n",
      "iteration 0 / 120000: loss 0.905209\n",
      "iteration 100 / 120000: loss 0.000000\n",
      "iteration 200 / 120000: loss 0.000000\n",
      "iteration 300 / 120000: loss 0.000000\n",
      "iteration 400 / 120000: loss 0.000000\n",
      "iteration 500 / 120000: loss 0.000000\n",
      "iteration 600 / 120000: loss 0.671257\n",
      "iteration 700 / 120000: loss 1.721766\n",
      "iteration 800 / 120000: loss 4.600748\n",
      "iteration 900 / 120000: loss 0.000000\n",
      "iteration 1000 / 120000: loss 0.000000\n",
      "iteration 1100 / 120000: loss 0.203816\n",
      "iteration 1200 / 120000: loss 0.000000\n",
      "iteration 1300 / 120000: loss 0.000000\n",
      "iteration 1400 / 120000: loss 4.682065\n",
      "iteration 1500 / 120000: loss 0.000000\n",
      "iteration 1600 / 120000: loss 1.178074\n",
      "iteration 1700 / 120000: loss 0.000000\n",
      "iteration 1800 / 120000: loss 0.000000\n",
      "iteration 1900 / 120000: loss 0.000000\n",
      "iteration 2000 / 120000: loss 0.000000\n",
      "iteration 2100 / 120000: loss 0.000000\n",
      "iteration 2200 / 120000: loss 0.000000\n",
      "iteration 2300 / 120000: loss 0.000000\n",
      "iteration 2400 / 120000: loss 3.070627\n",
      "iteration 2500 / 120000: loss 0.000000\n",
      "iteration 2600 / 120000: loss 0.394669\n",
      "iteration 2700 / 120000: loss 0.605028\n",
      "iteration 2800 / 120000: loss 0.000000\n",
      "iteration 2900 / 120000: loss 0.657924\n",
      "iteration 3000 / 120000: loss 0.000000\n",
      "iteration 3100 / 120000: loss 2.678692\n",
      "iteration 3200 / 120000: loss 0.000000\n",
      "iteration 3300 / 120000: loss 0.000000\n",
      "iteration 3400 / 120000: loss 0.000000\n",
      "iteration 3500 / 120000: loss 0.000000\n",
      "iteration 3600 / 120000: loss 0.000000\n",
      "iteration 3700 / 120000: loss 0.000000\n",
      "iteration 3800 / 120000: loss 3.722720\n",
      "iteration 3900 / 120000: loss 0.000000\n",
      "iteration 4000 / 120000: loss 0.000000\n",
      "iteration 4100 / 120000: loss 3.474193\n",
      "iteration 4200 / 120000: loss 0.000000\n",
      "iteration 4300 / 120000: loss 7.884070\n",
      "iteration 4400 / 120000: loss 0.000000\n",
      "iteration 4500 / 120000: loss 0.000000\n",
      "iteration 4600 / 120000: loss 0.000000\n",
      "iteration 4700 / 120000: loss 0.000000\n",
      "iteration 4800 / 120000: loss 0.000000\n",
      "iteration 4900 / 120000: loss 0.000000\n",
      "iteration 5000 / 120000: loss 0.000000\n",
      "iteration 5100 / 120000: loss 0.000000\n",
      "iteration 5200 / 120000: loss 2.269083\n",
      "iteration 5300 / 120000: loss 0.000000\n",
      "iteration 5400 / 120000: loss 0.000000\n",
      "iteration 5500 / 120000: loss 1.251728\n",
      "iteration 5600 / 120000: loss 0.000000\n",
      "iteration 5700 / 120000: loss 4.400070\n",
      "iteration 5800 / 120000: loss 0.000000\n",
      "iteration 5900 / 120000: loss 0.064532\n",
      "iteration 6000 / 120000: loss 0.000000\n",
      "iteration 6100 / 120000: loss 0.000000\n",
      "iteration 6200 / 120000: loss 0.000000\n",
      "iteration 6300 / 120000: loss 0.000000\n",
      "iteration 6400 / 120000: loss 0.000000\n",
      "iteration 6500 / 120000: loss 0.000000\n",
      "iteration 6600 / 120000: loss 2.289688\n",
      "iteration 6700 / 120000: loss 0.000000\n",
      "iteration 6800 / 120000: loss 0.000000\n",
      "iteration 6900 / 120000: loss 0.000000\n",
      "iteration 7000 / 120000: loss 0.000000\n",
      "iteration 7100 / 120000: loss 0.000000\n",
      "iteration 7200 / 120000: loss 2.361289\n",
      "iteration 7300 / 120000: loss 0.892712\n",
      "iteration 7400 / 120000: loss 0.910635\n",
      "iteration 7500 / 120000: loss 0.000000\n",
      "iteration 7600 / 120000: loss 2.019804\n",
      "iteration 7700 / 120000: loss 0.000000\n",
      "iteration 7800 / 120000: loss 0.000000\n",
      "iteration 7900 / 120000: loss 0.000000\n",
      "iteration 8000 / 120000: loss 1.527426\n",
      "iteration 8100 / 120000: loss 1.083049\n",
      "iteration 8200 / 120000: loss 0.000000\n",
      "iteration 8300 / 120000: loss 0.000000\n",
      "iteration 8400 / 120000: loss 0.000000\n",
      "iteration 8500 / 120000: loss 0.000000\n",
      "iteration 8600 / 120000: loss 0.000000\n",
      "iteration 8700 / 120000: loss 0.000000\n",
      "iteration 8800 / 120000: loss 2.011145\n",
      "iteration 8900 / 120000: loss 4.889295\n",
      "iteration 9000 / 120000: loss 0.000000\n",
      "iteration 9100 / 120000: loss 0.653875\n",
      "iteration 9200 / 120000: loss 0.000000\n",
      "iteration 9300 / 120000: loss 0.000000\n",
      "iteration 9400 / 120000: loss 0.000000\n",
      "iteration 9500 / 120000: loss 0.000000\n",
      "iteration 9600 / 120000: loss 0.000000\n",
      "iteration 9700 / 120000: loss 0.000000\n",
      "iteration 9800 / 120000: loss 0.000000\n",
      "iteration 9900 / 120000: loss 0.000000\n",
      "iteration 10000 / 120000: loss 0.071407\n",
      "iteration 10100 / 120000: loss 0.000000\n",
      "iteration 10200 / 120000: loss 0.000000\n",
      "iteration 10300 / 120000: loss 1.866866\n",
      "iteration 10400 / 120000: loss 0.000000\n",
      "iteration 10500 / 120000: loss 0.000000\n",
      "iteration 10600 / 120000: loss 3.755945\n",
      "iteration 10700 / 120000: loss 0.349430\n",
      "iteration 10800 / 120000: loss 0.219331\n",
      "iteration 10900 / 120000: loss 0.000000\n",
      "iteration 11000 / 120000: loss 3.005367\n",
      "iteration 11100 / 120000: loss 0.221322\n",
      "iteration 11200 / 120000: loss 0.000000\n",
      "iteration 11300 / 120000: loss 0.000000\n",
      "iteration 11400 / 120000: loss 0.000000\n",
      "iteration 11500 / 120000: loss 0.000000\n",
      "iteration 11600 / 120000: loss 0.000000\n",
      "iteration 11700 / 120000: loss 0.000000\n",
      "iteration 11800 / 120000: loss 0.000000\n",
      "iteration 11900 / 120000: loss 0.893065\n",
      "iteration 12000 / 120000: loss 4.652017\n",
      "iteration 12100 / 120000: loss 0.000000\n",
      "iteration 12200 / 120000: loss 0.000000\n",
      "iteration 12300 / 120000: loss 0.000000\n",
      "iteration 12400 / 120000: loss 1.964256\n",
      "iteration 12500 / 120000: loss 7.304227\n",
      "iteration 12600 / 120000: loss 0.000000\n",
      "iteration 12700 / 120000: loss 0.000000\n",
      "iteration 12800 / 120000: loss 0.000000\n",
      "iteration 12900 / 120000: loss 0.000000\n",
      "iteration 13000 / 120000: loss 1.791596\n",
      "iteration 13100 / 120000: loss 0.000000\n",
      "iteration 13200 / 120000: loss 0.000000\n",
      "iteration 13300 / 120000: loss 2.928005\n",
      "iteration 13400 / 120000: loss 0.000000\n",
      "iteration 13500 / 120000: loss 0.248263\n",
      "iteration 13600 / 120000: loss 0.763678\n",
      "iteration 13700 / 120000: loss 0.000000\n",
      "iteration 13800 / 120000: loss 0.122912\n",
      "iteration 13900 / 120000: loss 0.000000\n",
      "iteration 14000 / 120000: loss 0.000000\n",
      "iteration 14100 / 120000: loss 0.786667\n",
      "iteration 14200 / 120000: loss 1.292628\n",
      "iteration 14300 / 120000: loss 0.000000\n",
      "iteration 14400 / 120000: loss 3.466963\n",
      "iteration 14500 / 120000: loss 1.243780\n",
      "iteration 14600 / 120000: loss 0.000000\n",
      "iteration 14700 / 120000: loss 0.000000\n",
      "iteration 14800 / 120000: loss 0.000000\n",
      "iteration 14900 / 120000: loss 1.820794\n",
      "iteration 15000 / 120000: loss 0.000000\n",
      "iteration 15100 / 120000: loss 0.000000\n",
      "iteration 15200 / 120000: loss 0.000000\n",
      "iteration 15300 / 120000: loss 0.000000\n",
      "iteration 15400 / 120000: loss 0.000000\n",
      "iteration 15500 / 120000: loss 0.000000\n",
      "iteration 15600 / 120000: loss 0.000000\n",
      "iteration 15700 / 120000: loss 0.000000\n",
      "iteration 15800 / 120000: loss 3.622594\n",
      "iteration 15900 / 120000: loss 2.278978\n",
      "iteration 16000 / 120000: loss 0.000000\n",
      "iteration 16100 / 120000: loss 0.000000\n",
      "iteration 16200 / 120000: loss 0.473660\n",
      "iteration 16300 / 120000: loss 0.000000\n",
      "iteration 16400 / 120000: loss 0.000000\n",
      "iteration 16500 / 120000: loss 0.000000\n",
      "iteration 16600 / 120000: loss 0.071384\n",
      "iteration 16700 / 120000: loss 0.000000\n",
      "iteration 16800 / 120000: loss 0.000000\n",
      "iteration 16900 / 120000: loss 0.000000\n",
      "iteration 17000 / 120000: loss 0.000000\n",
      "iteration 17100 / 120000: loss 0.908278\n",
      "iteration 17200 / 120000: loss 0.370858\n",
      "iteration 17300 / 120000: loss 0.000000\n",
      "iteration 17400 / 120000: loss 0.000000\n",
      "iteration 17500 / 120000: loss 0.000000\n",
      "iteration 17600 / 120000: loss 0.000000\n",
      "iteration 17700 / 120000: loss 0.000000\n",
      "iteration 17800 / 120000: loss 0.683355\n",
      "iteration 17900 / 120000: loss 0.000000\n",
      "iteration 18000 / 120000: loss 7.344945\n",
      "iteration 18100 / 120000: loss 0.000000\n",
      "iteration 18200 / 120000: loss 0.000000\n",
      "iteration 18300 / 120000: loss 0.000000\n",
      "iteration 18400 / 120000: loss 0.000000\n",
      "iteration 18500 / 120000: loss 0.000000\n",
      "iteration 18600 / 120000: loss 0.000000\n",
      "iteration 18700 / 120000: loss 0.000000\n",
      "iteration 18800 / 120000: loss 0.000000\n",
      "iteration 18900 / 120000: loss 6.032006\n",
      "iteration 19000 / 120000: loss 0.000000\n",
      "iteration 19100 / 120000: loss 0.000000\n",
      "iteration 19200 / 120000: loss 1.418162\n",
      "iteration 19300 / 120000: loss 0.917552\n",
      "iteration 19400 / 120000: loss 0.000000\n",
      "iteration 19500 / 120000: loss 0.000000\n",
      "iteration 19600 / 120000: loss 0.000000\n",
      "iteration 19700 / 120000: loss 0.000000\n",
      "iteration 19800 / 120000: loss 4.098000\n",
      "iteration 19900 / 120000: loss 0.000000\n",
      "iteration 20000 / 120000: loss 0.000000\n",
      "iteration 20100 / 120000: loss 0.000000\n",
      "iteration 20200 / 120000: loss 0.000000\n",
      "iteration 20300 / 120000: loss 1.875183\n",
      "iteration 20400 / 120000: loss 0.000000\n",
      "iteration 20500 / 120000: loss 0.642599\n",
      "iteration 20600 / 120000: loss 0.000000\n",
      "iteration 20700 / 120000: loss 0.000000\n",
      "iteration 20800 / 120000: loss 0.000000\n",
      "iteration 20900 / 120000: loss 5.005501\n",
      "iteration 21000 / 120000: loss 0.174387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 21100 / 120000: loss 0.841548\n",
      "iteration 21200 / 120000: loss 0.435267\n",
      "iteration 21300 / 120000: loss 0.592241\n",
      "iteration 21400 / 120000: loss 0.000000\n",
      "iteration 21500 / 120000: loss 0.000000\n",
      "iteration 21600 / 120000: loss 0.000000\n",
      "iteration 21700 / 120000: loss 0.680275\n",
      "iteration 21800 / 120000: loss 0.000000\n",
      "iteration 21900 / 120000: loss 0.000000\n",
      "iteration 22000 / 120000: loss 0.000000\n",
      "iteration 22100 / 120000: loss 0.000000\n",
      "iteration 22200 / 120000: loss 0.000000\n",
      "iteration 22300 / 120000: loss 0.000000\n",
      "iteration 22400 / 120000: loss 0.094857\n",
      "iteration 22500 / 120000: loss 0.000000\n",
      "iteration 22600 / 120000: loss 0.236736\n",
      "iteration 22700 / 120000: loss 0.000000\n",
      "iteration 22800 / 120000: loss 3.175702\n",
      "iteration 22900 / 120000: loss 7.396120\n",
      "iteration 23000 / 120000: loss 0.000000\n",
      "iteration 23100 / 120000: loss 0.000000\n",
      "iteration 23200 / 120000: loss 0.000000\n",
      "iteration 23300 / 120000: loss 0.000000\n",
      "iteration 23400 / 120000: loss 2.052702\n",
      "iteration 23500 / 120000: loss 0.000000\n",
      "iteration 23600 / 120000: loss 0.000000\n",
      "iteration 23700 / 120000: loss 0.000000\n",
      "iteration 23800 / 120000: loss 2.469379\n",
      "iteration 23900 / 120000: loss 0.000000\n",
      "iteration 24000 / 120000: loss 0.000000\n",
      "iteration 24100 / 120000: loss 0.000000\n",
      "iteration 24200 / 120000: loss 0.000000\n",
      "iteration 24300 / 120000: loss 0.000000\n",
      "iteration 24400 / 120000: loss 0.000000\n",
      "iteration 24500 / 120000: loss 0.000000\n",
      "iteration 24600 / 120000: loss 0.000000\n",
      "iteration 24700 / 120000: loss 3.158939\n",
      "iteration 24800 / 120000: loss 2.303470\n",
      "iteration 24900 / 120000: loss 0.000000\n",
      "iteration 25000 / 120000: loss 1.104082\n",
      "iteration 25100 / 120000: loss 2.714576\n",
      "iteration 25200 / 120000: loss 0.000000\n",
      "iteration 25300 / 120000: loss 0.000000\n",
      "iteration 25400 / 120000: loss 0.000000\n",
      "iteration 25500 / 120000: loss 0.000000\n",
      "iteration 25600 / 120000: loss 0.000000\n",
      "iteration 25700 / 120000: loss 0.000000\n",
      "iteration 25800 / 120000: loss 0.000000\n",
      "iteration 25900 / 120000: loss 0.000000\n",
      "iteration 26000 / 120000: loss 0.000000\n",
      "iteration 26100 / 120000: loss 0.000000\n",
      "iteration 26200 / 120000: loss 2.049786\n",
      "iteration 26300 / 120000: loss 0.000000\n",
      "iteration 26400 / 120000: loss 0.000000\n",
      "iteration 26500 / 120000: loss 0.000000\n",
      "iteration 26600 / 120000: loss 0.000000\n",
      "iteration 26700 / 120000: loss 5.829775\n",
      "iteration 26800 / 120000: loss 0.000000\n",
      "iteration 26900 / 120000: loss 0.000000\n",
      "iteration 27000 / 120000: loss 0.000000\n",
      "iteration 27100 / 120000: loss 0.277705\n",
      "iteration 27200 / 120000: loss 1.329079\n",
      "iteration 27300 / 120000: loss 0.000000\n",
      "iteration 27400 / 120000: loss 0.000000\n",
      "iteration 27500 / 120000: loss 0.242335\n",
      "iteration 27600 / 120000: loss 0.000000\n",
      "iteration 27700 / 120000: loss 0.000000\n",
      "iteration 27800 / 120000: loss 5.346378\n",
      "iteration 27900 / 120000: loss 0.000000\n",
      "iteration 28000 / 120000: loss 0.000000\n",
      "iteration 28100 / 120000: loss 0.000000\n",
      "iteration 28200 / 120000: loss 5.725935\n",
      "iteration 28300 / 120000: loss 0.000000\n",
      "iteration 28400 / 120000: loss 0.000000\n",
      "iteration 28500 / 120000: loss 1.782756\n",
      "iteration 28600 / 120000: loss 2.351570\n",
      "iteration 28700 / 120000: loss 0.000000\n",
      "iteration 28800 / 120000: loss 0.000000\n",
      "iteration 28900 / 120000: loss 0.987102\n",
      "iteration 29000 / 120000: loss 0.829078\n",
      "iteration 29100 / 120000: loss 0.000000\n",
      "iteration 29200 / 120000: loss 3.222819\n",
      "iteration 29300 / 120000: loss 0.000000\n",
      "iteration 29400 / 120000: loss 1.305859\n",
      "iteration 29500 / 120000: loss 0.000000\n",
      "iteration 29600 / 120000: loss 0.000000\n",
      "iteration 29700 / 120000: loss 0.000000\n",
      "iteration 29800 / 120000: loss 0.000000\n",
      "iteration 29900 / 120000: loss 0.000000\n",
      "iteration 30000 / 120000: loss 0.000000\n",
      "iteration 30100 / 120000: loss 0.000000\n",
      "iteration 30200 / 120000: loss 0.000000\n",
      "iteration 30300 / 120000: loss 0.000000\n",
      "iteration 30400 / 120000: loss 0.000000\n",
      "iteration 30500 / 120000: loss 0.445658\n",
      "iteration 30600 / 120000: loss 0.000000\n",
      "iteration 30700 / 120000: loss 0.000000\n",
      "iteration 30800 / 120000: loss 0.000000\n",
      "iteration 30900 / 120000: loss 0.000000\n",
      "iteration 31000 / 120000: loss 0.000000\n",
      "iteration 31100 / 120000: loss 0.000000\n",
      "iteration 31200 / 120000: loss 0.000000\n",
      "iteration 31300 / 120000: loss 0.000000\n",
      "iteration 31400 / 120000: loss 0.000000\n",
      "iteration 31500 / 120000: loss 2.882478\n",
      "iteration 31600 / 120000: loss 1.645932\n",
      "iteration 31700 / 120000: loss 0.000000\n",
      "iteration 31800 / 120000: loss 0.968116\n",
      "iteration 31900 / 120000: loss 0.000000\n",
      "iteration 32000 / 120000: loss 1.459900\n",
      "iteration 32100 / 120000: loss 0.000000\n",
      "iteration 32200 / 120000: loss 0.000000\n",
      "iteration 32300 / 120000: loss 0.914515\n",
      "iteration 32400 / 120000: loss 0.000000\n",
      "iteration 32500 / 120000: loss 0.000000\n",
      "iteration 32600 / 120000: loss 0.000000\n",
      "iteration 32700 / 120000: loss 0.000000\n",
      "iteration 32800 / 120000: loss 0.000000\n",
      "iteration 32900 / 120000: loss 0.000000\n",
      "iteration 33000 / 120000: loss 0.000000\n",
      "iteration 33100 / 120000: loss 0.000000\n",
      "iteration 33200 / 120000: loss 0.000000\n",
      "iteration 33300 / 120000: loss 0.000000\n",
      "iteration 33400 / 120000: loss 0.000000\n",
      "iteration 33500 / 120000: loss 3.058010\n",
      "iteration 33600 / 120000: loss 0.000000\n",
      "iteration 33700 / 120000: loss 0.656176\n",
      "iteration 33800 / 120000: loss 2.247218\n",
      "iteration 33900 / 120000: loss 3.204783\n",
      "iteration 34000 / 120000: loss 0.000000\n",
      "iteration 34100 / 120000: loss 0.000000\n",
      "iteration 34200 / 120000: loss 0.000000\n",
      "iteration 34300 / 120000: loss 0.000000\n",
      "iteration 34400 / 120000: loss 0.000000\n",
      "iteration 34500 / 120000: loss 0.000000\n",
      "iteration 34600 / 120000: loss 0.000000\n",
      "iteration 34700 / 120000: loss 0.000000\n",
      "iteration 34800 / 120000: loss 0.000000\n",
      "iteration 34900 / 120000: loss 0.000000\n",
      "iteration 35000 / 120000: loss 0.000000\n",
      "iteration 35100 / 120000: loss 0.000000\n",
      "iteration 35200 / 120000: loss 0.000000\n",
      "iteration 35300 / 120000: loss 0.000000\n",
      "iteration 35400 / 120000: loss 0.710967\n",
      "iteration 35500 / 120000: loss 0.000000\n",
      "iteration 35600 / 120000: loss 0.000000\n",
      "iteration 35700 / 120000: loss 0.833183\n",
      "iteration 35800 / 120000: loss 0.000000\n",
      "iteration 35900 / 120000: loss 0.000000\n",
      "iteration 36000 / 120000: loss 0.000000\n",
      "iteration 36100 / 120000: loss 0.000000\n",
      "iteration 36200 / 120000: loss 0.000000\n",
      "iteration 36300 / 120000: loss 0.000000\n",
      "iteration 36400 / 120000: loss 0.000000\n",
      "iteration 36500 / 120000: loss 2.739721\n",
      "iteration 36600 / 120000: loss 1.565049\n",
      "iteration 36700 / 120000: loss 0.000000\n",
      "iteration 36800 / 120000: loss 0.000000\n",
      "iteration 36900 / 120000: loss 2.563146\n",
      "iteration 37000 / 120000: loss 0.000000\n",
      "iteration 37100 / 120000: loss 0.000000\n",
      "iteration 37200 / 120000: loss 0.000000\n",
      "iteration 37300 / 120000: loss 0.000000\n",
      "iteration 37400 / 120000: loss 0.000000\n",
      "iteration 37500 / 120000: loss 0.000000\n",
      "iteration 37600 / 120000: loss 3.009986\n",
      "iteration 37700 / 120000: loss 0.000000\n",
      "iteration 37800 / 120000: loss 0.000000\n",
      "iteration 37900 / 120000: loss 0.000000\n",
      "iteration 38000 / 120000: loss 1.780660\n",
      "iteration 38100 / 120000: loss 0.000000\n",
      "iteration 38200 / 120000: loss 0.000000\n",
      "iteration 38300 / 120000: loss 0.000000\n",
      "iteration 38400 / 120000: loss 0.000000\n",
      "iteration 38500 / 120000: loss 0.000000\n",
      "iteration 38600 / 120000: loss 0.000000\n",
      "iteration 38700 / 120000: loss 0.000000\n",
      "iteration 38800 / 120000: loss 0.000000\n",
      "iteration 38900 / 120000: loss 0.000000\n",
      "iteration 39000 / 120000: loss 0.000000\n",
      "iteration 39100 / 120000: loss 0.000000\n",
      "iteration 39200 / 120000: loss 0.000000\n",
      "iteration 39300 / 120000: loss 0.000000\n",
      "iteration 39400 / 120000: loss 0.000000\n",
      "iteration 39500 / 120000: loss 0.000000\n",
      "iteration 39600 / 120000: loss 0.000000\n",
      "iteration 39700 / 120000: loss 0.256039\n",
      "iteration 39800 / 120000: loss 0.000000\n",
      "iteration 39900 / 120000: loss 0.000000\n",
      "iteration 40000 / 120000: loss 0.326622\n",
      "iteration 40100 / 120000: loss 0.000000\n",
      "iteration 40200 / 120000: loss 0.000000\n",
      "iteration 40300 / 120000: loss 0.000000\n",
      "iteration 40400 / 120000: loss 4.897682\n",
      "iteration 40500 / 120000: loss 0.000000\n",
      "iteration 40600 / 120000: loss 0.000000\n",
      "iteration 40700 / 120000: loss 0.000000\n",
      "iteration 40800 / 120000: loss 0.000000\n",
      "iteration 40900 / 120000: loss 1.952198\n",
      "iteration 41000 / 120000: loss 0.000000\n",
      "iteration 41100 / 120000: loss 1.236230\n",
      "iteration 41200 / 120000: loss 2.124240\n",
      "iteration 41300 / 120000: loss 0.000000\n",
      "iteration 41400 / 120000: loss 0.000000\n",
      "iteration 41500 / 120000: loss 7.870393\n",
      "iteration 41600 / 120000: loss 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 41700 / 120000: loss 0.000000\n",
      "iteration 41800 / 120000: loss 0.000000\n",
      "iteration 41900 / 120000: loss 5.557993\n",
      "iteration 42000 / 120000: loss 0.000000\n",
      "iteration 42100 / 120000: loss 0.000000\n",
      "iteration 42200 / 120000: loss 0.000000\n",
      "iteration 42300 / 120000: loss 0.000000\n",
      "iteration 42400 / 120000: loss 1.481809\n",
      "iteration 42500 / 120000: loss 6.549686\n",
      "iteration 42600 / 120000: loss 0.000000\n",
      "iteration 42700 / 120000: loss 0.975159\n",
      "iteration 42800 / 120000: loss 0.000000\n",
      "iteration 42900 / 120000: loss 0.000000\n",
      "iteration 43000 / 120000: loss 0.000000\n",
      "iteration 43100 / 120000: loss 0.000000\n",
      "iteration 43200 / 120000: loss 0.000000\n",
      "iteration 43300 / 120000: loss 0.000000\n",
      "iteration 43400 / 120000: loss 0.387482\n",
      "iteration 43500 / 120000: loss 0.000000\n",
      "iteration 43600 / 120000: loss 0.000000\n",
      "iteration 43700 / 120000: loss 0.000000\n",
      "iteration 43800 / 120000: loss 0.000000\n",
      "iteration 43900 / 120000: loss 0.000000\n",
      "iteration 44000 / 120000: loss 0.000000\n",
      "iteration 44100 / 120000: loss 0.000000\n",
      "iteration 44200 / 120000: loss 0.000000\n",
      "iteration 44300 / 120000: loss 0.000000\n",
      "iteration 44400 / 120000: loss 0.000000\n",
      "iteration 44500 / 120000: loss 0.000000\n",
      "iteration 44600 / 120000: loss 0.000000\n",
      "iteration 44700 / 120000: loss 0.000000\n",
      "iteration 44800 / 120000: loss 1.014422\n",
      "iteration 44900 / 120000: loss 0.000000\n",
      "iteration 45000 / 120000: loss 0.000000\n",
      "iteration 45100 / 120000: loss 0.000000\n",
      "iteration 45200 / 120000: loss 0.000000\n",
      "iteration 45300 / 120000: loss 0.000000\n",
      "iteration 45400 / 120000: loss 0.000000\n",
      "iteration 45500 / 120000: loss 0.000000\n",
      "iteration 45600 / 120000: loss 0.000000\n",
      "iteration 45700 / 120000: loss 0.000000\n",
      "iteration 45800 / 120000: loss 0.000000\n",
      "iteration 45900 / 120000: loss 3.789277\n",
      "iteration 46000 / 120000: loss 3.367693\n",
      "iteration 46100 / 120000: loss 0.000000\n",
      "iteration 46200 / 120000: loss 0.000000\n",
      "iteration 46300 / 120000: loss 0.000000\n",
      "iteration 46400 / 120000: loss 0.206359\n",
      "iteration 46500 / 120000: loss 0.316497\n",
      "iteration 46600 / 120000: loss 0.000000\n",
      "iteration 46700 / 120000: loss 0.901020\n",
      "iteration 46800 / 120000: loss 0.000000\n",
      "iteration 46900 / 120000: loss 0.321602\n",
      "iteration 47000 / 120000: loss 0.761869\n",
      "iteration 47100 / 120000: loss 0.000000\n",
      "iteration 47200 / 120000: loss 6.531733\n",
      "iteration 47300 / 120000: loss 0.000000\n",
      "iteration 47400 / 120000: loss 0.000000\n",
      "iteration 47500 / 120000: loss 0.000000\n",
      "iteration 47600 / 120000: loss 2.677748\n",
      "iteration 47700 / 120000: loss 0.000000\n",
      "iteration 47800 / 120000: loss 0.000000\n",
      "iteration 47900 / 120000: loss 0.000000\n",
      "iteration 48000 / 120000: loss 0.000000\n",
      "iteration 48100 / 120000: loss 0.923176\n",
      "iteration 48200 / 120000: loss 1.904529\n",
      "iteration 48300 / 120000: loss 2.042075\n",
      "iteration 48400 / 120000: loss 0.129233\n",
      "iteration 48500 / 120000: loss 0.000000\n",
      "iteration 48600 / 120000: loss 3.312203\n",
      "iteration 48700 / 120000: loss 0.000000\n",
      "iteration 48800 / 120000: loss 0.000000\n",
      "iteration 48900 / 120000: loss 6.521986\n",
      "iteration 49000 / 120000: loss 0.000000\n",
      "iteration 49100 / 120000: loss 0.000000\n",
      "iteration 49200 / 120000: loss 0.000000\n",
      "iteration 49300 / 120000: loss 0.831608\n",
      "iteration 49400 / 120000: loss 0.000000\n",
      "iteration 49500 / 120000: loss 6.288046\n",
      "iteration 49600 / 120000: loss 0.000000\n",
      "iteration 49700 / 120000: loss 1.094985\n",
      "iteration 49800 / 120000: loss 2.058931\n",
      "iteration 49900 / 120000: loss 0.000000\n",
      "iteration 50000 / 120000: loss 0.480278\n",
      "iteration 50100 / 120000: loss 2.885241\n",
      "iteration 50200 / 120000: loss 0.000000\n",
      "iteration 50300 / 120000: loss 0.000000\n",
      "iteration 50400 / 120000: loss 0.000000\n",
      "iteration 50500 / 120000: loss 0.000000\n",
      "iteration 50600 / 120000: loss 0.000000\n",
      "iteration 50700 / 120000: loss 0.000000\n",
      "iteration 50800 / 120000: loss 0.000000\n",
      "iteration 50900 / 120000: loss 7.052528\n",
      "iteration 51000 / 120000: loss 0.000000\n",
      "iteration 51100 / 120000: loss 0.000000\n",
      "iteration 51200 / 120000: loss 0.000000\n",
      "iteration 51300 / 120000: loss 0.000000\n",
      "iteration 51400 / 120000: loss 0.000000\n",
      "iteration 51500 / 120000: loss 0.000000\n",
      "iteration 51600 / 120000: loss 2.527176\n",
      "iteration 51700 / 120000: loss 3.546513\n",
      "iteration 51800 / 120000: loss 0.000000\n",
      "iteration 51900 / 120000: loss 0.000000\n",
      "iteration 52000 / 120000: loss 0.000000\n",
      "iteration 52100 / 120000: loss 0.000000\n",
      "iteration 52200 / 120000: loss 0.000000\n",
      "iteration 52300 / 120000: loss 0.000000\n",
      "iteration 52400 / 120000: loss 0.210526\n",
      "iteration 52500 / 120000: loss 0.000000\n",
      "iteration 52600 / 120000: loss 0.000000\n",
      "iteration 52700 / 120000: loss 0.000000\n",
      "iteration 52800 / 120000: loss 2.230641\n",
      "iteration 52900 / 120000: loss 0.000000\n",
      "iteration 53000 / 120000: loss 0.000000\n",
      "iteration 53100 / 120000: loss 0.000000\n",
      "iteration 53200 / 120000: loss 0.000000\n",
      "iteration 53300 / 120000: loss 0.000000\n",
      "iteration 53400 / 120000: loss 4.376650\n",
      "iteration 53500 / 120000: loss 0.196497\n",
      "iteration 53600 / 120000: loss 1.095780\n",
      "iteration 53700 / 120000: loss 0.000000\n",
      "iteration 53800 / 120000: loss 0.000000\n",
      "iteration 53900 / 120000: loss 0.000000\n",
      "iteration 54000 / 120000: loss 0.000000\n",
      "iteration 54100 / 120000: loss 0.000000\n",
      "iteration 54200 / 120000: loss 0.000000\n",
      "iteration 54300 / 120000: loss 0.000000\n",
      "iteration 54400 / 120000: loss 7.068878\n",
      "iteration 54500 / 120000: loss 0.000000\n",
      "iteration 54600 / 120000: loss 0.000000\n",
      "iteration 54700 / 120000: loss 0.000000\n",
      "iteration 54800 / 120000: loss 1.631310\n",
      "iteration 54900 / 120000: loss 2.177171\n",
      "iteration 55000 / 120000: loss 1.405292\n",
      "iteration 55100 / 120000: loss 4.552041\n",
      "iteration 55200 / 120000: loss 1.318777\n",
      "iteration 55300 / 120000: loss 0.447553\n",
      "iteration 55400 / 120000: loss 0.000000\n",
      "iteration 55500 / 120000: loss 0.772335\n",
      "iteration 55600 / 120000: loss 0.000000\n",
      "iteration 55700 / 120000: loss 0.874507\n",
      "iteration 55800 / 120000: loss 2.784919\n",
      "iteration 55900 / 120000: loss 11.849152\n",
      "iteration 56000 / 120000: loss 0.000000\n",
      "iteration 56100 / 120000: loss 0.000000\n",
      "iteration 56200 / 120000: loss 0.000000\n",
      "iteration 56300 / 120000: loss 0.000000\n",
      "iteration 56400 / 120000: loss 1.387418\n",
      "iteration 56500 / 120000: loss 0.000000\n",
      "iteration 56600 / 120000: loss 0.000000\n",
      "iteration 56700 / 120000: loss 0.000000\n",
      "iteration 56800 / 120000: loss 0.000000\n",
      "iteration 56900 / 120000: loss 0.000000\n",
      "iteration 57000 / 120000: loss 0.000000\n",
      "iteration 57100 / 120000: loss 0.441119\n",
      "iteration 57200 / 120000: loss 0.000000\n",
      "iteration 57300 / 120000: loss 0.000000\n",
      "iteration 57400 / 120000: loss 0.000000\n",
      "iteration 57500 / 120000: loss 1.990484\n",
      "iteration 57600 / 120000: loss 0.000000\n",
      "iteration 57700 / 120000: loss 0.184197\n",
      "iteration 57800 / 120000: loss 0.000000\n",
      "iteration 57900 / 120000: loss 0.000000\n",
      "iteration 58000 / 120000: loss 0.000000\n",
      "iteration 58100 / 120000: loss 5.072964\n",
      "iteration 58200 / 120000: loss 0.000000\n",
      "iteration 58300 / 120000: loss 0.000000\n",
      "iteration 58400 / 120000: loss 0.889302\n",
      "iteration 58500 / 120000: loss 0.000000\n",
      "iteration 58600 / 120000: loss 0.000000\n",
      "iteration 58700 / 120000: loss 0.000000\n",
      "iteration 58800 / 120000: loss 0.000000\n",
      "iteration 58900 / 120000: loss 0.000000\n",
      "iteration 59000 / 120000: loss 0.000000\n",
      "iteration 59100 / 120000: loss 0.000000\n",
      "iteration 59200 / 120000: loss 0.000000\n",
      "iteration 59300 / 120000: loss 0.000000\n",
      "iteration 59400 / 120000: loss 0.000000\n",
      "iteration 59500 / 120000: loss 0.000000\n",
      "iteration 59600 / 120000: loss 0.000000\n",
      "iteration 59700 / 120000: loss 0.543942\n",
      "iteration 59800 / 120000: loss 0.000000\n",
      "iteration 59900 / 120000: loss 0.000000\n",
      "iteration 60000 / 120000: loss 1.185261\n",
      "iteration 60100 / 120000: loss 0.000000\n",
      "iteration 60200 / 120000: loss 0.000000\n",
      "iteration 60300 / 120000: loss 0.000000\n",
      "iteration 60400 / 120000: loss 0.000000\n",
      "iteration 60500 / 120000: loss 0.000000\n",
      "iteration 60600 / 120000: loss 0.000000\n",
      "iteration 60700 / 120000: loss 0.000000\n",
      "iteration 60800 / 120000: loss 0.000000\n",
      "iteration 60900 / 120000: loss 0.545310\n",
      "iteration 61000 / 120000: loss 0.008514\n",
      "iteration 61100 / 120000: loss 0.000000\n",
      "iteration 61200 / 120000: loss 0.000000\n",
      "iteration 61300 / 120000: loss 0.000000\n",
      "iteration 61400 / 120000: loss 0.487106\n",
      "iteration 61500 / 120000: loss 0.000000\n",
      "iteration 61600 / 120000: loss 0.000000\n",
      "iteration 61700 / 120000: loss 0.845849\n",
      "iteration 61800 / 120000: loss 1.994520\n",
      "iteration 61900 / 120000: loss 0.000000\n",
      "iteration 62000 / 120000: loss 0.000000\n",
      "iteration 62100 / 120000: loss 0.000000\n",
      "iteration 62200 / 120000: loss 0.000000\n",
      "iteration 62300 / 120000: loss 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 62400 / 120000: loss 0.000000\n",
      "iteration 62500 / 120000: loss 0.000000\n",
      "iteration 62600 / 120000: loss 4.399128\n",
      "iteration 62700 / 120000: loss 0.000000\n",
      "iteration 62800 / 120000: loss 3.210533\n",
      "iteration 62900 / 120000: loss 0.172265\n",
      "iteration 63000 / 120000: loss 0.000000\n",
      "iteration 63100 / 120000: loss 0.700138\n",
      "iteration 63200 / 120000: loss 0.000000\n",
      "iteration 63300 / 120000: loss 0.000000\n",
      "iteration 63400 / 120000: loss 0.000000\n",
      "iteration 63500 / 120000: loss 0.000000\n",
      "iteration 63600 / 120000: loss 0.000000\n",
      "iteration 63700 / 120000: loss 0.000000\n",
      "iteration 63800 / 120000: loss 1.702093\n",
      "iteration 63900 / 120000: loss 0.000000\n",
      "iteration 64000 / 120000: loss 0.250274\n",
      "iteration 64100 / 120000: loss 0.000000\n",
      "iteration 64200 / 120000: loss 4.713487\n",
      "iteration 64300 / 120000: loss 0.000000\n",
      "iteration 64400 / 120000: loss 0.000000\n",
      "iteration 64500 / 120000: loss 0.000000\n",
      "iteration 64600 / 120000: loss 0.000000\n",
      "iteration 64700 / 120000: loss 0.000000\n",
      "iteration 64800 / 120000: loss 0.000000\n",
      "iteration 64900 / 120000: loss 0.000000\n",
      "iteration 65000 / 120000: loss 0.000000\n",
      "iteration 65100 / 120000: loss 0.000000\n",
      "iteration 65200 / 120000: loss 0.253343\n",
      "iteration 65300 / 120000: loss 0.000000\n",
      "iteration 65400 / 120000: loss 0.000000\n",
      "iteration 65500 / 120000: loss 0.000000\n",
      "iteration 65600 / 120000: loss 0.000000\n",
      "iteration 65700 / 120000: loss 0.000000\n",
      "iteration 65800 / 120000: loss 0.000000\n",
      "iteration 65900 / 120000: loss 0.000000\n",
      "iteration 66000 / 120000: loss 0.000000\n",
      "iteration 66100 / 120000: loss 1.125104\n",
      "iteration 66200 / 120000: loss 0.000000\n",
      "iteration 66300 / 120000: loss 0.000000\n",
      "iteration 66400 / 120000: loss 0.000000\n",
      "iteration 66500 / 120000: loss 0.283290\n",
      "iteration 66600 / 120000: loss 0.000000\n",
      "iteration 66700 / 120000: loss 0.000000\n",
      "iteration 66800 / 120000: loss 0.000000\n",
      "iteration 66900 / 120000: loss 2.270366\n",
      "iteration 67000 / 120000: loss 0.000000\n",
      "iteration 67100 / 120000: loss 0.000000\n",
      "iteration 67200 / 120000: loss 5.401072\n",
      "iteration 67300 / 120000: loss 0.000000\n",
      "iteration 67400 / 120000: loss 0.000000\n",
      "iteration 67500 / 120000: loss 0.000000\n",
      "iteration 67600 / 120000: loss 0.279334\n",
      "iteration 67700 / 120000: loss 0.000000\n",
      "iteration 67800 / 120000: loss 2.705005\n",
      "iteration 67900 / 120000: loss 0.000000\n",
      "iteration 68000 / 120000: loss 0.000000\n",
      "iteration 68100 / 120000: loss 8.737035\n",
      "iteration 68200 / 120000: loss 0.000000\n",
      "iteration 68300 / 120000: loss 0.000000\n",
      "iteration 68400 / 120000: loss 0.000000\n",
      "iteration 68500 / 120000: loss 0.000000\n",
      "iteration 68600 / 120000: loss 0.000000\n",
      "iteration 68700 / 120000: loss 4.074709\n",
      "iteration 68800 / 120000: loss 2.305982\n",
      "iteration 68900 / 120000: loss 0.000000\n",
      "iteration 69000 / 120000: loss 1.699088\n",
      "iteration 69100 / 120000: loss 0.000000\n",
      "iteration 69200 / 120000: loss 0.000000\n",
      "iteration 69300 / 120000: loss 0.000000\n",
      "iteration 69400 / 120000: loss 0.000000\n",
      "iteration 69500 / 120000: loss 0.000000\n",
      "iteration 69600 / 120000: loss 2.183004\n",
      "iteration 69700 / 120000: loss 0.000000\n",
      "iteration 69800 / 120000: loss 0.000000\n",
      "iteration 69900 / 120000: loss 0.000000\n",
      "iteration 70000 / 120000: loss 0.312527\n",
      "iteration 70100 / 120000: loss 0.000000\n",
      "iteration 70200 / 120000: loss 0.000000\n",
      "iteration 70300 / 120000: loss 3.357859\n",
      "iteration 70400 / 120000: loss 0.524447\n",
      "iteration 70500 / 120000: loss 0.000000\n",
      "iteration 70600 / 120000: loss 3.451594\n",
      "iteration 70700 / 120000: loss 0.000000\n",
      "iteration 70800 / 120000: loss 0.000000\n",
      "iteration 70900 / 120000: loss 0.070714\n",
      "iteration 71000 / 120000: loss 0.000000\n",
      "iteration 71100 / 120000: loss 0.000000\n",
      "iteration 71200 / 120000: loss 0.000000\n",
      "iteration 71300 / 120000: loss 2.505029\n",
      "iteration 71400 / 120000: loss 0.000000\n",
      "iteration 71500 / 120000: loss 0.000000\n",
      "iteration 71600 / 120000: loss 0.000000\n",
      "iteration 71700 / 120000: loss 0.000000\n",
      "iteration 71800 / 120000: loss 0.000000\n",
      "iteration 71900 / 120000: loss 0.000000\n",
      "iteration 72000 / 120000: loss 0.000000\n",
      "iteration 72100 / 120000: loss 0.000000\n",
      "iteration 72200 / 120000: loss 3.712602\n",
      "iteration 72300 / 120000: loss 0.000000\n",
      "iteration 72400 / 120000: loss 4.087591\n",
      "iteration 72500 / 120000: loss 2.611720\n",
      "iteration 72600 / 120000: loss 0.000000\n",
      "iteration 72700 / 120000: loss 0.000000\n",
      "iteration 72800 / 120000: loss 0.000000\n",
      "iteration 72900 / 120000: loss 0.000000\n",
      "iteration 73000 / 120000: loss 0.000000\n",
      "iteration 73100 / 120000: loss 0.000000\n",
      "iteration 73200 / 120000: loss 0.140576\n",
      "iteration 73300 / 120000: loss 0.000000\n",
      "iteration 73400 / 120000: loss 0.000000\n",
      "iteration 73500 / 120000: loss 0.000000\n",
      "iteration 73600 / 120000: loss 0.000000\n",
      "iteration 73700 / 120000: loss 0.000000\n",
      "iteration 73800 / 120000: loss 0.000000\n",
      "iteration 73900 / 120000: loss 0.000000\n",
      "iteration 74000 / 120000: loss 0.000000\n",
      "iteration 74100 / 120000: loss 0.000000\n",
      "iteration 74200 / 120000: loss 0.000000\n",
      "iteration 74300 / 120000: loss 0.000000\n",
      "iteration 74400 / 120000: loss 0.000000\n",
      "iteration 74500 / 120000: loss 0.572137\n",
      "iteration 74600 / 120000: loss 0.000000\n",
      "iteration 74700 / 120000: loss 7.324110\n",
      "iteration 74800 / 120000: loss 0.681516\n",
      "iteration 74900 / 120000: loss 0.000000\n",
      "iteration 75000 / 120000: loss 0.492831\n",
      "iteration 75100 / 120000: loss 0.000000\n",
      "iteration 75200 / 120000: loss 1.822007\n",
      "iteration 75300 / 120000: loss 0.000000\n",
      "iteration 75400 / 120000: loss 0.000000\n",
      "iteration 75500 / 120000: loss 1.737508\n",
      "iteration 75600 / 120000: loss 1.855003\n",
      "iteration 75700 / 120000: loss 0.000000\n",
      "iteration 75800 / 120000: loss 0.673543\n",
      "iteration 75900 / 120000: loss 0.000000\n",
      "iteration 76000 / 120000: loss 0.000000\n",
      "iteration 76100 / 120000: loss 0.000000\n",
      "iteration 76200 / 120000: loss 0.000000\n",
      "iteration 76300 / 120000: loss 2.354185\n",
      "iteration 76400 / 120000: loss 0.000000\n",
      "iteration 76500 / 120000: loss 2.249734\n",
      "iteration 76600 / 120000: loss 0.000000\n",
      "iteration 76700 / 120000: loss 0.000000\n",
      "iteration 76800 / 120000: loss 0.000000\n",
      "iteration 76900 / 120000: loss 0.000000\n",
      "iteration 77000 / 120000: loss 0.000000\n",
      "iteration 77100 / 120000: loss 0.000000\n",
      "iteration 77200 / 120000: loss 0.000000\n",
      "iteration 77300 / 120000: loss 0.000000\n",
      "iteration 77400 / 120000: loss 0.000000\n",
      "iteration 77500 / 120000: loss 0.000000\n",
      "iteration 77600 / 120000: loss 0.000000\n",
      "iteration 77700 / 120000: loss 0.000000\n",
      "iteration 77800 / 120000: loss 5.987667\n",
      "iteration 77900 / 120000: loss 0.000000\n",
      "iteration 78000 / 120000: loss 0.000000\n",
      "iteration 78100 / 120000: loss 0.000000\n",
      "iteration 78200 / 120000: loss 0.000000\n",
      "iteration 78300 / 120000: loss 0.000000\n",
      "iteration 78400 / 120000: loss 0.000000\n",
      "iteration 78500 / 120000: loss 0.000000\n",
      "iteration 78600 / 120000: loss 0.271275\n",
      "iteration 78700 / 120000: loss 6.305735\n",
      "iteration 78800 / 120000: loss 0.000000\n",
      "iteration 78900 / 120000: loss 0.000000\n",
      "iteration 79000 / 120000: loss 0.000000\n",
      "iteration 79100 / 120000: loss 0.000000\n",
      "iteration 79200 / 120000: loss 2.188742\n",
      "iteration 79300 / 120000: loss 0.000000\n",
      "iteration 79400 / 120000: loss 2.535788\n",
      "iteration 79500 / 120000: loss 0.000000\n",
      "iteration 79600 / 120000: loss 0.210718\n",
      "iteration 79700 / 120000: loss 0.000001\n",
      "iteration 79800 / 120000: loss 0.000001\n",
      "iteration 79900 / 120000: loss 0.456488\n",
      "iteration 80000 / 120000: loss 0.000001\n",
      "iteration 80100 / 120000: loss 0.000001\n",
      "iteration 80200 / 120000: loss 0.000001\n",
      "iteration 80300 / 120000: loss 1.460437\n",
      "iteration 80400 / 120000: loss 0.000001\n",
      "iteration 80500 / 120000: loss 2.422887\n",
      "iteration 80600 / 120000: loss 0.000001\n",
      "iteration 80700 / 120000: loss 0.000001\n",
      "iteration 80800 / 120000: loss 1.701256\n",
      "iteration 80900 / 120000: loss 0.000001\n",
      "iteration 81000 / 120000: loss 0.687777\n",
      "iteration 81100 / 120000: loss 0.000001\n",
      "iteration 81200 / 120000: loss 0.279144\n",
      "iteration 81300 / 120000: loss 0.000001\n",
      "iteration 81400 / 120000: loss 0.000001\n",
      "iteration 81500 / 120000: loss 0.000001\n",
      "iteration 81600 / 120000: loss 2.724624\n",
      "iteration 81700 / 120000: loss 0.000001\n",
      "iteration 81800 / 120000: loss 0.000001\n",
      "iteration 81900 / 120000: loss 0.000001\n",
      "iteration 82000 / 120000: loss 0.000001\n",
      "iteration 82100 / 120000: loss 3.327181\n",
      "iteration 82200 / 120000: loss 0.184208\n",
      "iteration 82300 / 120000: loss 1.989394\n",
      "iteration 82400 / 120000: loss 0.000001\n",
      "iteration 82500 / 120000: loss 0.545307\n",
      "iteration 82600 / 120000: loss 0.000001\n",
      "iteration 82700 / 120000: loss 2.843050\n",
      "iteration 82800 / 120000: loss 0.000001\n",
      "iteration 82900 / 120000: loss 0.000001\n",
      "iteration 83000 / 120000: loss 6.609138\n",
      "iteration 83100 / 120000: loss 0.000001\n",
      "iteration 83200 / 120000: loss 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 83300 / 120000: loss 0.002083\n",
      "iteration 83400 / 120000: loss 0.000001\n",
      "iteration 83500 / 120000: loss 0.000001\n",
      "iteration 83600 / 120000: loss 0.000001\n",
      "iteration 83700 / 120000: loss 8.677646\n",
      "iteration 83800 / 120000: loss 0.000001\n",
      "iteration 83900 / 120000: loss 0.000001\n",
      "iteration 84000 / 120000: loss 0.000001\n",
      "iteration 84100 / 120000: loss 0.000001\n",
      "iteration 84200 / 120000: loss 0.000001\n",
      "iteration 84300 / 120000: loss 0.000001\n",
      "iteration 84400 / 120000: loss 0.000001\n",
      "iteration 84500 / 120000: loss 0.000001\n",
      "iteration 84600 / 120000: loss 0.000001\n",
      "iteration 84700 / 120000: loss 0.000001\n",
      "iteration 84800 / 120000: loss 0.000001\n",
      "iteration 84900 / 120000: loss 0.567392\n",
      "iteration 85000 / 120000: loss 0.000001\n",
      "iteration 85100 / 120000: loss 1.249000\n",
      "iteration 85200 / 120000: loss 4.319012\n",
      "iteration 85300 / 120000: loss 0.000001\n",
      "iteration 85400 / 120000: loss 0.000001\n",
      "iteration 85500 / 120000: loss 0.000001\n",
      "iteration 85600 / 120000: loss 0.000001\n",
      "iteration 85700 / 120000: loss 0.000001\n",
      "iteration 85800 / 120000: loss 0.000001\n",
      "iteration 85900 / 120000: loss 0.000001\n",
      "iteration 86000 / 120000: loss 6.479771\n",
      "iteration 86100 / 120000: loss 1.146431\n",
      "iteration 86200 / 120000: loss 0.000001\n",
      "iteration 86300 / 120000: loss 1.810353\n",
      "iteration 86400 / 120000: loss 4.128300\n",
      "iteration 86500 / 120000: loss 0.000001\n",
      "iteration 86600 / 120000: loss 0.000001\n",
      "iteration 86700 / 120000: loss 0.000001\n",
      "iteration 86800 / 120000: loss 4.717130\n",
      "iteration 86900 / 120000: loss 0.206235\n",
      "iteration 87000 / 120000: loss 0.000001\n",
      "iteration 87100 / 120000: loss 0.000001\n",
      "iteration 87200 / 120000: loss 0.000001\n",
      "iteration 87300 / 120000: loss 0.000001\n",
      "iteration 87400 / 120000: loss 0.000001\n",
      "iteration 87500 / 120000: loss 5.747846\n",
      "iteration 87600 / 120000: loss 0.000001\n",
      "iteration 87700 / 120000: loss 0.000001\n",
      "iteration 87800 / 120000: loss 0.000001\n",
      "iteration 87900 / 120000: loss 0.000001\n",
      "iteration 88000 / 120000: loss 0.000001\n",
      "iteration 88100 / 120000: loss 0.000001\n",
      "iteration 88200 / 120000: loss 0.000001\n",
      "iteration 88300 / 120000: loss 1.985940\n",
      "iteration 88400 / 120000: loss 0.000001\n",
      "iteration 88500 / 120000: loss 0.000001\n",
      "iteration 88600 / 120000: loss 0.000001\n",
      "iteration 88700 / 120000: loss 0.905943\n",
      "iteration 88800 / 120000: loss 3.228861\n",
      "iteration 88900 / 120000: loss 0.000001\n",
      "iteration 89000 / 120000: loss 0.000001\n",
      "iteration 89100 / 120000: loss 0.000001\n",
      "iteration 89200 / 120000: loss 3.922704\n",
      "iteration 89300 / 120000: loss 0.000001\n",
      "iteration 89400 / 120000: loss 0.000001\n",
      "iteration 89500 / 120000: loss 0.000001\n",
      "iteration 89600 / 120000: loss 3.251093\n",
      "iteration 89700 / 120000: loss 2.663681\n",
      "iteration 89800 / 120000: loss 0.000001\n",
      "iteration 89900 / 120000: loss 5.323743\n",
      "iteration 90000 / 120000: loss 0.000001\n",
      "iteration 90100 / 120000: loss 0.000001\n",
      "iteration 90200 / 120000: loss 0.000001\n",
      "iteration 90300 / 120000: loss 0.530888\n",
      "iteration 90400 / 120000: loss 3.209760\n",
      "iteration 90500 / 120000: loss 0.000001\n",
      "iteration 90600 / 120000: loss 8.199688\n",
      "iteration 90700 / 120000: loss 0.000001\n",
      "iteration 90800 / 120000: loss 0.000001\n",
      "iteration 90900 / 120000: loss 0.000001\n",
      "iteration 91000 / 120000: loss 1.673129\n",
      "iteration 91100 / 120000: loss 0.000001\n",
      "iteration 91200 / 120000: loss 0.000001\n",
      "iteration 91300 / 120000: loss 4.123794\n",
      "iteration 91400 / 120000: loss 0.000001\n",
      "iteration 91500 / 120000: loss 0.000001\n",
      "iteration 91600 / 120000: loss 0.000001\n",
      "iteration 91700 / 120000: loss 0.000001\n",
      "iteration 91800 / 120000: loss 2.509964\n",
      "iteration 91900 / 120000: loss 0.851261\n",
      "iteration 92000 / 120000: loss 0.128220\n",
      "iteration 92100 / 120000: loss 0.489029\n",
      "iteration 92200 / 120000: loss 0.000001\n",
      "iteration 92300 / 120000: loss 1.032145\n",
      "iteration 92400 / 120000: loss 0.000001\n",
      "iteration 92500 / 120000: loss 0.000001\n",
      "iteration 92600 / 120000: loss 0.000001\n",
      "iteration 92700 / 120000: loss 0.000001\n",
      "iteration 92800 / 120000: loss 0.000001\n",
      "iteration 92900 / 120000: loss 1.288043\n",
      "iteration 93000 / 120000: loss 3.950688\n",
      "iteration 93100 / 120000: loss 0.000001\n",
      "iteration 93200 / 120000: loss 0.000001\n",
      "iteration 93300 / 120000: loss 0.662191\n",
      "iteration 93400 / 120000: loss 0.000001\n",
      "iteration 93500 / 120000: loss 3.344941\n",
      "iteration 93600 / 120000: loss 0.000001\n",
      "iteration 93700 / 120000: loss 2.314096\n",
      "iteration 93800 / 120000: loss 0.393636\n",
      "iteration 93900 / 120000: loss 0.000001\n",
      "iteration 94000 / 120000: loss 0.000001\n",
      "iteration 94100 / 120000: loss 0.000001\n",
      "iteration 94200 / 120000: loss 0.507168\n",
      "iteration 94300 / 120000: loss 0.000001\n",
      "iteration 94400 / 120000: loss 0.000001\n",
      "iteration 94500 / 120000: loss 0.000001\n",
      "iteration 94600 / 120000: loss 0.000001\n",
      "iteration 94700 / 120000: loss 0.000001\n",
      "iteration 94800 / 120000: loss 0.000001\n",
      "iteration 94900 / 120000: loss 2.169950\n",
      "iteration 95000 / 120000: loss 2.549164\n",
      "iteration 95100 / 120000: loss 0.000001\n",
      "iteration 95200 / 120000: loss 0.000001\n",
      "iteration 95300 / 120000: loss 2.664236\n",
      "iteration 95400 / 120000: loss 0.000001\n",
      "iteration 95500 / 120000: loss 2.743613\n",
      "iteration 95600 / 120000: loss 0.000001\n",
      "iteration 95700 / 120000: loss 0.000001\n",
      "iteration 95800 / 120000: loss 3.487254\n",
      "iteration 95900 / 120000: loss 0.000001\n",
      "iteration 96000 / 120000: loss 4.749868\n",
      "iteration 96100 / 120000: loss 0.000001\n",
      "iteration 96200 / 120000: loss 3.992778\n",
      "iteration 96300 / 120000: loss 0.000001\n",
      "iteration 96400 / 120000: loss 0.000001\n",
      "iteration 96500 / 120000: loss 1.417475\n",
      "iteration 96600 / 120000: loss 0.000001\n",
      "iteration 96700 / 120000: loss 0.000001\n",
      "iteration 96800 / 120000: loss 0.000001\n",
      "iteration 96900 / 120000: loss 0.000001\n",
      "iteration 97000 / 120000: loss 0.000001\n",
      "iteration 97100 / 120000: loss 0.000001\n",
      "iteration 97200 / 120000: loss 0.000001\n",
      "iteration 97300 / 120000: loss 0.000001\n",
      "iteration 97400 / 120000: loss 0.000001\n",
      "iteration 97500 / 120000: loss 0.000001\n",
      "iteration 97600 / 120000: loss 0.000001\n",
      "iteration 97700 / 120000: loss 1.242437\n",
      "iteration 97800 / 120000: loss 0.000001\n",
      "iteration 97900 / 120000: loss 0.000001\n",
      "iteration 98000 / 120000: loss 0.000001\n",
      "iteration 98100 / 120000: loss 0.000001\n",
      "iteration 98200 / 120000: loss 0.000001\n",
      "iteration 98300 / 120000: loss 0.000001\n",
      "iteration 98400 / 120000: loss 0.000001\n",
      "iteration 98500 / 120000: loss 0.000001\n",
      "iteration 98600 / 120000: loss 0.306724\n",
      "iteration 98700 / 120000: loss 0.000001\n",
      "iteration 98800 / 120000: loss 0.000001\n",
      "iteration 98900 / 120000: loss 0.000001\n",
      "iteration 99000 / 120000: loss 0.000001\n",
      "iteration 99100 / 120000: loss 0.000001\n",
      "iteration 99200 / 120000: loss 0.000001\n",
      "iteration 99300 / 120000: loss 0.000001\n",
      "iteration 99400 / 120000: loss 0.000001\n",
      "iteration 99500 / 120000: loss 0.161056\n",
      "iteration 99600 / 120000: loss 0.000001\n",
      "iteration 99700 / 120000: loss 0.000001\n",
      "iteration 99800 / 120000: loss 0.000001\n",
      "iteration 99900 / 120000: loss 0.000001\n",
      "iteration 100000 / 120000: loss 0.000001\n",
      "iteration 100100 / 120000: loss 6.983386\n",
      "iteration 100200 / 120000: loss 0.000001\n",
      "iteration 100300 / 120000: loss 0.000001\n",
      "iteration 100400 / 120000: loss 0.000001\n",
      "iteration 100500 / 120000: loss 0.212088\n",
      "iteration 100600 / 120000: loss 0.812251\n",
      "iteration 100700 / 120000: loss 0.000001\n",
      "iteration 100800 / 120000: loss 0.000001\n",
      "iteration 100900 / 120000: loss 0.000001\n",
      "iteration 101000 / 120000: loss 0.000001\n",
      "iteration 101100 / 120000: loss 1.341923\n",
      "iteration 101200 / 120000: loss 4.284433\n",
      "iteration 101300 / 120000: loss 0.000001\n",
      "iteration 101400 / 120000: loss 0.000001\n",
      "iteration 101500 / 120000: loss 0.000001\n",
      "iteration 101600 / 120000: loss 2.816933\n",
      "iteration 101700 / 120000: loss 0.549687\n",
      "iteration 101800 / 120000: loss 0.000001\n",
      "iteration 101900 / 120000: loss 0.000001\n",
      "iteration 102000 / 120000: loss 0.000001\n",
      "iteration 102100 / 120000: loss 0.841150\n",
      "iteration 102200 / 120000: loss 0.000001\n",
      "iteration 102300 / 120000: loss 0.000001\n",
      "iteration 102400 / 120000: loss 0.000001\n",
      "iteration 102500 / 120000: loss 0.000001\n",
      "iteration 102600 / 120000: loss 0.000001\n",
      "iteration 102700 / 120000: loss 0.000001\n",
      "iteration 102800 / 120000: loss 3.747581\n",
      "iteration 102900 / 120000: loss 3.311694\n",
      "iteration 103000 / 120000: loss 0.000001\n",
      "iteration 103100 / 120000: loss 5.859580\n",
      "iteration 103200 / 120000: loss 1.566728\n",
      "iteration 103300 / 120000: loss 0.000001\n",
      "iteration 103400 / 120000: loss 0.000001\n",
      "iteration 103500 / 120000: loss 0.000001\n",
      "iteration 103600 / 120000: loss 1.946284\n",
      "iteration 103700 / 120000: loss 0.000001\n",
      "iteration 103800 / 120000: loss 6.330360\n",
      "iteration 103900 / 120000: loss 1.179170\n",
      "iteration 104000 / 120000: loss 0.404567\n",
      "iteration 104100 / 120000: loss 0.000001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 104200 / 120000: loss 0.000001\n",
      "iteration 104300 / 120000: loss 0.000001\n",
      "iteration 104400 / 120000: loss 0.288296\n",
      "iteration 104500 / 120000: loss 0.000001\n",
      "iteration 104600 / 120000: loss 0.000001\n",
      "iteration 104700 / 120000: loss 0.000001\n",
      "iteration 104800 / 120000: loss 0.000001\n",
      "iteration 104900 / 120000: loss 0.000001\n",
      "iteration 105000 / 120000: loss 0.254204\n",
      "iteration 105100 / 120000: loss 0.000001\n",
      "iteration 105200 / 120000: loss 0.000001\n",
      "iteration 105300 / 120000: loss 0.000001\n",
      "iteration 105400 / 120000: loss 0.000001\n",
      "iteration 105500 / 120000: loss 0.000001\n",
      "iteration 105600 / 120000: loss 3.224323\n",
      "iteration 105700 / 120000: loss 0.006141\n",
      "iteration 105800 / 120000: loss 0.000001\n",
      "iteration 105900 / 120000: loss 4.086488\n",
      "iteration 106000 / 120000: loss 1.589497\n",
      "iteration 106100 / 120000: loss 0.000001\n",
      "iteration 106200 / 120000: loss 0.000001\n",
      "iteration 106300 / 120000: loss 0.000001\n",
      "iteration 106400 / 120000: loss 0.296796\n",
      "iteration 106500 / 120000: loss 0.000001\n",
      "iteration 106600 / 120000: loss 0.855453\n",
      "iteration 106700 / 120000: loss 0.000001\n",
      "iteration 106800 / 120000: loss 0.000001\n",
      "iteration 106900 / 120000: loss 0.000001\n",
      "iteration 107000 / 120000: loss 0.000001\n",
      "iteration 107100 / 120000: loss 0.000001\n",
      "iteration 107200 / 120000: loss 0.000001\n",
      "iteration 107300 / 120000: loss 0.000001\n",
      "iteration 107400 / 120000: loss 0.000001\n",
      "iteration 107500 / 120000: loss 0.000001\n",
      "iteration 107600 / 120000: loss 4.350626\n",
      "iteration 107700 / 120000: loss 0.000001\n",
      "iteration 107800 / 120000: loss 0.000001\n",
      "iteration 107900 / 120000: loss 5.362672\n",
      "iteration 108000 / 120000: loss 2.928837\n",
      "iteration 108100 / 120000: loss 0.000001\n",
      "iteration 108200 / 120000: loss 0.000001\n",
      "iteration 108300 / 120000: loss 0.000001\n",
      "iteration 108400 / 120000: loss 0.000001\n",
      "iteration 108500 / 120000: loss 0.000001\n",
      "iteration 108600 / 120000: loss 0.000001\n",
      "iteration 108700 / 120000: loss 0.000001\n",
      "iteration 108800 / 120000: loss 0.000001\n",
      "iteration 108900 / 120000: loss 0.000001\n",
      "iteration 109000 / 120000: loss 0.000001\n",
      "iteration 109100 / 120000: loss 0.000001\n",
      "iteration 109200 / 120000: loss 0.000001\n",
      "iteration 109300 / 120000: loss 0.000001\n",
      "iteration 109400 / 120000: loss 0.000001\n",
      "iteration 109500 / 120000: loss 0.000001\n",
      "iteration 109600 / 120000: loss 0.734758\n",
      "iteration 109700 / 120000: loss 0.000001\n",
      "iteration 109800 / 120000: loss 4.418737\n",
      "iteration 109900 / 120000: loss 0.000001\n",
      "iteration 110000 / 120000: loss 0.000001\n",
      "iteration 110100 / 120000: loss 0.000001\n",
      "iteration 110200 / 120000: loss 1.651331\n",
      "iteration 110300 / 120000: loss 0.000001\n",
      "iteration 110400 / 120000: loss 0.000001\n",
      "iteration 110500 / 120000: loss 0.000001\n",
      "iteration 110600 / 120000: loss 0.000001\n",
      "iteration 110700 / 120000: loss 0.000001\n",
      "iteration 110800 / 120000: loss 0.000001\n",
      "iteration 110900 / 120000: loss 0.000001\n",
      "iteration 111000 / 120000: loss 4.754481\n",
      "iteration 111100 / 120000: loss 0.529586\n",
      "iteration 111200 / 120000: loss 1.219670\n",
      "iteration 111300 / 120000: loss 0.000001\n",
      "iteration 111400 / 120000: loss 0.000001\n",
      "iteration 111500 / 120000: loss 3.090575\n",
      "iteration 111600 / 120000: loss 0.000001\n",
      "iteration 111700 / 120000: loss 0.000001\n",
      "iteration 111800 / 120000: loss 0.000001\n",
      "iteration 111900 / 120000: loss 0.000001\n",
      "iteration 112000 / 120000: loss 0.663768\n",
      "iteration 112100 / 120000: loss 0.000001\n",
      "iteration 112200 / 120000: loss 0.310330\n",
      "iteration 112300 / 120000: loss 0.000001\n",
      "iteration 112400 / 120000: loss 0.000001\n",
      "iteration 112500 / 120000: loss 1.184009\n",
      "iteration 112600 / 120000: loss 0.000001\n",
      "iteration 112700 / 120000: loss 1.685940\n",
      "iteration 112800 / 120000: loss 0.546873\n",
      "iteration 112900 / 120000: loss 0.000001\n",
      "iteration 113000 / 120000: loss 0.000001\n",
      "iteration 113100 / 120000: loss 0.000001\n",
      "iteration 113200 / 120000: loss 0.000001\n",
      "iteration 113300 / 120000: loss 0.000001\n",
      "iteration 113400 / 120000: loss 0.000001\n",
      "iteration 113500 / 120000: loss 2.482511\n",
      "iteration 113600 / 120000: loss 0.000001\n",
      "iteration 113700 / 120000: loss 0.000001\n",
      "iteration 113800 / 120000: loss 0.000001\n",
      "iteration 113900 / 120000: loss 0.000001\n",
      "iteration 114000 / 120000: loss 4.576289\n",
      "iteration 114100 / 120000: loss 0.000001\n",
      "iteration 114200 / 120000: loss 0.000001\n",
      "iteration 114300 / 120000: loss 0.000001\n",
      "iteration 114400 / 120000: loss 0.000001\n",
      "iteration 114500 / 120000: loss 0.000001\n",
      "iteration 114600 / 120000: loss 0.000001\n",
      "iteration 114700 / 120000: loss 0.000001\n",
      "iteration 114800 / 120000: loss 0.131684\n",
      "iteration 114900 / 120000: loss 0.000001\n",
      "iteration 115000 / 120000: loss 3.889599\n",
      "iteration 115100 / 120000: loss 0.000001\n",
      "iteration 115200 / 120000: loss 0.000001\n",
      "iteration 115300 / 120000: loss 0.000001\n",
      "iteration 115400 / 120000: loss 0.661871\n",
      "iteration 115500 / 120000: loss 0.859542\n",
      "iteration 115600 / 120000: loss 0.000001\n",
      "iteration 115700 / 120000: loss 0.000001\n",
      "iteration 115800 / 120000: loss 0.000001\n",
      "iteration 115900 / 120000: loss 0.656529\n",
      "iteration 116000 / 120000: loss 0.000001\n",
      "iteration 116100 / 120000: loss 0.000001\n",
      "iteration 116200 / 120000: loss 1.393457\n",
      "iteration 116300 / 120000: loss 0.000001\n",
      "iteration 116400 / 120000: loss 0.000001\n",
      "iteration 116500 / 120000: loss 2.746735\n",
      "iteration 116600 / 120000: loss 0.000001\n",
      "iteration 116700 / 120000: loss 0.000001\n",
      "iteration 116800 / 120000: loss 0.000001\n",
      "iteration 116900 / 120000: loss 0.000001\n",
      "iteration 117000 / 120000: loss 0.000001\n",
      "iteration 117100 / 120000: loss 0.000001\n",
      "iteration 117200 / 120000: loss 0.000001\n",
      "iteration 117300 / 120000: loss 0.000001\n",
      "iteration 117400 / 120000: loss 0.000001\n",
      "iteration 117500 / 120000: loss 2.596140\n",
      "iteration 117600 / 120000: loss 1.158795\n",
      "iteration 117700 / 120000: loss 0.000001\n",
      "iteration 117800 / 120000: loss 0.748721\n",
      "iteration 117900 / 120000: loss 0.000001\n",
      "iteration 118000 / 120000: loss 0.000001\n",
      "iteration 118100 / 120000: loss 1.376260\n",
      "iteration 118200 / 120000: loss 0.000001\n",
      "iteration 118300 / 120000: loss 0.000001\n",
      "iteration 118400 / 120000: loss 0.000001\n",
      "iteration 118500 / 120000: loss 0.000001\n",
      "iteration 118600 / 120000: loss 0.502268\n",
      "iteration 118700 / 120000: loss 0.000001\n",
      "iteration 118800 / 120000: loss 1.414743\n",
      "iteration 118900 / 120000: loss 0.000001\n",
      "iteration 119000 / 120000: loss 0.000001\n",
      "iteration 119100 / 120000: loss 0.000001\n",
      "iteration 119200 / 120000: loss 0.000001\n",
      "iteration 119300 / 120000: loss 0.000001\n",
      "iteration 119400 / 120000: loss 0.000001\n",
      "iteration 119500 / 120000: loss 0.000001\n",
      "iteration 119600 / 120000: loss 0.000001\n",
      "iteration 119700 / 120000: loss 0.000001\n",
      "iteration 119800 / 120000: loss 0.000001\n",
      "iteration 119900 / 120000: loss 0.120870\n",
      "lr=1e-07 bs=1 regularization_rate=0.0005\n",
      "iteration 0 / 120000: loss 0.921403\n",
      "iteration 100 / 120000: loss 0.000000\n",
      "iteration 200 / 120000: loss 0.000000\n",
      "iteration 300 / 120000: loss 0.000000\n",
      "iteration 400 / 120000: loss 2.196211\n",
      "iteration 500 / 120000: loss 6.511602\n",
      "iteration 600 / 120000: loss 0.000000\n",
      "iteration 700 / 120000: loss 0.719348\n",
      "iteration 800 / 120000: loss 0.000000\n",
      "iteration 900 / 120000: loss 0.000000\n",
      "iteration 1000 / 120000: loss 1.833789\n",
      "iteration 1100 / 120000: loss 0.000000\n",
      "iteration 1200 / 120000: loss 0.000000\n",
      "iteration 1300 / 120000: loss 0.000000\n",
      "iteration 1400 / 120000: loss 0.000000\n",
      "iteration 1500 / 120000: loss 0.000000\n",
      "iteration 1600 / 120000: loss 0.005316\n",
      "iteration 1700 / 120000: loss 0.000000\n",
      "iteration 1800 / 120000: loss 0.000000\n",
      "iteration 1900 / 120000: loss 6.468200\n",
      "iteration 2000 / 120000: loss 0.000000\n",
      "iteration 2100 / 120000: loss 0.000000\n",
      "iteration 2200 / 120000: loss 0.000000\n",
      "iteration 2300 / 120000: loss 0.000000\n",
      "iteration 2400 / 120000: loss 0.000000\n",
      "iteration 2500 / 120000: loss 3.064372\n",
      "iteration 2600 / 120000: loss 0.000000\n",
      "iteration 2700 / 120000: loss 0.500237\n",
      "iteration 2800 / 120000: loss 0.000000\n",
      "iteration 2900 / 120000: loss 0.000000\n",
      "iteration 3000 / 120000: loss 0.000000\n",
      "iteration 3100 / 120000: loss 0.000000\n",
      "iteration 3200 / 120000: loss 0.000000\n",
      "iteration 3300 / 120000: loss 0.000000\n",
      "iteration 3400 / 120000: loss 0.000000\n",
      "iteration 3500 / 120000: loss 0.000000\n",
      "iteration 3600 / 120000: loss 0.000000\n",
      "iteration 3700 / 120000: loss 0.000000\n",
      "iteration 3800 / 120000: loss 0.000000\n",
      "iteration 3900 / 120000: loss 0.000000\n",
      "iteration 4000 / 120000: loss 2.757170\n",
      "iteration 4100 / 120000: loss 0.000000\n",
      "iteration 4200 / 120000: loss 0.000000\n",
      "iteration 4300 / 120000: loss 1.546703\n",
      "iteration 4400 / 120000: loss 3.935624\n",
      "iteration 4500 / 120000: loss 0.000000\n",
      "iteration 4600 / 120000: loss 0.000000\n",
      "iteration 4700 / 120000: loss 0.000000\n",
      "iteration 4800 / 120000: loss 4.016591\n",
      "iteration 4900 / 120000: loss 2.955762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 5000 / 120000: loss 3.062584\n",
      "iteration 5100 / 120000: loss 3.527494\n",
      "iteration 5200 / 120000: loss 0.000000\n",
      "iteration 5300 / 120000: loss 0.000000\n",
      "iteration 5400 / 120000: loss 1.565038\n",
      "iteration 5500 / 120000: loss 0.000000\n",
      "iteration 5600 / 120000: loss 0.000000\n",
      "iteration 5700 / 120000: loss 0.000000\n",
      "iteration 5800 / 120000: loss 0.000000\n",
      "iteration 5900 / 120000: loss 0.000000\n",
      "iteration 6000 / 120000: loss 0.000000\n",
      "iteration 6100 / 120000: loss 0.000000\n",
      "iteration 6200 / 120000: loss 0.000000\n",
      "iteration 6300 / 120000: loss 4.659628\n",
      "iteration 6400 / 120000: loss 0.000000\n",
      "iteration 6500 / 120000: loss 1.911584\n",
      "iteration 6600 / 120000: loss 0.000000\n",
      "iteration 6700 / 120000: loss 0.000000\n",
      "iteration 6800 / 120000: loss 0.000000\n",
      "iteration 6900 / 120000: loss 2.361429\n",
      "iteration 7000 / 120000: loss 0.000000\n",
      "iteration 7100 / 120000: loss 1.435373\n",
      "iteration 7200 / 120000: loss 4.396291\n",
      "iteration 7300 / 120000: loss 0.000000\n",
      "iteration 7400 / 120000: loss 0.000000\n",
      "iteration 7500 / 120000: loss 0.000000\n",
      "iteration 7600 / 120000: loss 0.000000\n",
      "iteration 7700 / 120000: loss 0.000000\n",
      "iteration 7800 / 120000: loss 0.000000\n",
      "iteration 7900 / 120000: loss 0.000000\n",
      "iteration 8000 / 120000: loss 0.000000\n",
      "iteration 8100 / 120000: loss 0.000000\n",
      "iteration 8200 / 120000: loss 0.000000\n",
      "iteration 8300 / 120000: loss 0.000000\n",
      "iteration 8400 / 120000: loss 0.000000\n",
      "iteration 8500 / 120000: loss 0.876234\n",
      "iteration 8600 / 120000: loss 0.000000\n",
      "iteration 8700 / 120000: loss 1.833618\n",
      "iteration 8800 / 120000: loss 0.000000\n",
      "iteration 8900 / 120000: loss 0.000000\n",
      "iteration 9000 / 120000: loss 0.000000\n",
      "iteration 9100 / 120000: loss 0.000000\n",
      "iteration 9200 / 120000: loss 0.961379\n",
      "iteration 9300 / 120000: loss 0.000000\n",
      "iteration 9400 / 120000: loss 0.000000\n",
      "iteration 9500 / 120000: loss 0.000000\n",
      "iteration 9600 / 120000: loss 0.000000\n",
      "iteration 9700 / 120000: loss 0.000000\n",
      "iteration 9800 / 120000: loss 0.000000\n",
      "iteration 9900 / 120000: loss 0.000000\n",
      "iteration 10000 / 120000: loss 0.320695\n",
      "iteration 10100 / 120000: loss 0.000000\n",
      "iteration 10200 / 120000: loss 0.000000\n",
      "iteration 10300 / 120000: loss 0.000000\n",
      "iteration 10400 / 120000: loss 0.000000\n",
      "iteration 10500 / 120000: loss 4.033210\n",
      "iteration 10600 / 120000: loss 0.000000\n",
      "iteration 10700 / 120000: loss 0.767799\n",
      "iteration 10800 / 120000: loss 4.336089\n",
      "iteration 10900 / 120000: loss 4.422643\n",
      "iteration 11000 / 120000: loss 3.621403\n",
      "iteration 11100 / 120000: loss 0.889322\n",
      "iteration 11200 / 120000: loss 0.000000\n",
      "iteration 11300 / 120000: loss 0.000000\n",
      "iteration 11400 / 120000: loss 0.000000\n",
      "iteration 11500 / 120000: loss 0.000000\n",
      "iteration 11600 / 120000: loss 0.000000\n",
      "iteration 11700 / 120000: loss 0.000000\n",
      "iteration 11800 / 120000: loss 0.000000\n",
      "iteration 11900 / 120000: loss 0.000000\n",
      "iteration 12000 / 120000: loss 0.635594\n",
      "iteration 12100 / 120000: loss 0.723055\n",
      "iteration 12200 / 120000: loss 1.299594\n",
      "iteration 12300 / 120000: loss 0.000000\n",
      "iteration 12400 / 120000: loss 4.088819\n",
      "iteration 12500 / 120000: loss 0.000000\n",
      "iteration 12600 / 120000: loss 0.000000\n",
      "iteration 12700 / 120000: loss 0.000000\n",
      "iteration 12800 / 120000: loss 0.000000\n",
      "iteration 12900 / 120000: loss 0.003965\n",
      "iteration 13000 / 120000: loss 0.000000\n",
      "iteration 13100 / 120000: loss 0.000000\n",
      "iteration 13200 / 120000: loss 3.178171\n",
      "iteration 13300 / 120000: loss 3.232080\n",
      "iteration 13400 / 120000: loss 0.000000\n",
      "iteration 13500 / 120000: loss 0.366610\n",
      "iteration 13600 / 120000: loss 0.000000\n",
      "iteration 13700 / 120000: loss 0.000000\n",
      "iteration 13800 / 120000: loss 0.000000\n",
      "iteration 13900 / 120000: loss 0.000000\n",
      "iteration 14000 / 120000: loss 0.107952\n",
      "iteration 14100 / 120000: loss 0.000000\n",
      "iteration 14200 / 120000: loss 2.939313\n",
      "iteration 14300 / 120000: loss 1.009562\n",
      "iteration 14400 / 120000: loss 4.336085\n",
      "iteration 14500 / 120000: loss 0.000000\n",
      "iteration 14600 / 120000: loss 1.087237\n",
      "iteration 14700 / 120000: loss 0.000000\n",
      "iteration 14800 / 120000: loss 2.059624\n",
      "iteration 14900 / 120000: loss 3.107575\n",
      "iteration 15000 / 120000: loss 0.502900\n",
      "iteration 15100 / 120000: loss 0.000000\n",
      "iteration 15200 / 120000: loss 0.000000\n",
      "iteration 15300 / 120000: loss 0.545906\n",
      "iteration 15400 / 120000: loss 0.000000\n",
      "iteration 15500 / 120000: loss 0.000000\n",
      "iteration 15600 / 120000: loss 2.620467\n",
      "iteration 15700 / 120000: loss 0.000000\n",
      "iteration 15800 / 120000: loss 0.551087\n",
      "iteration 15900 / 120000: loss 5.376514\n",
      "iteration 16000 / 120000: loss 0.000000\n",
      "iteration 16100 / 120000: loss 0.000000\n",
      "iteration 16200 / 120000: loss 0.000000\n",
      "iteration 16300 / 120000: loss 1.584144\n",
      "iteration 16400 / 120000: loss 0.000000\n",
      "iteration 16500 / 120000: loss 0.000000\n",
      "iteration 16600 / 120000: loss 0.000000\n",
      "iteration 16700 / 120000: loss 1.758975\n",
      "iteration 16800 / 120000: loss 3.342321\n",
      "iteration 16900 / 120000: loss 0.000000\n",
      "iteration 17000 / 120000: loss 4.488269\n",
      "iteration 17100 / 120000: loss 0.000000\n",
      "iteration 17200 / 120000: loss 3.218061\n",
      "iteration 17300 / 120000: loss 0.000000\n",
      "iteration 17400 / 120000: loss 1.252890\n",
      "iteration 17500 / 120000: loss 0.000000\n",
      "iteration 17600 / 120000: loss 0.000000\n",
      "iteration 17700 / 120000: loss 0.000000\n",
      "iteration 17800 / 120000: loss 0.000000\n",
      "iteration 17900 / 120000: loss 0.000000\n",
      "iteration 18000 / 120000: loss 4.128585\n",
      "iteration 18100 / 120000: loss 0.349118\n",
      "iteration 18200 / 120000: loss 2.371453\n",
      "iteration 18300 / 120000: loss 0.230114\n",
      "iteration 18400 / 120000: loss 0.000000\n",
      "iteration 18500 / 120000: loss 0.000000\n",
      "iteration 18600 / 120000: loss 1.141603\n",
      "iteration 18700 / 120000: loss 0.000000\n",
      "iteration 18800 / 120000: loss 0.000000\n",
      "iteration 18900 / 120000: loss 0.000000\n",
      "iteration 19000 / 120000: loss 0.000000\n",
      "iteration 19100 / 120000: loss 0.000000\n",
      "iteration 19200 / 120000: loss 0.000000\n",
      "iteration 19300 / 120000: loss 0.000000\n",
      "iteration 19400 / 120000: loss 0.000000\n",
      "iteration 19500 / 120000: loss 0.000000\n",
      "iteration 19600 / 120000: loss 0.000000\n",
      "iteration 19700 / 120000: loss 0.000000\n",
      "iteration 19800 / 120000: loss 8.783765\n",
      "iteration 19900 / 120000: loss 0.000000\n",
      "iteration 20000 / 120000: loss 0.000000\n",
      "iteration 20100 / 120000: loss 0.000000\n",
      "iteration 20200 / 120000: loss 0.000000\n",
      "iteration 20300 / 120000: loss 2.393346\n",
      "iteration 20400 / 120000: loss 0.000000\n",
      "iteration 20500 / 120000: loss 4.081799\n",
      "iteration 20600 / 120000: loss 0.000000\n",
      "iteration 20700 / 120000: loss 7.060783\n",
      "iteration 20800 / 120000: loss 0.000000\n",
      "iteration 20900 / 120000: loss 0.000000\n",
      "iteration 21000 / 120000: loss 0.000000\n",
      "iteration 21100 / 120000: loss 0.000000\n",
      "iteration 21200 / 120000: loss 0.000000\n",
      "iteration 21300 / 120000: loss 0.000000\n",
      "iteration 21400 / 120000: loss 12.962773\n",
      "iteration 21500 / 120000: loss 0.000000\n",
      "iteration 21600 / 120000: loss 0.000000\n",
      "iteration 21700 / 120000: loss 0.685038\n",
      "iteration 21800 / 120000: loss 0.000000\n",
      "iteration 21900 / 120000: loss 1.994722\n",
      "iteration 22000 / 120000: loss 0.000000\n",
      "iteration 22100 / 120000: loss 0.000000\n",
      "iteration 22200 / 120000: loss 1.552480\n",
      "iteration 22300 / 120000: loss 0.000000\n",
      "iteration 22400 / 120000: loss 0.000000\n",
      "iteration 22500 / 120000: loss 0.000000\n",
      "iteration 22600 / 120000: loss 0.000000\n",
      "iteration 22700 / 120000: loss 0.000000\n",
      "iteration 22800 / 120000: loss 0.000000\n",
      "iteration 22900 / 120000: loss 0.000000\n",
      "iteration 23000 / 120000: loss 0.000000\n",
      "iteration 23100 / 120000: loss 0.000000\n",
      "iteration 23200 / 120000: loss 0.000000\n",
      "iteration 23300 / 120000: loss 0.000000\n",
      "iteration 23400 / 120000: loss 0.000000\n",
      "iteration 23500 / 120000: loss 0.000000\n",
      "iteration 23600 / 120000: loss 1.937362\n",
      "iteration 23700 / 120000: loss 0.000000\n",
      "iteration 23800 / 120000: loss 0.000000\n",
      "iteration 23900 / 120000: loss 2.060201\n",
      "iteration 24000 / 120000: loss 3.499702\n",
      "iteration 24100 / 120000: loss 3.801714\n",
      "iteration 24200 / 120000: loss 0.000000\n",
      "iteration 24300 / 120000: loss 0.000000\n",
      "iteration 24400 / 120000: loss 0.000000\n",
      "iteration 24500 / 120000: loss 0.000000\n",
      "iteration 24600 / 120000: loss 0.000000\n",
      "iteration 24700 / 120000: loss 0.000000\n",
      "iteration 24800 / 120000: loss 0.459153\n",
      "iteration 24900 / 120000: loss 1.746571\n",
      "iteration 25000 / 120000: loss 0.000000\n",
      "iteration 25100 / 120000: loss 9.900924\n",
      "iteration 25200 / 120000: loss 0.000000\n",
      "iteration 25300 / 120000: loss 3.200695\n",
      "iteration 25400 / 120000: loss 0.000000\n",
      "iteration 25500 / 120000: loss 0.000000\n",
      "iteration 25600 / 120000: loss 1.219637\n",
      "iteration 25700 / 120000: loss 2.627386\n",
      "iteration 25800 / 120000: loss 0.000000\n",
      "iteration 25900 / 120000: loss 0.000000\n",
      "iteration 26000 / 120000: loss 1.883536\n",
      "iteration 26100 / 120000: loss 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 26200 / 120000: loss 0.000000\n",
      "iteration 26300 / 120000: loss 0.000000\n",
      "iteration 26400 / 120000: loss 0.000000\n",
      "iteration 26500 / 120000: loss 0.000000\n",
      "iteration 26600 / 120000: loss 0.000000\n",
      "iteration 26700 / 120000: loss 0.000000\n",
      "iteration 26800 / 120000: loss 0.000000\n",
      "iteration 26900 / 120000: loss 2.276575\n",
      "iteration 27000 / 120000: loss 0.000000\n",
      "iteration 27100 / 120000: loss 0.000000\n",
      "iteration 27200 / 120000: loss 0.000000\n",
      "iteration 27300 / 120000: loss 0.000000\n",
      "iteration 27400 / 120000: loss 2.867922\n",
      "iteration 27500 / 120000: loss 0.000000\n",
      "iteration 27600 / 120000: loss 0.000000\n",
      "iteration 27700 / 120000: loss 2.038304\n",
      "iteration 27800 / 120000: loss 0.000000\n",
      "iteration 27900 / 120000: loss 0.000000\n",
      "iteration 28000 / 120000: loss 2.176847\n",
      "iteration 28100 / 120000: loss 0.000000\n",
      "iteration 28200 / 120000: loss 0.000000\n",
      "iteration 28300 / 120000: loss 0.000000\n",
      "iteration 28400 / 120000: loss 0.000000\n",
      "iteration 28500 / 120000: loss 0.000000\n",
      "iteration 28600 / 120000: loss 0.000000\n",
      "iteration 28700 / 120000: loss 0.000000\n",
      "iteration 28800 / 120000: loss 4.192941\n",
      "iteration 28900 / 120000: loss 0.000000\n",
      "iteration 29000 / 120000: loss 2.737407\n",
      "iteration 29100 / 120000: loss 0.000000\n",
      "iteration 29200 / 120000: loss 0.000000\n",
      "iteration 29300 / 120000: loss 0.000000\n",
      "iteration 29400 / 120000: loss 0.000000\n",
      "iteration 29500 / 120000: loss 0.093512\n",
      "iteration 29600 / 120000: loss 0.000000\n",
      "iteration 29700 / 120000: loss 0.000000\n",
      "iteration 29800 / 120000: loss 0.000000\n",
      "iteration 29900 / 120000: loss 2.751404\n",
      "iteration 30000 / 120000: loss 0.000000\n",
      "iteration 30100 / 120000: loss 0.000000\n",
      "iteration 30200 / 120000: loss 0.000000\n",
      "iteration 30300 / 120000: loss 1.686791\n",
      "iteration 30400 / 120000: loss 0.000000\n",
      "iteration 30500 / 120000: loss 3.667917\n",
      "iteration 30600 / 120000: loss 5.366797\n",
      "iteration 30700 / 120000: loss 0.000000\n",
      "iteration 30800 / 120000: loss 0.164530\n",
      "iteration 30900 / 120000: loss 0.000000\n",
      "iteration 31000 / 120000: loss 0.986932\n",
      "iteration 31100 / 120000: loss 0.558939\n",
      "iteration 31200 / 120000: loss 0.000000\n",
      "iteration 31300 / 120000: loss 0.000000\n",
      "iteration 31400 / 120000: loss 0.000000\n",
      "iteration 31500 / 120000: loss 0.815792\n",
      "iteration 31600 / 120000: loss 0.000000\n",
      "iteration 31700 / 120000: loss 0.000000\n",
      "iteration 31800 / 120000: loss 0.000000\n",
      "iteration 31900 / 120000: loss 0.000000\n",
      "iteration 32000 / 120000: loss 1.334079\n",
      "iteration 32100 / 120000: loss 0.000000\n",
      "iteration 32200 / 120000: loss 3.530476\n",
      "iteration 32300 / 120000: loss 1.864930\n",
      "iteration 32400 / 120000: loss 0.000000\n",
      "iteration 32500 / 120000: loss 0.000000\n",
      "iteration 32600 / 120000: loss 0.000000\n",
      "iteration 32700 / 120000: loss 0.000000\n",
      "iteration 32800 / 120000: loss 0.000000\n",
      "iteration 32900 / 120000: loss 0.000000\n",
      "iteration 33000 / 120000: loss 0.000000\n",
      "iteration 33100 / 120000: loss 0.000000\n",
      "iteration 33200 / 120000: loss 5.123762\n",
      "iteration 33300 / 120000: loss 0.000000\n",
      "iteration 33400 / 120000: loss 0.000000\n",
      "iteration 33500 / 120000: loss 0.000000\n",
      "iteration 33600 / 120000: loss 0.000000\n",
      "iteration 33700 / 120000: loss 0.000000\n",
      "iteration 33800 / 120000: loss 1.270038\n",
      "iteration 33900 / 120000: loss 0.000000\n",
      "iteration 34000 / 120000: loss 0.000000\n",
      "iteration 34100 / 120000: loss 0.000000\n",
      "iteration 34200 / 120000: loss 0.000000\n",
      "iteration 34300 / 120000: loss 1.190161\n",
      "iteration 34400 / 120000: loss 0.000000\n",
      "iteration 34500 / 120000: loss 0.000000\n",
      "iteration 34600 / 120000: loss 0.000000\n",
      "iteration 34700 / 120000: loss 0.000000\n",
      "iteration 34800 / 120000: loss 0.000000\n",
      "iteration 34900 / 120000: loss 2.911540\n",
      "iteration 35000 / 120000: loss 0.000000\n",
      "iteration 35100 / 120000: loss 0.000000\n",
      "iteration 35200 / 120000: loss 0.000000\n",
      "iteration 35300 / 120000: loss 0.000000\n",
      "iteration 35400 / 120000: loss 0.000000\n",
      "iteration 35500 / 120000: loss 0.000000\n",
      "iteration 35600 / 120000: loss 0.000000\n",
      "iteration 35700 / 120000: loss 0.000000\n",
      "iteration 35800 / 120000: loss 0.000000\n",
      "iteration 35900 / 120000: loss 0.000000\n",
      "iteration 36000 / 120000: loss 1.394709\n",
      "iteration 36100 / 120000: loss 0.000000\n",
      "iteration 36200 / 120000: loss 0.000000\n",
      "iteration 36300 / 120000: loss 0.000000\n",
      "iteration 36400 / 120000: loss 0.000000\n",
      "iteration 36500 / 120000: loss 0.000000\n",
      "iteration 36600 / 120000: loss 1.162707\n",
      "iteration 36700 / 120000: loss 0.000000\n",
      "iteration 36800 / 120000: loss 0.337491\n",
      "iteration 36900 / 120000: loss 0.000000\n",
      "iteration 37000 / 120000: loss 0.000000\n",
      "iteration 37100 / 120000: loss 0.000000\n",
      "iteration 37200 / 120000: loss 0.000000\n",
      "iteration 37300 / 120000: loss 0.000000\n",
      "iteration 37400 / 120000: loss 0.000000\n",
      "iteration 37500 / 120000: loss 0.000000\n",
      "iteration 37600 / 120000: loss 0.000000\n",
      "iteration 37700 / 120000: loss 4.449643\n",
      "iteration 37800 / 120000: loss 3.184416\n",
      "iteration 37900 / 120000: loss 0.000000\n",
      "iteration 38000 / 120000: loss 0.000000\n",
      "iteration 38100 / 120000: loss 0.000000\n",
      "iteration 38200 / 120000: loss 0.000000\n",
      "iteration 38300 / 120000: loss 0.000000\n",
      "iteration 38400 / 120000: loss 0.000000\n",
      "iteration 38500 / 120000: loss 0.000000\n",
      "iteration 38600 / 120000: loss 0.000000\n",
      "iteration 38700 / 120000: loss 6.873021\n",
      "iteration 38800 / 120000: loss 0.000000\n",
      "iteration 38900 / 120000: loss 0.000000\n",
      "iteration 39000 / 120000: loss 0.918474\n",
      "iteration 39100 / 120000: loss 8.347985\n",
      "iteration 39200 / 120000: loss 0.000000\n",
      "iteration 39300 / 120000: loss 0.000000\n",
      "iteration 39400 / 120000: loss 2.018534\n",
      "iteration 39500 / 120000: loss 0.000000\n",
      "iteration 39600 / 120000: loss 2.281480\n",
      "iteration 39700 / 120000: loss 0.000000\n",
      "iteration 39800 / 120000: loss 0.000000\n",
      "iteration 39900 / 120000: loss 0.000000\n",
      "iteration 40000 / 120000: loss 2.310395\n",
      "iteration 40100 / 120000: loss 0.000000\n",
      "iteration 40200 / 120000: loss 1.364976\n",
      "iteration 40300 / 120000: loss 7.903580\n",
      "iteration 40400 / 120000: loss 0.000000\n",
      "iteration 40500 / 120000: loss 0.000000\n",
      "iteration 40600 / 120000: loss 0.000000\n",
      "iteration 40700 / 120000: loss 0.361431\n",
      "iteration 40800 / 120000: loss 0.000000\n",
      "iteration 40900 / 120000: loss 0.000000\n",
      "iteration 41000 / 120000: loss 0.000000\n",
      "iteration 41100 / 120000: loss 0.000000\n",
      "iteration 41200 / 120000: loss 0.926072\n",
      "iteration 41300 / 120000: loss 0.000000\n",
      "iteration 41400 / 120000: loss 0.000000\n",
      "iteration 41500 / 120000: loss 0.000000\n",
      "iteration 41600 / 120000: loss 0.000000\n",
      "iteration 41700 / 120000: loss 0.000000\n",
      "iteration 41800 / 120000: loss 0.000000\n",
      "iteration 41900 / 120000: loss 0.000000\n",
      "iteration 42000 / 120000: loss 3.206864\n",
      "iteration 42100 / 120000: loss 0.000000\n",
      "iteration 42200 / 120000: loss 0.573568\n",
      "iteration 42300 / 120000: loss 0.000000\n",
      "iteration 42400 / 120000: loss 3.529698\n",
      "iteration 42500 / 120000: loss 2.625041\n",
      "iteration 42600 / 120000: loss 0.000000\n",
      "iteration 42700 / 120000: loss 0.000000\n",
      "iteration 42800 / 120000: loss 0.000000\n",
      "iteration 42900 / 120000: loss 0.000000\n",
      "iteration 43000 / 120000: loss 0.000000\n",
      "iteration 43100 / 120000: loss 0.000000\n",
      "iteration 43200 / 120000: loss 0.000000\n",
      "iteration 43300 / 120000: loss 0.000000\n",
      "iteration 43400 / 120000: loss 2.228629\n",
      "iteration 43500 / 120000: loss 1.592752\n",
      "iteration 43600 / 120000: loss 0.436469\n",
      "iteration 43700 / 120000: loss 0.000000\n",
      "iteration 43800 / 120000: loss 0.000000\n",
      "iteration 43900 / 120000: loss 1.151151\n",
      "iteration 44000 / 120000: loss 0.000000\n",
      "iteration 44100 / 120000: loss 0.000000\n",
      "iteration 44200 / 120000: loss 1.218979\n",
      "iteration 44300 / 120000: loss 0.000000\n",
      "iteration 44400 / 120000: loss 0.000000\n",
      "iteration 44500 / 120000: loss 2.005457\n",
      "iteration 44600 / 120000: loss 0.000000\n",
      "iteration 44700 / 120000: loss 0.000000\n",
      "iteration 44800 / 120000: loss 0.000000\n",
      "iteration 44900 / 120000: loss 0.422491\n",
      "iteration 45000 / 120000: loss 0.000000\n",
      "iteration 45100 / 120000: loss 6.544974\n",
      "iteration 45200 / 120000: loss 0.000000\n",
      "iteration 45300 / 120000: loss 0.000000\n",
      "iteration 45400 / 120000: loss 0.000000\n",
      "iteration 45500 / 120000: loss 0.000000\n",
      "iteration 45600 / 120000: loss 0.000000\n",
      "iteration 45700 / 120000: loss 0.000000\n",
      "iteration 45800 / 120000: loss 0.000000\n",
      "iteration 45900 / 120000: loss 0.000000\n",
      "iteration 46000 / 120000: loss 5.990372\n",
      "iteration 46100 / 120000: loss 0.431858\n",
      "iteration 46200 / 120000: loss 0.000000\n",
      "iteration 46300 / 120000: loss 5.285175\n",
      "iteration 46400 / 120000: loss 0.000000\n",
      "iteration 46500 / 120000: loss 0.924126\n",
      "iteration 46600 / 120000: loss 5.100903\n",
      "iteration 46700 / 120000: loss 0.000000\n",
      "iteration 46800 / 120000: loss 2.347850\n",
      "iteration 46900 / 120000: loss 0.000000\n",
      "iteration 47000 / 120000: loss 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 47100 / 120000: loss 0.000000\n",
      "iteration 47200 / 120000: loss 0.000000\n",
      "iteration 47300 / 120000: loss 0.879255\n",
      "iteration 47400 / 120000: loss 0.000000\n",
      "iteration 47500 / 120000: loss 0.000000\n",
      "iteration 47600 / 120000: loss 0.000000\n",
      "iteration 47700 / 120000: loss 0.582532\n",
      "iteration 47800 / 120000: loss 0.397561\n",
      "iteration 47900 / 120000: loss 0.000000\n",
      "iteration 48000 / 120000: loss 0.000000\n",
      "iteration 48100 / 120000: loss 0.000000\n",
      "iteration 48200 / 120000: loss 0.212009\n",
      "iteration 48300 / 120000: loss 0.000000\n",
      "iteration 48400 / 120000: loss 0.000000\n",
      "iteration 48500 / 120000: loss 0.000000\n",
      "iteration 48600 / 120000: loss 0.000000\n",
      "iteration 48700 / 120000: loss 2.345600\n",
      "iteration 48800 / 120000: loss 0.000000\n",
      "iteration 48900 / 120000: loss 1.195547\n",
      "iteration 49000 / 120000: loss 0.000000\n",
      "iteration 49100 / 120000: loss 0.000000\n",
      "iteration 49200 / 120000: loss 0.000000\n",
      "iteration 49300 / 120000: loss 0.000000\n",
      "iteration 49400 / 120000: loss 0.000000\n",
      "iteration 49500 / 120000: loss 0.000000\n",
      "iteration 49600 / 120000: loss 0.000000\n",
      "iteration 49700 / 120000: loss 0.000000\n",
      "iteration 49800 / 120000: loss 0.000000\n",
      "iteration 49900 / 120000: loss 2.669681\n",
      "iteration 50000 / 120000: loss 0.000000\n",
      "iteration 50100 / 120000: loss 0.000000\n",
      "iteration 50200 / 120000: loss 0.000000\n",
      "iteration 50300 / 120000: loss 0.000000\n",
      "iteration 50400 / 120000: loss 0.000000\n",
      "iteration 50500 / 120000: loss 0.810338\n",
      "iteration 50600 / 120000: loss 0.000000\n",
      "iteration 50700 / 120000: loss 0.000000\n",
      "iteration 50800 / 120000: loss 0.000000\n",
      "iteration 50900 / 120000: loss 0.000000\n",
      "iteration 51000 / 120000: loss 0.000000\n",
      "iteration 51100 / 120000: loss 3.127750\n",
      "iteration 51200 / 120000: loss 0.000000\n",
      "iteration 51300 / 120000: loss 0.000000\n",
      "iteration 51400 / 120000: loss 2.930195\n",
      "iteration 51500 / 120000: loss 0.000000\n",
      "iteration 51600 / 120000: loss 0.000000\n",
      "iteration 51700 / 120000: loss 0.000000\n",
      "iteration 51800 / 120000: loss 0.000000\n",
      "iteration 51900 / 120000: loss 0.000000\n",
      "iteration 52000 / 120000: loss 0.000000\n",
      "iteration 52100 / 120000: loss 0.000000\n",
      "iteration 52200 / 120000: loss 0.250047\n",
      "iteration 52300 / 120000: loss 0.000000\n",
      "iteration 52400 / 120000: loss 0.000000\n",
      "iteration 52500 / 120000: loss 0.000000\n",
      "iteration 52600 / 120000: loss 0.000000\n",
      "iteration 52700 / 120000: loss 1.108890\n",
      "iteration 52800 / 120000: loss 0.000000\n",
      "iteration 52900 / 120000: loss 0.000000\n",
      "iteration 53000 / 120000: loss 0.188553\n",
      "iteration 53100 / 120000: loss 0.105457\n",
      "iteration 53200 / 120000: loss 0.000000\n",
      "iteration 53300 / 120000: loss 2.345626\n",
      "iteration 53400 / 120000: loss 0.360825\n",
      "iteration 53500 / 120000: loss 0.000000\n",
      "iteration 53600 / 120000: loss 0.000000\n",
      "iteration 53700 / 120000: loss 1.475965\n",
      "iteration 53800 / 120000: loss 0.000000\n",
      "iteration 53900 / 120000: loss 0.000000\n",
      "iteration 54000 / 120000: loss 0.000000\n",
      "iteration 54100 / 120000: loss 0.000000\n",
      "iteration 54200 / 120000: loss 0.000000\n",
      "iteration 54300 / 120000: loss 0.000000\n",
      "iteration 54400 / 120000: loss 0.000000\n",
      "iteration 54500 / 120000: loss 0.000000\n",
      "iteration 54600 / 120000: loss 1.736468\n",
      "iteration 54700 / 120000: loss 0.000000\n",
      "iteration 54800 / 120000: loss 3.189291\n",
      "iteration 54900 / 120000: loss 0.000000\n",
      "iteration 55000 / 120000: loss 0.000000\n",
      "iteration 55100 / 120000: loss 0.000000\n",
      "iteration 55200 / 120000: loss 0.442642\n",
      "iteration 55300 / 120000: loss 0.000000\n",
      "iteration 55400 / 120000: loss 0.000000\n",
      "iteration 55500 / 120000: loss 0.000000\n",
      "iteration 55600 / 120000: loss 0.000000\n",
      "iteration 55700 / 120000: loss 0.000000\n",
      "iteration 55800 / 120000: loss 0.000000\n",
      "iteration 55900 / 120000: loss 0.000000\n",
      "iteration 56000 / 120000: loss 0.000000\n",
      "iteration 56100 / 120000: loss 0.043271\n",
      "iteration 56200 / 120000: loss 1.562354\n",
      "iteration 56300 / 120000: loss 0.000000\n",
      "iteration 56400 / 120000: loss 0.000000\n",
      "iteration 56500 / 120000: loss 0.000000\n",
      "iteration 56600 / 120000: loss 0.000000\n",
      "iteration 56700 / 120000: loss 0.000000\n",
      "iteration 56800 / 120000: loss 0.000000\n",
      "iteration 56900 / 120000: loss 1.154130\n",
      "iteration 57000 / 120000: loss 0.000000\n",
      "iteration 57100 / 120000: loss 0.000000\n",
      "iteration 57200 / 120000: loss 0.000000\n",
      "iteration 57300 / 120000: loss 0.503203\n",
      "iteration 57400 / 120000: loss 0.000000\n",
      "iteration 57500 / 120000: loss 0.000000\n",
      "iteration 57600 / 120000: loss 0.000000\n",
      "iteration 57700 / 120000: loss 0.000000\n",
      "iteration 57800 / 120000: loss 0.000000\n",
      "iteration 57900 / 120000: loss 0.000000\n",
      "iteration 58000 / 120000: loss 0.151800\n",
      "iteration 58100 / 120000: loss 0.000000\n",
      "iteration 58200 / 120000: loss 0.000000\n",
      "iteration 58300 / 120000: loss 0.683604\n",
      "iteration 58400 / 120000: loss 0.000000\n",
      "iteration 58500 / 120000: loss 0.000000\n",
      "iteration 58600 / 120000: loss 0.000000\n",
      "iteration 58700 / 120000: loss 0.000000\n",
      "iteration 58800 / 120000: loss 0.000000\n",
      "iteration 58900 / 120000: loss 0.000000\n",
      "iteration 59000 / 120000: loss 0.000000\n",
      "iteration 59100 / 120000: loss 0.000000\n",
      "iteration 59200 / 120000: loss 1.469519\n",
      "iteration 59300 / 120000: loss 0.000000\n",
      "iteration 59400 / 120000: loss 0.000000\n",
      "iteration 59500 / 120000: loss 0.000000\n",
      "iteration 59600 / 120000: loss 0.000000\n",
      "iteration 59700 / 120000: loss 2.154772\n",
      "iteration 59800 / 120000: loss 0.000000\n",
      "iteration 59900 / 120000: loss 0.000000\n",
      "iteration 60000 / 120000: loss 0.000000\n",
      "iteration 60100 / 120000: loss 1.451757\n",
      "iteration 60200 / 120000: loss 2.717800\n",
      "iteration 60300 / 120000: loss 0.000000\n",
      "iteration 60400 / 120000: loss 0.000000\n",
      "iteration 60500 / 120000: loss 0.000000\n",
      "iteration 60600 / 120000: loss 0.000000\n",
      "iteration 60700 / 120000: loss 0.000000\n",
      "iteration 60800 / 120000: loss 0.000000\n",
      "iteration 60900 / 120000: loss 0.000000\n",
      "iteration 61000 / 120000: loss 0.987277\n",
      "iteration 61100 / 120000: loss 2.985056\n",
      "iteration 61200 / 120000: loss 1.086165\n",
      "iteration 61300 / 120000: loss 0.000000\n",
      "iteration 61400 / 120000: loss 0.000000\n",
      "iteration 61500 / 120000: loss 0.000000\n",
      "iteration 61600 / 120000: loss 0.000000\n",
      "iteration 61700 / 120000: loss 2.700311\n",
      "iteration 61800 / 120000: loss 1.930551\n",
      "iteration 61900 / 120000: loss 0.230718\n",
      "iteration 62000 / 120000: loss 0.000000\n",
      "iteration 62100 / 120000: loss 0.000000\n",
      "iteration 62200 / 120000: loss 0.000000\n",
      "iteration 62300 / 120000: loss 0.000000\n",
      "iteration 62400 / 120000: loss 0.207470\n",
      "iteration 62500 / 120000: loss 0.000000\n",
      "iteration 62600 / 120000: loss 0.000000\n",
      "iteration 62700 / 120000: loss 0.754463\n",
      "iteration 62800 / 120000: loss 0.127898\n",
      "iteration 62900 / 120000: loss 0.000000\n",
      "iteration 63000 / 120000: loss 3.707959\n",
      "iteration 63100 / 120000: loss 0.000000\n",
      "iteration 63200 / 120000: loss 0.000000\n",
      "iteration 63300 / 120000: loss 0.000000\n",
      "iteration 63400 / 120000: loss 1.005253\n",
      "iteration 63500 / 120000: loss 0.000000\n",
      "iteration 63600 / 120000: loss 0.000000\n",
      "iteration 63700 / 120000: loss 0.000000\n",
      "iteration 63800 / 120000: loss 3.830741\n",
      "iteration 63900 / 120000: loss 0.000000\n",
      "iteration 64000 / 120000: loss 1.363312\n",
      "iteration 64100 / 120000: loss 0.000000\n",
      "iteration 64200 / 120000: loss 0.000000\n",
      "iteration 64300 / 120000: loss 0.000000\n",
      "iteration 64400 / 120000: loss 0.000000\n",
      "iteration 64500 / 120000: loss 0.330638\n",
      "iteration 64600 / 120000: loss 0.491868\n",
      "iteration 64700 / 120000: loss 0.000000\n",
      "iteration 64800 / 120000: loss 0.000000\n",
      "iteration 64900 / 120000: loss 0.000000\n",
      "iteration 65000 / 120000: loss 0.000000\n",
      "iteration 65100 / 120000: loss 0.000000\n",
      "iteration 65200 / 120000: loss 0.000000\n",
      "iteration 65300 / 120000: loss 0.000000\n",
      "iteration 65400 / 120000: loss 9.666189\n",
      "iteration 65500 / 120000: loss 0.000000\n",
      "iteration 65600 / 120000: loss 0.000000\n",
      "iteration 65700 / 120000: loss 0.000000\n",
      "iteration 65800 / 120000: loss 0.000000\n",
      "iteration 65900 / 120000: loss 0.000000\n",
      "iteration 66000 / 120000: loss 2.405157\n",
      "iteration 66100 / 120000: loss 1.986347\n",
      "iteration 66200 / 120000: loss 0.000000\n",
      "iteration 66300 / 120000: loss 0.000000\n",
      "iteration 66400 / 120000: loss 0.000000\n",
      "iteration 66500 / 120000: loss 0.945555\n",
      "iteration 66600 / 120000: loss 0.148075\n",
      "iteration 66700 / 120000: loss 1.655332\n",
      "iteration 66800 / 120000: loss 0.000000\n",
      "iteration 66900 / 120000: loss 2.223945\n",
      "iteration 67000 / 120000: loss 0.000000\n",
      "iteration 67100 / 120000: loss 0.000000\n",
      "iteration 67200 / 120000: loss 0.000000\n",
      "iteration 67300 / 120000: loss 0.426245\n",
      "iteration 67400 / 120000: loss 0.000000\n",
      "iteration 67500 / 120000: loss 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 67600 / 120000: loss 2.069745\n",
      "iteration 67700 / 120000: loss 0.000000\n",
      "iteration 67800 / 120000: loss 0.000000\n",
      "iteration 67900 / 120000: loss 0.000000\n",
      "iteration 68000 / 120000: loss 1.904574\n",
      "iteration 68100 / 120000: loss 0.000000\n",
      "iteration 68200 / 120000: loss 0.000000\n",
      "iteration 68300 / 120000: loss 4.353833\n",
      "iteration 68400 / 120000: loss 0.000000\n",
      "iteration 68500 / 120000: loss 11.703421\n",
      "iteration 68600 / 120000: loss 0.000000\n",
      "iteration 68700 / 120000: loss 0.000000\n",
      "iteration 68800 / 120000: loss 0.000000\n",
      "iteration 68900 / 120000: loss 0.000000\n",
      "iteration 69000 / 120000: loss 0.000000\n",
      "iteration 69100 / 120000: loss 0.000000\n",
      "iteration 69200 / 120000: loss 1.042351\n",
      "iteration 69300 / 120000: loss 0.000000\n",
      "iteration 69400 / 120000: loss 0.000000\n",
      "iteration 69500 / 120000: loss 0.000000\n",
      "iteration 69600 / 120000: loss 3.351186\n",
      "iteration 69700 / 120000: loss 0.000000\n",
      "iteration 69800 / 120000: loss 0.000000\n",
      "iteration 69900 / 120000: loss 0.000000\n",
      "iteration 70000 / 120000: loss 0.000000\n",
      "iteration 70100 / 120000: loss 2.216276\n",
      "iteration 70200 / 120000: loss 0.222231\n",
      "iteration 70300 / 120000: loss 0.000000\n",
      "iteration 70400 / 120000: loss 0.000000\n",
      "iteration 70500 / 120000: loss 0.000000\n",
      "iteration 70600 / 120000: loss 0.000000\n",
      "iteration 70700 / 120000: loss 0.000000\n",
      "iteration 70800 / 120000: loss 0.000000\n",
      "iteration 70900 / 120000: loss 0.000000\n",
      "iteration 71000 / 120000: loss 3.872033\n",
      "iteration 71100 / 120000: loss 0.000000\n",
      "iteration 71200 / 120000: loss 0.000000\n",
      "iteration 71300 / 120000: loss 0.000000\n",
      "iteration 71400 / 120000: loss 0.000000\n",
      "iteration 71500 / 120000: loss 0.000000\n",
      "iteration 71600 / 120000: loss 1.883019\n",
      "iteration 71700 / 120000: loss 0.000000\n",
      "iteration 71800 / 120000: loss 1.261741\n",
      "iteration 71900 / 120000: loss 0.000000\n",
      "iteration 72000 / 120000: loss 3.803638\n",
      "iteration 72100 / 120000: loss 0.000000\n",
      "iteration 72200 / 120000: loss 1.968543\n",
      "iteration 72300 / 120000: loss 0.000000\n",
      "iteration 72400 / 120000: loss 0.000000\n",
      "iteration 72500 / 120000: loss 0.000000\n",
      "iteration 72600 / 120000: loss 0.000000\n",
      "iteration 72700 / 120000: loss 2.820868\n",
      "iteration 72800 / 120000: loss 0.742641\n",
      "iteration 72900 / 120000: loss 0.000000\n",
      "iteration 73000 / 120000: loss 0.000000\n",
      "iteration 73100 / 120000: loss 0.000000\n",
      "iteration 73200 / 120000: loss 1.707335\n",
      "iteration 73300 / 120000: loss 0.000000\n",
      "iteration 73400 / 120000: loss 0.000000\n",
      "iteration 73500 / 120000: loss 1.162378\n",
      "iteration 73600 / 120000: loss 0.000000\n",
      "iteration 73700 / 120000: loss 0.383464\n",
      "iteration 73800 / 120000: loss 0.533762\n",
      "iteration 73900 / 120000: loss 0.000000\n",
      "iteration 74000 / 120000: loss 0.000000\n",
      "iteration 74100 / 120000: loss 0.000000\n",
      "iteration 74200 / 120000: loss 1.080560\n",
      "iteration 74300 / 120000: loss 1.510298\n",
      "iteration 74400 / 120000: loss 0.735040\n",
      "iteration 74500 / 120000: loss 0.000000\n",
      "iteration 74600 / 120000: loss 2.727681\n",
      "iteration 74700 / 120000: loss 0.000000\n",
      "iteration 74800 / 120000: loss 0.000000\n",
      "iteration 74900 / 120000: loss 0.000000\n",
      "iteration 75000 / 120000: loss 0.000000\n",
      "iteration 75100 / 120000: loss 0.000000\n",
      "iteration 75200 / 120000: loss 0.000000\n",
      "iteration 75300 / 120000: loss 0.000000\n",
      "iteration 75400 / 120000: loss 0.300754\n",
      "iteration 75500 / 120000: loss 0.000000\n",
      "iteration 75600 / 120000: loss 0.000000\n",
      "iteration 75700 / 120000: loss 0.000000\n",
      "iteration 75800 / 120000: loss 0.000000\n",
      "iteration 75900 / 120000: loss 2.530063\n",
      "iteration 76000 / 120000: loss 0.000000\n",
      "iteration 76100 / 120000: loss 0.000000\n",
      "iteration 76200 / 120000: loss 0.000000\n",
      "iteration 76300 / 120000: loss 0.000000\n",
      "iteration 76400 / 120000: loss 0.000000\n",
      "iteration 76500 / 120000: loss 1.809246\n",
      "iteration 76600 / 120000: loss 0.000000\n",
      "iteration 76700 / 120000: loss 0.000000\n",
      "iteration 76800 / 120000: loss 0.000000\n",
      "iteration 76900 / 120000: loss 0.000000\n",
      "iteration 77000 / 120000: loss 3.527199\n",
      "iteration 77100 / 120000: loss 0.000000\n",
      "iteration 77200 / 120000: loss 0.000000\n",
      "iteration 77300 / 120000: loss 0.000000\n",
      "iteration 77400 / 120000: loss 0.000000\n",
      "iteration 77500 / 120000: loss 0.000000\n",
      "iteration 77600 / 120000: loss 0.000000\n",
      "iteration 77700 / 120000: loss 0.000000\n",
      "iteration 77800 / 120000: loss 0.000000\n",
      "iteration 77900 / 120000: loss 0.000000\n",
      "iteration 78000 / 120000: loss 0.000000\n",
      "iteration 78100 / 120000: loss 1.367652\n",
      "iteration 78200 / 120000: loss 0.000000\n",
      "iteration 78300 / 120000: loss 0.000000\n",
      "iteration 78400 / 120000: loss 1.030646\n",
      "iteration 78500 / 120000: loss 0.000000\n",
      "iteration 78600 / 120000: loss 0.000000\n",
      "iteration 78700 / 120000: loss 0.000000\n",
      "iteration 78800 / 120000: loss 2.550843\n",
      "iteration 78900 / 120000: loss 0.000000\n",
      "iteration 79000 / 120000: loss 0.000000\n",
      "iteration 79100 / 120000: loss 1.846714\n",
      "iteration 79200 / 120000: loss 0.000000\n",
      "iteration 79300 / 120000: loss 0.000000\n",
      "iteration 79400 / 120000: loss 0.000000\n",
      "iteration 79500 / 120000: loss 0.000000\n",
      "iteration 79600 / 120000: loss 0.167794\n",
      "iteration 79700 / 120000: loss 0.000000\n",
      "iteration 79800 / 120000: loss 0.000000\n",
      "iteration 79900 / 120000: loss 0.000000\n",
      "iteration 80000 / 120000: loss 0.000000\n",
      "iteration 80100 / 120000: loss 0.000000\n",
      "iteration 80200 / 120000: loss 0.000000\n",
      "iteration 80300 / 120000: loss 0.000000\n",
      "iteration 80400 / 120000: loss 3.664613\n",
      "iteration 80500 / 120000: loss 0.000000\n",
      "iteration 80600 / 120000: loss 0.000000\n",
      "iteration 80700 / 120000: loss 3.060035\n",
      "iteration 80800 / 120000: loss 0.000000\n",
      "iteration 80900 / 120000: loss 0.000000\n",
      "iteration 81000 / 120000: loss 12.970132\n",
      "iteration 81100 / 120000: loss 0.000000\n",
      "iteration 81200 / 120000: loss 0.000000\n",
      "iteration 81300 / 120000: loss 0.000000\n",
      "iteration 81400 / 120000: loss 0.000000\n",
      "iteration 81500 / 120000: loss 0.000000\n",
      "iteration 81600 / 120000: loss 0.894664\n",
      "iteration 81700 / 120000: loss 2.346568\n",
      "iteration 81800 / 120000: loss 0.000000\n",
      "iteration 81900 / 120000: loss 0.000000\n",
      "iteration 82000 / 120000: loss 0.000000\n",
      "iteration 82100 / 120000: loss 0.000000\n",
      "iteration 82200 / 120000: loss 1.721190\n",
      "iteration 82300 / 120000: loss 0.000000\n",
      "iteration 82400 / 120000: loss 0.474687\n",
      "iteration 82500 / 120000: loss 5.278213\n",
      "iteration 82600 / 120000: loss 0.000000\n",
      "iteration 82700 / 120000: loss 0.000000\n",
      "iteration 82800 / 120000: loss 0.000000\n",
      "iteration 82900 / 120000: loss 0.000000\n",
      "iteration 83000 / 120000: loss 2.045188\n",
      "iteration 83100 / 120000: loss 0.819216\n",
      "iteration 83200 / 120000: loss 0.000000\n",
      "iteration 83300 / 120000: loss 0.000000\n",
      "iteration 83400 / 120000: loss 0.000000\n",
      "iteration 83500 / 120000: loss 0.000000\n",
      "iteration 83600 / 120000: loss 0.000000\n",
      "iteration 83700 / 120000: loss 1.951297\n",
      "iteration 83800 / 120000: loss 0.000000\n",
      "iteration 83900 / 120000: loss 1.880828\n",
      "iteration 84000 / 120000: loss 2.889136\n",
      "iteration 84100 / 120000: loss 0.000000\n",
      "iteration 84200 / 120000: loss 0.000000\n",
      "iteration 84300 / 120000: loss 0.000000\n",
      "iteration 84400 / 120000: loss 0.410019\n",
      "iteration 84500 / 120000: loss 0.000000\n",
      "iteration 84600 / 120000: loss 0.786911\n",
      "iteration 84700 / 120000: loss 0.000000\n",
      "iteration 84800 / 120000: loss 0.000000\n",
      "iteration 84900 / 120000: loss 0.000000\n",
      "iteration 85000 / 120000: loss 0.000000\n",
      "iteration 85100 / 120000: loss 0.000000\n",
      "iteration 85200 / 120000: loss 0.000000\n",
      "iteration 85300 / 120000: loss 0.000000\n",
      "iteration 85400 / 120000: loss 0.000000\n",
      "iteration 85500 / 120000: loss 0.000000\n",
      "iteration 85600 / 120000: loss 5.680275\n",
      "iteration 85700 / 120000: loss 0.000000\n",
      "iteration 85800 / 120000: loss 0.000000\n",
      "iteration 85900 / 120000: loss 0.000000\n",
      "iteration 86000 / 120000: loss 0.000000\n",
      "iteration 86100 / 120000: loss 0.000000\n",
      "iteration 86200 / 120000: loss 0.000000\n",
      "iteration 86300 / 120000: loss 0.000000\n",
      "iteration 86400 / 120000: loss 0.289130\n",
      "iteration 86500 / 120000: loss 2.519567\n",
      "iteration 86600 / 120000: loss 0.000000\n",
      "iteration 86700 / 120000: loss 0.000000\n",
      "iteration 86800 / 120000: loss 0.000000\n",
      "iteration 86900 / 120000: loss 0.000000\n",
      "iteration 87000 / 120000: loss 0.441490\n",
      "iteration 87100 / 120000: loss 0.000000\n",
      "iteration 87200 / 120000: loss 0.000000\n",
      "iteration 87300 / 120000: loss 0.000000\n",
      "iteration 87400 / 120000: loss 1.338223\n",
      "iteration 87500 / 120000: loss 0.000000\n",
      "iteration 87600 / 120000: loss 3.190591\n",
      "iteration 87700 / 120000: loss 0.000000\n",
      "iteration 87800 / 120000: loss 0.000000\n",
      "iteration 87900 / 120000: loss 3.656280\n",
      "iteration 88000 / 120000: loss 3.436555\n",
      "iteration 88100 / 120000: loss 0.000000\n",
      "iteration 88200 / 120000: loss 0.000000\n",
      "iteration 88300 / 120000: loss 0.000000\n",
      "iteration 88400 / 120000: loss 0.000000\n",
      "iteration 88500 / 120000: loss 1.237099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 88600 / 120000: loss 3.698239\n",
      "iteration 88700 / 120000: loss 0.000000\n",
      "iteration 88800 / 120000: loss 0.000000\n",
      "iteration 88900 / 120000: loss 1.215268\n",
      "iteration 89000 / 120000: loss 5.922478\n",
      "iteration 89100 / 120000: loss 0.000000\n",
      "iteration 89200 / 120000: loss 7.883893\n",
      "iteration 89300 / 120000: loss 0.748953\n",
      "iteration 89400 / 120000: loss 0.000000\n",
      "iteration 89500 / 120000: loss 0.000000\n",
      "iteration 89600 / 120000: loss 0.000000\n",
      "iteration 89700 / 120000: loss 0.000000\n",
      "iteration 89800 / 120000: loss 0.000000\n",
      "iteration 89900 / 120000: loss 0.000000\n",
      "iteration 90000 / 120000: loss 0.000000\n",
      "iteration 90100 / 120000: loss 1.479114\n",
      "iteration 90200 / 120000: loss 0.094174\n",
      "iteration 90300 / 120000: loss 0.000000\n",
      "iteration 90400 / 120000: loss 0.517083\n",
      "iteration 90500 / 120000: loss 0.000000\n",
      "iteration 90600 / 120000: loss 0.000000\n",
      "iteration 90700 / 120000: loss 0.000000\n",
      "iteration 90800 / 120000: loss 0.000000\n",
      "iteration 90900 / 120000: loss 0.000000\n",
      "iteration 91000 / 120000: loss 0.000000\n",
      "iteration 91100 / 120000: loss 2.549874\n",
      "iteration 91200 / 120000: loss 0.000000\n",
      "iteration 91300 / 120000: loss 2.007011\n",
      "iteration 91400 / 120000: loss 0.000000\n",
      "iteration 91500 / 120000: loss 0.000000\n",
      "iteration 91600 / 120000: loss 2.035583\n",
      "iteration 91700 / 120000: loss 0.000000\n",
      "iteration 91800 / 120000: loss 0.000000\n",
      "iteration 91900 / 120000: loss 0.000000\n",
      "iteration 92000 / 120000: loss 0.000000\n",
      "iteration 92100 / 120000: loss 9.095667\n",
      "iteration 92200 / 120000: loss 0.000000\n",
      "iteration 92300 / 120000: loss 0.497132\n",
      "iteration 92400 / 120000: loss 0.000000\n",
      "iteration 92500 / 120000: loss 3.515117\n",
      "iteration 92600 / 120000: loss 1.977880\n",
      "iteration 92700 / 120000: loss 1.418196\n",
      "iteration 92800 / 120000: loss 0.000000\n",
      "iteration 92900 / 120000: loss 0.000000\n",
      "iteration 93000 / 120000: loss 2.191577\n",
      "iteration 93100 / 120000: loss 2.318920\n",
      "iteration 93200 / 120000: loss 0.000000\n",
      "iteration 93300 / 120000: loss 0.000000\n",
      "iteration 93400 / 120000: loss 0.000000\n",
      "iteration 93500 / 120000: loss 0.000000\n",
      "iteration 93600 / 120000: loss 0.000000\n",
      "iteration 93700 / 120000: loss 0.000000\n",
      "iteration 93800 / 120000: loss 0.000000\n",
      "iteration 93900 / 120000: loss 3.000736\n",
      "iteration 94000 / 120000: loss 0.000000\n",
      "iteration 94100 / 120000: loss 0.612050\n",
      "iteration 94200 / 120000: loss 0.000000\n",
      "iteration 94300 / 120000: loss 0.000000\n",
      "iteration 94400 / 120000: loss 0.000000\n",
      "iteration 94500 / 120000: loss 0.892352\n",
      "iteration 94600 / 120000: loss 0.000000\n",
      "iteration 94700 / 120000: loss 2.376047\n",
      "iteration 94800 / 120000: loss 0.000000\n",
      "iteration 94900 / 120000: loss 0.000000\n",
      "iteration 95000 / 120000: loss 0.000000\n",
      "iteration 95100 / 120000: loss 0.000000\n",
      "iteration 95200 / 120000: loss 0.037661\n",
      "iteration 95300 / 120000: loss 3.745391\n",
      "iteration 95400 / 120000: loss 0.803353\n",
      "iteration 95500 / 120000: loss 0.000000\n",
      "iteration 95600 / 120000: loss 0.000000\n",
      "iteration 95700 / 120000: loss 0.000000\n",
      "iteration 95800 / 120000: loss 0.000000\n",
      "iteration 95900 / 120000: loss 0.000000\n",
      "iteration 96000 / 120000: loss 0.000000\n",
      "iteration 96100 / 120000: loss 0.065100\n",
      "iteration 96200 / 120000: loss 0.000000\n",
      "iteration 96300 / 120000: loss 0.000000\n",
      "iteration 96400 / 120000: loss 7.890898\n",
      "iteration 96500 / 120000: loss 0.000000\n",
      "iteration 96600 / 120000: loss 1.448349\n",
      "iteration 96700 / 120000: loss 0.000000\n",
      "iteration 96800 / 120000: loss 0.000000\n",
      "iteration 96900 / 120000: loss 0.000000\n",
      "iteration 97000 / 120000: loss 0.000000\n",
      "iteration 97100 / 120000: loss 0.000000\n",
      "iteration 97200 / 120000: loss 0.000000\n",
      "iteration 97300 / 120000: loss 2.842497\n",
      "iteration 97400 / 120000: loss 0.000000\n",
      "iteration 97500 / 120000: loss 0.000000\n",
      "iteration 97600 / 120000: loss 0.000000\n",
      "iteration 97700 / 120000: loss 0.356907\n",
      "iteration 97800 / 120000: loss 0.295622\n",
      "iteration 97900 / 120000: loss 0.000000\n",
      "iteration 98000 / 120000: loss 0.000000\n",
      "iteration 98100 / 120000: loss 1.520928\n",
      "iteration 98200 / 120000: loss 0.000000\n",
      "iteration 98300 / 120000: loss 0.000000\n",
      "iteration 98400 / 120000: loss 0.000000\n",
      "iteration 98500 / 120000: loss 2.125887\n",
      "iteration 98600 / 120000: loss 0.000000\n",
      "iteration 98700 / 120000: loss 1.322761\n",
      "iteration 98800 / 120000: loss 2.145818\n",
      "iteration 98900 / 120000: loss 0.000000\n",
      "iteration 99000 / 120000: loss 0.000000\n",
      "iteration 99100 / 120000: loss 0.980303\n",
      "iteration 99200 / 120000: loss 0.000000\n",
      "iteration 99300 / 120000: loss 0.000000\n",
      "iteration 99400 / 120000: loss 0.000000\n",
      "iteration 99500 / 120000: loss 0.000000\n",
      "iteration 99600 / 120000: loss 1.329402\n",
      "iteration 99700 / 120000: loss 4.498924\n",
      "iteration 99800 / 120000: loss 0.000000\n",
      "iteration 99900 / 120000: loss 2.307088\n",
      "iteration 100000 / 120000: loss 1.725796\n",
      "iteration 100100 / 120000: loss 0.000000\n",
      "iteration 100200 / 120000: loss 0.000000\n",
      "iteration 100300 / 120000: loss 0.000000\n",
      "iteration 100400 / 120000: loss 0.000000\n",
      "iteration 100500 / 120000: loss 0.000000\n",
      "iteration 100600 / 120000: loss 0.000000\n",
      "iteration 100700 / 120000: loss 0.000000\n",
      "iteration 100800 / 120000: loss 0.000000\n",
      "iteration 100900 / 120000: loss 1.545372\n",
      "iteration 101000 / 120000: loss 0.000000\n",
      "iteration 101100 / 120000: loss 0.000000\n",
      "iteration 101200 / 120000: loss 1.072413\n",
      "iteration 101300 / 120000: loss 0.000001\n",
      "iteration 101400 / 120000: loss 0.000000\n",
      "iteration 101500 / 120000: loss 0.734757\n",
      "iteration 101600 / 120000: loss 0.518025\n",
      "iteration 101700 / 120000: loss 0.000000\n",
      "iteration 101800 / 120000: loss 0.000001\n",
      "iteration 101900 / 120000: loss 3.923202\n",
      "iteration 102000 / 120000: loss 0.000001\n",
      "iteration 102100 / 120000: loss 0.000001\n",
      "iteration 102200 / 120000: loss 0.000001\n",
      "iteration 102300 / 120000: loss 0.000001\n",
      "iteration 102400 / 120000: loss 0.481676\n",
      "iteration 102500 / 120000: loss 0.000001\n",
      "iteration 102600 / 120000: loss 0.000001\n",
      "iteration 102700 / 120000: loss 0.000001\n",
      "iteration 102800 / 120000: loss 0.000001\n",
      "iteration 102900 / 120000: loss 5.450160\n",
      "iteration 103000 / 120000: loss 0.000001\n",
      "iteration 103100 / 120000: loss 0.976916\n",
      "iteration 103200 / 120000: loss 0.000001\n",
      "iteration 103300 / 120000: loss 4.497281\n",
      "iteration 103400 / 120000: loss 0.000001\n",
      "iteration 103500 / 120000: loss 0.000001\n",
      "iteration 103600 / 120000: loss 0.000001\n",
      "iteration 103700 / 120000: loss 1.586261\n",
      "iteration 103800 / 120000: loss 0.000001\n",
      "iteration 103900 / 120000: loss 0.000001\n",
      "iteration 104000 / 120000: loss 1.604154\n",
      "iteration 104100 / 120000: loss 0.000001\n",
      "iteration 104200 / 120000: loss 0.000001\n",
      "iteration 104300 / 120000: loss 1.474654\n",
      "iteration 104400 / 120000: loss 0.000001\n",
      "iteration 104500 / 120000: loss 0.000001\n",
      "iteration 104600 / 120000: loss 0.000001\n",
      "iteration 104700 / 120000: loss 9.372475\n",
      "iteration 104800 / 120000: loss 0.000001\n",
      "iteration 104900 / 120000: loss 0.000001\n",
      "iteration 105000 / 120000: loss 0.000001\n",
      "iteration 105100 / 120000: loss 0.000001\n",
      "iteration 105200 / 120000: loss 0.000001\n",
      "iteration 105300 / 120000: loss 0.000001\n",
      "iteration 105400 / 120000: loss 0.000001\n",
      "iteration 105500 / 120000: loss 0.000001\n",
      "iteration 105600 / 120000: loss 0.457760\n",
      "iteration 105700 / 120000: loss 0.000001\n",
      "iteration 105800 / 120000: loss 3.171672\n",
      "iteration 105900 / 120000: loss 0.000001\n",
      "iteration 106000 / 120000: loss 0.000001\n",
      "iteration 106100 / 120000: loss 2.636356\n",
      "iteration 106200 / 120000: loss 0.000001\n",
      "iteration 106300 / 120000: loss 0.000001\n",
      "iteration 106400 / 120000: loss 0.000001\n",
      "iteration 106500 / 120000: loss 0.104876\n",
      "iteration 106600 / 120000: loss 0.000001\n",
      "iteration 106700 / 120000: loss 0.584001\n",
      "iteration 106800 / 120000: loss 0.000001\n",
      "iteration 106900 / 120000: loss 0.483844\n",
      "iteration 107000 / 120000: loss 0.637527\n",
      "iteration 107100 / 120000: loss 0.000001\n",
      "iteration 107200 / 120000: loss 0.000001\n",
      "iteration 107300 / 120000: loss 0.000001\n",
      "iteration 107400 / 120000: loss 1.758932\n",
      "iteration 107500 / 120000: loss 0.000001\n",
      "iteration 107600 / 120000: loss 0.000001\n",
      "iteration 107700 / 120000: loss 0.000001\n",
      "iteration 107800 / 120000: loss 0.000001\n",
      "iteration 107900 / 120000: loss 2.848619\n",
      "iteration 108000 / 120000: loss 2.799457\n",
      "iteration 108100 / 120000: loss 2.322097\n",
      "iteration 108200 / 120000: loss 0.000001\n",
      "iteration 108300 / 120000: loss 0.000001\n",
      "iteration 108400 / 120000: loss 0.466703\n",
      "iteration 108500 / 120000: loss 1.261776\n",
      "iteration 108600 / 120000: loss 0.000001\n",
      "iteration 108700 / 120000: loss 0.000001\n",
      "iteration 108800 / 120000: loss 0.000001\n",
      "iteration 108900 / 120000: loss 0.000001\n",
      "iteration 109000 / 120000: loss 0.000001\n",
      "iteration 109100 / 120000: loss 1.398145\n",
      "iteration 109200 / 120000: loss 0.000001\n",
      "iteration 109300 / 120000: loss 3.930444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 109400 / 120000: loss 0.000001\n",
      "iteration 109500 / 120000: loss 0.000001\n",
      "iteration 109600 / 120000: loss 2.394559\n",
      "iteration 109700 / 120000: loss 0.504500\n",
      "iteration 109800 / 120000: loss 0.000001\n",
      "iteration 109900 / 120000: loss 0.000001\n",
      "iteration 110000 / 120000: loss 0.000001\n",
      "iteration 110100 / 120000: loss 0.000001\n",
      "iteration 110200 / 120000: loss 0.000001\n",
      "iteration 110300 / 120000: loss 0.000001\n",
      "iteration 110400 / 120000: loss 1.324245\n",
      "iteration 110500 / 120000: loss 1.807034\n",
      "iteration 110600 / 120000: loss 0.000001\n",
      "iteration 110700 / 120000: loss 0.831422\n",
      "iteration 110800 / 120000: loss 0.000001\n",
      "iteration 110900 / 120000: loss 0.000001\n",
      "iteration 111000 / 120000: loss 0.000001\n",
      "iteration 111100 / 120000: loss 0.000001\n",
      "iteration 111200 / 120000: loss 0.000001\n",
      "iteration 111300 / 120000: loss 0.000001\n",
      "iteration 111400 / 120000: loss 0.000001\n",
      "iteration 111500 / 120000: loss 1.712764\n",
      "iteration 111600 / 120000: loss 0.000001\n",
      "iteration 111700 / 120000: loss 0.568666\n",
      "iteration 111800 / 120000: loss 0.000001\n",
      "iteration 111900 / 120000: loss 0.000001\n",
      "iteration 112000 / 120000: loss 0.000001\n",
      "iteration 112100 / 120000: loss 0.000001\n",
      "iteration 112200 / 120000: loss 0.605679\n",
      "iteration 112300 / 120000: loss 0.000001\n",
      "iteration 112400 / 120000: loss 1.720376\n",
      "iteration 112500 / 120000: loss 0.000001\n",
      "iteration 112600 / 120000: loss 0.000001\n",
      "iteration 112700 / 120000: loss 0.000001\n",
      "iteration 112800 / 120000: loss 0.000001\n",
      "iteration 112900 / 120000: loss 1.317095\n",
      "iteration 113000 / 120000: loss 0.000001\n",
      "iteration 113100 / 120000: loss 0.000001\n",
      "iteration 113200 / 120000: loss 0.440436\n",
      "iteration 113300 / 120000: loss 0.000001\n",
      "iteration 113400 / 120000: loss 0.000001\n",
      "iteration 113500 / 120000: loss 3.617561\n",
      "iteration 113600 / 120000: loss 6.055648\n",
      "iteration 113700 / 120000: loss 0.000001\n",
      "iteration 113800 / 120000: loss 0.755697\n",
      "iteration 113900 / 120000: loss 2.319684\n",
      "iteration 114000 / 120000: loss 0.000001\n",
      "iteration 114100 / 120000: loss 0.000001\n",
      "iteration 114200 / 120000: loss 0.000001\n",
      "iteration 114300 / 120000: loss 0.345432\n",
      "iteration 114400 / 120000: loss 0.000001\n",
      "iteration 114500 / 120000: loss 0.427524\n",
      "iteration 114600 / 120000: loss 0.000001\n",
      "iteration 114700 / 120000: loss 0.000001\n",
      "iteration 114800 / 120000: loss 0.077977\n",
      "iteration 114900 / 120000: loss 1.552096\n",
      "iteration 115000 / 120000: loss 0.000001\n",
      "iteration 115100 / 120000: loss 2.892705\n",
      "iteration 115200 / 120000: loss 0.000001\n",
      "iteration 115300 / 120000: loss 0.000001\n",
      "iteration 115400 / 120000: loss 0.000001\n",
      "iteration 115500 / 120000: loss 0.000001\n",
      "iteration 115600 / 120000: loss 0.000001\n",
      "iteration 115700 / 120000: loss 3.497056\n",
      "iteration 115800 / 120000: loss 0.000001\n",
      "iteration 115900 / 120000: loss 0.000001\n",
      "iteration 116000 / 120000: loss 0.564345\n",
      "iteration 116100 / 120000: loss 2.990183\n",
      "iteration 116200 / 120000: loss 0.000001\n",
      "iteration 116300 / 120000: loss 0.000001\n",
      "iteration 116400 / 120000: loss 0.644602\n",
      "iteration 116500 / 120000: loss 0.000001\n",
      "iteration 116600 / 120000: loss 0.000001\n",
      "iteration 116700 / 120000: loss 0.000001\n",
      "iteration 116800 / 120000: loss 0.000001\n",
      "iteration 116900 / 120000: loss 0.000001\n",
      "iteration 117000 / 120000: loss 0.000001\n",
      "iteration 117100 / 120000: loss 0.000001\n",
      "iteration 117200 / 120000: loss 0.000001\n",
      "iteration 117300 / 120000: loss 0.000001\n",
      "iteration 117400 / 120000: loss 0.000001\n",
      "iteration 117500 / 120000: loss 0.000001\n",
      "iteration 117600 / 120000: loss 0.000001\n",
      "iteration 117700 / 120000: loss 6.553351\n",
      "iteration 117800 / 120000: loss 1.809256\n",
      "iteration 117900 / 120000: loss 0.000001\n",
      "iteration 118000 / 120000: loss 0.000001\n",
      "iteration 118100 / 120000: loss 0.000001\n",
      "iteration 118200 / 120000: loss 0.000001\n",
      "iteration 118300 / 120000: loss 0.000001\n",
      "iteration 118400 / 120000: loss 6.156852\n",
      "iteration 118500 / 120000: loss 0.000001\n",
      "iteration 118600 / 120000: loss 0.147569\n",
      "iteration 118700 / 120000: loss 0.000001\n",
      "iteration 118800 / 120000: loss 0.000001\n",
      "iteration 118900 / 120000: loss 0.000001\n",
      "iteration 119000 / 120000: loss 0.000001\n",
      "iteration 119100 / 120000: loss 1.804508\n",
      "iteration 119200 / 120000: loss 0.000001\n",
      "iteration 119300 / 120000: loss 0.000001\n",
      "iteration 119400 / 120000: loss 0.000001\n",
      "iteration 119500 / 120000: loss 3.669275\n",
      "iteration 119600 / 120000: loss 0.000001\n",
      "iteration 119700 / 120000: loss 0.000001\n",
      "iteration 119800 / 120000: loss 5.638547\n",
      "iteration 119900 / 120000: loss 4.257163\n",
      "lr=1e-07 bs=1 regularization_rate=0.0004\n",
      "iteration 0 / 120000: loss 1.027924\n",
      "iteration 100 / 120000: loss 3.943959\n",
      "iteration 200 / 120000: loss 0.000000\n",
      "iteration 300 / 120000: loss 0.000000\n",
      "iteration 400 / 120000: loss 1.673386\n",
      "iteration 500 / 120000: loss 0.000000\n",
      "iteration 600 / 120000: loss 2.055362\n",
      "iteration 700 / 120000: loss 0.000000\n",
      "iteration 800 / 120000: loss 1.662110\n",
      "iteration 900 / 120000: loss 2.275819\n",
      "iteration 1000 / 120000: loss 0.000000\n",
      "iteration 1100 / 120000: loss 0.000000\n",
      "iteration 1200 / 120000: loss 2.003819\n",
      "iteration 1300 / 120000: loss 0.000000\n",
      "iteration 1400 / 120000: loss 0.356868\n",
      "iteration 1500 / 120000: loss 0.487602\n",
      "iteration 1600 / 120000: loss 0.000000\n",
      "iteration 1700 / 120000: loss 0.000000\n",
      "iteration 1800 / 120000: loss 3.071764\n",
      "iteration 1900 / 120000: loss 0.000000\n",
      "iteration 2000 / 120000: loss 0.000000\n",
      "iteration 2100 / 120000: loss 0.000000\n",
      "iteration 2200 / 120000: loss 0.000000\n",
      "iteration 2300 / 120000: loss 12.234437\n",
      "iteration 2400 / 120000: loss 0.000000\n",
      "iteration 2500 / 120000: loss 0.448699\n",
      "iteration 2600 / 120000: loss 0.000000\n",
      "iteration 2700 / 120000: loss 0.000000\n",
      "iteration 2800 / 120000: loss 0.000000\n",
      "iteration 2900 / 120000: loss 0.000000\n",
      "iteration 3000 / 120000: loss 1.956765\n",
      "iteration 3100 / 120000: loss 0.534434\n",
      "iteration 3200 / 120000: loss 0.000000\n",
      "iteration 3300 / 120000: loss 0.000000\n",
      "iteration 3400 / 120000: loss 1.482869\n",
      "iteration 3500 / 120000: loss 0.000000\n",
      "iteration 3600 / 120000: loss 0.000000\n",
      "iteration 3700 / 120000: loss 0.000000\n",
      "iteration 3800 / 120000: loss 0.914564\n",
      "iteration 3900 / 120000: loss 0.000000\n",
      "iteration 4000 / 120000: loss 0.000000\n",
      "iteration 4100 / 120000: loss 0.000000\n",
      "iteration 4200 / 120000: loss 0.000000\n",
      "iteration 4300 / 120000: loss 0.000000\n",
      "iteration 4400 / 120000: loss 0.000000\n",
      "iteration 4500 / 120000: loss 0.000000\n",
      "iteration 4600 / 120000: loss 2.824527\n",
      "iteration 4700 / 120000: loss 0.000000\n",
      "iteration 4800 / 120000: loss 0.000000\n",
      "iteration 4900 / 120000: loss 3.685931\n",
      "iteration 5000 / 120000: loss 0.000000\n",
      "iteration 5100 / 120000: loss 0.000000\n",
      "iteration 5200 / 120000: loss 0.000000\n",
      "iteration 5300 / 120000: loss 0.000000\n",
      "iteration 5400 / 120000: loss 0.000000\n",
      "iteration 5500 / 120000: loss 0.000000\n",
      "iteration 5600 / 120000: loss 0.427204\n",
      "iteration 5700 / 120000: loss 0.000000\n",
      "iteration 5800 / 120000: loss 0.000000\n",
      "iteration 5900 / 120000: loss 0.026885\n",
      "iteration 6000 / 120000: loss 9.220527\n",
      "iteration 6100 / 120000: loss 4.050184\n",
      "iteration 6200 / 120000: loss 4.388282\n",
      "iteration 6300 / 120000: loss 0.000000\n",
      "iteration 6400 / 120000: loss 0.824991\n",
      "iteration 6500 / 120000: loss 0.000000\n",
      "iteration 6600 / 120000: loss 2.792456\n",
      "iteration 6700 / 120000: loss 0.000000\n",
      "iteration 6800 / 120000: loss 2.059468\n",
      "iteration 6900 / 120000: loss 0.000000\n",
      "iteration 7000 / 120000: loss 0.000000\n",
      "iteration 7100 / 120000: loss 0.000000\n",
      "iteration 7200 / 120000: loss 0.000000\n",
      "iteration 7300 / 120000: loss 0.000000\n",
      "iteration 7400 / 120000: loss 0.000000\n",
      "iteration 7500 / 120000: loss 2.752245\n",
      "iteration 7600 / 120000: loss 0.000000\n",
      "iteration 7700 / 120000: loss 0.000000\n",
      "iteration 7800 / 120000: loss 0.000000\n",
      "iteration 7900 / 120000: loss 3.610594\n",
      "iteration 8000 / 120000: loss 0.000000\n",
      "iteration 8100 / 120000: loss 0.000000\n",
      "iteration 8200 / 120000: loss 3.160393\n",
      "iteration 8300 / 120000: loss 0.000000\n",
      "iteration 8400 / 120000: loss 3.188834\n",
      "iteration 8500 / 120000: loss 0.000000\n",
      "iteration 8600 / 120000: loss 0.000000\n",
      "iteration 8700 / 120000: loss 3.970138\n",
      "iteration 8800 / 120000: loss 0.000000\n",
      "iteration 8900 / 120000: loss 0.000000\n",
      "iteration 9000 / 120000: loss 3.333783\n",
      "iteration 9100 / 120000: loss 0.000000\n",
      "iteration 9200 / 120000: loss 0.000000\n",
      "iteration 9300 / 120000: loss 0.000000\n",
      "iteration 9400 / 120000: loss 0.000000\n",
      "iteration 9500 / 120000: loss 0.670042\n",
      "iteration 9600 / 120000: loss 3.997379\n",
      "iteration 9700 / 120000: loss 0.000000\n",
      "iteration 9800 / 120000: loss 0.000000\n",
      "iteration 9900 / 120000: loss 0.000000\n",
      "iteration 10000 / 120000: loss 0.000000\n",
      "iteration 10100 / 120000: loss 0.000000\n",
      "iteration 10200 / 120000: loss 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 10300 / 120000: loss 2.553830\n",
      "iteration 10400 / 120000: loss 3.677239\n",
      "iteration 10500 / 120000: loss 6.724882\n",
      "iteration 10600 / 120000: loss 5.869838\n",
      "iteration 10700 / 120000: loss 3.020048\n",
      "iteration 10800 / 120000: loss 0.000000\n",
      "iteration 10900 / 120000: loss 0.061555\n",
      "iteration 11000 / 120000: loss 0.310766\n",
      "iteration 11100 / 120000: loss 0.000000\n",
      "iteration 11200 / 120000: loss 0.000000\n",
      "iteration 11300 / 120000: loss 2.744021\n",
      "iteration 11400 / 120000: loss 0.935701\n",
      "iteration 11500 / 120000: loss 0.000000\n",
      "iteration 11600 / 120000: loss 0.000000\n",
      "iteration 11700 / 120000: loss 0.000000\n",
      "iteration 11800 / 120000: loss 0.506056\n",
      "iteration 11900 / 120000: loss 0.000000\n",
      "iteration 12000 / 120000: loss 0.000000\n",
      "iteration 12100 / 120000: loss 0.000000\n",
      "iteration 12200 / 120000: loss 1.009432\n",
      "iteration 12300 / 120000: loss 0.000000\n",
      "iteration 12400 / 120000: loss 0.462149\n",
      "iteration 12500 / 120000: loss 0.544078\n",
      "iteration 12600 / 120000: loss 0.398397\n",
      "iteration 12700 / 120000: loss 2.172005\n",
      "iteration 12800 / 120000: loss 0.000000\n",
      "iteration 12900 / 120000: loss 0.000000\n",
      "iteration 13000 / 120000: loss 0.000000\n",
      "iteration 13100 / 120000: loss 0.000000\n",
      "iteration 13200 / 120000: loss 0.000000\n",
      "iteration 13300 / 120000: loss 0.761810\n",
      "iteration 13400 / 120000: loss 0.000000\n",
      "iteration 13500 / 120000: loss 1.626547\n",
      "iteration 13600 / 120000: loss 7.190183\n",
      "iteration 13700 / 120000: loss 0.000000\n",
      "iteration 13800 / 120000: loss 0.535790\n",
      "iteration 13900 / 120000: loss 0.127359\n",
      "iteration 14000 / 120000: loss 0.000000\n",
      "iteration 14100 / 120000: loss 0.000000\n",
      "iteration 14200 / 120000: loss 0.000000\n",
      "iteration 14300 / 120000: loss 0.532614\n",
      "iteration 14400 / 120000: loss 0.000000\n",
      "iteration 14500 / 120000: loss 0.379985\n",
      "iteration 14600 / 120000: loss 0.740892\n",
      "iteration 14700 / 120000: loss 0.000000\n",
      "iteration 14800 / 120000: loss 0.000000\n",
      "iteration 14900 / 120000: loss 1.971589\n",
      "iteration 15000 / 120000: loss 0.000000\n",
      "iteration 15100 / 120000: loss 0.000000\n",
      "iteration 15200 / 120000: loss 0.000000\n",
      "iteration 15300 / 120000: loss 0.000000\n",
      "iteration 15400 / 120000: loss 0.000000\n",
      "iteration 15500 / 120000: loss 3.140174\n",
      "iteration 15600 / 120000: loss 0.830276\n",
      "iteration 15700 / 120000: loss 2.992463\n",
      "iteration 15800 / 120000: loss 0.000000\n",
      "iteration 15900 / 120000: loss 0.000000\n",
      "iteration 16000 / 120000: loss 0.000000\n",
      "iteration 16100 / 120000: loss 1.830663\n",
      "iteration 16200 / 120000: loss 0.000000\n",
      "iteration 16300 / 120000: loss 0.170554\n",
      "iteration 16400 / 120000: loss 0.000000\n",
      "iteration 16500 / 120000: loss 1.155211\n",
      "iteration 16600 / 120000: loss 9.014764\n",
      "iteration 16700 / 120000: loss 0.000000\n",
      "iteration 16800 / 120000: loss 0.000000\n",
      "iteration 16900 / 120000: loss 0.000000\n",
      "iteration 17000 / 120000: loss 0.000000\n",
      "iteration 17100 / 120000: loss 0.000000\n",
      "iteration 17200 / 120000: loss 0.000000\n",
      "iteration 17300 / 120000: loss 0.000000\n",
      "iteration 17400 / 120000: loss 0.000000\n",
      "iteration 17500 / 120000: loss 0.000000\n",
      "iteration 17600 / 120000: loss 0.000000\n",
      "iteration 17700 / 120000: loss 0.492691\n",
      "iteration 17800 / 120000: loss 7.621598\n",
      "iteration 17900 / 120000: loss 0.000000\n",
      "iteration 18000 / 120000: loss 0.000000\n",
      "iteration 18100 / 120000: loss 0.000000\n",
      "iteration 18200 / 120000: loss 0.000000\n",
      "iteration 18300 / 120000: loss 0.000000\n",
      "iteration 18400 / 120000: loss 0.000000\n",
      "iteration 18500 / 120000: loss 0.000000\n",
      "iteration 18600 / 120000: loss 0.000000\n",
      "iteration 18700 / 120000: loss 0.000000\n",
      "iteration 18800 / 120000: loss 0.000000\n",
      "iteration 18900 / 120000: loss 0.000000\n",
      "iteration 19000 / 120000: loss 0.000000\n",
      "iteration 19100 / 120000: loss 0.000000\n",
      "iteration 19200 / 120000: loss 1.392637\n",
      "iteration 19300 / 120000: loss 0.000000\n",
      "iteration 19400 / 120000: loss 0.000000\n",
      "iteration 19500 / 120000: loss 0.000000\n",
      "iteration 19600 / 120000: loss 0.000000\n",
      "iteration 19700 / 120000: loss 0.000000\n",
      "iteration 19800 / 120000: loss 0.000000\n",
      "iteration 19900 / 120000: loss 0.000000\n",
      "iteration 20000 / 120000: loss 0.000000\n",
      "iteration 20100 / 120000: loss 0.000000\n",
      "iteration 20200 / 120000: loss 0.596462\n",
      "iteration 20300 / 120000: loss 0.000000\n",
      "iteration 20400 / 120000: loss 1.953660\n",
      "iteration 20500 / 120000: loss 0.000000\n",
      "iteration 20600 / 120000: loss 0.000000\n",
      "iteration 20700 / 120000: loss 1.710029\n",
      "iteration 20800 / 120000: loss 0.000000\n",
      "iteration 20900 / 120000: loss 0.000000\n",
      "iteration 21000 / 120000: loss 0.000000\n",
      "iteration 21100 / 120000: loss 0.000000\n",
      "iteration 21200 / 120000: loss 0.447120\n",
      "iteration 21300 / 120000: loss 0.000000\n",
      "iteration 21400 / 120000: loss 0.333580\n",
      "iteration 21500 / 120000: loss 0.000000\n",
      "iteration 21600 / 120000: loss 0.000000\n",
      "iteration 21700 / 120000: loss 0.000000\n",
      "iteration 21800 / 120000: loss 1.230988\n",
      "iteration 21900 / 120000: loss 0.000000\n",
      "iteration 22000 / 120000: loss 0.000000\n",
      "iteration 22100 / 120000: loss 0.000000\n",
      "iteration 22200 / 120000: loss 2.523305\n",
      "iteration 22300 / 120000: loss 2.246245\n",
      "iteration 22400 / 120000: loss 0.000000\n",
      "iteration 22500 / 120000: loss 0.000000\n",
      "iteration 22600 / 120000: loss 2.372850\n",
      "iteration 22700 / 120000: loss 0.000000\n",
      "iteration 22800 / 120000: loss 0.000000\n",
      "iteration 22900 / 120000: loss 0.000000\n",
      "iteration 23000 / 120000: loss 0.000000\n",
      "iteration 23100 / 120000: loss 0.763596\n",
      "iteration 23200 / 120000: loss 0.000000\n",
      "iteration 23300 / 120000: loss 0.000000\n",
      "iteration 23400 / 120000: loss 0.000000\n",
      "iteration 23500 / 120000: loss 0.000000\n",
      "iteration 23600 / 120000: loss 0.000000\n",
      "iteration 23700 / 120000: loss 0.000000\n",
      "iteration 23800 / 120000: loss 0.000000\n",
      "iteration 23900 / 120000: loss 0.000000\n",
      "iteration 24000 / 120000: loss 0.000000\n",
      "iteration 24100 / 120000: loss 0.000000\n",
      "iteration 24200 / 120000: loss 0.000000\n",
      "iteration 24300 / 120000: loss 0.000000\n",
      "iteration 24400 / 120000: loss 0.000000\n",
      "iteration 24500 / 120000: loss 0.039084\n",
      "iteration 24600 / 120000: loss 2.521812\n",
      "iteration 24700 / 120000: loss 0.000000\n",
      "iteration 24800 / 120000: loss 0.000000\n",
      "iteration 24900 / 120000: loss 0.000000\n",
      "iteration 25000 / 120000: loss 1.162606\n",
      "iteration 25100 / 120000: loss 0.000000\n",
      "iteration 25200 / 120000: loss 7.064129\n",
      "iteration 25300 / 120000: loss 0.000000\n",
      "iteration 25400 / 120000: loss 0.000000\n",
      "iteration 25500 / 120000: loss 3.982727\n",
      "iteration 25600 / 120000: loss 0.000000\n",
      "iteration 25700 / 120000: loss 0.000000\n",
      "iteration 25800 / 120000: loss 2.123590\n",
      "iteration 25900 / 120000: loss 0.000000\n",
      "iteration 26000 / 120000: loss 0.000000\n",
      "iteration 26100 / 120000: loss 0.000000\n",
      "iteration 26200 / 120000: loss 0.806593\n",
      "iteration 26300 / 120000: loss 0.000000\n",
      "iteration 26400 / 120000: loss 3.186242\n",
      "iteration 26500 / 120000: loss 0.000000\n",
      "iteration 26600 / 120000: loss 0.000000\n",
      "iteration 26700 / 120000: loss 0.000000\n",
      "iteration 26800 / 120000: loss 7.197630\n",
      "iteration 26900 / 120000: loss 0.000000\n",
      "iteration 27000 / 120000: loss 6.750969\n",
      "iteration 27100 / 120000: loss 0.000000\n",
      "iteration 27200 / 120000: loss 0.000000\n",
      "iteration 27300 / 120000: loss 0.000000\n",
      "iteration 27400 / 120000: loss 1.456326\n",
      "iteration 27500 / 120000: loss 0.000000\n",
      "iteration 27600 / 120000: loss 0.000000\n",
      "iteration 27700 / 120000: loss 0.000000\n",
      "iteration 27800 / 120000: loss 12.005656\n",
      "iteration 27900 / 120000: loss 0.000000\n",
      "iteration 28000 / 120000: loss 0.000000\n",
      "iteration 28100 / 120000: loss 0.000000\n",
      "iteration 28200 / 120000: loss 0.000000\n",
      "iteration 28300 / 120000: loss 0.000000\n",
      "iteration 28400 / 120000: loss 0.000000\n",
      "iteration 28500 / 120000: loss 3.072882\n",
      "iteration 28600 / 120000: loss 0.000000\n",
      "iteration 28700 / 120000: loss 0.000000\n",
      "iteration 28800 / 120000: loss 0.720380\n",
      "iteration 28900 / 120000: loss 1.863703\n",
      "iteration 29000 / 120000: loss 0.000000\n",
      "iteration 29100 / 120000: loss 0.000000\n",
      "iteration 29200 / 120000: loss 0.000000\n",
      "iteration 29300 / 120000: loss 10.328531\n",
      "iteration 29400 / 120000: loss 3.569516\n",
      "iteration 29500 / 120000: loss 4.878074\n",
      "iteration 29600 / 120000: loss 0.638918\n",
      "iteration 29700 / 120000: loss 0.000000\n",
      "iteration 29800 / 120000: loss 3.492411\n",
      "iteration 29900 / 120000: loss 0.000000\n",
      "iteration 30000 / 120000: loss 0.000000\n",
      "iteration 30100 / 120000: loss 0.410006\n",
      "iteration 30200 / 120000: loss 0.000000\n",
      "iteration 30300 / 120000: loss 0.000000\n",
      "iteration 30400 / 120000: loss 1.053668\n",
      "iteration 30500 / 120000: loss 0.000000\n",
      "iteration 30600 / 120000: loss 0.000000\n",
      "iteration 30700 / 120000: loss 0.000000\n",
      "iteration 30800 / 120000: loss 0.052201\n",
      "iteration 30900 / 120000: loss 0.000000\n",
      "iteration 31000 / 120000: loss 4.476894\n",
      "iteration 31100 / 120000: loss 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 31200 / 120000: loss 1.777345\n",
      "iteration 31300 / 120000: loss 0.000000\n",
      "iteration 31400 / 120000: loss 0.000000\n",
      "iteration 31500 / 120000: loss 0.000000\n",
      "iteration 31600 / 120000: loss 0.000000\n",
      "iteration 31700 / 120000: loss 0.000000\n",
      "iteration 31800 / 120000: loss 0.000000\n",
      "iteration 31900 / 120000: loss 0.000000\n",
      "iteration 32000 / 120000: loss 0.000000\n",
      "iteration 32100 / 120000: loss 0.000000\n",
      "iteration 32200 / 120000: loss 0.000000\n",
      "iteration 32300 / 120000: loss 0.000000\n",
      "iteration 32400 / 120000: loss 0.000000\n",
      "iteration 32500 / 120000: loss 0.000000\n",
      "iteration 32600 / 120000: loss 0.000000\n",
      "iteration 32700 / 120000: loss 0.000000\n",
      "iteration 32800 / 120000: loss 2.275673\n",
      "iteration 32900 / 120000: loss 0.000000\n",
      "iteration 33000 / 120000: loss 0.000000\n",
      "iteration 33100 / 120000: loss 0.000000\n",
      "iteration 33200 / 120000: loss 0.000000\n",
      "iteration 33300 / 120000: loss 1.467135\n",
      "iteration 33400 / 120000: loss 0.000000\n",
      "iteration 33500 / 120000: loss 0.000000\n",
      "iteration 33600 / 120000: loss 0.284086\n",
      "iteration 33700 / 120000: loss 0.000000\n",
      "iteration 33800 / 120000: loss 0.000000\n",
      "iteration 33900 / 120000: loss 0.025774\n",
      "iteration 34000 / 120000: loss 2.240505\n",
      "iteration 34100 / 120000: loss 0.000000\n",
      "iteration 34200 / 120000: loss 0.000000\n",
      "iteration 34300 / 120000: loss 0.000000\n",
      "iteration 34400 / 120000: loss 0.000000\n",
      "iteration 34500 / 120000: loss 0.000000\n",
      "iteration 34600 / 120000: loss 0.559172\n",
      "iteration 34700 / 120000: loss 0.000000\n",
      "iteration 34800 / 120000: loss 1.638016\n",
      "iteration 34900 / 120000: loss 0.000000\n",
      "iteration 35000 / 120000: loss 0.000000\n",
      "iteration 35100 / 120000: loss 0.000000\n",
      "iteration 35200 / 120000: loss 0.000000\n",
      "iteration 35300 / 120000: loss 0.000000\n",
      "iteration 35400 / 120000: loss 0.000000\n",
      "iteration 35500 / 120000: loss 1.117997\n",
      "iteration 35600 / 120000: loss 0.000000\n",
      "iteration 35700 / 120000: loss 0.000000\n",
      "iteration 35800 / 120000: loss 0.606944\n",
      "iteration 35900 / 120000: loss 0.000000\n",
      "iteration 36000 / 120000: loss 0.000000\n",
      "iteration 36100 / 120000: loss 0.000000\n",
      "iteration 36200 / 120000: loss 1.331862\n",
      "iteration 36300 / 120000: loss 4.438872\n",
      "iteration 36400 / 120000: loss 0.000000\n",
      "iteration 36500 / 120000: loss 0.000000\n",
      "iteration 36600 / 120000: loss 0.000000\n",
      "iteration 36700 / 120000: loss 0.000000\n",
      "iteration 36800 / 120000: loss 2.284978\n",
      "iteration 36900 / 120000: loss 0.000000\n",
      "iteration 37000 / 120000: loss 0.000000\n",
      "iteration 37100 / 120000: loss 0.388026\n",
      "iteration 37200 / 120000: loss 0.000000\n",
      "iteration 37300 / 120000: loss 0.000000\n",
      "iteration 37400 / 120000: loss 0.000000\n",
      "iteration 37500 / 120000: loss 0.000000\n",
      "iteration 37600 / 120000: loss 0.000000\n",
      "iteration 37700 / 120000: loss 0.000000\n",
      "iteration 37800 / 120000: loss 0.000000\n",
      "iteration 37900 / 120000: loss 0.000000\n",
      "iteration 38000 / 120000: loss 4.240158\n",
      "iteration 38100 / 120000: loss 0.000000\n",
      "iteration 38200 / 120000: loss 0.000000\n",
      "iteration 38300 / 120000: loss 0.000000\n",
      "iteration 38400 / 120000: loss 0.384677\n",
      "iteration 38500 / 120000: loss 0.000000\n",
      "iteration 38600 / 120000: loss 0.626573\n",
      "iteration 38700 / 120000: loss 0.000000\n",
      "iteration 38800 / 120000: loss 0.000000\n",
      "iteration 38900 / 120000: loss 3.400339\n",
      "iteration 39000 / 120000: loss 3.104707\n",
      "iteration 39100 / 120000: loss 0.000000\n",
      "iteration 39200 / 120000: loss 0.415500\n",
      "iteration 39300 / 120000: loss 2.286274\n",
      "iteration 39400 / 120000: loss 0.000000\n",
      "iteration 39500 / 120000: loss 0.000000\n",
      "iteration 39600 / 120000: loss 0.000000\n",
      "iteration 39700 / 120000: loss 0.000000\n",
      "iteration 39800 / 120000: loss 0.000000\n",
      "iteration 39900 / 120000: loss 0.000000\n",
      "iteration 40000 / 120000: loss 1.104084\n",
      "iteration 40100 / 120000: loss 0.000000\n",
      "iteration 40200 / 120000: loss 0.000000\n",
      "iteration 40300 / 120000: loss 0.000000\n",
      "iteration 40400 / 120000: loss 0.000000\n",
      "iteration 40500 / 120000: loss 2.595745\n",
      "iteration 40600 / 120000: loss 0.000000\n",
      "iteration 40700 / 120000: loss 0.000000\n",
      "iteration 40800 / 120000: loss 0.000000\n",
      "iteration 40900 / 120000: loss 0.000000\n",
      "iteration 41000 / 120000: loss 1.443731\n",
      "iteration 41100 / 120000: loss 0.000000\n",
      "iteration 41200 / 120000: loss 3.325604\n",
      "iteration 41300 / 120000: loss 0.000000\n",
      "iteration 41400 / 120000: loss 0.301825\n",
      "iteration 41500 / 120000: loss 0.000000\n",
      "iteration 41600 / 120000: loss 0.000000\n",
      "iteration 41700 / 120000: loss 0.000000\n",
      "iteration 41800 / 120000: loss 0.000000\n",
      "iteration 41900 / 120000: loss 0.000000\n",
      "iteration 42000 / 120000: loss 3.363751\n",
      "iteration 42100 / 120000: loss 0.000000\n",
      "iteration 42200 / 120000: loss 2.627665\n",
      "iteration 42300 / 120000: loss 0.000000\n",
      "iteration 42400 / 120000: loss 1.950487\n",
      "iteration 42500 / 120000: loss 0.000000\n",
      "iteration 42600 / 120000: loss 0.000000\n",
      "iteration 42700 / 120000: loss 0.000000\n",
      "iteration 42800 / 120000: loss 0.000000\n",
      "iteration 42900 / 120000: loss 0.000000\n",
      "iteration 43000 / 120000: loss 2.294515\n",
      "iteration 43100 / 120000: loss 0.000000\n",
      "iteration 43200 / 120000: loss 4.540072\n",
      "iteration 43300 / 120000: loss 0.000000\n",
      "iteration 43400 / 120000: loss 4.069423\n",
      "iteration 43500 / 120000: loss 0.000000\n",
      "iteration 43600 / 120000: loss 2.351615\n",
      "iteration 43700 / 120000: loss 3.956315\n",
      "iteration 43800 / 120000: loss 0.000000\n",
      "iteration 43900 / 120000: loss 0.458949\n",
      "iteration 44000 / 120000: loss 3.374477\n",
      "iteration 44100 / 120000: loss 3.682203\n",
      "iteration 44200 / 120000: loss 0.000000\n",
      "iteration 44300 / 120000: loss 0.000000\n",
      "iteration 44400 / 120000: loss 0.000000\n",
      "iteration 44500 / 120000: loss 2.264227\n",
      "iteration 44600 / 120000: loss 0.000000\n",
      "iteration 44700 / 120000: loss 1.470586\n",
      "iteration 44800 / 120000: loss 0.847570\n",
      "iteration 44900 / 120000: loss 0.000000\n",
      "iteration 45000 / 120000: loss 0.000000\n",
      "iteration 45100 / 120000: loss 0.000000\n",
      "iteration 45200 / 120000: loss 0.000000\n",
      "iteration 45300 / 120000: loss 0.186450\n",
      "iteration 45400 / 120000: loss 0.000000\n",
      "iteration 45500 / 120000: loss 0.000000\n",
      "iteration 45600 / 120000: loss 2.699521\n",
      "iteration 45700 / 120000: loss 0.000000\n",
      "iteration 45800 / 120000: loss 0.000000\n",
      "iteration 45900 / 120000: loss 3.443530\n",
      "iteration 46000 / 120000: loss 0.000000\n",
      "iteration 46100 / 120000: loss 0.000000\n",
      "iteration 46200 / 120000: loss 1.073913\n",
      "iteration 46300 / 120000: loss 0.000000\n",
      "iteration 46400 / 120000: loss 0.000000\n",
      "iteration 46500 / 120000: loss 0.527117\n",
      "iteration 46600 / 120000: loss 0.000000\n",
      "iteration 46700 / 120000: loss 0.000000\n",
      "iteration 46800 / 120000: loss 0.000000\n",
      "iteration 46900 / 120000: loss 0.000000\n",
      "iteration 47000 / 120000: loss 0.000000\n",
      "iteration 47100 / 120000: loss 0.618887\n",
      "iteration 47200 / 120000: loss 0.000000\n",
      "iteration 47300 / 120000: loss 0.072676\n",
      "iteration 47400 / 120000: loss 0.000000\n",
      "iteration 47500 / 120000: loss 0.000000\n",
      "iteration 47600 / 120000: loss 0.000000\n",
      "iteration 47700 / 120000: loss 0.000000\n",
      "iteration 47800 / 120000: loss 0.000000\n",
      "iteration 47900 / 120000: loss 0.000000\n",
      "iteration 48000 / 120000: loss 0.000000\n",
      "iteration 48100 / 120000: loss 0.000000\n",
      "iteration 48200 / 120000: loss 1.668012\n",
      "iteration 48300 / 120000: loss 0.000000\n",
      "iteration 48400 / 120000: loss 0.000000\n",
      "iteration 48500 / 120000: loss 0.000000\n",
      "iteration 48600 / 120000: loss 0.000000\n",
      "iteration 48700 / 120000: loss 0.000000\n",
      "iteration 48800 / 120000: loss 0.000000\n",
      "iteration 48900 / 120000: loss 0.000000\n",
      "iteration 49000 / 120000: loss 0.000000\n",
      "iteration 49100 / 120000: loss 0.000000\n",
      "iteration 49200 / 120000: loss 0.000000\n",
      "iteration 49300 / 120000: loss 1.026785\n",
      "iteration 49400 / 120000: loss 3.657359\n",
      "iteration 49500 / 120000: loss 5.623054\n",
      "iteration 49600 / 120000: loss 0.000000\n",
      "iteration 49700 / 120000: loss 0.000000\n",
      "iteration 49800 / 120000: loss 0.000000\n",
      "iteration 49900 / 120000: loss 1.217401\n",
      "iteration 50000 / 120000: loss 2.390806\n",
      "iteration 50100 / 120000: loss 0.000000\n",
      "iteration 50200 / 120000: loss 6.280510\n",
      "iteration 50300 / 120000: loss 0.000000\n",
      "iteration 50400 / 120000: loss 0.000000\n",
      "iteration 50500 / 120000: loss 0.000000\n",
      "iteration 50600 / 120000: loss 0.785066\n",
      "iteration 50700 / 120000: loss 0.285029\n",
      "iteration 50800 / 120000: loss 0.000000\n",
      "iteration 50900 / 120000: loss 0.000000\n",
      "iteration 51000 / 120000: loss 0.000000\n",
      "iteration 51100 / 120000: loss 0.000000\n",
      "iteration 51200 / 120000: loss 0.000000\n",
      "iteration 51300 / 120000: loss 0.299804\n",
      "iteration 51400 / 120000: loss 0.216350\n",
      "iteration 51500 / 120000: loss 2.430012\n",
      "iteration 51600 / 120000: loss 2.316868\n",
      "iteration 51700 / 120000: loss 0.000000\n",
      "iteration 51800 / 120000: loss 0.000000\n",
      "iteration 51900 / 120000: loss 1.397705\n",
      "iteration 52000 / 120000: loss 0.000000\n",
      "iteration 52100 / 120000: loss 0.000000\n",
      "iteration 52200 / 120000: loss 4.352980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 52300 / 120000: loss 0.000000\n",
      "iteration 52400 / 120000: loss 0.000000\n",
      "iteration 52500 / 120000: loss 0.000000\n",
      "iteration 52600 / 120000: loss 0.000000\n",
      "iteration 52700 / 120000: loss 0.000000\n",
      "iteration 52800 / 120000: loss 2.417147\n",
      "iteration 52900 / 120000: loss 0.231839\n",
      "iteration 53000 / 120000: loss 0.000000\n",
      "iteration 53100 / 120000: loss 1.096532\n",
      "iteration 53200 / 120000: loss 0.035454\n",
      "iteration 53300 / 120000: loss 4.257239\n",
      "iteration 53400 / 120000: loss 0.979958\n",
      "iteration 53500 / 120000: loss 0.000000\n",
      "iteration 53600 / 120000: loss 2.085031\n",
      "iteration 53700 / 120000: loss 0.739664\n",
      "iteration 53800 / 120000: loss 0.770527\n",
      "iteration 53900 / 120000: loss 0.000000\n",
      "iteration 54000 / 120000: loss 0.000000\n",
      "iteration 54100 / 120000: loss 2.882541\n",
      "iteration 54200 / 120000: loss 0.000000\n",
      "iteration 54300 / 120000: loss 0.000000\n",
      "iteration 54400 / 120000: loss 0.000000\n",
      "iteration 54500 / 120000: loss 2.594626\n",
      "iteration 54600 / 120000: loss 1.755479\n",
      "iteration 54700 / 120000: loss 2.092784\n",
      "iteration 54800 / 120000: loss 0.000000\n",
      "iteration 54900 / 120000: loss 0.000000\n",
      "iteration 55000 / 120000: loss 0.000000\n",
      "iteration 55100 / 120000: loss 3.595297\n",
      "iteration 55200 / 120000: loss 0.000000\n",
      "iteration 55300 / 120000: loss 0.000000\n",
      "iteration 55400 / 120000: loss 0.000000\n",
      "iteration 55500 / 120000: loss 0.000000\n",
      "iteration 55600 / 120000: loss 0.000000\n",
      "iteration 55700 / 120000: loss 0.000000\n",
      "iteration 55800 / 120000: loss 2.449471\n",
      "iteration 55900 / 120000: loss 0.000000\n",
      "iteration 56000 / 120000: loss 0.000000\n",
      "iteration 56100 / 120000: loss 0.555833\n",
      "iteration 56200 / 120000: loss 0.000000\n",
      "iteration 56300 / 120000: loss 0.000000\n",
      "iteration 56400 / 120000: loss 0.143050\n",
      "iteration 56500 / 120000: loss 2.245404\n",
      "iteration 56600 / 120000: loss 1.801701\n",
      "iteration 56700 / 120000: loss 4.380164\n",
      "iteration 56800 / 120000: loss 0.000000\n",
      "iteration 56900 / 120000: loss 0.012118\n",
      "iteration 57000 / 120000: loss 6.173751\n",
      "iteration 57100 / 120000: loss 0.000000\n",
      "iteration 57200 / 120000: loss 0.000000\n",
      "iteration 57300 / 120000: loss 1.702821\n",
      "iteration 57400 / 120000: loss 0.280995\n",
      "iteration 57500 / 120000: loss 0.000000\n",
      "iteration 57600 / 120000: loss 0.000000\n",
      "iteration 57700 / 120000: loss 0.000000\n",
      "iteration 57800 / 120000: loss 3.599894\n",
      "iteration 57900 / 120000: loss 0.000000\n",
      "iteration 58000 / 120000: loss 1.032668\n",
      "iteration 58100 / 120000: loss 0.015252\n",
      "iteration 58200 / 120000: loss 0.391443\n",
      "iteration 58300 / 120000: loss 0.000000\n",
      "iteration 58400 / 120000: loss 0.304817\n",
      "iteration 58500 / 120000: loss 0.000000\n",
      "iteration 58600 / 120000: loss 8.851764\n",
      "iteration 58700 / 120000: loss 0.146109\n",
      "iteration 58800 / 120000: loss 0.000000\n",
      "iteration 58900 / 120000: loss 2.487395\n",
      "iteration 59000 / 120000: loss 0.000000\n",
      "iteration 59100 / 120000: loss 0.489203\n",
      "iteration 59200 / 120000: loss 0.000000\n",
      "iteration 59300 / 120000: loss 0.464443\n",
      "iteration 59400 / 120000: loss 0.000000\n",
      "iteration 59500 / 120000: loss 0.000000\n",
      "iteration 59600 / 120000: loss 0.000000\n",
      "iteration 59700 / 120000: loss 1.921719\n",
      "iteration 59800 / 120000: loss 0.000000\n",
      "iteration 59900 / 120000: loss 0.000000\n",
      "iteration 60000 / 120000: loss 0.000000\n",
      "iteration 60100 / 120000: loss 0.000000\n",
      "iteration 60200 / 120000: loss 0.000000\n",
      "iteration 60300 / 120000: loss 0.998148\n",
      "iteration 60400 / 120000: loss 1.200823\n",
      "iteration 60500 / 120000: loss 5.365293\n",
      "iteration 60600 / 120000: loss 0.000000\n",
      "iteration 60700 / 120000: loss 0.000000\n",
      "iteration 60800 / 120000: loss 0.000000\n",
      "iteration 60900 / 120000: loss 0.000000\n",
      "iteration 61000 / 120000: loss 0.000000\n",
      "iteration 61100 / 120000: loss 2.210035\n",
      "iteration 61200 / 120000: loss 2.856433\n",
      "iteration 61300 / 120000: loss 0.000000\n",
      "iteration 61400 / 120000: loss 1.261697\n",
      "iteration 61500 / 120000: loss 0.000000\n",
      "iteration 61600 / 120000: loss 0.000000\n",
      "iteration 61700 / 120000: loss 0.829743\n",
      "iteration 61800 / 120000: loss 0.000000\n",
      "iteration 61900 / 120000: loss 0.000000\n",
      "iteration 62000 / 120000: loss 0.000000\n",
      "iteration 62100 / 120000: loss 2.407319\n",
      "iteration 62200 / 120000: loss 1.911522\n",
      "iteration 62300 / 120000: loss 0.000000\n",
      "iteration 62400 / 120000: loss 0.000000\n",
      "iteration 62500 / 120000: loss 0.391448\n",
      "iteration 62600 / 120000: loss 0.000000\n",
      "iteration 62700 / 120000: loss 0.000000\n",
      "iteration 62800 / 120000: loss 0.978464\n",
      "iteration 62900 / 120000: loss 0.000000\n",
      "iteration 63000 / 120000: loss 0.000000\n",
      "iteration 63100 / 120000: loss 0.000000\n",
      "iteration 63200 / 120000: loss 0.000000\n",
      "iteration 63300 / 120000: loss 0.000000\n",
      "iteration 63400 / 120000: loss 0.000000\n",
      "iteration 63500 / 120000: loss 1.481872\n",
      "iteration 63600 / 120000: loss 0.000000\n",
      "iteration 63700 / 120000: loss 0.000000\n",
      "iteration 63800 / 120000: loss 0.000000\n",
      "iteration 63900 / 120000: loss 3.372712\n",
      "iteration 64000 / 120000: loss 0.000000\n",
      "iteration 64100 / 120000: loss 0.000000\n",
      "iteration 64200 / 120000: loss 0.000000\n",
      "iteration 64300 / 120000: loss 0.000000\n",
      "iteration 64400 / 120000: loss 0.000000\n",
      "iteration 64500 / 120000: loss 0.000000\n",
      "iteration 64600 / 120000: loss 0.000000\n",
      "iteration 64700 / 120000: loss 3.177959\n",
      "iteration 64800 / 120000: loss 1.891595\n",
      "iteration 64900 / 120000: loss 0.000000\n",
      "iteration 65000 / 120000: loss 0.000000\n",
      "iteration 65100 / 120000: loss 2.168121\n",
      "iteration 65200 / 120000: loss 0.000000\n",
      "iteration 65300 / 120000: loss 0.000000\n",
      "iteration 65400 / 120000: loss 0.000000\n",
      "iteration 65500 / 120000: loss 0.000000\n",
      "iteration 65600 / 120000: loss 4.196189\n",
      "iteration 65700 / 120000: loss 1.339707\n",
      "iteration 65800 / 120000: loss 1.008131\n",
      "iteration 65900 / 120000: loss 0.000000\n",
      "iteration 66000 / 120000: loss 0.000000\n",
      "iteration 66100 / 120000: loss 1.605724\n",
      "iteration 66200 / 120000: loss 0.000000\n",
      "iteration 66300 / 120000: loss 0.000000\n",
      "iteration 66400 / 120000: loss 0.000000\n",
      "iteration 66500 / 120000: loss 2.277273\n",
      "iteration 66600 / 120000: loss 4.165750\n",
      "iteration 66700 / 120000: loss 0.000000\n",
      "iteration 66800 / 120000: loss 0.048055\n",
      "iteration 66900 / 120000: loss 0.000000\n",
      "iteration 67000 / 120000: loss 0.000000\n",
      "iteration 67100 / 120000: loss 3.069892\n",
      "iteration 67200 / 120000: loss 0.000000\n",
      "iteration 67300 / 120000: loss 0.000000\n",
      "iteration 67400 / 120000: loss 0.000000\n",
      "iteration 67500 / 120000: loss 0.000000\n",
      "iteration 67600 / 120000: loss 0.000000\n",
      "iteration 67700 / 120000: loss 0.000000\n",
      "iteration 67800 / 120000: loss 6.825342\n",
      "iteration 67900 / 120000: loss 2.843604\n",
      "iteration 68000 / 120000: loss 0.000000\n",
      "iteration 68100 / 120000: loss 0.000000\n",
      "iteration 68200 / 120000: loss 3.174914\n",
      "iteration 68300 / 120000: loss 0.000000\n",
      "iteration 68400 / 120000: loss 0.000000\n",
      "iteration 68500 / 120000: loss 0.000000\n",
      "iteration 68600 / 120000: loss 0.000000\n",
      "iteration 68700 / 120000: loss 3.000610\n",
      "iteration 68800 / 120000: loss 0.000000\n",
      "iteration 68900 / 120000: loss 0.149792\n",
      "iteration 69000 / 120000: loss 0.000000\n",
      "iteration 69100 / 120000: loss 0.000000\n",
      "iteration 69200 / 120000: loss 0.000000\n",
      "iteration 69300 / 120000: loss 0.000000\n",
      "iteration 69400 / 120000: loss 0.000000\n",
      "iteration 69500 / 120000: loss 1.478047\n",
      "iteration 69600 / 120000: loss 0.000000\n",
      "iteration 69700 / 120000: loss 0.000000\n",
      "iteration 69800 / 120000: loss 0.000000\n",
      "iteration 69900 / 120000: loss 1.504517\n",
      "iteration 70000 / 120000: loss 0.000000\n",
      "iteration 70100 / 120000: loss 0.000000\n",
      "iteration 70200 / 120000: loss 0.000000\n",
      "iteration 70300 / 120000: loss 0.959591\n",
      "iteration 70400 / 120000: loss 0.000000\n",
      "iteration 70500 / 120000: loss 0.000000\n",
      "iteration 70600 / 120000: loss 0.996947\n",
      "iteration 70700 / 120000: loss 0.000000\n",
      "iteration 70800 / 120000: loss 0.058264\n",
      "iteration 70900 / 120000: loss 0.000000\n",
      "iteration 71000 / 120000: loss 11.153835\n",
      "iteration 71100 / 120000: loss 0.000000\n",
      "iteration 71200 / 120000: loss 0.000000\n",
      "iteration 71300 / 120000: loss 3.372131\n",
      "iteration 71400 / 120000: loss 0.000000\n",
      "iteration 71500 / 120000: loss 3.991909\n",
      "iteration 71600 / 120000: loss 0.000000\n",
      "iteration 71700 / 120000: loss 0.000000\n",
      "iteration 71800 / 120000: loss 0.000000\n",
      "iteration 71900 / 120000: loss 0.000000\n",
      "iteration 72000 / 120000: loss 0.000000\n",
      "iteration 72100 / 120000: loss 0.000000\n",
      "iteration 72200 / 120000: loss 0.000000\n",
      "iteration 72300 / 120000: loss 0.000000\n",
      "iteration 72400 / 120000: loss 0.288060\n",
      "iteration 72500 / 120000: loss 0.000000\n",
      "iteration 72600 / 120000: loss 0.000000\n",
      "iteration 72700 / 120000: loss 0.000000\n",
      "iteration 72800 / 120000: loss 0.000000\n",
      "iteration 72900 / 120000: loss 0.000000\n",
      "iteration 73000 / 120000: loss 0.000000\n",
      "iteration 73100 / 120000: loss 0.000000\n",
      "iteration 73200 / 120000: loss 4.156030\n",
      "iteration 73300 / 120000: loss 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 73400 / 120000: loss 0.000000\n",
      "iteration 73500 / 120000: loss 0.000000\n",
      "iteration 73600 / 120000: loss 0.062011\n",
      "iteration 73700 / 120000: loss 0.979755\n",
      "iteration 73800 / 120000: loss 0.000000\n",
      "iteration 73900 / 120000: loss 0.000000\n",
      "iteration 74000 / 120000: loss 0.000000\n",
      "iteration 74100 / 120000: loss 0.000000\n",
      "iteration 74200 / 120000: loss 0.000000\n",
      "iteration 74300 / 120000: loss 1.987751\n",
      "iteration 74400 / 120000: loss 0.000000\n",
      "iteration 74500 / 120000: loss 1.121682\n",
      "iteration 74600 / 120000: loss 0.217558\n",
      "iteration 74700 / 120000: loss 0.040236\n",
      "iteration 74800 / 120000: loss 0.000000\n",
      "iteration 74900 / 120000: loss 0.000000\n",
      "iteration 75000 / 120000: loss 0.000000\n",
      "iteration 75100 / 120000: loss 0.000000\n",
      "iteration 75200 / 120000: loss 0.000000\n",
      "iteration 75300 / 120000: loss 2.616357\n",
      "iteration 75400 / 120000: loss 0.000000\n",
      "iteration 75500 / 120000: loss 0.000000\n",
      "iteration 75600 / 120000: loss 0.000000\n",
      "iteration 75700 / 120000: loss 0.000000\n",
      "iteration 75800 / 120000: loss 0.000000\n",
      "iteration 75900 / 120000: loss 0.000000\n",
      "iteration 76000 / 120000: loss 0.363723\n",
      "iteration 76100 / 120000: loss 0.000000\n",
      "iteration 76200 / 120000: loss 0.000000\n",
      "iteration 76300 / 120000: loss 0.000000\n",
      "iteration 76400 / 120000: loss 0.000000\n",
      "iteration 76500 / 120000: loss 0.000000\n",
      "iteration 76600 / 120000: loss 0.000000\n",
      "iteration 76700 / 120000: loss 5.173442\n",
      "iteration 76800 / 120000: loss 0.000000\n",
      "iteration 76900 / 120000: loss 0.000000\n",
      "iteration 77000 / 120000: loss 0.000000\n",
      "iteration 77100 / 120000: loss 0.000000\n",
      "iteration 77200 / 120000: loss 0.000000\n",
      "iteration 77300 / 120000: loss 0.000000\n",
      "iteration 77400 / 120000: loss 0.000000\n",
      "iteration 77500 / 120000: loss 0.000000\n",
      "iteration 77600 / 120000: loss 0.000000\n",
      "iteration 77700 / 120000: loss 0.000000\n",
      "iteration 77800 / 120000: loss 1.935091\n",
      "iteration 77900 / 120000: loss 0.000000\n",
      "iteration 78000 / 120000: loss 0.000000\n",
      "iteration 78100 / 120000: loss 0.650894\n",
      "iteration 78200 / 120000: loss 0.000000\n",
      "iteration 78300 / 120000: loss 2.598232\n",
      "iteration 78400 / 120000: loss 1.335104\n",
      "iteration 78500 / 120000: loss 1.081272\n",
      "iteration 78600 / 120000: loss 0.000000\n",
      "iteration 78700 / 120000: loss 0.224125\n",
      "iteration 78800 / 120000: loss 0.000000\n",
      "iteration 78900 / 120000: loss 0.000000\n",
      "iteration 79000 / 120000: loss 0.000000\n",
      "iteration 79100 / 120000: loss 0.000000\n",
      "iteration 79200 / 120000: loss 0.000000\n",
      "iteration 79300 / 120000: loss 0.000000\n",
      "iteration 79400 / 120000: loss 0.000000\n",
      "iteration 79500 / 120000: loss 0.000000\n",
      "iteration 79600 / 120000: loss 0.000000\n",
      "iteration 79700 / 120000: loss 0.000000\n",
      "iteration 79800 / 120000: loss 0.000000\n",
      "iteration 79900 / 120000: loss 0.000000\n",
      "iteration 80000 / 120000: loss 0.000000\n",
      "iteration 80100 / 120000: loss 1.794850\n",
      "iteration 80200 / 120000: loss 0.000000\n",
      "iteration 80300 / 120000: loss 0.000000\n",
      "iteration 80400 / 120000: loss 0.000000\n",
      "iteration 80500 / 120000: loss 0.000000\n",
      "iteration 80600 / 120000: loss 2.857681\n",
      "iteration 80700 / 120000: loss 0.703846\n",
      "iteration 80800 / 120000: loss 0.000000\n",
      "iteration 80900 / 120000: loss 0.000000\n",
      "iteration 81000 / 120000: loss 0.000000\n",
      "iteration 81100 / 120000: loss 4.255132\n",
      "iteration 81200 / 120000: loss 2.408018\n",
      "iteration 81300 / 120000: loss 0.000000\n",
      "iteration 81400 / 120000: loss 0.000000\n",
      "iteration 81500 / 120000: loss 1.270572\n",
      "iteration 81600 / 120000: loss 0.000000\n",
      "iteration 81700 / 120000: loss 0.000000\n",
      "iteration 81800 / 120000: loss 0.000000\n",
      "iteration 81900 / 120000: loss 0.000000\n",
      "iteration 82000 / 120000: loss 0.000000\n",
      "iteration 82100 / 120000: loss 0.000000\n",
      "iteration 82200 / 120000: loss 0.000000\n",
      "iteration 82300 / 120000: loss 0.000000\n",
      "iteration 82400 / 120000: loss 2.157501\n",
      "iteration 82500 / 120000: loss 0.000000\n",
      "iteration 82600 / 120000: loss 0.000000\n",
      "iteration 82700 / 120000: loss 0.000000\n",
      "iteration 82800 / 120000: loss 0.000000\n",
      "iteration 82900 / 120000: loss 0.000000\n",
      "iteration 83000 / 120000: loss 0.000000\n",
      "iteration 83100 / 120000: loss 8.519524\n",
      "iteration 83200 / 120000: loss 0.000000\n",
      "iteration 83300 / 120000: loss 4.654533\n",
      "iteration 83400 / 120000: loss 0.000000\n",
      "iteration 83500 / 120000: loss 1.054306\n",
      "iteration 83600 / 120000: loss 0.993423\n",
      "iteration 83700 / 120000: loss 0.000000\n",
      "iteration 83800 / 120000: loss 0.000000\n",
      "iteration 83900 / 120000: loss 0.000000\n",
      "iteration 84000 / 120000: loss 0.000000\n",
      "iteration 84100 / 120000: loss 0.000000\n",
      "iteration 84200 / 120000: loss 0.000000\n",
      "iteration 84300 / 120000: loss 5.309276\n",
      "iteration 84400 / 120000: loss 0.000000\n",
      "iteration 84500 / 120000: loss 2.226813\n",
      "iteration 84600 / 120000: loss 0.000000\n",
      "iteration 84700 / 120000: loss 0.000000\n",
      "iteration 84800 / 120000: loss 0.000000\n",
      "iteration 84900 / 120000: loss 0.000000\n",
      "iteration 85000 / 120000: loss 0.215301\n",
      "iteration 85100 / 120000: loss 0.000000\n",
      "iteration 85200 / 120000: loss 0.000000\n",
      "iteration 85300 / 120000: loss 0.000000\n",
      "iteration 85400 / 120000: loss 0.000000\n",
      "iteration 85500 / 120000: loss 0.000000\n",
      "iteration 85600 / 120000: loss 0.000000\n",
      "iteration 85700 / 120000: loss 1.813162\n",
      "iteration 85800 / 120000: loss 2.348718\n",
      "iteration 85900 / 120000: loss 0.000000\n",
      "iteration 86000 / 120000: loss 0.000000\n",
      "iteration 86100 / 120000: loss 2.787615\n",
      "iteration 86200 / 120000: loss 2.686868\n",
      "iteration 86300 / 120000: loss 0.000000\n",
      "iteration 86400 / 120000: loss 0.000000\n",
      "iteration 86500 / 120000: loss 1.012660\n",
      "iteration 86600 / 120000: loss 0.000000\n",
      "iteration 86700 / 120000: loss 0.000000\n",
      "iteration 86800 / 120000: loss 0.000000\n",
      "iteration 86900 / 120000: loss 0.000000\n",
      "iteration 87000 / 120000: loss 0.153344\n",
      "iteration 87100 / 120000: loss 0.000000\n",
      "iteration 87200 / 120000: loss 0.000000\n",
      "iteration 87300 / 120000: loss 0.000000\n",
      "iteration 87400 / 120000: loss 5.242751\n",
      "iteration 87500 / 120000: loss 0.000000\n",
      "iteration 87600 / 120000: loss 7.176167\n",
      "iteration 87700 / 120000: loss 0.000000\n",
      "iteration 87800 / 120000: loss 0.000000\n",
      "iteration 87900 / 120000: loss 0.000000\n",
      "iteration 88000 / 120000: loss 0.000000\n",
      "iteration 88100 / 120000: loss 0.000000\n",
      "iteration 88200 / 120000: loss 1.767707\n",
      "iteration 88300 / 120000: loss 0.000000\n",
      "iteration 88400 / 120000: loss 1.590886\n",
      "iteration 88500 / 120000: loss 0.000000\n",
      "iteration 88600 / 120000: loss 4.317499\n",
      "iteration 88700 / 120000: loss 0.000000\n",
      "iteration 88800 / 120000: loss 0.262879\n",
      "iteration 88900 / 120000: loss 0.000000\n",
      "iteration 89000 / 120000: loss 1.499294\n",
      "iteration 89100 / 120000: loss 0.000000\n",
      "iteration 89200 / 120000: loss 0.000000\n",
      "iteration 89300 / 120000: loss 0.000000\n",
      "iteration 89400 / 120000: loss 0.000000\n",
      "iteration 89500 / 120000: loss 0.000000\n",
      "iteration 89600 / 120000: loss 0.000000\n",
      "iteration 89700 / 120000: loss 0.000000\n",
      "iteration 89800 / 120000: loss 0.000000\n",
      "iteration 89900 / 120000: loss 0.000000\n",
      "iteration 90000 / 120000: loss 2.933079\n",
      "iteration 90100 / 120000: loss 0.000000\n",
      "iteration 90200 / 120000: loss 0.000000\n",
      "iteration 90300 / 120000: loss 0.000000\n",
      "iteration 90400 / 120000: loss 0.000000\n",
      "iteration 90500 / 120000: loss 1.133355\n",
      "iteration 90600 / 120000: loss 0.000000\n",
      "iteration 90700 / 120000: loss 4.150293\n",
      "iteration 90800 / 120000: loss 0.000000\n",
      "iteration 90900 / 120000: loss 3.331343\n",
      "iteration 91000 / 120000: loss 0.000000\n",
      "iteration 91100 / 120000: loss 3.233365\n",
      "iteration 91200 / 120000: loss 0.150174\n",
      "iteration 91300 / 120000: loss 0.000000\n",
      "iteration 91400 / 120000: loss 1.177055\n",
      "iteration 91500 / 120000: loss 0.000000\n",
      "iteration 91600 / 120000: loss 0.385238\n",
      "iteration 91700 / 120000: loss 0.000000\n",
      "iteration 91800 / 120000: loss 0.000000\n",
      "iteration 91900 / 120000: loss 0.000000\n",
      "iteration 92000 / 120000: loss 0.000000\n",
      "iteration 92100 / 120000: loss 6.244191\n",
      "iteration 92200 / 120000: loss 0.892294\n",
      "iteration 92300 / 120000: loss 7.835624\n",
      "iteration 92400 / 120000: loss 0.000000\n",
      "iteration 92500 / 120000: loss 0.000000\n",
      "iteration 92600 / 120000: loss 0.000000\n",
      "iteration 92700 / 120000: loss 0.000000\n",
      "iteration 92800 / 120000: loss 0.000000\n",
      "iteration 92900 / 120000: loss 0.000000\n",
      "iteration 93000 / 120000: loss 0.000000\n",
      "iteration 93100 / 120000: loss 3.816697\n",
      "iteration 93200 / 120000: loss 0.000000\n",
      "iteration 93300 / 120000: loss 2.486360\n",
      "iteration 93400 / 120000: loss 0.240218\n",
      "iteration 93500 / 120000: loss 0.000000\n",
      "iteration 93600 / 120000: loss 0.000000\n",
      "iteration 93700 / 120000: loss 0.000000\n",
      "iteration 93800 / 120000: loss 0.048912\n",
      "iteration 93900 / 120000: loss 0.000000\n",
      "iteration 94000 / 120000: loss 3.604190\n",
      "iteration 94100 / 120000: loss 0.000000\n",
      "iteration 94200 / 120000: loss 0.000000\n",
      "iteration 94300 / 120000: loss 0.000000\n",
      "iteration 94400 / 120000: loss 0.000000\n",
      "iteration 94500 / 120000: loss 0.000000\n",
      "iteration 94600 / 120000: loss 0.000000\n",
      "iteration 94700 / 120000: loss 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 94800 / 120000: loss 0.000000\n",
      "iteration 94900 / 120000: loss 0.000000\n",
      "iteration 95000 / 120000: loss 0.000000\n",
      "iteration 95100 / 120000: loss 0.000000\n",
      "iteration 95200 / 120000: loss 0.313179\n",
      "iteration 95300 / 120000: loss 0.000000\n",
      "iteration 95400 / 120000: loss 2.318212\n",
      "iteration 95500 / 120000: loss 0.247696\n",
      "iteration 95600 / 120000: loss 2.362608\n",
      "iteration 95700 / 120000: loss 0.000000\n",
      "iteration 95800 / 120000: loss 0.000000\n",
      "iteration 95900 / 120000: loss 0.000000\n",
      "iteration 96000 / 120000: loss 0.000000\n",
      "iteration 96100 / 120000: loss 0.000000\n",
      "iteration 96200 / 120000: loss 0.000000\n",
      "iteration 96300 / 120000: loss 0.000000\n",
      "iteration 96400 / 120000: loss 0.363262\n",
      "iteration 96500 / 120000: loss 0.000000\n",
      "iteration 96600 / 120000: loss 1.900353\n",
      "iteration 96700 / 120000: loss 0.000000\n",
      "iteration 96800 / 120000: loss 0.000000\n",
      "iteration 96900 / 120000: loss 0.000000\n",
      "iteration 97000 / 120000: loss 0.195365\n",
      "iteration 97100 / 120000: loss 0.000000\n",
      "iteration 97200 / 120000: loss 0.000000\n",
      "iteration 97300 / 120000: loss 0.000000\n",
      "iteration 97400 / 120000: loss 0.000000\n",
      "iteration 97500 / 120000: loss 1.456355\n",
      "iteration 97600 / 120000: loss 0.000000\n",
      "iteration 97700 / 120000: loss 1.584547\n",
      "iteration 97800 / 120000: loss 0.000000\n",
      "iteration 97900 / 120000: loss 1.121928\n",
      "iteration 98000 / 120000: loss 1.778688\n",
      "iteration 98100 / 120000: loss 0.000000\n",
      "iteration 98200 / 120000: loss 3.457822\n",
      "iteration 98300 / 120000: loss 0.000000\n",
      "iteration 98400 / 120000: loss 0.259139\n",
      "iteration 98500 / 120000: loss 0.000000\n",
      "iteration 98600 / 120000: loss 0.000000\n",
      "iteration 98700 / 120000: loss 0.000000\n",
      "iteration 98800 / 120000: loss 0.000000\n",
      "iteration 98900 / 120000: loss 0.373495\n",
      "iteration 99000 / 120000: loss 5.234938\n",
      "iteration 99100 / 120000: loss 0.000000\n",
      "iteration 99200 / 120000: loss 0.000000\n",
      "iteration 99300 / 120000: loss 0.000000\n",
      "iteration 99400 / 120000: loss 0.000000\n",
      "iteration 99500 / 120000: loss 0.000000\n",
      "iteration 99600 / 120000: loss 2.585897\n",
      "iteration 99700 / 120000: loss 0.000000\n",
      "iteration 99800 / 120000: loss 1.367120\n",
      "iteration 99900 / 120000: loss 0.832167\n",
      "iteration 100000 / 120000: loss 0.652337\n",
      "iteration 100100 / 120000: loss 0.000000\n",
      "iteration 100200 / 120000: loss 0.700126\n",
      "iteration 100300 / 120000: loss 0.983754\n",
      "iteration 100400 / 120000: loss 0.000000\n",
      "iteration 100500 / 120000: loss 0.000000\n",
      "iteration 100600 / 120000: loss 0.000000\n",
      "iteration 100700 / 120000: loss 1.778419\n",
      "iteration 100800 / 120000: loss 0.000000\n",
      "iteration 100900 / 120000: loss 0.000000\n",
      "iteration 101000 / 120000: loss 1.755878\n",
      "iteration 101100 / 120000: loss 0.000000\n",
      "iteration 101200 / 120000: loss 0.000000\n",
      "iteration 101300 / 120000: loss 2.694514\n",
      "iteration 101400 / 120000: loss 0.000000\n",
      "iteration 101500 / 120000: loss 0.000000\n",
      "iteration 101600 / 120000: loss 0.597936\n",
      "iteration 101700 / 120000: loss 2.495365\n",
      "iteration 101800 / 120000: loss 0.348527\n",
      "iteration 101900 / 120000: loss 0.000000\n",
      "iteration 102000 / 120000: loss 1.552890\n",
      "iteration 102100 / 120000: loss 0.000000\n",
      "iteration 102200 / 120000: loss 0.000000\n",
      "iteration 102300 / 120000: loss 0.000000\n",
      "iteration 102400 / 120000: loss 0.000000\n",
      "iteration 102500 / 120000: loss 0.000000\n",
      "iteration 102600 / 120000: loss 2.631332\n",
      "iteration 102700 / 120000: loss 0.000000\n",
      "iteration 102800 / 120000: loss 0.000000\n",
      "iteration 102900 / 120000: loss 0.000000\n",
      "iteration 103000 / 120000: loss 2.565552\n",
      "iteration 103100 / 120000: loss 1.078243\n",
      "iteration 103200 / 120000: loss 0.000000\n",
      "iteration 103300 / 120000: loss 1.881527\n",
      "iteration 103400 / 120000: loss 0.000000\n",
      "iteration 103500 / 120000: loss 0.365992\n",
      "iteration 103600 / 120000: loss 0.000000\n",
      "iteration 103700 / 120000: loss 0.000000\n",
      "iteration 103800 / 120000: loss 0.000000\n",
      "iteration 103900 / 120000: loss 0.000000\n",
      "iteration 104000 / 120000: loss 0.000000\n",
      "iteration 104100 / 120000: loss 0.157095\n",
      "iteration 104200 / 120000: loss 0.000000\n",
      "iteration 104300 / 120000: loss 0.080636\n",
      "iteration 104400 / 120000: loss 0.000000\n",
      "iteration 104500 / 120000: loss 1.999005\n",
      "iteration 104600 / 120000: loss 1.399675\n",
      "iteration 104700 / 120000: loss 0.000000\n",
      "iteration 104800 / 120000: loss 0.000000\n",
      "iteration 104900 / 120000: loss 0.021795\n",
      "iteration 105000 / 120000: loss 0.000000\n",
      "iteration 105100 / 120000: loss 0.000000\n",
      "iteration 105200 / 120000: loss 0.000000\n",
      "iteration 105300 / 120000: loss 0.000000\n",
      "iteration 105400 / 120000: loss 1.377580\n",
      "iteration 105500 / 120000: loss 0.000000\n",
      "iteration 105600 / 120000: loss 0.000000\n",
      "iteration 105700 / 120000: loss 1.012573\n",
      "iteration 105800 / 120000: loss 0.000000\n",
      "iteration 105900 / 120000: loss 0.000000\n",
      "iteration 106000 / 120000: loss 0.234139\n",
      "iteration 106100 / 120000: loss 0.894625\n",
      "iteration 106200 / 120000: loss 2.690335\n",
      "iteration 106300 / 120000: loss 0.000000\n",
      "iteration 106400 / 120000: loss 0.000000\n",
      "iteration 106500 / 120000: loss 0.000000\n",
      "iteration 106600 / 120000: loss 0.078980\n",
      "iteration 106700 / 120000: loss 0.000000\n",
      "iteration 106800 / 120000: loss 3.443514\n",
      "iteration 106900 / 120000: loss 0.000000\n",
      "iteration 107000 / 120000: loss 0.000000\n",
      "iteration 107100 / 120000: loss 0.000000\n",
      "iteration 107200 / 120000: loss 3.924878\n",
      "iteration 107300 / 120000: loss 0.000000\n",
      "iteration 107400 / 120000: loss 3.419153\n",
      "iteration 107500 / 120000: loss 0.000000\n",
      "iteration 107600 / 120000: loss 0.000000\n",
      "iteration 107700 / 120000: loss 0.000000\n",
      "iteration 107800 / 120000: loss 0.000000\n",
      "iteration 107900 / 120000: loss 0.000000\n",
      "iteration 108000 / 120000: loss 0.000000\n",
      "iteration 108100 / 120000: loss 0.000000\n",
      "iteration 108200 / 120000: loss 0.000000\n",
      "iteration 108300 / 120000: loss 0.000000\n",
      "iteration 108400 / 120000: loss 0.895827\n",
      "iteration 108500 / 120000: loss 0.000000\n",
      "iteration 108600 / 120000: loss 0.000000\n",
      "iteration 108700 / 120000: loss 0.000000\n",
      "iteration 108800 / 120000: loss 0.000000\n",
      "iteration 108900 / 120000: loss 1.758230\n",
      "iteration 109000 / 120000: loss 0.000000\n",
      "iteration 109100 / 120000: loss 2.680624\n",
      "iteration 109200 / 120000: loss 0.000000\n",
      "iteration 109300 / 120000: loss 0.000000\n",
      "iteration 109400 / 120000: loss 0.000000\n",
      "iteration 109500 / 120000: loss 0.000000\n",
      "iteration 109600 / 120000: loss 0.944519\n",
      "iteration 109700 / 120000: loss 0.000000\n",
      "iteration 109800 / 120000: loss 0.000000\n",
      "iteration 109900 / 120000: loss 0.000000\n",
      "iteration 110000 / 120000: loss 0.000000\n",
      "iteration 110100 / 120000: loss 0.000000\n",
      "iteration 110200 / 120000: loss 0.000000\n",
      "iteration 110300 / 120000: loss 0.000000\n",
      "iteration 110400 / 120000: loss 0.000000\n",
      "iteration 110500 / 120000: loss 0.000000\n",
      "iteration 110600 / 120000: loss 3.110300\n",
      "iteration 110700 / 120000: loss 0.003967\n",
      "iteration 110800 / 120000: loss 2.622530\n",
      "iteration 110900 / 120000: loss 0.000000\n",
      "iteration 111000 / 120000: loss 0.000000\n",
      "iteration 111100 / 120000: loss 7.804948\n",
      "iteration 111200 / 120000: loss 0.000000\n",
      "iteration 111300 / 120000: loss 0.000000\n",
      "iteration 111400 / 120000: loss 2.794107\n",
      "iteration 111500 / 120000: loss 0.000000\n",
      "iteration 111600 / 120000: loss 0.000000\n",
      "iteration 111700 / 120000: loss 0.000000\n",
      "iteration 111800 / 120000: loss 0.000000\n",
      "iteration 111900 / 120000: loss 0.000000\n",
      "iteration 112000 / 120000: loss 3.210990\n",
      "iteration 112100 / 120000: loss 5.479817\n",
      "iteration 112200 / 120000: loss 0.000000\n",
      "iteration 112300 / 120000: loss 0.000000\n",
      "iteration 112400 / 120000: loss 1.903139\n",
      "iteration 112500 / 120000: loss 1.838461\n",
      "iteration 112600 / 120000: loss 0.000000\n",
      "iteration 112700 / 120000: loss 0.000000\n",
      "iteration 112800 / 120000: loss 0.000000\n",
      "iteration 112900 / 120000: loss 0.000000\n",
      "iteration 113000 / 120000: loss 0.000000\n",
      "iteration 113100 / 120000: loss 0.000000\n",
      "iteration 113200 / 120000: loss 0.000000\n",
      "iteration 113300 / 120000: loss 0.000000\n",
      "iteration 113400 / 120000: loss 0.000000\n",
      "iteration 113500 / 120000: loss 0.000000\n",
      "iteration 113600 / 120000: loss 0.000000\n",
      "iteration 113700 / 120000: loss 0.000000\n",
      "iteration 113800 / 120000: loss 0.000000\n",
      "iteration 113900 / 120000: loss 0.000000\n",
      "iteration 114000 / 120000: loss 0.000000\n",
      "iteration 114100 / 120000: loss 2.217802\n",
      "iteration 114200 / 120000: loss 0.000000\n",
      "iteration 114300 / 120000: loss 0.000000\n",
      "iteration 114400 / 120000: loss 0.000000\n",
      "iteration 114500 / 120000: loss 0.000000\n",
      "iteration 114600 / 120000: loss 0.207012\n",
      "iteration 114700 / 120000: loss 3.018568\n",
      "iteration 114800 / 120000: loss 0.000000\n",
      "iteration 114900 / 120000: loss 0.000000\n",
      "iteration 115000 / 120000: loss 0.000000\n",
      "iteration 115100 / 120000: loss 0.000000\n",
      "iteration 115200 / 120000: loss 3.736473\n",
      "iteration 115300 / 120000: loss 0.000000\n",
      "iteration 115400 / 120000: loss 0.000000\n",
      "iteration 115500 / 120000: loss 0.000000\n",
      "iteration 115600 / 120000: loss 0.000000\n",
      "iteration 115700 / 120000: loss 1.375021\n",
      "iteration 115800 / 120000: loss 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 115900 / 120000: loss 0.000000\n",
      "iteration 116000 / 120000: loss 0.000000\n",
      "iteration 116100 / 120000: loss 0.000000\n",
      "iteration 116200 / 120000: loss 0.000000\n",
      "iteration 116300 / 120000: loss 0.000000\n",
      "iteration 116400 / 120000: loss 0.000000\n",
      "iteration 116500 / 120000: loss 0.000000\n",
      "iteration 116600 / 120000: loss 0.000000\n",
      "iteration 116700 / 120000: loss 0.000000\n",
      "iteration 116800 / 120000: loss 0.000000\n",
      "iteration 116900 / 120000: loss 0.000000\n",
      "iteration 117000 / 120000: loss 0.000000\n",
      "iteration 117100 / 120000: loss 0.000000\n",
      "iteration 117200 / 120000: loss 2.309192\n",
      "iteration 117300 / 120000: loss 0.000000\n",
      "iteration 117400 / 120000: loss 0.000000\n",
      "iteration 117500 / 120000: loss 0.000000\n",
      "iteration 117600 / 120000: loss 0.000000\n",
      "iteration 117700 / 120000: loss 0.000000\n",
      "iteration 117800 / 120000: loss 0.000000\n",
      "iteration 117900 / 120000: loss 0.000000\n",
      "iteration 118000 / 120000: loss 0.000000\n",
      "iteration 118100 / 120000: loss 0.000000\n",
      "iteration 118200 / 120000: loss 1.360488\n",
      "iteration 118300 / 120000: loss 0.000000\n",
      "iteration 118400 / 120000: loss 0.000000\n",
      "iteration 118500 / 120000: loss 0.000000\n",
      "iteration 118600 / 120000: loss 0.000000\n",
      "iteration 118700 / 120000: loss 0.000000\n",
      "iteration 118800 / 120000: loss 1.664583\n",
      "iteration 118900 / 120000: loss 0.000000\n",
      "iteration 119000 / 120000: loss 0.000000\n",
      "iteration 119100 / 120000: loss 1.914567\n",
      "iteration 119200 / 120000: loss 3.741018\n",
      "iteration 119300 / 120000: loss 0.000000\n",
      "iteration 119400 / 120000: loss 0.000000\n",
      "iteration 119500 / 120000: loss 0.000000\n",
      "iteration 119600 / 120000: loss 0.000000\n",
      "iteration 119700 / 120000: loss 0.000000\n",
      "iteration 119800 / 120000: loss 0.409573\n",
      "iteration 119900 / 120000: loss 0.312644\n",
      "lr=1e-07 bs=1 regularization_rate=0.0003\n",
      "iteration 0 / 120000: loss 0.960645\n",
      "iteration 100 / 120000: loss 1.508800\n",
      "iteration 200 / 120000: loss 0.000000\n",
      "iteration 300 / 120000: loss 0.000000\n",
      "iteration 400 / 120000: loss 0.000000\n",
      "iteration 500 / 120000: loss 2.254317\n",
      "iteration 600 / 120000: loss 0.000000\n",
      "iteration 700 / 120000: loss 0.090634\n",
      "iteration 800 / 120000: loss 0.615668\n",
      "iteration 900 / 120000: loss 2.090812\n",
      "iteration 1000 / 120000: loss 0.000000\n",
      "iteration 1100 / 120000: loss 7.710000\n",
      "iteration 1200 / 120000: loss 0.000000\n",
      "iteration 1300 / 120000: loss 0.000000\n",
      "iteration 1400 / 120000: loss 0.000000\n",
      "iteration 1500 / 120000: loss 0.000000\n",
      "iteration 1600 / 120000: loss 0.000000\n",
      "iteration 1700 / 120000: loss 2.064181\n",
      "iteration 1800 / 120000: loss 0.000000\n",
      "iteration 1900 / 120000: loss 0.000000\n",
      "iteration 2000 / 120000: loss 1.774025\n",
      "iteration 2100 / 120000: loss 0.000000\n",
      "iteration 2200 / 120000: loss 0.000000\n",
      "iteration 2300 / 120000: loss 0.000000\n",
      "iteration 2400 / 120000: loss 2.247478\n",
      "iteration 2500 / 120000: loss 0.377115\n",
      "iteration 2600 / 120000: loss 0.000000\n",
      "iteration 2700 / 120000: loss 0.000000\n",
      "iteration 2800 / 120000: loss 0.000000\n",
      "iteration 2900 / 120000: loss 5.033914\n",
      "iteration 3000 / 120000: loss 0.000000\n",
      "iteration 3100 / 120000: loss 0.000000\n",
      "iteration 3200 / 120000: loss 0.520087\n",
      "iteration 3300 / 120000: loss 0.000000\n",
      "iteration 3400 / 120000: loss 2.866193\n",
      "iteration 3500 / 120000: loss 0.000000\n",
      "iteration 3600 / 120000: loss 1.487831\n",
      "iteration 3700 / 120000: loss 0.000000\n",
      "iteration 3800 / 120000: loss 0.000000\n",
      "iteration 3900 / 120000: loss 0.052851\n",
      "iteration 4000 / 120000: loss 2.125298\n",
      "iteration 4100 / 120000: loss 0.000000\n",
      "iteration 4200 / 120000: loss 0.000000\n",
      "iteration 4300 / 120000: loss 0.000000\n",
      "iteration 4400 / 120000: loss 0.430007\n",
      "iteration 4500 / 120000: loss 0.000000\n",
      "iteration 4600 / 120000: loss 0.000000\n",
      "iteration 4700 / 120000: loss 0.000000\n",
      "iteration 4800 / 120000: loss 0.286508\n",
      "iteration 4900 / 120000: loss 0.000000\n",
      "iteration 5000 / 120000: loss 4.257719\n",
      "iteration 5100 / 120000: loss 0.000000\n",
      "iteration 5200 / 120000: loss 4.726711\n",
      "iteration 5300 / 120000: loss 0.000000\n",
      "iteration 5400 / 120000: loss 0.000000\n",
      "iteration 5500 / 120000: loss 2.613448\n",
      "iteration 5600 / 120000: loss 0.000000\n",
      "iteration 5700 / 120000: loss 0.918259\n",
      "iteration 5800 / 120000: loss 0.000000\n",
      "iteration 5900 / 120000: loss 2.155161\n",
      "iteration 6000 / 120000: loss 0.000000\n",
      "iteration 6100 / 120000: loss 2.991891\n",
      "iteration 6200 / 120000: loss 0.000000\n",
      "iteration 6300 / 120000: loss 0.000000\n",
      "iteration 6400 / 120000: loss 0.335332\n",
      "iteration 6500 / 120000: loss 0.000000\n",
      "iteration 6600 / 120000: loss 5.489212\n",
      "iteration 6700 / 120000: loss 0.000000\n",
      "iteration 6800 / 120000: loss 0.000000\n",
      "iteration 6900 / 120000: loss 0.562388\n",
      "iteration 7000 / 120000: loss 0.000000\n",
      "iteration 7100 / 120000: loss 3.041426\n",
      "iteration 7200 / 120000: loss 0.000000\n",
      "iteration 7300 / 120000: loss 1.757733\n",
      "iteration 7400 / 120000: loss 0.000000\n",
      "iteration 7500 / 120000: loss 0.377589\n",
      "iteration 7600 / 120000: loss 0.000000\n",
      "iteration 7700 / 120000: loss 0.000000\n",
      "iteration 7800 / 120000: loss 0.000000\n",
      "iteration 7900 / 120000: loss 0.000000\n",
      "iteration 8000 / 120000: loss 0.000000\n",
      "iteration 8100 / 120000: loss 1.598882\n",
      "iteration 8200 / 120000: loss 1.796324\n",
      "iteration 8300 / 120000: loss 0.544197\n",
      "iteration 8400 / 120000: loss 2.529622\n",
      "iteration 8500 / 120000: loss 1.460888\n",
      "iteration 8600 / 120000: loss 0.540265\n",
      "iteration 8700 / 120000: loss 1.959035\n",
      "iteration 8800 / 120000: loss 5.213997\n",
      "iteration 8900 / 120000: loss 0.000000\n",
      "iteration 9000 / 120000: loss 0.000000\n",
      "iteration 9100 / 120000: loss 0.000000\n",
      "iteration 9200 / 120000: loss 0.000000\n",
      "iteration 9300 / 120000: loss 0.000000\n",
      "iteration 9400 / 120000: loss 0.000000\n",
      "iteration 9500 / 120000: loss 0.061847\n",
      "iteration 9600 / 120000: loss 0.000000\n",
      "iteration 9700 / 120000: loss 0.000000\n",
      "iteration 9800 / 120000: loss 4.397742\n",
      "iteration 9900 / 120000: loss 2.968334\n",
      "iteration 10000 / 120000: loss 1.703327\n",
      "iteration 10100 / 120000: loss 2.187757\n",
      "iteration 10200 / 120000: loss 0.000000\n",
      "iteration 10300 / 120000: loss 3.034052\n",
      "iteration 10400 / 120000: loss 3.640436\n",
      "iteration 10500 / 120000: loss 1.899556\n",
      "iteration 10600 / 120000: loss 0.000000\n",
      "iteration 10700 / 120000: loss 0.000000\n",
      "iteration 10800 / 120000: loss 0.000000\n",
      "iteration 10900 / 120000: loss 0.000000\n",
      "iteration 11000 / 120000: loss 0.000000\n",
      "iteration 11100 / 120000: loss 0.000000\n",
      "iteration 11200 / 120000: loss 0.000000\n",
      "iteration 11300 / 120000: loss 1.110797\n",
      "iteration 11400 / 120000: loss 4.190751\n",
      "iteration 11500 / 120000: loss 1.900639\n",
      "iteration 11600 / 120000: loss 9.963873\n",
      "iteration 11700 / 120000: loss 0.000000\n",
      "iteration 11800 / 120000: loss 0.000000\n",
      "iteration 11900 / 120000: loss 0.000000\n",
      "iteration 12000 / 120000: loss 0.713099\n",
      "iteration 12100 / 120000: loss 0.000000\n",
      "iteration 12200 / 120000: loss 0.000000\n",
      "iteration 12300 / 120000: loss 0.838426\n",
      "iteration 12400 / 120000: loss 0.000000\n",
      "iteration 12500 / 120000: loss 0.244456\n",
      "iteration 12600 / 120000: loss 4.399911\n",
      "iteration 12700 / 120000: loss 0.000000\n",
      "iteration 12800 / 120000: loss 0.705036\n",
      "iteration 12900 / 120000: loss 0.000000\n",
      "iteration 13000 / 120000: loss 0.000000\n",
      "iteration 13100 / 120000: loss 0.000000\n",
      "iteration 13200 / 120000: loss 0.000000\n",
      "iteration 13300 / 120000: loss 0.000000\n",
      "iteration 13400 / 120000: loss 0.000000\n",
      "iteration 13500 / 120000: loss 0.000000\n",
      "iteration 13600 / 120000: loss 0.000000\n",
      "iteration 13700 / 120000: loss 0.956802\n",
      "iteration 13800 / 120000: loss 0.000000\n",
      "iteration 13900 / 120000: loss 0.000000\n",
      "iteration 14000 / 120000: loss 0.000000\n",
      "iteration 14100 / 120000: loss 7.859995\n",
      "iteration 14200 / 120000: loss 0.000000\n",
      "iteration 14300 / 120000: loss 0.000000\n",
      "iteration 14400 / 120000: loss 0.000000\n",
      "iteration 14500 / 120000: loss 0.000000\n",
      "iteration 14600 / 120000: loss 1.927223\n",
      "iteration 14700 / 120000: loss 0.000000\n",
      "iteration 14800 / 120000: loss 1.391105\n",
      "iteration 14900 / 120000: loss 0.000000\n",
      "iteration 15000 / 120000: loss 0.000000\n",
      "iteration 15100 / 120000: loss 2.262685\n",
      "iteration 15200 / 120000: loss 0.000000\n",
      "iteration 15300 / 120000: loss 0.000000\n",
      "iteration 15400 / 120000: loss 0.000000\n",
      "iteration 15500 / 120000: loss 0.000000\n",
      "iteration 15600 / 120000: loss 0.000000\n",
      "iteration 15700 / 120000: loss 0.000000\n",
      "iteration 15800 / 120000: loss 0.000000\n",
      "iteration 15900 / 120000: loss 1.630029\n",
      "iteration 16000 / 120000: loss 0.000000\n",
      "iteration 16100 / 120000: loss 0.000000\n",
      "iteration 16200 / 120000: loss 2.294486\n",
      "iteration 16300 / 120000: loss 2.641701\n",
      "iteration 16400 / 120000: loss 0.000000\n",
      "iteration 16500 / 120000: loss 0.000000\n",
      "iteration 16600 / 120000: loss 0.000000\n",
      "iteration 16700 / 120000: loss 0.000000\n",
      "iteration 16800 / 120000: loss 0.000000\n",
      "iteration 16900 / 120000: loss 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 17000 / 120000: loss 0.000000\n",
      "iteration 17100 / 120000: loss 0.000000\n",
      "iteration 17200 / 120000: loss 0.000000\n",
      "iteration 17300 / 120000: loss 0.000000\n",
      "iteration 17400 / 120000: loss 3.255352\n",
      "iteration 17500 / 120000: loss 0.000000\n",
      "iteration 17600 / 120000: loss 0.000000\n",
      "iteration 17700 / 120000: loss 6.744333\n",
      "iteration 17800 / 120000: loss 0.000000\n",
      "iteration 17900 / 120000: loss 0.000000\n",
      "iteration 18000 / 120000: loss 0.000000\n",
      "iteration 18100 / 120000: loss 1.442064\n",
      "iteration 18200 / 120000: loss 0.612676\n",
      "iteration 18300 / 120000: loss 0.000000\n",
      "iteration 18400 / 120000: loss 0.000000\n",
      "iteration 18500 / 120000: loss 0.000000\n",
      "iteration 18600 / 120000: loss 0.118020\n",
      "iteration 18700 / 120000: loss 0.000000\n",
      "iteration 18800 / 120000: loss 2.367678\n",
      "iteration 18900 / 120000: loss 0.000000\n",
      "iteration 19000 / 120000: loss 4.286814\n",
      "iteration 19100 / 120000: loss 1.525364\n",
      "iteration 19200 / 120000: loss 3.791379\n",
      "iteration 19300 / 120000: loss 0.000000\n",
      "iteration 19400 / 120000: loss 1.953530\n",
      "iteration 19500 / 120000: loss 0.000000\n",
      "iteration 19600 / 120000: loss 0.000000\n",
      "iteration 19700 / 120000: loss 0.000000\n",
      "iteration 19800 / 120000: loss 0.000000\n",
      "iteration 19900 / 120000: loss 8.337849\n",
      "iteration 20000 / 120000: loss 0.000000\n",
      "iteration 20100 / 120000: loss 0.000000\n",
      "iteration 20200 / 120000: loss 0.000000\n",
      "iteration 20300 / 120000: loss 0.844964\n",
      "iteration 20400 / 120000: loss 0.000000\n",
      "iteration 20500 / 120000: loss 0.000000\n",
      "iteration 20600 / 120000: loss 0.000000\n",
      "iteration 20700 / 120000: loss 0.000000\n",
      "iteration 20800 / 120000: loss 0.000000\n",
      "iteration 20900 / 120000: loss 0.000000\n",
      "iteration 21000 / 120000: loss 0.000000\n",
      "iteration 21100 / 120000: loss 1.439618\n",
      "iteration 21200 / 120000: loss 0.000000\n",
      "iteration 21300 / 120000: loss 0.000000\n",
      "iteration 21400 / 120000: loss 0.000000\n",
      "iteration 21500 / 120000: loss 0.000000\n",
      "iteration 21600 / 120000: loss 0.000000\n",
      "iteration 21700 / 120000: loss 0.000000\n",
      "iteration 21800 / 120000: loss 0.000000\n",
      "iteration 21900 / 120000: loss 4.912092\n",
      "iteration 22000 / 120000: loss 0.000000\n",
      "iteration 22100 / 120000: loss 0.199948\n",
      "iteration 22200 / 120000: loss 0.000000\n",
      "iteration 22300 / 120000: loss 0.000000\n",
      "iteration 22400 / 120000: loss 1.221447\n",
      "iteration 22500 / 120000: loss 0.000000\n",
      "iteration 22600 / 120000: loss 0.000000\n",
      "iteration 22700 / 120000: loss 0.000000\n",
      "iteration 22800 / 120000: loss 0.000000\n",
      "iteration 22900 / 120000: loss 0.000000\n",
      "iteration 23000 / 120000: loss 0.000000\n",
      "iteration 23100 / 120000: loss 0.000000\n",
      "iteration 23200 / 120000: loss 0.000000\n",
      "iteration 23300 / 120000: loss 1.005476\n",
      "iteration 23400 / 120000: loss 0.000000\n",
      "iteration 23500 / 120000: loss 6.799765\n",
      "iteration 23600 / 120000: loss 0.000000\n",
      "iteration 23700 / 120000: loss 0.000000\n",
      "iteration 23800 / 120000: loss 0.000000\n",
      "iteration 23900 / 120000: loss 0.000000\n",
      "iteration 24000 / 120000: loss 0.000000\n",
      "iteration 24100 / 120000: loss 0.000000\n",
      "iteration 24200 / 120000: loss 0.000000\n",
      "iteration 24300 / 120000: loss 1.035923\n",
      "iteration 24400 / 120000: loss 0.000000\n",
      "iteration 24500 / 120000: loss 5.203257\n",
      "iteration 24600 / 120000: loss 0.000000\n",
      "iteration 24700 / 120000: loss 0.000000\n",
      "iteration 24800 / 120000: loss 0.000000\n",
      "iteration 24900 / 120000: loss 0.000000\n",
      "iteration 25000 / 120000: loss 0.000000\n",
      "iteration 25100 / 120000: loss 0.000000\n",
      "iteration 25200 / 120000: loss 0.367192\n",
      "iteration 25300 / 120000: loss 2.073617\n",
      "iteration 25400 / 120000: loss 0.000000\n",
      "iteration 25500 / 120000: loss 0.000000\n",
      "iteration 25600 / 120000: loss 0.000000\n",
      "iteration 25700 / 120000: loss 0.000000\n",
      "iteration 25800 / 120000: loss 0.000000\n",
      "iteration 25900 / 120000: loss 0.000000\n",
      "iteration 26000 / 120000: loss 0.000000\n",
      "iteration 26100 / 120000: loss 0.000000\n",
      "iteration 26200 / 120000: loss 1.987434\n",
      "iteration 26300 / 120000: loss 0.890461\n",
      "iteration 26400 / 120000: loss 0.000000\n",
      "iteration 26500 / 120000: loss 0.000000\n",
      "iteration 26600 / 120000: loss 0.000000\n",
      "iteration 26700 / 120000: loss 1.512753\n",
      "iteration 26800 / 120000: loss 0.070883\n",
      "iteration 26900 / 120000: loss 0.000000\n",
      "iteration 27000 / 120000: loss 0.000000\n",
      "iteration 27100 / 120000: loss 0.000000\n",
      "iteration 27200 / 120000: loss 0.000000\n",
      "iteration 27300 / 120000: loss 0.000000\n",
      "iteration 27400 / 120000: loss 0.042008\n",
      "iteration 27500 / 120000: loss 0.000000\n",
      "iteration 27600 / 120000: loss 2.483440\n",
      "iteration 27700 / 120000: loss 0.000000\n",
      "iteration 27800 / 120000: loss 0.000000\n",
      "iteration 27900 / 120000: loss 0.000000\n",
      "iteration 28000 / 120000: loss 1.502766\n",
      "iteration 28100 / 120000: loss 0.000000\n",
      "iteration 28200 / 120000: loss 0.000000\n",
      "iteration 28300 / 120000: loss 0.000000\n",
      "iteration 28400 / 120000: loss 0.000000\n",
      "iteration 28500 / 120000: loss 0.000000\n",
      "iteration 28600 / 120000: loss 0.000000\n",
      "iteration 28700 / 120000: loss 3.412934\n",
      "iteration 28800 / 120000: loss 0.000000\n",
      "iteration 28900 / 120000: loss 0.000000\n",
      "iteration 29000 / 120000: loss 0.000000\n",
      "iteration 29100 / 120000: loss 0.000000\n",
      "iteration 29200 / 120000: loss 0.000000\n",
      "iteration 29300 / 120000: loss 7.293952\n",
      "iteration 29400 / 120000: loss 0.000000\n",
      "iteration 29500 / 120000: loss 0.667481\n",
      "iteration 29600 / 120000: loss 0.065322\n",
      "iteration 29700 / 120000: loss 0.000000\n",
      "iteration 29800 / 120000: loss 0.027536\n",
      "iteration 29900 / 120000: loss 0.000000\n",
      "iteration 30000 / 120000: loss 0.000000\n",
      "iteration 30100 / 120000: loss 1.179262\n",
      "iteration 30200 / 120000: loss 0.000000\n",
      "iteration 30300 / 120000: loss 0.000000\n",
      "iteration 30400 / 120000: loss 0.000000\n",
      "iteration 30500 / 120000: loss 1.994772\n",
      "iteration 30600 / 120000: loss 0.784810\n",
      "iteration 30700 / 120000: loss 1.378631\n",
      "iteration 30800 / 120000: loss 0.000000\n",
      "iteration 30900 / 120000: loss 0.000000\n",
      "iteration 31000 / 120000: loss 0.000000\n",
      "iteration 31100 / 120000: loss 0.000000\n",
      "iteration 31200 / 120000: loss 4.963378\n",
      "iteration 31300 / 120000: loss 1.315086\n",
      "iteration 31400 / 120000: loss 0.849432\n",
      "iteration 31500 / 120000: loss 0.000000\n",
      "iteration 31600 / 120000: loss 0.000000\n",
      "iteration 31700 / 120000: loss 0.000000\n",
      "iteration 31800 / 120000: loss 0.000000\n",
      "iteration 31900 / 120000: loss 3.992262\n",
      "iteration 32000 / 120000: loss 0.000000\n",
      "iteration 32100 / 120000: loss 1.997401\n",
      "iteration 32200 / 120000: loss 0.941910\n",
      "iteration 32300 / 120000: loss 0.000000\n",
      "iteration 32400 / 120000: loss 0.000000\n",
      "iteration 32500 / 120000: loss 0.191259\n",
      "iteration 32600 / 120000: loss 0.000000\n",
      "iteration 32700 / 120000: loss 2.791520\n",
      "iteration 32800 / 120000: loss 0.000000\n",
      "iteration 32900 / 120000: loss 0.000000\n",
      "iteration 33000 / 120000: loss 2.752584\n",
      "iteration 33100 / 120000: loss 0.000000\n",
      "iteration 33200 / 120000: loss 0.000000\n",
      "iteration 33300 / 120000: loss 3.302988\n",
      "iteration 33400 / 120000: loss 0.000000\n",
      "iteration 33500 / 120000: loss 0.000000\n",
      "iteration 33600 / 120000: loss 0.000000\n",
      "iteration 33700 / 120000: loss 12.074022\n",
      "iteration 33800 / 120000: loss 0.000000\n",
      "iteration 33900 / 120000: loss 0.000000\n",
      "iteration 34000 / 120000: loss 0.000000\n",
      "iteration 34100 / 120000: loss 4.338442\n",
      "iteration 34200 / 120000: loss 3.390689\n",
      "iteration 34300 / 120000: loss 0.000000\n",
      "iteration 34400 / 120000: loss 1.258289\n",
      "iteration 34500 / 120000: loss 0.000000\n",
      "iteration 34600 / 120000: loss 1.064248\n",
      "iteration 34700 / 120000: loss 0.000000\n",
      "iteration 34800 / 120000: loss 0.000000\n",
      "iteration 34900 / 120000: loss 0.000000\n",
      "iteration 35000 / 120000: loss 0.000000\n",
      "iteration 35100 / 120000: loss 0.000000\n",
      "iteration 35200 / 120000: loss 0.000000\n",
      "iteration 35300 / 120000: loss 0.000000\n",
      "iteration 35400 / 120000: loss 4.921039\n",
      "iteration 35500 / 120000: loss 1.266220\n",
      "iteration 35600 / 120000: loss 0.000000\n",
      "iteration 35700 / 120000: loss 0.000000\n",
      "iteration 35800 / 120000: loss 2.177458\n",
      "iteration 35900 / 120000: loss 0.036061\n",
      "iteration 36000 / 120000: loss 0.000000\n",
      "iteration 36100 / 120000: loss 0.000000\n",
      "iteration 36200 / 120000: loss 3.224251\n",
      "iteration 36300 / 120000: loss 1.467373\n",
      "iteration 36400 / 120000: loss 1.316251\n",
      "iteration 36500 / 120000: loss 0.000000\n",
      "iteration 36600 / 120000: loss 0.879100\n",
      "iteration 36700 / 120000: loss 0.000000\n",
      "iteration 36800 / 120000: loss 1.118089\n",
      "iteration 36900 / 120000: loss 0.000000\n",
      "iteration 37000 / 120000: loss 0.000000\n",
      "iteration 37100 / 120000: loss 1.198801\n",
      "iteration 37200 / 120000: loss 0.000000\n",
      "iteration 37300 / 120000: loss 0.000000\n",
      "iteration 37400 / 120000: loss 0.000000\n",
      "iteration 37500 / 120000: loss 1.899546\n",
      "iteration 37600 / 120000: loss 0.000000\n",
      "iteration 37700 / 120000: loss 0.000000\n",
      "iteration 37800 / 120000: loss 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 37900 / 120000: loss 0.000000\n",
      "iteration 38000 / 120000: loss 0.000000\n",
      "iteration 38100 / 120000: loss 0.203683\n",
      "iteration 38200 / 120000: loss 0.971044\n",
      "iteration 38300 / 120000: loss 3.789872\n",
      "iteration 38400 / 120000: loss 0.000000\n",
      "iteration 38500 / 120000: loss 2.494709\n",
      "iteration 38600 / 120000: loss 4.685088\n",
      "iteration 38700 / 120000: loss 0.000000\n",
      "iteration 38800 / 120000: loss 0.000000\n",
      "iteration 38900 / 120000: loss 0.000000\n",
      "iteration 39000 / 120000: loss 0.000000\n",
      "iteration 39100 / 120000: loss 0.000000\n",
      "iteration 39200 / 120000: loss 0.000000\n",
      "iteration 39300 / 120000: loss 1.202790\n",
      "iteration 39400 / 120000: loss 0.000000\n",
      "iteration 39500 / 120000: loss 0.000000\n",
      "iteration 39600 / 120000: loss 0.000000\n",
      "iteration 39700 / 120000: loss 0.000000\n",
      "iteration 39800 / 120000: loss 0.000000\n",
      "iteration 39900 / 120000: loss 0.000000\n",
      "iteration 40000 / 120000: loss 0.235911\n",
      "iteration 40100 / 120000: loss 0.000000\n",
      "iteration 40200 / 120000: loss 0.000000\n",
      "iteration 40300 / 120000: loss 0.000000\n",
      "iteration 40400 / 120000: loss 0.432896\n",
      "iteration 40500 / 120000: loss 0.000000\n",
      "iteration 40600 / 120000: loss 0.000000\n",
      "iteration 40700 / 120000: loss 1.812741\n",
      "iteration 40800 / 120000: loss 0.000000\n",
      "iteration 40900 / 120000: loss 0.000000\n",
      "iteration 41000 / 120000: loss 4.364949\n",
      "iteration 41100 / 120000: loss 0.000000\n",
      "iteration 41200 / 120000: loss 0.000000\n",
      "iteration 41300 / 120000: loss 0.000000\n",
      "iteration 41400 / 120000: loss 0.000000\n",
      "iteration 41500 / 120000: loss 0.000000\n",
      "iteration 41600 / 120000: loss 2.056283\n",
      "iteration 41700 / 120000: loss 0.000000\n",
      "iteration 41800 / 120000: loss 0.000000\n",
      "iteration 41900 / 120000: loss 0.000000\n",
      "iteration 42000 / 120000: loss 0.000000\n",
      "iteration 42100 / 120000: loss 0.000000\n",
      "iteration 42200 / 120000: loss 0.000000\n",
      "iteration 42300 / 120000: loss 0.000000\n",
      "iteration 42400 / 120000: loss 0.000000\n",
      "iteration 42500 / 120000: loss 0.000000\n",
      "iteration 42600 / 120000: loss 2.125382\n",
      "iteration 42700 / 120000: loss 0.000000\n",
      "iteration 42800 / 120000: loss 0.392969\n",
      "iteration 42900 / 120000: loss 0.000000\n",
      "iteration 43000 / 120000: loss 7.497815\n",
      "iteration 43100 / 120000: loss 0.000000\n",
      "iteration 43200 / 120000: loss 0.000000\n",
      "iteration 43300 / 120000: loss 0.000000\n",
      "iteration 43400 / 120000: loss 0.000000\n",
      "iteration 43500 / 120000: loss 0.000000\n",
      "iteration 43600 / 120000: loss 1.781125\n",
      "iteration 43700 / 120000: loss 0.047323\n",
      "iteration 43800 / 120000: loss 0.000000\n",
      "iteration 43900 / 120000: loss 2.268426\n",
      "iteration 44000 / 120000: loss 0.000000\n",
      "iteration 44100 / 120000: loss 1.158885\n",
      "iteration 44200 / 120000: loss 0.000000\n",
      "iteration 44300 / 120000: loss 0.000000\n",
      "iteration 44400 / 120000: loss 0.937465\n",
      "iteration 44500 / 120000: loss 0.528896\n",
      "iteration 44600 / 120000: loss 0.000000\n",
      "iteration 44700 / 120000: loss 0.000000\n",
      "iteration 44800 / 120000: loss 0.000000\n",
      "iteration 44900 / 120000: loss 0.000000\n",
      "iteration 45000 / 120000: loss 0.000000\n",
      "iteration 45100 / 120000: loss 0.000000\n",
      "iteration 45200 / 120000: loss 0.091736\n",
      "iteration 45300 / 120000: loss 2.688287\n",
      "iteration 45400 / 120000: loss 8.660625\n",
      "iteration 45500 / 120000: loss 0.000000\n",
      "iteration 45600 / 120000: loss 0.000000\n",
      "iteration 45700 / 120000: loss 4.914876\n",
      "iteration 45800 / 120000: loss 0.000000\n",
      "iteration 45900 / 120000: loss 0.000000\n",
      "iteration 46000 / 120000: loss 0.000000\n",
      "iteration 46100 / 120000: loss 0.000000\n",
      "iteration 46200 / 120000: loss 3.128227\n",
      "iteration 46300 / 120000: loss 0.000000\n",
      "iteration 46400 / 120000: loss 1.147160\n",
      "iteration 46500 / 120000: loss 0.000000\n",
      "iteration 46600 / 120000: loss 0.000000\n",
      "iteration 46700 / 120000: loss 0.474138\n",
      "iteration 46800 / 120000: loss 0.000000\n",
      "iteration 46900 / 120000: loss 0.000000\n",
      "iteration 47000 / 120000: loss 0.000000\n",
      "iteration 47100 / 120000: loss 0.000000\n",
      "iteration 47200 / 120000: loss 0.000000\n",
      "iteration 47300 / 120000: loss 2.359078\n",
      "iteration 47400 / 120000: loss 0.000000\n",
      "iteration 47500 / 120000: loss 0.000000\n",
      "iteration 47600 / 120000: loss 0.000000\n",
      "iteration 47700 / 120000: loss 0.000000\n",
      "iteration 47800 / 120000: loss 0.000000\n",
      "iteration 47900 / 120000: loss 0.000000\n",
      "iteration 48000 / 120000: loss 0.000000\n",
      "iteration 48100 / 120000: loss 0.000000\n",
      "iteration 48200 / 120000: loss 2.933460\n",
      "iteration 48300 / 120000: loss 0.000000\n",
      "iteration 48400 / 120000: loss 0.000000\n",
      "iteration 48500 / 120000: loss 0.180988\n",
      "iteration 48600 / 120000: loss 0.000000\n",
      "iteration 48700 / 120000: loss 0.247259\n",
      "iteration 48800 / 120000: loss 0.848296\n",
      "iteration 48900 / 120000: loss 2.100032\n",
      "iteration 49000 / 120000: loss 4.140586\n",
      "iteration 49100 / 120000: loss 0.000000\n",
      "iteration 49200 / 120000: loss 3.628995\n",
      "iteration 49300 / 120000: loss 0.000000\n",
      "iteration 49400 / 120000: loss 0.000000\n",
      "iteration 49500 / 120000: loss 1.935554\n",
      "iteration 49600 / 120000: loss 3.443513\n",
      "iteration 49700 / 120000: loss 1.289083\n",
      "iteration 49800 / 120000: loss 0.000000\n",
      "iteration 49900 / 120000: loss 0.000000\n",
      "iteration 50000 / 120000: loss 2.888412\n",
      "iteration 50100 / 120000: loss 0.000000\n",
      "iteration 50200 / 120000: loss 0.000000\n",
      "iteration 50300 / 120000: loss 0.000000\n",
      "iteration 50400 / 120000: loss 0.000000\n",
      "iteration 50500 / 120000: loss 0.419226\n",
      "iteration 50600 / 120000: loss 0.000000\n",
      "iteration 50700 / 120000: loss 0.000000\n",
      "iteration 50800 / 120000: loss 0.000000\n",
      "iteration 50900 / 120000: loss 0.000000\n",
      "iteration 51000 / 120000: loss 0.000000\n",
      "iteration 51100 / 120000: loss 0.000000\n",
      "iteration 51200 / 120000: loss 0.000000\n",
      "iteration 51300 / 120000: loss 0.572068\n",
      "iteration 51400 / 120000: loss 0.000000\n",
      "iteration 51500 / 120000: loss 2.302530\n",
      "iteration 51600 / 120000: loss 0.826819\n",
      "iteration 51700 / 120000: loss 0.000000\n",
      "iteration 51800 / 120000: loss 0.000000\n",
      "iteration 51900 / 120000: loss 1.284355\n",
      "iteration 52000 / 120000: loss 0.000000\n",
      "iteration 52100 / 120000: loss 0.000000\n",
      "iteration 52200 / 120000: loss 0.000000\n",
      "iteration 52300 / 120000: loss 0.000000\n",
      "iteration 52400 / 120000: loss 2.416842\n",
      "iteration 52500 / 120000: loss 0.000000\n",
      "iteration 52600 / 120000: loss 0.000000\n",
      "iteration 52700 / 120000: loss 0.000000\n",
      "iteration 52800 / 120000: loss 0.000000\n",
      "iteration 52900 / 120000: loss 0.000000\n",
      "iteration 53000 / 120000: loss 0.000000\n",
      "iteration 53100 / 120000: loss 0.000000\n",
      "iteration 53200 / 120000: loss 0.000000\n",
      "iteration 53300 / 120000: loss 0.000000\n",
      "iteration 53400 / 120000: loss 0.000000\n",
      "iteration 53500 / 120000: loss 1.932153\n",
      "iteration 53600 / 120000: loss 0.000000\n",
      "iteration 53700 / 120000: loss 0.294620\n",
      "iteration 53800 / 120000: loss 0.000000\n",
      "iteration 53900 / 120000: loss 0.000000\n",
      "iteration 54000 / 120000: loss 2.117818\n",
      "iteration 54100 / 120000: loss 0.000000\n",
      "iteration 54200 / 120000: loss 0.000000\n",
      "iteration 54300 / 120000: loss 0.000000\n",
      "iteration 54400 / 120000: loss 0.000000\n",
      "iteration 54500 / 120000: loss 0.000000\n",
      "iteration 54600 / 120000: loss 0.000000\n",
      "iteration 54700 / 120000: loss 0.000000\n",
      "iteration 54800 / 120000: loss 0.000000\n",
      "iteration 54900 / 120000: loss 0.000000\n",
      "iteration 55000 / 120000: loss 0.000000\n",
      "iteration 55100 / 120000: loss 0.000000\n",
      "iteration 55200 / 120000: loss 0.000000\n",
      "iteration 55300 / 120000: loss 0.000000\n",
      "iteration 55400 / 120000: loss 5.532734\n",
      "iteration 55500 / 120000: loss 0.000000\n",
      "iteration 55600 / 120000: loss 0.000000\n",
      "iteration 55700 / 120000: loss 0.000000\n",
      "iteration 55800 / 120000: loss 0.000000\n",
      "iteration 55900 / 120000: loss 2.636090\n",
      "iteration 56000 / 120000: loss 0.000000\n",
      "iteration 56100 / 120000: loss 2.478093\n",
      "iteration 56200 / 120000: loss 1.595410\n",
      "iteration 56300 / 120000: loss 0.000000\n",
      "iteration 56400 / 120000: loss 0.000000\n",
      "iteration 56500 / 120000: loss 0.000000\n",
      "iteration 56600 / 120000: loss 0.000000\n",
      "iteration 56700 / 120000: loss 0.000000\n",
      "iteration 56800 / 120000: loss 0.000000\n",
      "iteration 56900 / 120000: loss 0.000000\n",
      "iteration 57000 / 120000: loss 0.000000\n",
      "iteration 57100 / 120000: loss 0.624585\n",
      "iteration 57200 / 120000: loss 7.632038\n",
      "iteration 57300 / 120000: loss 1.041462\n",
      "iteration 57400 / 120000: loss 0.000000\n",
      "iteration 57500 / 120000: loss 0.000000\n",
      "iteration 57600 / 120000: loss 1.513912\n",
      "iteration 57700 / 120000: loss 0.000000\n",
      "iteration 57800 / 120000: loss 0.000000\n",
      "iteration 57900 / 120000: loss 0.000000\n",
      "iteration 58000 / 120000: loss 1.623740\n",
      "iteration 58100 / 120000: loss 0.282985\n",
      "iteration 58200 / 120000: loss 3.154087\n",
      "iteration 58300 / 120000: loss 0.000000\n",
      "iteration 58400 / 120000: loss 0.000000\n",
      "iteration 58500 / 120000: loss 0.000000\n",
      "iteration 58600 / 120000: loss 0.000000\n",
      "iteration 58700 / 120000: loss 0.000000\n",
      "iteration 58800 / 120000: loss 0.000000\n",
      "iteration 58900 / 120000: loss 3.829469\n",
      "iteration 59000 / 120000: loss 1.945340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 59100 / 120000: loss 3.210966\n",
      "iteration 59200 / 120000: loss 0.000000\n",
      "iteration 59300 / 120000: loss 1.429116\n",
      "iteration 59400 / 120000: loss 0.000000\n",
      "iteration 59500 / 120000: loss 0.000000\n",
      "iteration 59600 / 120000: loss 0.000000\n",
      "iteration 59700 / 120000: loss 0.000000\n",
      "iteration 59800 / 120000: loss 0.000000\n",
      "iteration 59900 / 120000: loss 0.000000\n",
      "iteration 60000 / 120000: loss 0.188705\n",
      "iteration 60100 / 120000: loss 0.000000\n",
      "iteration 60200 / 120000: loss 0.267441\n",
      "iteration 60300 / 120000: loss 0.000000\n",
      "iteration 60400 / 120000: loss 0.000000\n",
      "iteration 60500 / 120000: loss 2.964751\n",
      "iteration 60600 / 120000: loss 0.000000\n",
      "iteration 60700 / 120000: loss 0.000000\n",
      "iteration 60800 / 120000: loss 0.000000\n",
      "iteration 60900 / 120000: loss 0.000000\n",
      "iteration 61000 / 120000: loss 0.000000\n",
      "iteration 61100 / 120000: loss 0.000000\n",
      "iteration 61200 / 120000: loss 10.992185\n",
      "iteration 61300 / 120000: loss 0.000000\n",
      "iteration 61400 / 120000: loss 0.000000\n",
      "iteration 61500 / 120000: loss 0.000000\n",
      "iteration 61600 / 120000: loss 0.710954\n",
      "iteration 61700 / 120000: loss 0.000000\n",
      "iteration 61800 / 120000: loss 0.000000\n",
      "iteration 61900 / 120000: loss 0.000000\n",
      "iteration 62000 / 120000: loss 0.457795\n",
      "iteration 62100 / 120000: loss 0.000000\n",
      "iteration 62200 / 120000: loss 1.040046\n",
      "iteration 62300 / 120000: loss 0.000000\n",
      "iteration 62400 / 120000: loss 0.000000\n",
      "iteration 62500 / 120000: loss 0.000000\n",
      "iteration 62600 / 120000: loss 0.000000\n",
      "iteration 62700 / 120000: loss 1.761861\n",
      "iteration 62800 / 120000: loss 5.496514\n",
      "iteration 62900 / 120000: loss 1.820831\n",
      "iteration 63000 / 120000: loss 0.000000\n",
      "iteration 63100 / 120000: loss 0.000000\n",
      "iteration 63200 / 120000: loss 0.000000\n",
      "iteration 63300 / 120000: loss 0.000000\n",
      "iteration 63400 / 120000: loss 1.635564\n",
      "iteration 63500 / 120000: loss 0.000000\n",
      "iteration 63600 / 120000: loss 0.000000\n",
      "iteration 63700 / 120000: loss 0.000000\n",
      "iteration 63800 / 120000: loss 0.000000\n",
      "iteration 63900 / 120000: loss 0.000000\n",
      "iteration 64000 / 120000: loss 0.000000\n",
      "iteration 64100 / 120000: loss 0.000000\n",
      "iteration 64200 / 120000: loss 1.822488\n",
      "iteration 64300 / 120000: loss 0.000000\n",
      "iteration 64400 / 120000: loss 0.000000\n",
      "iteration 64500 / 120000: loss 0.000000\n",
      "iteration 64600 / 120000: loss 4.362586\n",
      "iteration 64700 / 120000: loss 0.000000\n",
      "iteration 64800 / 120000: loss 0.000000\n",
      "iteration 64900 / 120000: loss 0.019339\n",
      "iteration 65000 / 120000: loss 0.000000\n",
      "iteration 65100 / 120000: loss 0.000000\n",
      "iteration 65200 / 120000: loss 0.000000\n",
      "iteration 65300 / 120000: loss 0.000000\n",
      "iteration 65400 / 120000: loss 0.000000\n",
      "iteration 65500 / 120000: loss 0.000000\n",
      "iteration 65600 / 120000: loss 0.000000\n",
      "iteration 65700 / 120000: loss 0.000000\n",
      "iteration 65800 / 120000: loss 0.000000\n",
      "iteration 65900 / 120000: loss 0.710328\n",
      "iteration 66000 / 120000: loss 0.354986\n",
      "iteration 66100 / 120000: loss 0.000000\n",
      "iteration 66200 / 120000: loss 0.000000\n",
      "iteration 66300 / 120000: loss 0.000000\n",
      "iteration 66400 / 120000: loss 0.000000\n",
      "iteration 66500 / 120000: loss 0.000000\n",
      "iteration 66600 / 120000: loss 0.000000\n",
      "iteration 66700 / 120000: loss 0.000000\n",
      "iteration 66800 / 120000: loss 0.694079\n",
      "iteration 66900 / 120000: loss 0.000000\n",
      "iteration 67000 / 120000: loss 1.241080\n",
      "iteration 67100 / 120000: loss 0.000000\n",
      "iteration 67200 / 120000: loss 0.000000\n",
      "iteration 67300 / 120000: loss 0.000000\n",
      "iteration 67400 / 120000: loss 0.000000\n",
      "iteration 67500 / 120000: loss 0.000000\n",
      "iteration 67600 / 120000: loss 0.000000\n",
      "iteration 67700 / 120000: loss 0.000000\n",
      "iteration 67800 / 120000: loss 2.360694\n",
      "iteration 67900 / 120000: loss 0.000000\n",
      "iteration 68000 / 120000: loss 1.493474\n",
      "iteration 68100 / 120000: loss 0.000000\n",
      "iteration 68200 / 120000: loss 0.000000\n",
      "iteration 68300 / 120000: loss 4.189224\n",
      "iteration 68400 / 120000: loss 0.000000\n",
      "iteration 68500 / 120000: loss 2.203519\n",
      "iteration 68600 / 120000: loss 0.000000\n",
      "iteration 68700 / 120000: loss 0.000000\n",
      "iteration 68800 / 120000: loss 0.000000\n",
      "iteration 68900 / 120000: loss 0.000000\n",
      "iteration 69000 / 120000: loss 0.000000\n",
      "iteration 69100 / 120000: loss 0.000000\n",
      "iteration 69200 / 120000: loss 0.696372\n",
      "iteration 69300 / 120000: loss 0.000000\n",
      "iteration 69400 / 120000: loss 4.109806\n",
      "iteration 69500 / 120000: loss 0.000000\n",
      "iteration 69600 / 120000: loss 0.000000\n",
      "iteration 69700 / 120000: loss 0.000000\n",
      "iteration 69800 / 120000: loss 0.000000\n",
      "iteration 69900 / 120000: loss 0.000000\n",
      "iteration 70000 / 120000: loss 0.000000\n",
      "iteration 70100 / 120000: loss 5.467070\n",
      "iteration 70200 / 120000: loss 0.342421\n",
      "iteration 70300 / 120000: loss 0.000000\n",
      "iteration 70400 / 120000: loss 0.000000\n",
      "iteration 70500 / 120000: loss 0.000000\n",
      "iteration 70600 / 120000: loss 0.204064\n",
      "iteration 70700 / 120000: loss 0.000000\n",
      "iteration 70800 / 120000: loss 0.019941\n",
      "iteration 70900 / 120000: loss 0.000000\n",
      "iteration 71000 / 120000: loss 0.000000\n",
      "iteration 71100 / 120000: loss 0.000000\n",
      "iteration 71200 / 120000: loss 0.000000\n",
      "iteration 71300 / 120000: loss 0.000000\n",
      "iteration 71400 / 120000: loss 0.346382\n",
      "iteration 71500 / 120000: loss 0.000000\n",
      "iteration 71600 / 120000: loss 0.000000\n",
      "iteration 71700 / 120000: loss 0.000000\n",
      "iteration 71800 / 120000: loss 0.000000\n",
      "iteration 71900 / 120000: loss 1.124372\n",
      "iteration 72000 / 120000: loss 0.000000\n",
      "iteration 72100 / 120000: loss 0.000000\n",
      "iteration 72200 / 120000: loss 0.000000\n",
      "iteration 72300 / 120000: loss 0.000000\n",
      "iteration 72400 / 120000: loss 0.000000\n",
      "iteration 72500 / 120000: loss 0.000000\n",
      "iteration 72600 / 120000: loss 0.090328\n",
      "iteration 72700 / 120000: loss 0.840705\n",
      "iteration 72800 / 120000: loss 0.000000\n",
      "iteration 72900 / 120000: loss 0.000000\n",
      "iteration 73000 / 120000: loss 0.000000\n",
      "iteration 73100 / 120000: loss 1.704557\n",
      "iteration 73200 / 120000: loss 1.646118\n",
      "iteration 73300 / 120000: loss 0.000000\n",
      "iteration 73400 / 120000: loss 0.000000\n",
      "iteration 73500 / 120000: loss 0.000000\n",
      "iteration 73600 / 120000: loss 2.126465\n",
      "iteration 73700 / 120000: loss 0.119180\n",
      "iteration 73800 / 120000: loss 4.189714\n",
      "iteration 73900 / 120000: loss 0.000000\n",
      "iteration 74000 / 120000: loss 0.000000\n",
      "iteration 74100 / 120000: loss 0.348385\n",
      "iteration 74200 / 120000: loss 0.000000\n",
      "iteration 74300 / 120000: loss 0.000000\n",
      "iteration 74400 / 120000: loss 1.954706\n",
      "iteration 74500 / 120000: loss 0.000000\n",
      "iteration 74600 / 120000: loss 0.000000\n",
      "iteration 74700 / 120000: loss 0.000000\n",
      "iteration 74800 / 120000: loss 0.000000\n",
      "iteration 74900 / 120000: loss 0.000000\n",
      "iteration 75000 / 120000: loss 0.000000\n",
      "iteration 75100 / 120000: loss 0.000000\n",
      "iteration 75200 / 120000: loss 0.000000\n",
      "iteration 75300 / 120000: loss 0.000000\n",
      "iteration 75400 / 120000: loss 5.611052\n",
      "iteration 75500 / 120000: loss 0.000000\n",
      "iteration 75600 / 120000: loss 3.270867\n",
      "iteration 75700 / 120000: loss 3.142379\n",
      "iteration 75800 / 120000: loss 0.000000\n",
      "iteration 75900 / 120000: loss 0.000000\n",
      "iteration 76000 / 120000: loss 0.000000\n",
      "iteration 76100 / 120000: loss 0.000000\n",
      "iteration 76200 / 120000: loss 0.000000\n",
      "iteration 76300 / 120000: loss 0.000000\n",
      "iteration 76400 / 120000: loss 2.851347\n",
      "iteration 76500 / 120000: loss 0.654514\n",
      "iteration 76600 / 120000: loss 0.368055\n",
      "iteration 76700 / 120000: loss 4.582353\n",
      "iteration 76800 / 120000: loss 2.584693\n",
      "iteration 76900 / 120000: loss 0.000000\n",
      "iteration 77000 / 120000: loss 2.630142\n",
      "iteration 77100 / 120000: loss 0.000000\n",
      "iteration 77200 / 120000: loss 0.000000\n",
      "iteration 77300 / 120000: loss 0.000000\n",
      "iteration 77400 / 120000: loss 0.676998\n",
      "iteration 77500 / 120000: loss 0.000000\n",
      "iteration 77600 / 120000: loss 0.000000\n",
      "iteration 77700 / 120000: loss 0.000000\n",
      "iteration 77800 / 120000: loss 0.000000\n",
      "iteration 77900 / 120000: loss 0.000000\n",
      "iteration 78000 / 120000: loss 0.000000\n",
      "iteration 78100 / 120000: loss 0.000000\n",
      "iteration 78200 / 120000: loss 0.375825\n",
      "iteration 78300 / 120000: loss 0.000000\n",
      "iteration 78400 / 120000: loss 0.165484\n",
      "iteration 78500 / 120000: loss 0.000000\n",
      "iteration 78600 / 120000: loss 0.000000\n",
      "iteration 78700 / 120000: loss 3.840806\n",
      "iteration 78800 / 120000: loss 0.000000\n",
      "iteration 78900 / 120000: loss 0.000000\n",
      "iteration 79000 / 120000: loss 0.000000\n",
      "iteration 79100 / 120000: loss 0.000000\n",
      "iteration 79200 / 120000: loss 1.808285\n",
      "iteration 79300 / 120000: loss 2.030525\n",
      "iteration 79400 / 120000: loss 0.000000\n",
      "iteration 79500 / 120000: loss 0.000000\n",
      "iteration 79600 / 120000: loss 0.000000\n",
      "iteration 79700 / 120000: loss 0.315578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 79800 / 120000: loss 0.000000\n",
      "iteration 79900 / 120000: loss 0.000000\n",
      "iteration 80000 / 120000: loss 0.746695\n",
      "iteration 80100 / 120000: loss 0.000232\n",
      "iteration 80200 / 120000: loss 0.000000\n",
      "iteration 80300 / 120000: loss 1.417472\n",
      "iteration 80400 / 120000: loss 0.942847\n",
      "iteration 80500 / 120000: loss 4.795329\n",
      "iteration 80600 / 120000: loss 0.000000\n",
      "iteration 80700 / 120000: loss 0.593705\n",
      "iteration 80800 / 120000: loss 1.071906\n",
      "iteration 80900 / 120000: loss 7.250241\n",
      "iteration 81000 / 120000: loss 0.000000\n",
      "iteration 81100 / 120000: loss 0.000000\n",
      "iteration 81200 / 120000: loss 0.000000\n",
      "iteration 81300 / 120000: loss 0.000000\n",
      "iteration 81400 / 120000: loss 0.000000\n",
      "iteration 81500 / 120000: loss 0.000000\n",
      "iteration 81600 / 120000: loss 0.000000\n",
      "iteration 81700 / 120000: loss 0.000000\n",
      "iteration 81800 / 120000: loss 2.380876\n",
      "iteration 81900 / 120000: loss 0.000000\n",
      "iteration 82000 / 120000: loss 0.000000\n",
      "iteration 82100 / 120000: loss 0.000000\n",
      "iteration 82200 / 120000: loss 0.262566\n",
      "iteration 82300 / 120000: loss 0.000000\n",
      "iteration 82400 / 120000: loss 0.000000\n",
      "iteration 82500 / 120000: loss 0.000000\n",
      "iteration 82600 / 120000: loss 0.000000\n",
      "iteration 82700 / 120000: loss 0.000000\n",
      "iteration 82800 / 120000: loss 2.142649\n",
      "iteration 82900 / 120000: loss 1.954451\n",
      "iteration 83000 / 120000: loss 0.000000\n",
      "iteration 83100 / 120000: loss 0.000000\n",
      "iteration 83200 / 120000: loss 0.000000\n",
      "iteration 83300 / 120000: loss 0.000000\n",
      "iteration 83400 / 120000: loss 2.612122\n",
      "iteration 83500 / 120000: loss 0.000000\n",
      "iteration 83600 / 120000: loss 0.000000\n",
      "iteration 83700 / 120000: loss 4.319940\n",
      "iteration 83800 / 120000: loss 0.000000\n",
      "iteration 83900 / 120000: loss 0.000000\n",
      "iteration 84000 / 120000: loss 0.000000\n",
      "iteration 84100 / 120000: loss 0.000000\n",
      "iteration 84200 / 120000: loss 0.000000\n",
      "iteration 84300 / 120000: loss 0.000000\n",
      "iteration 84400 / 120000: loss 0.000000\n",
      "iteration 84500 / 120000: loss 0.299500\n",
      "iteration 84600 / 120000: loss 0.000000\n",
      "iteration 84700 / 120000: loss 3.395800\n",
      "iteration 84800 / 120000: loss 1.409347\n",
      "iteration 84900 / 120000: loss 0.000000\n",
      "iteration 85000 / 120000: loss 0.000000\n",
      "iteration 85100 / 120000: loss 0.000000\n",
      "iteration 85200 / 120000: loss 0.000000\n",
      "iteration 85300 / 120000: loss 0.000000\n",
      "iteration 85400 / 120000: loss 0.000000\n",
      "iteration 85500 / 120000: loss 0.000000\n",
      "iteration 85600 / 120000: loss 0.000000\n",
      "iteration 85700 / 120000: loss 0.000000\n",
      "iteration 85800 / 120000: loss 0.000000\n",
      "iteration 85900 / 120000: loss 0.000000\n",
      "iteration 86000 / 120000: loss 1.034152\n",
      "iteration 86100 / 120000: loss 0.000000\n",
      "iteration 86200 / 120000: loss 0.000000\n",
      "iteration 86300 / 120000: loss 0.314895\n",
      "iteration 86400 / 120000: loss 0.000000\n",
      "iteration 86500 / 120000: loss 0.000000\n",
      "iteration 86600 / 120000: loss 0.000000\n",
      "iteration 86700 / 120000: loss 0.000000\n",
      "iteration 86800 / 120000: loss 4.709483\n",
      "iteration 86900 / 120000: loss 0.471863\n",
      "iteration 87000 / 120000: loss 0.000000\n",
      "iteration 87100 / 120000: loss 0.000000\n",
      "iteration 87200 / 120000: loss 0.000000\n",
      "iteration 87300 / 120000: loss 0.000000\n",
      "iteration 87400 / 120000: loss 0.011399\n",
      "iteration 87500 / 120000: loss 2.111612\n",
      "iteration 87600 / 120000: loss 0.000000\n",
      "iteration 87700 / 120000: loss 0.000000\n",
      "iteration 87800 / 120000: loss 0.000000\n",
      "iteration 87900 / 120000: loss 0.000000\n",
      "iteration 88000 / 120000: loss 0.000000\n",
      "iteration 88100 / 120000: loss 0.000000\n",
      "iteration 88200 / 120000: loss 0.000000\n",
      "iteration 88300 / 120000: loss 0.000000\n",
      "iteration 88400 / 120000: loss 0.000000\n",
      "iteration 88500 / 120000: loss 0.000000\n",
      "iteration 88600 / 120000: loss 1.355100\n",
      "iteration 88700 / 120000: loss 0.000000\n",
      "iteration 88800 / 120000: loss 0.000000\n",
      "iteration 88900 / 120000: loss 0.000000\n",
      "iteration 89000 / 120000: loss 1.293419\n",
      "iteration 89100 / 120000: loss 0.000000\n",
      "iteration 89200 / 120000: loss 0.000000\n",
      "iteration 89300 / 120000: loss 0.000000\n",
      "iteration 89400 / 120000: loss 0.000000\n",
      "iteration 89500 / 120000: loss 0.000000\n",
      "iteration 89600 / 120000: loss 0.493875\n",
      "iteration 89700 / 120000: loss 0.000000\n",
      "iteration 89800 / 120000: loss 0.000000\n",
      "iteration 89900 / 120000: loss 0.024228\n",
      "iteration 90000 / 120000: loss 0.000000\n",
      "iteration 90100 / 120000: loss 0.000000\n",
      "iteration 90200 / 120000: loss 0.000000\n",
      "iteration 90300 / 120000: loss 0.394547\n",
      "iteration 90400 / 120000: loss 0.000000\n",
      "iteration 90500 / 120000: loss 0.000000\n",
      "iteration 90600 / 120000: loss 0.000000\n",
      "iteration 90700 / 120000: loss 2.170943\n",
      "iteration 90800 / 120000: loss 1.069763\n",
      "iteration 90900 / 120000: loss 0.000000\n",
      "iteration 91000 / 120000: loss 2.709741\n",
      "iteration 91100 / 120000: loss 2.064483\n",
      "iteration 91200 / 120000: loss 0.000000\n",
      "iteration 91300 / 120000: loss 0.000000\n",
      "iteration 91400 / 120000: loss 2.305232\n",
      "iteration 91500 / 120000: loss 0.000000\n",
      "iteration 91600 / 120000: loss 0.000000\n",
      "iteration 91700 / 120000: loss 0.000000\n",
      "iteration 91800 / 120000: loss 0.000000\n",
      "iteration 91900 / 120000: loss 0.000000\n",
      "iteration 92000 / 120000: loss 0.000000\n",
      "iteration 92100 / 120000: loss 1.865442\n",
      "iteration 92200 / 120000: loss 0.000000\n",
      "iteration 92300 / 120000: loss 0.000000\n",
      "iteration 92400 / 120000: loss 0.000000\n",
      "iteration 92500 / 120000: loss 0.000000\n",
      "iteration 92600 / 120000: loss 0.000000\n",
      "iteration 92700 / 120000: loss 2.027079\n",
      "iteration 92800 / 120000: loss 0.462415\n",
      "iteration 92900 / 120000: loss 0.000000\n",
      "iteration 93000 / 120000: loss 0.000000\n",
      "iteration 93100 / 120000: loss 0.000000\n",
      "iteration 93200 / 120000: loss 0.769523\n",
      "iteration 93300 / 120000: loss 0.000000\n",
      "iteration 93400 / 120000: loss 0.000000\n",
      "iteration 93500 / 120000: loss 0.000000\n",
      "iteration 93600 / 120000: loss 0.000000\n",
      "iteration 93700 / 120000: loss 3.640181\n",
      "iteration 93800 / 120000: loss 0.000000\n",
      "iteration 93900 / 120000: loss 0.000000\n",
      "iteration 94000 / 120000: loss 0.000000\n",
      "iteration 94100 / 120000: loss 0.000000\n",
      "iteration 94200 / 120000: loss 0.000000\n",
      "iteration 94300 / 120000: loss 0.000000\n",
      "iteration 94400 / 120000: loss 2.209387\n",
      "iteration 94500 / 120000: loss 0.000000\n",
      "iteration 94600 / 120000: loss 0.000000\n",
      "iteration 94700 / 120000: loss 0.000000\n",
      "iteration 94800 / 120000: loss 1.505538\n",
      "iteration 94900 / 120000: loss 0.000000\n",
      "iteration 95000 / 120000: loss 0.000000\n",
      "iteration 95100 / 120000: loss 0.000000\n",
      "iteration 95200 / 120000: loss 1.969152\n",
      "iteration 95300 / 120000: loss 0.000000\n",
      "iteration 95400 / 120000: loss 0.000000\n",
      "iteration 95500 / 120000: loss 0.000000\n",
      "iteration 95600 / 120000: loss 0.000000\n",
      "iteration 95700 / 120000: loss 0.283464\n",
      "iteration 95800 / 120000: loss 1.092256\n",
      "iteration 95900 / 120000: loss 0.000000\n",
      "iteration 96000 / 120000: loss 0.000000\n",
      "iteration 96100 / 120000: loss 0.000000\n",
      "iteration 96200 / 120000: loss 0.000000\n",
      "iteration 96300 / 120000: loss 0.000000\n",
      "iteration 96400 / 120000: loss 1.074995\n",
      "iteration 96500 / 120000: loss 0.906813\n",
      "iteration 96600 / 120000: loss 0.000000\n",
      "iteration 96700 / 120000: loss 0.000000\n",
      "iteration 96800 / 120000: loss 0.000000\n",
      "iteration 96900 / 120000: loss 7.209003\n",
      "iteration 97000 / 120000: loss 0.000000\n",
      "iteration 97100 / 120000: loss 0.000000\n",
      "iteration 97200 / 120000: loss 0.000000\n",
      "iteration 97300 / 120000: loss 0.000000\n",
      "iteration 97400 / 120000: loss 0.000000\n",
      "iteration 97500 / 120000: loss 0.000000\n",
      "iteration 97600 / 120000: loss 0.315418\n",
      "iteration 97700 / 120000: loss 0.544450\n",
      "iteration 97800 / 120000: loss 0.000000\n",
      "iteration 97900 / 120000: loss 0.000000\n",
      "iteration 98000 / 120000: loss 0.794835\n",
      "iteration 98100 / 120000: loss 0.000000\n",
      "iteration 98200 / 120000: loss 0.000000\n",
      "iteration 98300 / 120000: loss 0.000000\n",
      "iteration 98400 / 120000: loss 0.000000\n",
      "iteration 98500 / 120000: loss 4.107119\n",
      "iteration 98600 / 120000: loss 0.000000\n",
      "iteration 98700 / 120000: loss 0.000000\n",
      "iteration 98800 / 120000: loss 7.323072\n",
      "iteration 98900 / 120000: loss 0.000000\n",
      "iteration 99000 / 120000: loss 0.000000\n",
      "iteration 99100 / 120000: loss 0.000000\n",
      "iteration 99200 / 120000: loss 0.000000\n",
      "iteration 99300 / 120000: loss 1.077757\n",
      "iteration 99400 / 120000: loss 0.000000\n",
      "iteration 99500 / 120000: loss 0.000000\n",
      "iteration 99600 / 120000: loss 2.405025\n",
      "iteration 99700 / 120000: loss 0.000000\n",
      "iteration 99800 / 120000: loss 0.000000\n",
      "iteration 99900 / 120000: loss 1.592596\n",
      "iteration 100000 / 120000: loss 0.124335\n",
      "iteration 100100 / 120000: loss 0.000000\n",
      "iteration 100200 / 120000: loss 0.000000\n",
      "iteration 100300 / 120000: loss 2.316818\n",
      "iteration 100400 / 120000: loss 0.000000\n",
      "iteration 100500 / 120000: loss 0.000000\n",
      "iteration 100600 / 120000: loss 0.000000\n",
      "iteration 100700 / 120000: loss 0.000000\n",
      "iteration 100800 / 120000: loss 0.842100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100900 / 120000: loss 0.280123\n",
      "iteration 101000 / 120000: loss 0.634248\n",
      "iteration 101100 / 120000: loss 0.000000\n",
      "iteration 101200 / 120000: loss 0.000000\n",
      "iteration 101300 / 120000: loss 0.000000\n",
      "iteration 101400 / 120000: loss 0.000000\n",
      "iteration 101500 / 120000: loss 0.000000\n",
      "iteration 101600 / 120000: loss 0.000000\n",
      "iteration 101700 / 120000: loss 0.000000\n",
      "iteration 101800 / 120000: loss 0.244391\n",
      "iteration 101900 / 120000: loss 0.000000\n",
      "iteration 102000 / 120000: loss 0.000000\n",
      "iteration 102100 / 120000: loss 0.000000\n",
      "iteration 102200 / 120000: loss 0.000000\n",
      "iteration 102300 / 120000: loss 0.000000\n",
      "iteration 102400 / 120000: loss 5.648885\n",
      "iteration 102500 / 120000: loss 1.990824\n",
      "iteration 102600 / 120000: loss 0.000000\n",
      "iteration 102700 / 120000: loss 0.000000\n",
      "iteration 102800 / 120000: loss 0.000000\n",
      "iteration 102900 / 120000: loss 0.000000\n",
      "iteration 103000 / 120000: loss 0.000000\n",
      "iteration 103100 / 120000: loss 0.000000\n",
      "iteration 103200 / 120000: loss 0.182793\n",
      "iteration 103300 / 120000: loss 0.000000\n",
      "iteration 103400 / 120000: loss 0.000000\n",
      "iteration 103500 / 120000: loss 2.060539\n",
      "iteration 103600 / 120000: loss 0.000000\n",
      "iteration 103700 / 120000: loss 2.697042\n",
      "iteration 103800 / 120000: loss 1.040412\n",
      "iteration 103900 / 120000: loss 0.163754\n",
      "iteration 104000 / 120000: loss 0.000000\n",
      "iteration 104100 / 120000: loss 0.000000\n",
      "iteration 104200 / 120000: loss 0.000000\n",
      "iteration 104300 / 120000: loss 0.000000\n",
      "iteration 104400 / 120000: loss 0.000000\n",
      "iteration 104500 / 120000: loss 5.094966\n",
      "iteration 104600 / 120000: loss 0.000000\n",
      "iteration 104700 / 120000: loss 0.000000\n",
      "iteration 104800 / 120000: loss 0.000000\n",
      "iteration 104900 / 120000: loss 0.000000\n",
      "iteration 105000 / 120000: loss 0.000000\n",
      "iteration 105100 / 120000: loss 0.000000\n",
      "iteration 105200 / 120000: loss 3.970722\n",
      "iteration 105300 / 120000: loss 0.000000\n",
      "iteration 105400 / 120000: loss 0.000000\n",
      "iteration 105500 / 120000: loss 0.000000\n",
      "iteration 105600 / 120000: loss 0.000000\n",
      "iteration 105700 / 120000: loss 0.000000\n",
      "iteration 105800 / 120000: loss 0.000000\n",
      "iteration 105900 / 120000: loss 0.000000\n",
      "iteration 106000 / 120000: loss 0.000000\n",
      "iteration 106100 / 120000: loss 0.000000\n",
      "iteration 106200 / 120000: loss 0.000000\n",
      "iteration 106300 / 120000: loss 1.144741\n",
      "iteration 106400 / 120000: loss 0.000000\n",
      "iteration 106500 / 120000: loss 0.000000\n",
      "iteration 106600 / 120000: loss 0.000000\n",
      "iteration 106700 / 120000: loss 0.000000\n",
      "iteration 106800 / 120000: loss 0.000000\n",
      "iteration 106900 / 120000: loss 0.766076\n",
      "iteration 107000 / 120000: loss 3.680195\n",
      "iteration 107100 / 120000: loss 0.000000\n",
      "iteration 107200 / 120000: loss 0.000000\n",
      "iteration 107300 / 120000: loss 0.000000\n",
      "iteration 107400 / 120000: loss 0.000000\n",
      "iteration 107500 / 120000: loss 0.000000\n",
      "iteration 107600 / 120000: loss 1.302556\n",
      "iteration 107700 / 120000: loss 0.000000\n",
      "iteration 107800 / 120000: loss 0.170455\n",
      "iteration 107900 / 120000: loss 0.000000\n",
      "iteration 108000 / 120000: loss 0.000000\n",
      "iteration 108100 / 120000: loss 0.000000\n",
      "iteration 108200 / 120000: loss 0.000000\n",
      "iteration 108300 / 120000: loss 0.199871\n",
      "iteration 108400 / 120000: loss 0.000000\n",
      "iteration 108500 / 120000: loss 0.000000\n",
      "iteration 108600 / 120000: loss 0.000000\n",
      "iteration 108700 / 120000: loss 0.000000\n",
      "iteration 108800 / 120000: loss 0.318154\n",
      "iteration 108900 / 120000: loss 2.029507\n",
      "iteration 109000 / 120000: loss 0.000000\n",
      "iteration 109100 / 120000: loss 0.000000\n",
      "iteration 109200 / 120000: loss 0.000000\n",
      "iteration 109300 / 120000: loss 0.000000\n",
      "iteration 109400 / 120000: loss 0.000000\n",
      "iteration 109500 / 120000: loss 0.000000\n",
      "iteration 109600 / 120000: loss 0.000000\n",
      "iteration 109700 / 120000: loss 0.000000\n",
      "iteration 109800 / 120000: loss 2.908011\n",
      "iteration 109900 / 120000: loss 0.000000\n",
      "iteration 110000 / 120000: loss 0.000000\n",
      "iteration 110100 / 120000: loss 0.000000\n",
      "iteration 110200 / 120000: loss 0.723057\n",
      "iteration 110300 / 120000: loss 0.000000\n",
      "iteration 110400 / 120000: loss 3.390288\n",
      "iteration 110500 / 120000: loss 0.000000\n",
      "iteration 110600 / 120000: loss 4.852292\n",
      "iteration 110700 / 120000: loss 0.000000\n",
      "iteration 110800 / 120000: loss 0.000000\n",
      "iteration 110900 / 120000: loss 0.000000\n",
      "iteration 111000 / 120000: loss 0.000000\n",
      "iteration 111100 / 120000: loss 0.000000\n",
      "iteration 111200 / 120000: loss 0.000000\n",
      "iteration 111300 / 120000: loss 1.524334\n",
      "iteration 111400 / 120000: loss 0.790205\n",
      "iteration 111500 / 120000: loss 0.000000\n",
      "iteration 111600 / 120000: loss 4.016544\n",
      "iteration 111700 / 120000: loss 0.000000\n",
      "iteration 111800 / 120000: loss 0.000000\n",
      "iteration 111900 / 120000: loss 0.000000\n",
      "iteration 112000 / 120000: loss 0.000000\n",
      "iteration 112100 / 120000: loss 1.146969\n",
      "iteration 112200 / 120000: loss 0.000000\n",
      "iteration 112300 / 120000: loss 0.000000\n",
      "iteration 112400 / 120000: loss 0.000000\n",
      "iteration 112500 / 120000: loss 0.000000\n",
      "iteration 112600 / 120000: loss 0.000000\n",
      "iteration 112700 / 120000: loss 0.000000\n",
      "iteration 112800 / 120000: loss 0.000000\n",
      "iteration 112900 / 120000: loss 0.000000\n",
      "iteration 113000 / 120000: loss 0.000000\n",
      "iteration 113100 / 120000: loss 0.000000\n",
      "iteration 113200 / 120000: loss 0.000000\n",
      "iteration 113300 / 120000: loss 0.000000\n",
      "iteration 113400 / 120000: loss 0.000000\n",
      "iteration 113500 / 120000: loss 0.000000\n",
      "iteration 113600 / 120000: loss 0.000000\n",
      "iteration 113700 / 120000: loss 0.000000\n",
      "iteration 113800 / 120000: loss 0.640965\n",
      "iteration 113900 / 120000: loss 3.352272\n",
      "iteration 114000 / 120000: loss 0.000000\n",
      "iteration 114100 / 120000: loss 0.000000\n",
      "iteration 114200 / 120000: loss 0.000000\n",
      "iteration 114300 / 120000: loss 0.000000\n",
      "iteration 114400 / 120000: loss 0.000000\n",
      "iteration 114500 / 120000: loss 0.000000\n",
      "iteration 114600 / 120000: loss 0.561028\n",
      "iteration 114700 / 120000: loss 0.686246\n",
      "iteration 114800 / 120000: loss 0.000000\n",
      "iteration 114900 / 120000: loss 0.000000\n",
      "iteration 115000 / 120000: loss 0.000000\n",
      "iteration 115100 / 120000: loss 0.000000\n",
      "iteration 115200 / 120000: loss 0.000000\n",
      "iteration 115300 / 120000: loss 0.000000\n",
      "iteration 115400 / 120000: loss 0.000000\n",
      "iteration 115500 / 120000: loss 0.000000\n",
      "iteration 115600 / 120000: loss 0.000000\n",
      "iteration 115700 / 120000: loss 0.000000\n",
      "iteration 115800 / 120000: loss 0.000000\n",
      "iteration 115900 / 120000: loss 7.217397\n",
      "iteration 116000 / 120000: loss 0.000000\n",
      "iteration 116100 / 120000: loss 0.000000\n",
      "iteration 116200 / 120000: loss 0.000000\n",
      "iteration 116300 / 120000: loss 2.372672\n",
      "iteration 116400 / 120000: loss 0.000000\n",
      "iteration 116500 / 120000: loss 0.000000\n",
      "iteration 116600 / 120000: loss 0.000000\n",
      "iteration 116700 / 120000: loss 2.767341\n",
      "iteration 116800 / 120000: loss 0.000000\n",
      "iteration 116900 / 120000: loss 1.076186\n",
      "iteration 117000 / 120000: loss 0.355163\n",
      "iteration 117100 / 120000: loss 0.000000\n",
      "iteration 117200 / 120000: loss 0.000000\n",
      "iteration 117300 / 120000: loss 0.000000\n",
      "iteration 117400 / 120000: loss 0.329503\n",
      "iteration 117500 / 120000: loss 0.000000\n",
      "iteration 117600 / 120000: loss 0.000000\n",
      "iteration 117700 / 120000: loss 0.222104\n",
      "iteration 117800 / 120000: loss 0.000000\n",
      "iteration 117900 / 120000: loss 0.000000\n",
      "iteration 118000 / 120000: loss 2.930029\n",
      "iteration 118100 / 120000: loss 0.000000\n",
      "iteration 118200 / 120000: loss 0.000000\n",
      "iteration 118300 / 120000: loss 0.000000\n",
      "iteration 118400 / 120000: loss 0.000000\n",
      "iteration 118500 / 120000: loss 0.000000\n",
      "iteration 118600 / 120000: loss 0.000000\n",
      "iteration 118700 / 120000: loss 1.448719\n",
      "iteration 118800 / 120000: loss 1.639530\n",
      "iteration 118900 / 120000: loss 0.000000\n",
      "iteration 119000 / 120000: loss 0.569163\n",
      "iteration 119100 / 120000: loss 0.000000\n",
      "iteration 119200 / 120000: loss 0.000000\n",
      "iteration 119300 / 120000: loss 1.174546\n",
      "iteration 119400 / 120000: loss 0.000000\n",
      "iteration 119500 / 120000: loss 0.000000\n",
      "iteration 119600 / 120000: loss 0.000000\n",
      "iteration 119700 / 120000: loss 0.000000\n",
      "iteration 119800 / 120000: loss 1.488344\n",
      "iteration 119900 / 120000: loss 0.000000\n",
      "lr=1e-07 bs=100 regularization_rate=0.0006\n",
      "iteration 0 / 1200: loss 1.027725\n",
      "iteration 100 / 1200: loss 0.395786\n",
      "iteration 200 / 1200: loss 0.509134\n",
      "iteration 300 / 1200: loss 0.444301\n",
      "iteration 400 / 1200: loss 0.398001\n",
      "iteration 500 / 1200: loss 0.548071\n",
      "iteration 600 / 1200: loss 0.472623\n",
      "iteration 700 / 1200: loss 0.463550\n",
      "iteration 800 / 1200: loss 0.359675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 900 / 1200: loss 0.499379\n",
      "iteration 1000 / 1200: loss 0.276464\n",
      "iteration 1100 / 1200: loss 0.435066\n",
      "lr=1e-07 bs=100 regularization_rate=0.0005\n",
      "iteration 0 / 1200: loss 1.002244\n",
      "iteration 100 / 1200: loss 0.486773\n",
      "iteration 200 / 1200: loss 0.405130\n",
      "iteration 300 / 1200: loss 0.547260\n",
      "iteration 400 / 1200: loss 0.424669\n",
      "iteration 500 / 1200: loss 0.399420\n",
      "iteration 600 / 1200: loss 0.464978\n",
      "iteration 700 / 1200: loss 0.499269\n",
      "iteration 800 / 1200: loss 0.381420\n",
      "iteration 900 / 1200: loss 0.482064\n",
      "iteration 1000 / 1200: loss 0.428084\n",
      "iteration 1100 / 1200: loss 0.403992\n",
      "lr=1e-07 bs=100 regularization_rate=0.0004\n",
      "iteration 0 / 1200: loss 0.991530\n",
      "iteration 100 / 1200: loss 0.413460\n",
      "iteration 200 / 1200: loss 0.392913\n",
      "iteration 300 / 1200: loss 0.507233\n",
      "iteration 400 / 1200: loss 0.452950\n",
      "iteration 500 / 1200: loss 0.386162\n",
      "iteration 600 / 1200: loss 0.534468\n",
      "iteration 700 / 1200: loss 0.436926\n",
      "iteration 800 / 1200: loss 0.571848\n",
      "iteration 900 / 1200: loss 0.383501\n",
      "iteration 1000 / 1200: loss 0.508189\n",
      "iteration 1100 / 1200: loss 0.456921\n",
      "lr=1e-07 bs=100 regularization_rate=0.0003\n",
      "iteration 0 / 1200: loss 0.972410\n",
      "iteration 100 / 1200: loss 0.509826\n",
      "iteration 200 / 1200: loss 0.446428\n",
      "iteration 300 / 1200: loss 0.473484\n",
      "iteration 400 / 1200: loss 0.414377\n",
      "iteration 500 / 1200: loss 0.389872\n",
      "iteration 600 / 1200: loss 0.584204\n",
      "iteration 700 / 1200: loss 0.438593\n",
      "iteration 800 / 1200: loss 0.554732\n",
      "iteration 900 / 1200: loss 0.378114\n",
      "iteration 1000 / 1200: loss 0.433551\n",
      "iteration 1100 / 1200: loss 0.565144\n",
      "lr=1e-07 bs=200 regularization_rate=0.0006\n",
      "iteration 0 / 600: loss 1.069744\n",
      "iteration 100 / 600: loss 0.463154\n",
      "iteration 200 / 600: loss 0.506187\n",
      "iteration 300 / 600: loss 0.434138\n",
      "iteration 400 / 600: loss 0.402094\n",
      "iteration 500 / 600: loss 0.433559\n",
      "lr=1e-07 bs=200 regularization_rate=0.0005\n",
      "iteration 0 / 600: loss 1.003934\n",
      "iteration 100 / 600: loss 0.592294\n",
      "iteration 200 / 600: loss 0.412519\n",
      "iteration 300 / 600: loss 0.395233\n",
      "iteration 400 / 600: loss 0.451875\n",
      "iteration 500 / 600: loss 0.446508\n",
      "lr=1e-07 bs=200 regularization_rate=0.0004\n",
      "iteration 0 / 600: loss 1.016326\n",
      "iteration 100 / 600: loss 0.471026\n",
      "iteration 200 / 600: loss 0.425572\n",
      "iteration 300 / 600: loss 0.451428\n",
      "iteration 400 / 600: loss 0.510850\n",
      "iteration 500 / 600: loss 0.434232\n",
      "lr=1e-07 bs=200 regularization_rate=0.0003\n",
      "iteration 0 / 600: loss 0.962838\n",
      "iteration 100 / 600: loss 0.478040\n",
      "iteration 200 / 600: loss 0.464124\n",
      "iteration 300 / 600: loss 0.472094\n",
      "iteration 400 / 600: loss 0.459759\n",
      "iteration 500 / 600: loss 0.485713\n",
      "lr=1e-07 bs=500 regularization_rate=0.0006\n",
      "iteration 0 / 240: loss 0.917408\n",
      "iteration 100 / 240: loss 0.474116\n",
      "iteration 200 / 240: loss 0.510130\n",
      "lr=1e-07 bs=500 regularization_rate=0.0005\n",
      "iteration 0 / 240: loss 1.015920\n",
      "iteration 100 / 240: loss 0.502268\n",
      "iteration 200 / 240: loss 0.451111\n",
      "lr=1e-07 bs=500 regularization_rate=0.0004\n",
      "iteration 0 / 240: loss 0.975451\n",
      "iteration 100 / 240: loss 0.476603\n",
      "iteration 200 / 240: loss 0.437011\n",
      "lr=1e-07 bs=500 regularization_rate=0.0003\n",
      "iteration 0 / 240: loss 1.034626\n",
      "iteration 100 / 240: loss 0.497996\n",
      "iteration 200 / 240: loss 0.504150\n",
      "lr=1e-07 bs=10000 regularization_rate=0.0006\n",
      "iteration 0 / 12: loss 1.032809\n",
      "lr=1e-07 bs=10000 regularization_rate=0.0005\n",
      "iteration 0 / 12: loss 1.070527\n",
      "lr=1e-07 bs=10000 regularization_rate=0.0004\n",
      "iteration 0 / 12: loss 0.955857\n",
      "lr=1e-07 bs=10000 regularization_rate=0.0003\n",
      "iteration 0 / 12: loss 0.972888\n",
      "lr=5e-06 bs=1 regularization_rate=0.0006\n",
      "iteration 0 / 120000: loss 0.906092\n",
      "iteration 100 / 120000: loss 0.000007\n",
      "iteration 200 / 120000: loss 0.000010\n",
      "iteration 300 / 120000: loss 0.000014\n",
      "iteration 400 / 120000: loss 22.220490\n",
      "iteration 500 / 120000: loss 0.000019\n",
      "iteration 600 / 120000: loss 0.000023\n",
      "iteration 700 / 120000: loss 0.000025\n",
      "iteration 800 / 120000: loss 0.000025\n",
      "iteration 900 / 120000: loss 7.025851\n",
      "iteration 1000 / 120000: loss 0.000030\n",
      "iteration 1100 / 120000: loss 0.000033\n",
      "iteration 1200 / 120000: loss 13.351248\n",
      "iteration 1300 / 120000: loss 0.000042\n",
      "iteration 1400 / 120000: loss 0.000043\n",
      "iteration 1500 / 120000: loss 0.000044\n",
      "iteration 1600 / 120000: loss 0.000044\n",
      "iteration 1700 / 120000: loss 0.000046\n",
      "iteration 1800 / 120000: loss 0.428297\n",
      "iteration 1900 / 120000: loss 0.000049\n",
      "iteration 2000 / 120000: loss 0.000048\n",
      "iteration 2100 / 120000: loss 0.000050\n",
      "iteration 2200 / 120000: loss 0.000053\n",
      "iteration 2300 / 120000: loss 0.000053\n",
      "iteration 2400 / 120000: loss 8.890887\n",
      "iteration 2500 / 120000: loss 0.000058\n",
      "iteration 2600 / 120000: loss 0.000057\n",
      "iteration 2700 / 120000: loss 4.667547\n",
      "iteration 2800 / 120000: loss 0.000061\n",
      "iteration 2900 / 120000: loss 14.306132\n",
      "iteration 3000 / 120000: loss 0.000063\n",
      "iteration 3100 / 120000: loss 0.000064\n",
      "iteration 3200 / 120000: loss 0.000066\n",
      "iteration 3300 / 120000: loss 0.000068\n",
      "iteration 3400 / 120000: loss 0.000069\n",
      "iteration 3500 / 120000: loss 0.000071\n",
      "iteration 3600 / 120000: loss 0.000071\n",
      "iteration 3700 / 120000: loss 7.910061\n",
      "iteration 3800 / 120000: loss 0.000071\n",
      "iteration 3900 / 120000: loss 0.000070\n",
      "iteration 4000 / 120000: loss 0.000074\n",
      "iteration 4100 / 120000: loss 0.000072\n",
      "iteration 4200 / 120000: loss 0.000075\n",
      "iteration 4300 / 120000: loss 0.000075\n",
      "iteration 4400 / 120000: loss 87.628289\n",
      "iteration 4500 / 120000: loss 0.000074\n",
      "iteration 4600 / 120000: loss 0.000077\n",
      "iteration 4700 / 120000: loss 0.000080\n",
      "iteration 4800 / 120000: loss 0.000078\n",
      "iteration 4900 / 120000: loss 0.000080\n",
      "iteration 5000 / 120000: loss 18.528790\n",
      "iteration 5100 / 120000: loss 112.394164\n",
      "iteration 5200 / 120000: loss 0.000082\n",
      "iteration 5300 / 120000: loss 0.000084\n",
      "iteration 5400 / 120000: loss 0.000087\n",
      "iteration 5500 / 120000: loss 0.000087\n",
      "iteration 5600 / 120000: loss 0.699801\n",
      "iteration 5700 / 120000: loss 0.000086\n",
      "iteration 5800 / 120000: loss 0.000086\n",
      "iteration 5900 / 120000: loss 0.000091\n",
      "iteration 6000 / 120000: loss 0.000090\n",
      "iteration 6100 / 120000: loss 0.000092\n",
      "iteration 6200 / 120000: loss 0.000093\n",
      "iteration 6300 / 120000: loss 0.000093\n",
      "iteration 6400 / 120000: loss 0.000092\n",
      "iteration 6500 / 120000: loss 0.000094\n",
      "iteration 6600 / 120000: loss 0.000094\n",
      "iteration 6700 / 120000: loss 2.036370\n",
      "iteration 6800 / 120000: loss 14.061321\n",
      "iteration 6900 / 120000: loss 0.000099\n",
      "iteration 7000 / 120000: loss 0.000099\n",
      "iteration 7100 / 120000: loss 0.000098\n",
      "iteration 7200 / 120000: loss 0.000098\n",
      "iteration 7300 / 120000: loss 47.398349\n",
      "iteration 7400 / 120000: loss 0.000099\n",
      "iteration 7500 / 120000: loss 0.000101\n",
      "iteration 7600 / 120000: loss 0.000103\n",
      "iteration 7700 / 120000: loss 0.000104\n",
      "iteration 7800 / 120000: loss 37.072139\n",
      "iteration 7900 / 120000: loss 36.839539\n",
      "iteration 8000 / 120000: loss 196.077127\n",
      "iteration 8100 / 120000: loss 65.302580\n",
      "iteration 8200 / 120000: loss 0.000106\n",
      "iteration 8300 / 120000: loss 92.691574\n",
      "iteration 8400 / 120000: loss 96.030990\n",
      "iteration 8500 / 120000: loss 64.443690\n",
      "iteration 8600 / 120000: loss 0.000112\n",
      "iteration 8700 / 120000: loss 92.966922\n",
      "iteration 8800 / 120000: loss 0.000116\n",
      "iteration 8900 / 120000: loss 0.000117\n",
      "iteration 9000 / 120000: loss 0.000115\n",
      "iteration 9100 / 120000: loss 0.000113\n",
      "iteration 9200 / 120000: loss 19.644122\n",
      "iteration 9300 / 120000: loss 0.000114\n",
      "iteration 9400 / 120000: loss 0.000113\n",
      "iteration 9500 / 120000: loss 0.000118\n",
      "iteration 9600 / 120000: loss 0.000118\n",
      "iteration 9700 / 120000: loss 0.000118\n",
      "iteration 9800 / 120000: loss 0.000119\n",
      "iteration 9900 / 120000: loss 0.000119\n",
      "iteration 10000 / 120000: loss 157.454867\n",
      "iteration 10100 / 120000: loss 0.000120\n",
      "iteration 10200 / 120000: loss 0.000122\n",
      "iteration 10300 / 120000: loss 0.000122\n",
      "iteration 10400 / 120000: loss 0.000122\n",
      "iteration 10500 / 120000: loss 29.926576\n",
      "iteration 10600 / 120000: loss 0.000124\n",
      "iteration 10700 / 120000: loss 52.218209\n",
      "iteration 10800 / 120000: loss 0.000128\n",
      "iteration 10900 / 120000: loss 51.664976\n",
      "iteration 11000 / 120000: loss 0.000132\n",
      "iteration 11100 / 120000: loss 0.000132\n",
      "iteration 11200 / 120000: loss 0.000131\n",
      "iteration 11300 / 120000: loss 0.000132\n",
      "iteration 11400 / 120000: loss 0.000135\n",
      "iteration 11500 / 120000: loss 0.000134\n",
      "iteration 11600 / 120000: loss 0.000137\n",
      "iteration 11700 / 120000: loss 0.000137\n",
      "iteration 11800 / 120000: loss 17.246785\n",
      "iteration 11900 / 120000: loss 11.832102\n",
      "iteration 12000 / 120000: loss 6.727874\n",
      "iteration 12100 / 120000: loss 0.000140\n",
      "iteration 12200 / 120000: loss 0.000142\n",
      "iteration 12300 / 120000: loss 0.000144\n",
      "iteration 12400 / 120000: loss 0.000147\n",
      "iteration 12500 / 120000: loss 0.000149\n",
      "iteration 12600 / 120000: loss 11.483528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 12700 / 120000: loss 0.000152\n",
      "iteration 12800 / 120000: loss 0.000153\n",
      "iteration 12900 / 120000: loss 0.000153\n",
      "iteration 13000 / 120000: loss 0.000153\n",
      "iteration 13100 / 120000: loss 0.000152\n",
      "iteration 13200 / 120000: loss 46.116786\n",
      "iteration 13300 / 120000: loss 0.000151\n",
      "iteration 13400 / 120000: loss 0.000153\n",
      "iteration 13500 / 120000: loss 0.000155\n",
      "iteration 13600 / 120000: loss 0.000157\n",
      "iteration 13700 / 120000: loss 43.690712\n",
      "iteration 13800 / 120000: loss 0.000157\n",
      "iteration 13900 / 120000: loss 0.000158\n",
      "iteration 14000 / 120000: loss 0.000158\n",
      "iteration 14100 / 120000: loss 54.019992\n",
      "iteration 14200 / 120000: loss 178.641006\n",
      "iteration 14300 / 120000: loss 0.000164\n",
      "iteration 14400 / 120000: loss 76.051802\n",
      "iteration 14500 / 120000: loss 8.941573\n",
      "iteration 14600 / 120000: loss 0.000164\n",
      "iteration 14700 / 120000: loss 0.000164\n",
      "iteration 14800 / 120000: loss 0.000164\n",
      "iteration 14900 / 120000: loss 48.309196\n",
      "iteration 15000 / 120000: loss 0.000164\n",
      "iteration 15100 / 120000: loss 32.667640\n",
      "iteration 15200 / 120000: loss 0.000164\n",
      "iteration 15300 / 120000: loss 0.000165\n",
      "iteration 15400 / 120000: loss 0.000165\n",
      "iteration 15500 / 120000: loss 230.268869\n",
      "iteration 15600 / 120000: loss 0.000161\n",
      "iteration 15700 / 120000: loss 14.188517\n",
      "iteration 15800 / 120000: loss 0.000161\n",
      "iteration 15900 / 120000: loss 0.000161\n",
      "iteration 16000 / 120000: loss 0.000161\n",
      "iteration 16100 / 120000: loss 0.000164\n",
      "iteration 16200 / 120000: loss 0.000165\n",
      "iteration 16300 / 120000: loss 0.000167\n",
      "iteration 16400 / 120000: loss 0.000166\n",
      "iteration 16500 / 120000: loss 0.000167\n",
      "iteration 16600 / 120000: loss 0.000167\n",
      "iteration 16700 / 120000: loss 0.000170\n",
      "iteration 16800 / 120000: loss 0.000170\n",
      "iteration 16900 / 120000: loss 0.000170\n",
      "iteration 17000 / 120000: loss 0.000171\n",
      "iteration 17100 / 120000: loss 0.000172\n",
      "iteration 17200 / 120000: loss 0.000173\n",
      "iteration 17300 / 120000: loss 0.000174\n",
      "iteration 17400 / 120000: loss 116.176382\n",
      "iteration 17500 / 120000: loss 0.000175\n",
      "iteration 17600 / 120000: loss 0.000176\n",
      "iteration 17700 / 120000: loss 0.000175\n",
      "iteration 17800 / 120000: loss 0.000179\n",
      "iteration 17900 / 120000: loss 0.000181\n",
      "iteration 18000 / 120000: loss 61.562884\n",
      "iteration 18100 / 120000: loss 0.000179\n",
      "iteration 18200 / 120000: loss 121.252178\n",
      "iteration 18300 / 120000: loss 0.000184\n",
      "iteration 18400 / 120000: loss 0.000183\n",
      "iteration 18500 / 120000: loss 0.000184\n",
      "iteration 18600 / 120000: loss 0.000181\n",
      "iteration 18700 / 120000: loss 0.000182\n",
      "iteration 18800 / 120000: loss 0.000180\n",
      "iteration 18900 / 120000: loss 66.772366\n",
      "iteration 19000 / 120000: loss 0.000183\n",
      "iteration 19100 / 120000: loss 0.000182\n",
      "iteration 19200 / 120000: loss 0.000183\n",
      "iteration 19300 / 120000: loss 3.173587\n",
      "iteration 19400 / 120000: loss 0.000183\n",
      "iteration 19500 / 120000: loss 0.000185\n",
      "iteration 19600 / 120000: loss 0.000186\n",
      "iteration 19700 / 120000: loss 42.628923\n",
      "iteration 19800 / 120000: loss 0.000182\n",
      "iteration 19900 / 120000: loss 0.000182\n",
      "iteration 20000 / 120000: loss 0.000180\n",
      "iteration 20100 / 120000: loss 91.556658\n",
      "iteration 20200 / 120000: loss 0.000181\n",
      "iteration 20300 / 120000: loss 0.000183\n",
      "iteration 20400 / 120000: loss 0.000187\n",
      "iteration 20500 / 120000: loss 0.000188\n",
      "iteration 20600 / 120000: loss 0.000184\n",
      "iteration 20700 / 120000: loss 35.044330\n",
      "iteration 20800 / 120000: loss 81.577310\n",
      "iteration 20900 / 120000: loss 0.000187\n",
      "iteration 21000 / 120000: loss 0.000192\n",
      "iteration 21100 / 120000: loss 0.000193\n",
      "iteration 21200 / 120000: loss 0.000194\n",
      "iteration 21300 / 120000: loss 0.000193\n",
      "iteration 21400 / 120000: loss 0.000195\n",
      "iteration 21500 / 120000: loss 0.000194\n",
      "iteration 21600 / 120000: loss 9.685966\n",
      "iteration 21700 / 120000: loss 41.351218\n",
      "iteration 21800 / 120000: loss 0.000198\n",
      "iteration 21900 / 120000: loss 0.000200\n",
      "iteration 22000 / 120000: loss 0.000200\n",
      "iteration 22100 / 120000: loss 0.000198\n",
      "iteration 22200 / 120000: loss 0.000200\n",
      "iteration 22300 / 120000: loss 0.000200\n",
      "iteration 22400 / 120000: loss 0.000197\n",
      "iteration 22500 / 120000: loss 0.000198\n",
      "iteration 22600 / 120000: loss 0.000197\n",
      "iteration 22700 / 120000: loss 83.044019\n",
      "iteration 22800 / 120000: loss 0.000198\n",
      "iteration 22900 / 120000: loss 0.000199\n",
      "iteration 23000 / 120000: loss 109.295086\n",
      "iteration 23100 / 120000: loss 0.000203\n",
      "iteration 23200 / 120000: loss 0.000205\n",
      "iteration 23300 / 120000: loss 0.000208\n",
      "iteration 23400 / 120000: loss 0.000208\n",
      "iteration 23500 / 120000: loss 40.878730\n",
      "iteration 23600 / 120000: loss 0.000209\n",
      "iteration 23700 / 120000: loss 0.000210\n",
      "iteration 23800 / 120000: loss 0.000212\n",
      "iteration 23900 / 120000: loss 0.000213\n",
      "iteration 24000 / 120000: loss 6.696976\n",
      "iteration 24100 / 120000: loss 0.000211\n",
      "iteration 24200 / 120000: loss 0.000211\n",
      "iteration 24300 / 120000: loss 0.000213\n",
      "iteration 24400 / 120000: loss 0.000212\n",
      "iteration 24500 / 120000: loss 111.153924\n",
      "iteration 24600 / 120000: loss 0.000210\n",
      "iteration 24700 / 120000: loss 0.000210\n",
      "iteration 24800 / 120000: loss 0.000209\n",
      "iteration 24900 / 120000: loss 113.516984\n",
      "iteration 25000 / 120000: loss 0.000206\n",
      "iteration 25100 / 120000: loss 0.000208\n",
      "iteration 25200 / 120000: loss 0.000206\n",
      "iteration 25300 / 120000: loss 0.000208\n",
      "iteration 25400 / 120000: loss 33.490407\n",
      "iteration 25500 / 120000: loss 0.000209\n",
      "iteration 25600 / 120000: loss 125.120712\n",
      "iteration 25700 / 120000: loss 0.000213\n",
      "iteration 25800 / 120000: loss 0.000215\n",
      "iteration 25900 / 120000: loss 0.000216\n",
      "iteration 26000 / 120000: loss 51.631596\n",
      "iteration 26100 / 120000: loss 0.000211\n",
      "iteration 26200 / 120000: loss 0.000213\n",
      "iteration 26300 / 120000: loss 0.000216\n",
      "iteration 26400 / 120000: loss 0.000217\n",
      "iteration 26500 / 120000: loss 0.000218\n",
      "iteration 26600 / 120000: loss 0.000218\n",
      "iteration 26700 / 120000: loss 167.409107\n",
      "iteration 26800 / 120000: loss 0.000219\n",
      "iteration 26900 / 120000: loss 0.000222\n",
      "iteration 27000 / 120000: loss 53.983684\n",
      "iteration 27100 / 120000: loss 69.089550\n",
      "iteration 27200 / 120000: loss 0.000226\n",
      "iteration 27300 / 120000: loss 0.000228\n",
      "iteration 27400 / 120000: loss 0.000230\n",
      "iteration 27500 / 120000: loss 68.651164\n",
      "iteration 27600 / 120000: loss 0.000234\n",
      "iteration 27700 / 120000: loss 85.842365\n",
      "iteration 27800 / 120000: loss 0.000235\n",
      "iteration 27900 / 120000: loss 172.235474\n",
      "iteration 28000 / 120000: loss 0.000237\n",
      "iteration 28100 / 120000: loss 0.000236\n",
      "iteration 28200 / 120000: loss 0.000237\n",
      "iteration 28300 / 120000: loss 0.000239\n",
      "iteration 28400 / 120000: loss 0.000237\n",
      "iteration 28500 / 120000: loss 0.000237\n",
      "iteration 28600 / 120000: loss 37.264451\n",
      "iteration 28700 / 120000: loss 0.000238\n",
      "iteration 28800 / 120000: loss 0.000238\n",
      "iteration 28900 / 120000: loss 2.680697\n",
      "iteration 29000 / 120000: loss 0.000238\n",
      "iteration 29100 / 120000: loss 0.000235\n",
      "iteration 29200 / 120000: loss 0.000236\n",
      "iteration 29300 / 120000: loss 34.063898\n",
      "iteration 29400 / 120000: loss 69.456438\n",
      "iteration 29500 / 120000: loss 0.000235\n",
      "iteration 29600 / 120000: loss 0.000236\n",
      "iteration 29700 / 120000: loss 0.000238\n",
      "iteration 29800 / 120000: loss 0.000238\n",
      "iteration 29900 / 120000: loss 0.000237\n",
      "iteration 30000 / 120000: loss 0.000237\n",
      "iteration 30100 / 120000: loss 0.000238\n",
      "iteration 30200 / 120000: loss 0.000238\n",
      "iteration 30300 / 120000: loss 0.000239\n",
      "iteration 30400 / 120000: loss 0.000241\n",
      "iteration 30500 / 120000: loss 0.000243\n",
      "iteration 30600 / 120000: loss 0.000245\n",
      "iteration 30700 / 120000: loss 0.000245\n",
      "iteration 30800 / 120000: loss 0.000243\n",
      "iteration 30900 / 120000: loss 0.000244\n",
      "iteration 31000 / 120000: loss 0.000243\n",
      "iteration 31100 / 120000: loss 0.000242\n",
      "iteration 31200 / 120000: loss 0.000246\n",
      "iteration 31300 / 120000: loss 0.000244\n",
      "iteration 31400 / 120000: loss 0.000247\n",
      "iteration 31500 / 120000: loss 0.000248\n",
      "iteration 31600 / 120000: loss 0.000251\n",
      "iteration 31700 / 120000: loss 218.950458\n",
      "iteration 31800 / 120000: loss 0.000253\n",
      "iteration 31900 / 120000: loss 0.000255\n",
      "iteration 32000 / 120000: loss 0.000255\n",
      "iteration 32100 / 120000: loss 0.000257\n",
      "iteration 32200 / 120000: loss 0.000257\n",
      "iteration 32300 / 120000: loss 0.000256\n",
      "iteration 32400 / 120000: loss 0.000259\n",
      "iteration 32500 / 120000: loss 0.000258\n",
      "iteration 32600 / 120000: loss 0.000259\n",
      "iteration 32700 / 120000: loss 0.000260\n",
      "iteration 32800 / 120000: loss 56.405483\n",
      "iteration 32900 / 120000: loss 0.000265\n",
      "iteration 33000 / 120000: loss 0.000261\n",
      "iteration 33100 / 120000: loss 0.000261\n",
      "iteration 33200 / 120000: loss 0.000264\n",
      "iteration 33300 / 120000: loss 0.000262\n",
      "iteration 33400 / 120000: loss 0.000263\n",
      "iteration 33500 / 120000: loss 0.000264\n",
      "iteration 33600 / 120000: loss 23.220500\n",
      "iteration 33700 / 120000: loss 0.000265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 33800 / 120000: loss 0.000264\n",
      "iteration 33900 / 120000: loss 0.000264\n",
      "iteration 34000 / 120000: loss 0.000267\n",
      "iteration 34100 / 120000: loss 0.000268\n",
      "iteration 34200 / 120000: loss 43.499311\n",
      "iteration 34300 / 120000: loss 0.000269\n",
      "iteration 34400 / 120000: loss 0.000269\n",
      "iteration 34500 / 120000: loss 0.000273\n",
      "iteration 34600 / 120000: loss 0.000271\n",
      "iteration 34700 / 120000: loss 0.000274\n",
      "iteration 34800 / 120000: loss 0.000276\n",
      "iteration 34900 / 120000: loss 0.000275\n",
      "iteration 35000 / 120000: loss 0.000277\n",
      "iteration 35100 / 120000: loss 0.000279\n",
      "iteration 35200 / 120000: loss 0.000279\n",
      "iteration 35300 / 120000: loss 0.000280\n",
      "iteration 35400 / 120000: loss 0.000283\n",
      "iteration 35500 / 120000: loss 115.042457\n",
      "iteration 35600 / 120000: loss 0.000280\n",
      "iteration 35700 / 120000: loss 0.000279\n",
      "iteration 35800 / 120000: loss 0.000279\n",
      "iteration 35900 / 120000: loss 0.000279\n",
      "iteration 36000 / 120000: loss 0.000281\n",
      "iteration 36100 / 120000: loss 0.000281\n",
      "iteration 36200 / 120000: loss 0.000283\n",
      "iteration 36300 / 120000: loss 0.000281\n",
      "iteration 36400 / 120000: loss 54.595655\n",
      "iteration 36500 / 120000: loss 0.000281\n",
      "iteration 36600 / 120000: loss 0.000279\n",
      "iteration 36700 / 120000: loss 0.000282\n",
      "iteration 36800 / 120000: loss 0.000284\n",
      "iteration 36900 / 120000: loss 0.000287\n",
      "iteration 37000 / 120000: loss 84.768106\n",
      "iteration 37100 / 120000: loss 0.000288\n",
      "iteration 37200 / 120000: loss 0.000288\n",
      "iteration 37300 / 120000: loss 33.218285\n",
      "iteration 37400 / 120000: loss 44.374617\n",
      "iteration 37500 / 120000: loss 0.000290\n",
      "iteration 37600 / 120000: loss 0.000291\n",
      "iteration 37700 / 120000: loss 0.000292\n",
      "iteration 37800 / 120000: loss 0.849235\n",
      "iteration 37900 / 120000: loss 0.000290\n",
      "iteration 38000 / 120000: loss 0.000290\n",
      "iteration 38100 / 120000: loss 0.000293\n",
      "iteration 38200 / 120000: loss 0.000295\n",
      "iteration 38300 / 120000: loss 0.000295\n",
      "iteration 38400 / 120000: loss 56.303167\n",
      "iteration 38500 / 120000: loss 293.759280\n",
      "iteration 38600 / 120000: loss 0.000296\n",
      "iteration 38700 / 120000: loss 0.000298\n",
      "iteration 38800 / 120000: loss 0.000294\n",
      "iteration 38900 / 120000: loss 0.000296\n",
      "iteration 39000 / 120000: loss 14.945650\n",
      "iteration 39100 / 120000: loss 179.516566\n",
      "iteration 39200 / 120000: loss 0.000302\n",
      "iteration 39300 / 120000: loss 0.000301\n",
      "iteration 39400 / 120000: loss 0.000301\n",
      "iteration 39500 / 120000: loss 0.000301\n",
      "iteration 39600 / 120000: loss 0.000300\n",
      "iteration 39700 / 120000: loss 0.000300\n",
      "iteration 39800 / 120000: loss 0.000299\n",
      "iteration 39900 / 120000: loss 0.000298\n",
      "iteration 40000 / 120000: loss 0.000300\n",
      "iteration 40100 / 120000: loss 41.396408\n",
      "iteration 40200 / 120000: loss 28.705455\n",
      "iteration 40300 / 120000: loss 52.400946\n",
      "iteration 40400 / 120000: loss 0.000303\n",
      "iteration 40500 / 120000: loss 0.000299\n",
      "iteration 40600 / 120000: loss 0.000301\n",
      "iteration 40700 / 120000: loss 0.000301\n",
      "iteration 40800 / 120000: loss 0.000304\n",
      "iteration 40900 / 120000: loss 0.000306\n",
      "iteration 41000 / 120000: loss 29.582506\n",
      "iteration 41100 / 120000: loss 0.000307\n",
      "iteration 41200 / 120000: loss 24.343850\n",
      "iteration 41300 / 120000: loss 0.000312\n",
      "iteration 41400 / 120000: loss 0.000312\n",
      "iteration 41500 / 120000: loss 0.000311\n",
      "iteration 41600 / 120000: loss 89.546950\n",
      "iteration 41700 / 120000: loss 0.000310\n",
      "iteration 41800 / 120000: loss 41.020354\n",
      "iteration 41900 / 120000: loss 0.000312\n",
      "iteration 42000 / 120000: loss 0.000311\n",
      "iteration 42100 / 120000: loss 0.000311\n",
      "iteration 42200 / 120000: loss 0.000312\n",
      "iteration 42300 / 120000: loss 6.401201\n",
      "iteration 42400 / 120000: loss 0.000311\n",
      "iteration 42500 / 120000: loss 0.000312\n",
      "iteration 42600 / 120000: loss 90.753489\n",
      "iteration 42700 / 120000: loss 0.000312\n",
      "iteration 42800 / 120000: loss 0.000313\n",
      "iteration 42900 / 120000: loss 0.000315\n",
      "iteration 43000 / 120000: loss 0.000315\n",
      "iteration 43100 / 120000: loss 0.000317\n",
      "iteration 43200 / 120000: loss 0.000319\n",
      "iteration 43300 / 120000: loss 0.000322\n",
      "iteration 43400 / 120000: loss 0.000323\n",
      "iteration 43500 / 120000: loss 0.000323\n",
      "iteration 43600 / 120000: loss 0.000322\n",
      "iteration 43700 / 120000: loss 64.206508\n",
      "iteration 43800 / 120000: loss 0.000329\n",
      "iteration 43900 / 120000: loss 0.000330\n",
      "iteration 44000 / 120000: loss 15.847799\n",
      "iteration 44100 / 120000: loss 78.632189\n",
      "iteration 44200 / 120000: loss 53.267833\n",
      "iteration 44300 / 120000: loss 0.000331\n",
      "iteration 44400 / 120000: loss 0.000333\n",
      "iteration 44500 / 120000: loss 143.678256\n",
      "iteration 44600 / 120000: loss 0.000332\n",
      "iteration 44700 / 120000: loss 179.858878\n",
      "iteration 44800 / 120000: loss 0.000336\n",
      "iteration 44900 / 120000: loss 0.000337\n",
      "iteration 45000 / 120000: loss 0.000339\n",
      "iteration 45100 / 120000: loss 0.000339\n",
      "iteration 45200 / 120000: loss 0.000339\n",
      "iteration 45300 / 120000: loss 0.000341\n",
      "iteration 45400 / 120000: loss 0.000342\n",
      "iteration 45500 / 120000: loss 0.000344\n",
      "iteration 45600 / 120000: loss 4.012530\n",
      "iteration 45700 / 120000: loss 0.000344\n",
      "iteration 45800 / 120000: loss 0.000345\n",
      "iteration 45900 / 120000: loss 0.000344\n",
      "iteration 46000 / 120000: loss 0.000346\n",
      "iteration 46100 / 120000: loss 0.000347\n",
      "iteration 46200 / 120000: loss 0.000347\n",
      "iteration 46300 / 120000: loss 78.493856\n",
      "iteration 46400 / 120000: loss 0.000348\n",
      "iteration 46500 / 120000: loss 0.000347\n",
      "iteration 46600 / 120000: loss 0.000347\n",
      "iteration 46700 / 120000: loss 0.000346\n",
      "iteration 46800 / 120000: loss 0.000347\n",
      "iteration 46900 / 120000: loss 39.276774\n",
      "iteration 47000 / 120000: loss 0.000348\n",
      "iteration 47100 / 120000: loss 0.000347\n",
      "iteration 47200 / 120000: loss 115.095309\n",
      "iteration 47300 / 120000: loss 67.143288\n",
      "iteration 47400 / 120000: loss 0.000348\n",
      "iteration 47500 / 120000: loss 46.650725\n",
      "iteration 47600 / 120000: loss 0.000349\n",
      "iteration 47700 / 120000: loss 0.000351\n",
      "iteration 47800 / 120000: loss 0.000352\n",
      "iteration 47900 / 120000: loss 25.128765\n",
      "iteration 48000 / 120000: loss 0.000355\n",
      "iteration 48100 / 120000: loss 54.215621\n",
      "iteration 48200 / 120000: loss 0.000359\n",
      "iteration 48300 / 120000: loss 249.852496\n",
      "iteration 48400 / 120000: loss 0.000360\n",
      "iteration 48500 / 120000: loss 0.000362\n",
      "iteration 48600 / 120000: loss 85.389638\n",
      "iteration 48700 / 120000: loss 0.000364\n",
      "iteration 48800 / 120000: loss 0.000364\n",
      "iteration 48900 / 120000: loss 49.344694\n",
      "iteration 49000 / 120000: loss 0.000366\n",
      "iteration 49100 / 120000: loss 0.000366\n",
      "iteration 49200 / 120000: loss 0.000369\n",
      "iteration 49300 / 120000: loss 0.000371\n",
      "iteration 49400 / 120000: loss 0.000366\n",
      "iteration 49500 / 120000: loss 0.000363\n",
      "iteration 49600 / 120000: loss 0.000363\n",
      "iteration 49700 / 120000: loss 71.368907\n",
      "iteration 49800 / 120000: loss 0.000362\n",
      "iteration 49900 / 120000: loss 0.000364\n",
      "iteration 50000 / 120000: loss 0.000366\n",
      "iteration 50100 / 120000: loss 163.581566\n",
      "iteration 50200 / 120000: loss 0.000366\n",
      "iteration 50300 / 120000: loss 0.000370\n",
      "iteration 50400 / 120000: loss 0.000369\n",
      "iteration 50500 / 120000: loss 0.000370\n",
      "iteration 50600 / 120000: loss 43.586900\n",
      "iteration 50700 / 120000: loss 42.202868\n",
      "iteration 50800 / 120000: loss 0.000372\n",
      "iteration 50900 / 120000: loss 0.000375\n",
      "iteration 51000 / 120000: loss 0.000374\n",
      "iteration 51100 / 120000: loss 0.000377\n",
      "iteration 51200 / 120000: loss 0.000376\n",
      "iteration 51300 / 120000: loss 0.000372\n",
      "iteration 51400 / 120000: loss 0.000374\n",
      "iteration 51500 / 120000: loss 0.000374\n",
      "iteration 51600 / 120000: loss 0.000378\n",
      "iteration 51700 / 120000: loss 0.000380\n",
      "iteration 51800 / 120000: loss 82.225240\n",
      "iteration 51900 / 120000: loss 0.000383\n",
      "iteration 52000 / 120000: loss 0.000385\n",
      "iteration 52100 / 120000: loss 0.000386\n",
      "iteration 52200 / 120000: loss 0.000387\n",
      "iteration 52300 / 120000: loss 0.000387\n",
      "iteration 52400 / 120000: loss 0.000388\n",
      "iteration 52500 / 120000: loss 0.000387\n",
      "iteration 52600 / 120000: loss 0.000387\n",
      "iteration 52700 / 120000: loss 0.000387\n",
      "iteration 52800 / 120000: loss 0.000388\n",
      "iteration 52900 / 120000: loss 0.000388\n",
      "iteration 53000 / 120000: loss 21.106182\n",
      "iteration 53100 / 120000: loss 0.000390\n",
      "iteration 53200 / 120000: loss 0.000390\n",
      "iteration 53300 / 120000: loss 0.000391\n",
      "iteration 53400 / 120000: loss 0.000391\n",
      "iteration 53500 / 120000: loss 0.000391\n",
      "iteration 53600 / 120000: loss 0.000390\n",
      "iteration 53700 / 120000: loss 0.000392\n",
      "iteration 53800 / 120000: loss 0.000395\n",
      "iteration 53900 / 120000: loss 0.000393\n",
      "iteration 54000 / 120000: loss 0.000394\n",
      "iteration 54100 / 120000: loss 0.000394\n",
      "iteration 54200 / 120000: loss 0.000394\n",
      "iteration 54300 / 120000: loss 76.037827\n",
      "iteration 54400 / 120000: loss 0.000395\n",
      "iteration 54500 / 120000: loss 0.000395\n",
      "iteration 54600 / 120000: loss 0.000397\n",
      "iteration 54700 / 120000: loss 0.000397\n",
      "iteration 54800 / 120000: loss 0.000397\n",
      "iteration 54900 / 120000: loss 0.000400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 55000 / 120000: loss 0.000401\n",
      "iteration 55100 / 120000: loss 0.000403\n",
      "iteration 55200 / 120000: loss 0.000403\n",
      "iteration 55300 / 120000: loss 0.000403\n",
      "iteration 55400 / 120000: loss 0.000405\n",
      "iteration 55500 / 120000: loss 0.000408\n",
      "iteration 55600 / 120000: loss 80.511238\n",
      "iteration 55700 / 120000: loss 0.000412\n",
      "iteration 55800 / 120000: loss 0.000411\n",
      "iteration 55900 / 120000: loss 0.000411\n",
      "iteration 56000 / 120000: loss 0.000412\n",
      "iteration 56100 / 120000: loss 0.000415\n",
      "iteration 56200 / 120000: loss 8.459759\n",
      "iteration 56300 / 120000: loss 0.000415\n",
      "iteration 56400 / 120000: loss 0.000414\n",
      "iteration 56500 / 120000: loss 0.000413\n",
      "iteration 56600 / 120000: loss 0.000414\n",
      "iteration 56700 / 120000: loss 98.908114\n",
      "iteration 56800 / 120000: loss 1.582315\n",
      "iteration 56900 / 120000: loss 203.844994\n",
      "iteration 57000 / 120000: loss 0.000417\n",
      "iteration 57100 / 120000: loss 0.000417\n",
      "iteration 57200 / 120000: loss 0.000418\n",
      "iteration 57300 / 120000: loss 0.000420\n",
      "iteration 57400 / 120000: loss 0.000421\n",
      "iteration 57500 / 120000: loss 0.000422\n",
      "iteration 57600 / 120000: loss 0.000423\n",
      "iteration 57700 / 120000: loss 0.000424\n",
      "iteration 57800 / 120000: loss 0.000423\n",
      "iteration 57900 / 120000: loss 34.490113\n",
      "iteration 58000 / 120000: loss 0.000423\n",
      "iteration 58100 / 120000: loss 0.000425\n",
      "iteration 58200 / 120000: loss 0.000424\n",
      "iteration 58300 / 120000: loss 0.000424\n",
      "iteration 58400 / 120000: loss 0.000426\n",
      "iteration 58500 / 120000: loss 39.321947\n",
      "iteration 58600 / 120000: loss 0.000428\n",
      "iteration 58700 / 120000: loss 73.723399\n",
      "iteration 58800 / 120000: loss 0.000431\n",
      "iteration 58900 / 120000: loss 29.322449\n",
      "iteration 59000 / 120000: loss 0.000434\n",
      "iteration 59100 / 120000: loss 0.000434\n",
      "iteration 59200 / 120000: loss 0.000435\n",
      "iteration 59300 / 120000: loss 148.712717\n",
      "iteration 59400 / 120000: loss 0.000437\n",
      "iteration 59500 / 120000: loss 0.000438\n",
      "iteration 59600 / 120000: loss 0.000441\n",
      "iteration 59700 / 120000: loss 0.000442\n",
      "iteration 59800 / 120000: loss 0.000445\n",
      "iteration 59900 / 120000: loss 17.062029\n",
      "iteration 60000 / 120000: loss 0.000445\n",
      "iteration 60100 / 120000: loss 0.000446\n",
      "iteration 60200 / 120000: loss 20.010729\n",
      "iteration 60300 / 120000: loss 0.000449\n",
      "iteration 60400 / 120000: loss 0.000450\n",
      "iteration 60500 / 120000: loss 0.000452\n",
      "iteration 60600 / 120000: loss 0.000453\n",
      "iteration 60700 / 120000: loss 0.000455\n",
      "iteration 60800 / 120000: loss 52.662775\n",
      "iteration 60900 / 120000: loss 0.000453\n",
      "iteration 61000 / 120000: loss 0.000453\n",
      "iteration 61100 / 120000: loss 0.000452\n",
      "iteration 61200 / 120000: loss 0.000451\n",
      "iteration 61300 / 120000: loss 0.000450\n",
      "iteration 61400 / 120000: loss 0.000450\n",
      "iteration 61500 / 120000: loss 0.000449\n",
      "iteration 61600 / 120000: loss 0.000449\n",
      "iteration 61700 / 120000: loss 0.000447\n",
      "iteration 61800 / 120000: loss 0.000450\n",
      "iteration 61900 / 120000: loss 0.000451\n",
      "iteration 62000 / 120000: loss 192.557172\n",
      "iteration 62100 / 120000: loss 0.680398\n",
      "iteration 62200 / 120000: loss 0.000453\n",
      "iteration 62300 / 120000: loss 0.000452\n",
      "iteration 62400 / 120000: loss 0.000451\n",
      "iteration 62500 / 120000: loss 0.000451\n",
      "iteration 62600 / 120000: loss 0.000452\n",
      "iteration 62700 / 120000: loss 0.000451\n",
      "iteration 62800 / 120000: loss 0.000453\n",
      "iteration 62900 / 120000: loss 0.000453\n",
      "iteration 63000 / 120000: loss 0.000452\n",
      "iteration 63100 / 120000: loss 0.000452\n",
      "iteration 63200 / 120000: loss 0.000453\n",
      "iteration 63300 / 120000: loss 0.000455\n",
      "iteration 63400 / 120000: loss 0.000457\n",
      "iteration 63500 / 120000: loss 0.000458\n",
      "iteration 63600 / 120000: loss 16.731035\n",
      "iteration 63700 / 120000: loss 0.000462\n",
      "iteration 63800 / 120000: loss 185.639380\n",
      "iteration 63900 / 120000: loss 53.135844\n",
      "iteration 64000 / 120000: loss 135.773418\n",
      "iteration 64100 / 120000: loss 0.000464\n",
      "iteration 64200 / 120000: loss 0.000464\n",
      "iteration 64300 / 120000: loss 0.000466\n",
      "iteration 64400 / 120000: loss 0.000464\n",
      "iteration 64500 / 120000: loss 0.000466\n",
      "iteration 64600 / 120000: loss 0.000468\n",
      "iteration 64700 / 120000: loss 0.000468\n",
      "iteration 64800 / 120000: loss 0.000470\n",
      "iteration 64900 / 120000: loss 0.000471\n",
      "iteration 65000 / 120000: loss 0.000473\n",
      "iteration 65100 / 120000: loss 0.000471\n",
      "iteration 65200 / 120000: loss 0.000474\n",
      "iteration 65300 / 120000: loss 0.000477\n",
      "iteration 65400 / 120000: loss 5.555302\n",
      "iteration 65500 / 120000: loss 0.000476\n",
      "iteration 65600 / 120000: loss 0.000481\n",
      "iteration 65700 / 120000: loss 0.000480\n",
      "iteration 65800 / 120000: loss 0.000483\n",
      "iteration 65900 / 120000: loss 0.000482\n",
      "iteration 66000 / 120000: loss 0.000482\n",
      "iteration 66100 / 120000: loss 0.000483\n",
      "iteration 66200 / 120000: loss 0.000478\n",
      "iteration 66300 / 120000: loss 68.006903\n",
      "iteration 66400 / 120000: loss 0.000482\n",
      "iteration 66500 / 120000: loss 0.000484\n",
      "iteration 66600 / 120000: loss 0.000488\n",
      "iteration 66700 / 120000: loss 0.000490\n",
      "iteration 66800 / 120000: loss 0.000490\n",
      "iteration 66900 / 120000: loss 0.000489\n",
      "iteration 67000 / 120000: loss 0.000489\n",
      "iteration 67100 / 120000: loss 0.000489\n",
      "iteration 67200 / 120000: loss 13.255771\n",
      "iteration 67300 / 120000: loss 0.000493\n",
      "iteration 67400 / 120000: loss 0.000496\n",
      "iteration 67500 / 120000: loss 0.000499\n",
      "iteration 67600 / 120000: loss 0.000499\n",
      "iteration 67700 / 120000: loss 32.626279\n",
      "iteration 67800 / 120000: loss 0.000497\n",
      "iteration 67900 / 120000: loss 0.000497\n",
      "iteration 68000 / 120000: loss 165.919098\n",
      "iteration 68100 / 120000: loss 84.677925\n",
      "iteration 68200 / 120000: loss 0.000496\n",
      "iteration 68300 / 120000: loss 0.000497\n",
      "iteration 68400 / 120000: loss 0.000496\n",
      "iteration 68500 / 120000: loss 60.719037\n",
      "iteration 68600 / 120000: loss 0.000500\n",
      "iteration 68700 / 120000: loss 0.000500\n",
      "iteration 68800 / 120000: loss 139.351500\n",
      "iteration 68900 / 120000: loss 0.000497\n",
      "iteration 69000 / 120000: loss 0.000496\n",
      "iteration 69100 / 120000: loss 0.000496\n",
      "iteration 69200 / 120000: loss 0.000497\n",
      "iteration 69300 / 120000: loss 0.000498\n",
      "iteration 69400 / 120000: loss 31.220647\n",
      "iteration 69500 / 120000: loss 0.000496\n",
      "iteration 69600 / 120000: loss 0.000498\n",
      "iteration 69700 / 120000: loss 49.642723\n",
      "iteration 69800 / 120000: loss 0.000502\n",
      "iteration 69900 / 120000: loss 0.000505\n",
      "iteration 70000 / 120000: loss 0.000507\n",
      "iteration 70100 / 120000: loss 0.000508\n",
      "iteration 70200 / 120000: loss 0.000507\n",
      "iteration 70300 / 120000: loss 27.875565\n",
      "iteration 70400 / 120000: loss 27.083911\n",
      "iteration 70500 / 120000: loss 0.000510\n",
      "iteration 70600 / 120000: loss 0.000511\n",
      "iteration 70700 / 120000: loss 101.834477\n",
      "iteration 70800 / 120000: loss 0.000509\n",
      "iteration 70900 / 120000: loss 0.000508\n",
      "iteration 71000 / 120000: loss 0.000510\n",
      "iteration 71100 / 120000: loss 0.000510\n",
      "iteration 71200 / 120000: loss 0.000512\n",
      "iteration 71300 / 120000: loss 0.000512\n",
      "iteration 71400 / 120000: loss 0.000512\n",
      "iteration 71500 / 120000: loss 0.000511\n",
      "iteration 71600 / 120000: loss 46.912046\n",
      "iteration 71700 / 120000: loss 0.000513\n",
      "iteration 71800 / 120000: loss 12.607808\n",
      "iteration 71900 / 120000: loss 0.000516\n",
      "iteration 72000 / 120000: loss 0.000519\n",
      "iteration 72100 / 120000: loss 0.000522\n",
      "iteration 72200 / 120000: loss 15.444228\n",
      "iteration 72300 / 120000: loss 0.000523\n",
      "iteration 72400 / 120000: loss 0.000523\n",
      "iteration 72500 / 120000: loss 0.000524\n",
      "iteration 72600 / 120000: loss 0.000525\n",
      "iteration 72700 / 120000: loss 0.000526\n",
      "iteration 72800 / 120000: loss 19.569874\n",
      "iteration 72900 / 120000: loss 0.000529\n",
      "iteration 73000 / 120000: loss 0.000531\n",
      "iteration 73100 / 120000: loss 0.000529\n",
      "iteration 73200 / 120000: loss 0.000531\n",
      "iteration 73300 / 120000: loss 0.000531\n",
      "iteration 73400 / 120000: loss 0.000530\n",
      "iteration 73500 / 120000: loss 0.000529\n",
      "iteration 73600 / 120000: loss 0.000529\n",
      "iteration 73700 / 120000: loss 44.363183\n",
      "iteration 73800 / 120000: loss 187.485076\n",
      "iteration 73900 / 120000: loss 0.000531\n",
      "iteration 74000 / 120000: loss 0.000532\n",
      "iteration 74100 / 120000: loss 0.000532\n",
      "iteration 74200 / 120000: loss 0.000531\n",
      "iteration 74300 / 120000: loss 0.000532\n",
      "iteration 74400 / 120000: loss 140.382202\n",
      "iteration 74500 / 120000: loss 0.000536\n",
      "iteration 74600 / 120000: loss 19.630694\n",
      "iteration 74700 / 120000: loss 0.000534\n",
      "iteration 74800 / 120000: loss 0.000536\n",
      "iteration 74900 / 120000: loss 0.000536\n",
      "iteration 75000 / 120000: loss 0.000538\n",
      "iteration 75100 / 120000: loss 0.000538\n",
      "iteration 75200 / 120000: loss 0.000540\n",
      "iteration 75300 / 120000: loss 0.000542\n",
      "iteration 75400 / 120000: loss 0.000543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 75500 / 120000: loss 0.000545\n",
      "iteration 75600 / 120000: loss 0.000546\n",
      "iteration 75700 / 120000: loss 40.213544\n",
      "iteration 75800 / 120000: loss 0.000548\n",
      "iteration 75900 / 120000: loss 26.980375\n",
      "iteration 76000 / 120000: loss 0.000547\n",
      "iteration 76100 / 120000: loss 0.000548\n",
      "iteration 76200 / 120000: loss 0.000551\n",
      "iteration 76300 / 120000: loss 0.000551\n",
      "iteration 76400 / 120000: loss 0.000555\n",
      "iteration 76500 / 120000: loss 0.000556\n",
      "iteration 76600 / 120000: loss 0.000557\n",
      "iteration 76700 / 120000: loss 0.000558\n",
      "iteration 76800 / 120000: loss 21.189952\n",
      "iteration 76900 / 120000: loss 0.000562\n",
      "iteration 77000 / 120000: loss 38.850613\n",
      "iteration 77100 / 120000: loss 0.000561\n",
      "iteration 77200 / 120000: loss 0.000563\n",
      "iteration 77300 / 120000: loss 0.000560\n",
      "iteration 77400 / 120000: loss 0.000559\n",
      "iteration 77500 / 120000: loss 0.000562\n",
      "iteration 77600 / 120000: loss 0.000562\n",
      "iteration 77700 / 120000: loss 34.635704\n",
      "iteration 77800 / 120000: loss 0.000565\n",
      "iteration 77900 / 120000: loss 0.000564\n",
      "iteration 78000 / 120000: loss 1.301589\n",
      "iteration 78100 / 120000: loss 0.000566\n",
      "iteration 78200 / 120000: loss 0.000567\n",
      "iteration 78300 / 120000: loss 0.000569\n",
      "iteration 78400 / 120000: loss 0.000570\n",
      "iteration 78500 / 120000: loss 0.000572\n",
      "iteration 78600 / 120000: loss 0.000570\n",
      "iteration 78700 / 120000: loss 0.000572\n",
      "iteration 78800 / 120000: loss 0.000571\n",
      "iteration 78900 / 120000: loss 6.507064\n",
      "iteration 79000 / 120000: loss 34.187906\n",
      "iteration 79100 / 120000: loss 0.000574\n",
      "iteration 79200 / 120000: loss 35.442375\n",
      "iteration 79300 / 120000: loss 0.000577\n",
      "iteration 79400 / 120000: loss 0.000577\n",
      "iteration 79500 / 120000: loss 0.000576\n",
      "iteration 79600 / 120000: loss 0.000578\n",
      "iteration 79700 / 120000: loss 53.979688\n",
      "iteration 79800 / 120000: loss 0.000575\n",
      "iteration 79900 / 120000: loss 0.000576\n",
      "iteration 80000 / 120000: loss 0.000575\n",
      "iteration 80100 / 120000: loss 0.000575\n",
      "iteration 80200 / 120000: loss 0.000574\n",
      "iteration 80300 / 120000: loss 0.000575\n",
      "iteration 80400 / 120000: loss 0.000575\n",
      "iteration 80500 / 120000: loss 0.000575\n",
      "iteration 80600 / 120000: loss 0.000575\n",
      "iteration 80700 / 120000: loss 0.000574\n",
      "iteration 80800 / 120000: loss 70.864246\n",
      "iteration 80900 / 120000: loss 47.640625\n",
      "iteration 81000 / 120000: loss 0.000579\n",
      "iteration 81100 / 120000: loss 0.000579\n",
      "iteration 81200 / 120000: loss 0.000580\n",
      "iteration 81300 / 120000: loss 0.000576\n",
      "iteration 81400 / 120000: loss 0.000574\n",
      "iteration 81500 / 120000: loss 0.000575\n",
      "iteration 81600 / 120000: loss 0.000577\n",
      "iteration 81700 / 120000: loss 0.000579\n",
      "iteration 81800 / 120000: loss 0.000579\n",
      "iteration 81900 / 120000: loss 89.606513\n",
      "iteration 82000 / 120000: loss 0.000581\n",
      "iteration 82100 / 120000: loss 0.000583\n",
      "iteration 82200 / 120000: loss 0.000583\n",
      "iteration 82300 / 120000: loss 18.210565\n",
      "iteration 82400 / 120000: loss 40.170129\n",
      "iteration 82500 / 120000: loss 139.500465\n",
      "iteration 82600 / 120000: loss 20.935453\n",
      "iteration 82700 / 120000: loss 0.000589\n",
      "iteration 82800 / 120000: loss 0.000591\n",
      "iteration 82900 / 120000: loss 0.000591\n",
      "iteration 83000 / 120000: loss 0.000591\n",
      "iteration 83100 / 120000: loss 0.000592\n",
      "iteration 83200 / 120000: loss 0.000593\n",
      "iteration 83300 / 120000: loss 0.000593\n",
      "iteration 83400 / 120000: loss 51.554630\n",
      "iteration 83500 / 120000: loss 149.828001\n",
      "iteration 83600 / 120000: loss 0.000595\n",
      "iteration 83700 / 120000: loss 0.000596\n",
      "iteration 83800 / 120000: loss 49.151594\n",
      "iteration 83900 / 120000: loss 0.000598\n",
      "iteration 84000 / 120000: loss 0.000601\n",
      "iteration 84100 / 120000: loss 48.315681\n",
      "iteration 84200 / 120000: loss 76.912666\n",
      "iteration 84300 / 120000: loss 0.000604\n",
      "iteration 84400 / 120000: loss 0.000605\n",
      "iteration 84500 / 120000: loss 0.000604\n",
      "iteration 84600 / 120000: loss 3.579766\n",
      "iteration 84700 / 120000: loss 0.000606\n",
      "iteration 84800 / 120000: loss 0.000607\n",
      "iteration 84900 / 120000: loss 0.000606\n",
      "iteration 85000 / 120000: loss 0.000604\n",
      "iteration 85100 / 120000: loss 0.000606\n",
      "iteration 85200 / 120000: loss 0.000607\n",
      "iteration 85300 / 120000: loss 0.000606\n",
      "iteration 85400 / 120000: loss 0.000607\n",
      "iteration 85500 / 120000: loss 54.871772\n",
      "iteration 85600 / 120000: loss 0.000608\n",
      "iteration 85700 / 120000: loss 110.321384\n",
      "iteration 85800 / 120000: loss 0.000612\n",
      "iteration 85900 / 120000: loss 79.792443\n",
      "iteration 86000 / 120000: loss 0.000616\n",
      "iteration 86100 / 120000: loss 6.716518\n",
      "iteration 86200 / 120000: loss 0.000616\n",
      "iteration 86300 / 120000: loss 325.867056\n",
      "iteration 86400 / 120000: loss 0.000616\n",
      "iteration 86500 / 120000: loss 0.000618\n",
      "iteration 86600 / 120000: loss 0.000620\n",
      "iteration 86700 / 120000: loss 0.000618\n",
      "iteration 86800 / 120000: loss 0.000618\n",
      "iteration 86900 / 120000: loss 33.768946\n",
      "iteration 87000 / 120000: loss 0.000617\n",
      "iteration 87100 / 120000: loss 0.000618\n",
      "iteration 87200 / 120000: loss 0.000620\n",
      "iteration 87300 / 120000: loss 0.000621\n",
      "iteration 87400 / 120000: loss 0.000621\n",
      "iteration 87500 / 120000: loss 0.000621\n",
      "iteration 87600 / 120000: loss 0.000618\n",
      "iteration 87700 / 120000: loss 0.000618\n",
      "iteration 87800 / 120000: loss 53.512304\n",
      "iteration 87900 / 120000: loss 0.000619\n",
      "iteration 88000 / 120000: loss 0.000618\n",
      "iteration 88100 / 120000: loss 0.000618\n",
      "iteration 88200 / 120000: loss 0.000617\n",
      "iteration 88300 / 120000: loss 0.000618\n",
      "iteration 88400 / 120000: loss 0.000621\n",
      "iteration 88500 / 120000: loss 0.000623\n",
      "iteration 88600 / 120000: loss 0.000624\n",
      "iteration 88700 / 120000: loss 0.000623\n",
      "iteration 88800 / 120000: loss 5.365908\n",
      "iteration 88900 / 120000: loss 7.774505\n",
      "iteration 89000 / 120000: loss 6.835860\n",
      "iteration 89100 / 120000: loss 0.000626\n",
      "iteration 89200 / 120000: loss 117.694145\n",
      "iteration 89300 / 120000: loss 0.000625\n",
      "iteration 89400 / 120000: loss 0.000626\n",
      "iteration 89500 / 120000: loss 0.000628\n",
      "iteration 89600 / 120000: loss 0.000630\n",
      "iteration 89700 / 120000: loss 0.000631\n",
      "iteration 89800 / 120000: loss 6.379091\n",
      "iteration 89900 / 120000: loss 0.000627\n",
      "iteration 90000 / 120000: loss 0.000626\n",
      "iteration 90100 / 120000: loss 0.000626\n",
      "iteration 90200 / 120000: loss 0.000627\n",
      "iteration 90300 / 120000: loss 70.390543\n",
      "iteration 90400 / 120000: loss 51.755093\n",
      "iteration 90500 / 120000: loss 0.000626\n",
      "iteration 90600 / 120000: loss 0.000628\n",
      "iteration 90700 / 120000: loss 0.000629\n",
      "iteration 90800 / 120000: loss 0.000630\n",
      "iteration 90900 / 120000: loss 0.000632\n",
      "iteration 91000 / 120000: loss 0.000631\n",
      "iteration 91100 / 120000: loss 0.000634\n",
      "iteration 91200 / 120000: loss 0.000635\n",
      "iteration 91300 / 120000: loss 0.000638\n",
      "iteration 91400 / 120000: loss 0.000638\n",
      "iteration 91500 / 120000: loss 0.000640\n",
      "iteration 91600 / 120000: loss 63.608092\n",
      "iteration 91700 / 120000: loss 0.000641\n",
      "iteration 91800 / 120000: loss 0.000640\n",
      "iteration 91900 / 120000: loss 0.000643\n",
      "iteration 92000 / 120000: loss 0.000645\n",
      "iteration 92100 / 120000: loss 0.000644\n",
      "iteration 92200 / 120000: loss 84.677514\n",
      "iteration 92300 / 120000: loss 0.000643\n",
      "iteration 92400 / 120000: loss 0.000643\n",
      "iteration 92500 / 120000: loss 0.000646\n",
      "iteration 92600 / 120000: loss 0.000644\n",
      "iteration 92700 / 120000: loss 35.050604\n",
      "iteration 92800 / 120000: loss 0.000645\n",
      "iteration 92900 / 120000: loss 0.000648\n",
      "iteration 93000 / 120000: loss 0.000649\n",
      "iteration 93100 / 120000: loss 20.175804\n",
      "iteration 93200 / 120000: loss 21.244030\n",
      "iteration 93300 / 120000: loss 31.371757\n",
      "iteration 93400 / 120000: loss 0.000656\n",
      "iteration 93500 / 120000: loss 81.758262\n",
      "iteration 93600 / 120000: loss 120.774591\n",
      "iteration 93700 / 120000: loss 0.000659\n",
      "iteration 93800 / 120000: loss 0.000660\n",
      "iteration 93900 / 120000: loss 0.000659\n",
      "iteration 94000 / 120000: loss 0.000661\n",
      "iteration 94100 / 120000: loss 0.000658\n",
      "iteration 94200 / 120000: loss 0.000657\n",
      "iteration 94300 / 120000: loss 3.396309\n",
      "iteration 94400 / 120000: loss 0.000660\n",
      "iteration 94500 / 120000: loss 62.840207\n",
      "iteration 94600 / 120000: loss 0.000658\n",
      "iteration 94700 / 120000: loss 0.000659\n",
      "iteration 94800 / 120000: loss 0.000659\n",
      "iteration 94900 / 120000: loss 0.000662\n",
      "iteration 95000 / 120000: loss 0.000660\n",
      "iteration 95100 / 120000: loss 0.000661\n",
      "iteration 95200 / 120000: loss 50.658792\n",
      "iteration 95300 / 120000: loss 0.000664\n",
      "iteration 95400 / 120000: loss 135.312434\n",
      "iteration 95500 / 120000: loss 74.324370\n",
      "iteration 95600 / 120000: loss 0.000665\n",
      "iteration 95700 / 120000: loss 0.000666\n",
      "iteration 95800 / 120000: loss 6.193767\n",
      "iteration 95900 / 120000: loss 0.000667\n",
      "iteration 96000 / 120000: loss 0.000671\n",
      "iteration 96100 / 120000: loss 9.651098\n",
      "iteration 96200 / 120000: loss 0.000671\n",
      "iteration 96300 / 120000: loss 0.000670\n",
      "iteration 96400 / 120000: loss 0.000666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 96500 / 120000: loss 42.637155\n",
      "iteration 96600 / 120000: loss 0.000667\n",
      "iteration 96700 / 120000: loss 109.074014\n",
      "iteration 96800 / 120000: loss 172.701387\n",
      "iteration 96900 / 120000: loss 0.000670\n",
      "iteration 97000 / 120000: loss 0.000674\n",
      "iteration 97100 / 120000: loss 0.000675\n",
      "iteration 97200 / 120000: loss 0.000675\n",
      "iteration 97300 / 120000: loss 0.000674\n",
      "iteration 97400 / 120000: loss 155.192834\n",
      "iteration 97500 / 120000: loss 0.000677\n",
      "iteration 97600 / 120000: loss 0.000678\n",
      "iteration 97700 / 120000: loss 0.000678\n",
      "iteration 97800 / 120000: loss 0.000676\n",
      "iteration 97900 / 120000: loss 0.000678\n",
      "iteration 98000 / 120000: loss 0.000679\n",
      "iteration 98100 / 120000: loss 0.000678\n",
      "iteration 98200 / 120000: loss 30.331084\n",
      "iteration 98300 / 120000: loss 0.000680\n",
      "iteration 98400 / 120000: loss 0.000682\n",
      "iteration 98500 / 120000: loss 0.000683\n",
      "iteration 98600 / 120000: loss 0.000683\n",
      "iteration 98700 / 120000: loss 0.000684\n",
      "iteration 98800 / 120000: loss 0.000684\n",
      "iteration 98900 / 120000: loss 0.000683\n",
      "iteration 99000 / 120000: loss 0.000683\n",
      "iteration 99100 / 120000: loss 0.000683\n",
      "iteration 99200 / 120000: loss 0.000683\n",
      "iteration 99300 / 120000: loss 0.000685\n",
      "iteration 99400 / 120000: loss 30.468531\n",
      "iteration 99500 / 120000: loss 0.000686\n",
      "iteration 99600 / 120000: loss 3.584051\n",
      "iteration 99700 / 120000: loss 0.000685\n",
      "iteration 99800 / 120000: loss 0.000685\n",
      "iteration 99900 / 120000: loss 0.000685\n",
      "iteration 100000 / 120000: loss 7.835291\n",
      "iteration 100100 / 120000: loss 0.000684\n",
      "iteration 100200 / 120000: loss 217.076079\n",
      "iteration 100300 / 120000: loss 0.000684\n",
      "iteration 100400 / 120000: loss 0.000682\n",
      "iteration 100500 / 120000: loss 90.957700\n",
      "iteration 100600 / 120000: loss 0.000681\n",
      "iteration 100700 / 120000: loss 0.000682\n",
      "iteration 100800 / 120000: loss 23.102478\n",
      "iteration 100900 / 120000: loss 0.000679\n",
      "iteration 101000 / 120000: loss 25.513948\n",
      "iteration 101100 / 120000: loss 0.000681\n",
      "iteration 101200 / 120000: loss 0.000683\n",
      "iteration 101300 / 120000: loss 0.000687\n",
      "iteration 101400 / 120000: loss 0.000688\n",
      "iteration 101500 / 120000: loss 0.000687\n",
      "iteration 101600 / 120000: loss 0.000686\n",
      "iteration 101700 / 120000: loss 0.000687\n",
      "iteration 101800 / 120000: loss 59.649488\n",
      "iteration 101900 / 120000: loss 0.000690\n",
      "iteration 102000 / 120000: loss 17.891453\n",
      "iteration 102100 / 120000: loss 0.000690\n",
      "iteration 102200 / 120000: loss 0.000692\n",
      "iteration 102300 / 120000: loss 0.000693\n",
      "iteration 102400 / 120000: loss 388.563448\n",
      "iteration 102500 / 120000: loss 0.000691\n",
      "iteration 102600 / 120000: loss 0.000692\n",
      "iteration 102700 / 120000: loss 0.000691\n",
      "iteration 102800 / 120000: loss 46.176424\n",
      "iteration 102900 / 120000: loss 16.663934\n",
      "iteration 103000 / 120000: loss 0.000695\n",
      "iteration 103100 / 120000: loss 0.000694\n",
      "iteration 103200 / 120000: loss 0.000694\n",
      "iteration 103300 / 120000: loss 125.727605\n",
      "iteration 103400 / 120000: loss 0.000697\n",
      "iteration 103500 / 120000: loss 69.292962\n",
      "iteration 103600 / 120000: loss 0.000699\n",
      "iteration 103700 / 120000: loss 0.000701\n",
      "iteration 103800 / 120000: loss 0.000703\n",
      "iteration 103900 / 120000: loss 0.000704\n",
      "iteration 104000 / 120000: loss 0.000706\n",
      "iteration 104100 / 120000: loss 0.000708\n",
      "iteration 104200 / 120000: loss 0.000709\n",
      "iteration 104300 / 120000: loss 0.000710\n",
      "iteration 104400 / 120000: loss 0.000710\n",
      "iteration 104500 / 120000: loss 0.000713\n",
      "iteration 104600 / 120000: loss 0.000712\n",
      "iteration 104700 / 120000: loss 0.000709\n",
      "iteration 104800 / 120000: loss 0.000709\n",
      "iteration 104900 / 120000: loss 0.000712\n",
      "iteration 105000 / 120000: loss 0.000712\n",
      "iteration 105100 / 120000: loss 58.729629\n",
      "iteration 105200 / 120000: loss 0.000711\n",
      "iteration 105300 / 120000: loss 0.000712\n",
      "iteration 105400 / 120000: loss 40.158389\n",
      "iteration 105500 / 120000: loss 0.000715\n",
      "iteration 105600 / 120000: loss 63.389238\n",
      "iteration 105700 / 120000: loss 0.000718\n",
      "iteration 105800 / 120000: loss 109.726342\n",
      "iteration 105900 / 120000: loss 0.000720\n",
      "iteration 106000 / 120000: loss 45.783160\n",
      "iteration 106100 / 120000: loss 0.000724\n",
      "iteration 106200 / 120000: loss 0.000725\n",
      "iteration 106300 / 120000: loss 0.000726\n",
      "iteration 106400 / 120000: loss 0.000728\n",
      "iteration 106500 / 120000: loss 0.000728\n",
      "iteration 106600 / 120000: loss 0.000729\n",
      "iteration 106700 / 120000: loss 0.000731\n",
      "iteration 106800 / 120000: loss 0.000733\n",
      "iteration 106900 / 120000: loss 4.873694\n",
      "iteration 107000 / 120000: loss 167.516991\n",
      "iteration 107100 / 120000: loss 0.000734\n",
      "iteration 107200 / 120000: loss 0.000732\n",
      "iteration 107300 / 120000: loss 0.000732\n",
      "iteration 107400 / 120000: loss 0.000732\n",
      "iteration 107500 / 120000: loss 0.000733\n",
      "iteration 107600 / 120000: loss 0.000733\n",
      "iteration 107700 / 120000: loss 0.000734\n",
      "iteration 107800 / 120000: loss 0.000735\n",
      "iteration 107900 / 120000: loss 0.000735\n",
      "iteration 108000 / 120000: loss 0.000736\n",
      "iteration 108100 / 120000: loss 70.333311\n",
      "iteration 108200 / 120000: loss 0.000740\n",
      "iteration 108300 / 120000: loss 0.000742\n",
      "iteration 108400 / 120000: loss 0.000744\n",
      "iteration 108500 / 120000: loss 0.000745\n",
      "iteration 108600 / 120000: loss 0.000747\n",
      "iteration 108700 / 120000: loss 0.000745\n",
      "iteration 108800 / 120000: loss 29.094375\n",
      "iteration 108900 / 120000: loss 0.000745\n",
      "iteration 109000 / 120000: loss 0.000745\n",
      "iteration 109100 / 120000: loss 0.000745\n",
      "iteration 109200 / 120000: loss 15.270238\n",
      "iteration 109300 / 120000: loss 0.000746\n",
      "iteration 109400 / 120000: loss 47.963174\n",
      "iteration 109500 / 120000: loss 0.000747\n",
      "iteration 109600 / 120000: loss 0.000750\n",
      "iteration 109700 / 120000: loss 0.000752\n",
      "iteration 109800 / 120000: loss 36.297815\n",
      "iteration 109900 / 120000: loss 0.000754\n",
      "iteration 110000 / 120000: loss 0.000757\n",
      "iteration 110100 / 120000: loss 9.639097\n",
      "iteration 110200 / 120000: loss 21.405866\n",
      "iteration 110300 / 120000: loss 159.723152\n",
      "iteration 110400 / 120000: loss 0.000753\n",
      "iteration 110500 / 120000: loss 0.000755\n",
      "iteration 110600 / 120000: loss 0.000756\n",
      "iteration 110700 / 120000: loss 0.000754\n",
      "iteration 110800 / 120000: loss 0.000753\n",
      "iteration 110900 / 120000: loss 0.000751\n",
      "iteration 111000 / 120000: loss 17.462219\n",
      "iteration 111100 / 120000: loss 15.643866\n",
      "iteration 111200 / 120000: loss 0.000755\n",
      "iteration 111300 / 120000: loss 0.000755\n",
      "iteration 111400 / 120000: loss 0.000754\n",
      "iteration 111500 / 120000: loss 0.000754\n",
      "iteration 111600 / 120000: loss 0.000756\n",
      "iteration 111700 / 120000: loss 0.000757\n",
      "iteration 111800 / 120000: loss 30.715741\n",
      "iteration 111900 / 120000: loss 56.758145\n",
      "iteration 112000 / 120000: loss 0.000764\n",
      "iteration 112100 / 120000: loss 227.791765\n",
      "iteration 112200 / 120000: loss 0.000766\n",
      "iteration 112300 / 120000: loss 0.000767\n",
      "iteration 112400 / 120000: loss 0.000766\n",
      "iteration 112500 / 120000: loss 0.000768\n",
      "iteration 112600 / 120000: loss 0.000771\n",
      "iteration 112700 / 120000: loss 0.000771\n",
      "iteration 112800 / 120000: loss 0.000772\n",
      "iteration 112900 / 120000: loss 0.000774\n",
      "iteration 113000 / 120000: loss 230.738593\n",
      "iteration 113100 / 120000: loss 50.994271\n",
      "iteration 113200 / 120000: loss 0.000773\n",
      "iteration 113300 / 120000: loss 0.000776\n",
      "iteration 113400 / 120000: loss 0.000775\n",
      "iteration 113500 / 120000: loss 0.000778\n",
      "iteration 113600 / 120000: loss 0.000777\n",
      "iteration 113700 / 120000: loss 0.000780\n",
      "iteration 113800 / 120000: loss 0.000781\n",
      "iteration 113900 / 120000: loss 0.000783\n",
      "iteration 114000 / 120000: loss 0.000783\n",
      "iteration 114100 / 120000: loss 0.000782\n",
      "iteration 114200 / 120000: loss 0.000785\n",
      "iteration 114300 / 120000: loss 0.000785\n",
      "iteration 114400 / 120000: loss 0.000785\n",
      "iteration 114500 / 120000: loss 20.548681\n",
      "iteration 114600 / 120000: loss 0.000788\n",
      "iteration 114700 / 120000: loss 0.000786\n",
      "iteration 114800 / 120000: loss 0.000785\n",
      "iteration 114900 / 120000: loss 0.160552\n",
      "iteration 115000 / 120000: loss 117.277846\n",
      "iteration 115100 / 120000: loss 0.000781\n",
      "iteration 115200 / 120000: loss 21.747418\n",
      "iteration 115300 / 120000: loss 0.000781\n",
      "iteration 115400 / 120000: loss 33.856145\n",
      "iteration 115500 / 120000: loss 0.000788\n",
      "iteration 115600 / 120000: loss 0.000787\n",
      "iteration 115700 / 120000: loss 0.000789\n",
      "iteration 115800 / 120000: loss 0.000790\n",
      "iteration 115900 / 120000: loss 0.000789\n",
      "iteration 116000 / 120000: loss 0.000791\n",
      "iteration 116100 / 120000: loss 0.000793\n",
      "iteration 116200 / 120000: loss 37.977162\n",
      "iteration 116300 / 120000: loss 0.000795\n",
      "iteration 116400 / 120000: loss 65.762750\n",
      "iteration 116500 / 120000: loss 0.000798\n",
      "iteration 116600 / 120000: loss 0.000800\n",
      "iteration 116700 / 120000: loss 0.000800\n",
      "iteration 116800 / 120000: loss 0.000802\n",
      "iteration 116900 / 120000: loss 0.000803\n",
      "iteration 117000 / 120000: loss 0.000805\n",
      "iteration 117100 / 120000: loss 0.000804\n",
      "iteration 117200 / 120000: loss 0.000804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 117300 / 120000: loss 0.000802\n",
      "iteration 117400 / 120000: loss 0.000802\n",
      "iteration 117500 / 120000: loss 0.000804\n",
      "iteration 117600 / 120000: loss 13.958326\n",
      "iteration 117700 / 120000: loss 99.863049\n",
      "iteration 117800 / 120000: loss 0.000804\n",
      "iteration 117900 / 120000: loss 0.000806\n",
      "iteration 118000 / 120000: loss 0.000808\n",
      "iteration 118100 / 120000: loss 0.000809\n",
      "iteration 118200 / 120000: loss 0.000808\n",
      "iteration 118300 / 120000: loss 0.000809\n",
      "iteration 118400 / 120000: loss 0.000808\n",
      "iteration 118500 / 120000: loss 0.000810\n",
      "iteration 118600 / 120000: loss 0.000808\n",
      "iteration 118700 / 120000: loss 0.000809\n",
      "iteration 118800 / 120000: loss 0.000810\n",
      "iteration 118900 / 120000: loss 48.734672\n",
      "iteration 119000 / 120000: loss 0.000814\n",
      "iteration 119100 / 120000: loss 0.000814\n",
      "iteration 119200 / 120000: loss 0.000815\n",
      "iteration 119300 / 120000: loss 10.271272\n",
      "iteration 119400 / 120000: loss 0.000816\n",
      "iteration 119500 / 120000: loss 0.000815\n",
      "iteration 119600 / 120000: loss 0.000813\n",
      "iteration 119700 / 120000: loss 0.000813\n",
      "iteration 119800 / 120000: loss 196.582397\n",
      "iteration 119900 / 120000: loss 0.000815\n",
      "lr=5e-06 bs=1 regularization_rate=0.0005\n",
      "iteration 0 / 120000: loss 0.885955\n",
      "iteration 100 / 120000: loss 0.000004\n",
      "iteration 200 / 120000: loss 0.000007\n",
      "iteration 300 / 120000: loss 4.355715\n",
      "iteration 400 / 120000: loss 0.000013\n",
      "iteration 500 / 120000: loss 0.000013\n",
      "iteration 600 / 120000: loss 0.000016\n",
      "iteration 700 / 120000: loss 8.032079\n",
      "iteration 800 / 120000: loss 0.000020\n",
      "iteration 900 / 120000: loss 0.000019\n",
      "iteration 1000 / 120000: loss 0.000022\n",
      "iteration 1100 / 120000: loss 65.603336\n",
      "iteration 1200 / 120000: loss 0.000024\n",
      "iteration 1300 / 120000: loss 3.403458\n",
      "iteration 1400 / 120000: loss 25.473324\n",
      "iteration 1500 / 120000: loss 55.445998\n",
      "iteration 1600 / 120000: loss 0.000028\n",
      "iteration 1700 / 120000: loss 0.000031\n",
      "iteration 1800 / 120000: loss 0.000033\n",
      "iteration 1900 / 120000: loss 0.000034\n",
      "iteration 2000 / 120000: loss 8.893167\n",
      "iteration 2100 / 120000: loss 0.000037\n",
      "iteration 2200 / 120000: loss 0.000038\n",
      "iteration 2300 / 120000: loss 0.000040\n",
      "iteration 2400 / 120000: loss 10.634239\n",
      "iteration 2500 / 120000: loss 0.000041\n",
      "iteration 2600 / 120000: loss 0.000043\n",
      "iteration 2700 / 120000: loss 0.000043\n",
      "iteration 2800 / 120000: loss 87.755783\n",
      "iteration 2900 / 120000: loss 0.000043\n",
      "iteration 3000 / 120000: loss 32.781245\n",
      "iteration 3100 / 120000: loss 0.000044\n",
      "iteration 3200 / 120000: loss 0.000044\n",
      "iteration 3300 / 120000: loss 0.000045\n",
      "iteration 3400 / 120000: loss 0.000046\n",
      "iteration 3500 / 120000: loss 0.000049\n",
      "iteration 3600 / 120000: loss 0.000049\n",
      "iteration 3700 / 120000: loss 0.000049\n",
      "iteration 3800 / 120000: loss 0.000050\n",
      "iteration 3900 / 120000: loss 0.000051\n",
      "iteration 4000 / 120000: loss 0.000052\n",
      "iteration 4100 / 120000: loss 0.000054\n",
      "iteration 4200 / 120000: loss 80.409235\n",
      "iteration 4300 / 120000: loss 0.000056\n",
      "iteration 4400 / 120000: loss 0.000057\n",
      "iteration 4500 / 120000: loss 4.424497\n",
      "iteration 4600 / 120000: loss 0.000061\n",
      "iteration 4700 / 120000: loss 0.000061\n",
      "iteration 4800 / 120000: loss 0.000059\n",
      "iteration 4900 / 120000: loss 0.000059\n",
      "iteration 5000 / 120000: loss 0.000058\n",
      "iteration 5100 / 120000: loss 22.350226\n",
      "iteration 5200 / 120000: loss 0.000060\n",
      "iteration 5300 / 120000: loss 0.000060\n",
      "iteration 5400 / 120000: loss 0.000058\n",
      "iteration 5500 / 120000: loss 84.122180\n",
      "iteration 5600 / 120000: loss 0.000060\n",
      "iteration 5700 / 120000: loss 0.000059\n",
      "iteration 5800 / 120000: loss 0.000062\n",
      "iteration 5900 / 120000: loss 0.000064\n",
      "iteration 6000 / 120000: loss 0.000067\n",
      "iteration 6100 / 120000: loss 15.117205\n",
      "iteration 6200 / 120000: loss 196.887916\n",
      "iteration 6300 / 120000: loss 0.000070\n",
      "iteration 6400 / 120000: loss 0.000070\n",
      "iteration 6500 / 120000: loss 83.171996\n",
      "iteration 6600 / 120000: loss 0.000073\n",
      "iteration 6700 / 120000: loss 121.167389\n",
      "iteration 6800 / 120000: loss 0.000076\n",
      "iteration 6900 / 120000: loss 0.000076\n",
      "iteration 7000 / 120000: loss 0.000075\n",
      "iteration 7100 / 120000: loss 0.000076\n",
      "iteration 7200 / 120000: loss 0.000076\n",
      "iteration 7300 / 120000: loss 135.193100\n",
      "iteration 7400 / 120000: loss 0.000077\n",
      "iteration 7500 / 120000: loss 0.000077\n",
      "iteration 7600 / 120000: loss 0.000079\n",
      "iteration 7700 / 120000: loss 0.000080\n",
      "iteration 7800 / 120000: loss 0.000079\n",
      "iteration 7900 / 120000: loss 0.000077\n",
      "iteration 8000 / 120000: loss 1.961324\n",
      "iteration 8100 / 120000: loss 23.413148\n",
      "iteration 8200 / 120000: loss 0.000080\n",
      "iteration 8300 / 120000: loss 0.000081\n",
      "iteration 8400 / 120000: loss 8.647127\n",
      "iteration 8500 / 120000: loss 0.000086\n",
      "iteration 8600 / 120000: loss 0.000085\n",
      "iteration 8700 / 120000: loss 0.000085\n",
      "iteration 8800 / 120000: loss 119.263391\n",
      "iteration 8900 / 120000: loss 27.862072\n",
      "iteration 9000 / 120000: loss 28.503236\n",
      "iteration 9100 / 120000: loss 0.000084\n",
      "iteration 9200 / 120000: loss 1.547515\n",
      "iteration 9300 / 120000: loss 0.000086\n",
      "iteration 9400 / 120000: loss 75.080454\n",
      "iteration 9500 / 120000: loss 0.000088\n",
      "iteration 9600 / 120000: loss 0.000091\n",
      "iteration 9700 / 120000: loss 0.000091\n",
      "iteration 9800 / 120000: loss 0.000092\n",
      "iteration 9900 / 120000: loss 1.489601\n",
      "iteration 10000 / 120000: loss 15.162413\n",
      "iteration 10100 / 120000: loss 0.000091\n",
      "iteration 10200 / 120000: loss 119.756797\n",
      "iteration 10300 / 120000: loss 118.240010\n",
      "iteration 10400 / 120000: loss 183.332785\n",
      "iteration 10500 / 120000: loss 0.000097\n",
      "iteration 10600 / 120000: loss 0.000097\n",
      "iteration 10700 / 120000: loss 0.000098\n",
      "iteration 10800 / 120000: loss 0.000097\n",
      "iteration 10900 / 120000: loss 0.000096\n",
      "iteration 11000 / 120000: loss 95.736921\n",
      "iteration 11100 / 120000: loss 0.000097\n",
      "iteration 11200 / 120000: loss 0.000096\n",
      "iteration 11300 / 120000: loss 0.000098\n",
      "iteration 11400 / 120000: loss 100.987128\n",
      "iteration 11500 / 120000: loss 0.000097\n",
      "iteration 11600 / 120000: loss 131.830470\n",
      "iteration 11700 / 120000: loss 0.000098\n",
      "iteration 11800 / 120000: loss 0.000099\n",
      "iteration 11900 / 120000: loss 41.164883\n",
      "iteration 12000 / 120000: loss 0.000104\n",
      "iteration 12100 / 120000: loss 0.000106\n",
      "iteration 12200 / 120000: loss 0.000106\n",
      "iteration 12300 / 120000: loss 0.000107\n",
      "iteration 12400 / 120000: loss 9.418829\n",
      "iteration 12500 / 120000: loss 0.000105\n",
      "iteration 12600 / 120000: loss 0.000108\n",
      "iteration 12700 / 120000: loss 0.000109\n",
      "iteration 12800 / 120000: loss 0.000110\n",
      "iteration 12900 / 120000: loss 14.925701\n",
      "iteration 13000 / 120000: loss 17.624877\n",
      "iteration 13100 / 120000: loss 0.000112\n",
      "iteration 13200 / 120000: loss 0.000111\n",
      "iteration 13300 / 120000: loss 0.000112\n",
      "iteration 13400 / 120000: loss 0.000112\n",
      "iteration 13500 / 120000: loss 0.000112\n",
      "iteration 13600 / 120000: loss 0.000115\n",
      "iteration 13700 / 120000: loss 0.000115\n",
      "iteration 13800 / 120000: loss 171.031266\n",
      "iteration 13900 / 120000: loss 9.156318\n",
      "iteration 14000 / 120000: loss 0.000119\n",
      "iteration 14100 / 120000: loss 0.000120\n",
      "iteration 14200 / 120000: loss 29.551238\n",
      "iteration 14300 / 120000: loss 0.000121\n",
      "iteration 14400 / 120000: loss 63.916866\n",
      "iteration 14500 / 120000: loss 0.000121\n",
      "iteration 14600 / 120000: loss 0.000121\n",
      "iteration 14700 / 120000: loss 0.000123\n",
      "iteration 14800 / 120000: loss 0.000124\n",
      "iteration 14900 / 120000: loss 0.000124\n",
      "iteration 15000 / 120000: loss 0.000125\n",
      "iteration 15100 / 120000: loss 17.650916\n",
      "iteration 15200 / 120000: loss 0.000127\n",
      "iteration 15300 / 120000: loss 0.000127\n",
      "iteration 15400 / 120000: loss 0.000129\n",
      "iteration 15500 / 120000: loss 33.821807\n",
      "iteration 15600 / 120000: loss 0.000131\n",
      "iteration 15700 / 120000: loss 0.000131\n",
      "iteration 15800 / 120000: loss 0.000131\n",
      "iteration 15900 / 120000: loss 0.000131\n",
      "iteration 16000 / 120000: loss 0.000132\n",
      "iteration 16100 / 120000: loss 0.000131\n",
      "iteration 16200 / 120000: loss 35.149348\n",
      "iteration 16300 / 120000: loss 146.903330\n",
      "iteration 16400 / 120000: loss 0.000131\n",
      "iteration 16500 / 120000: loss 0.000132\n",
      "iteration 16600 / 120000: loss 0.000133\n",
      "iteration 16700 / 120000: loss 0.000133\n",
      "iteration 16800 / 120000: loss 0.000131\n",
      "iteration 16900 / 120000: loss 0.000135\n",
      "iteration 17000 / 120000: loss 26.979683\n",
      "iteration 17100 / 120000: loss 0.000136\n",
      "iteration 17200 / 120000: loss 142.926759\n",
      "iteration 17300 / 120000: loss 0.000142\n",
      "iteration 17400 / 120000: loss 0.000141\n",
      "iteration 17500 / 120000: loss 198.560219\n",
      "iteration 17600 / 120000: loss 0.000143\n",
      "iteration 17700 / 120000: loss 0.000142\n",
      "iteration 17800 / 120000: loss 0.000141\n",
      "iteration 17900 / 120000: loss 153.147438\n",
      "iteration 18000 / 120000: loss 0.000142\n",
      "iteration 18100 / 120000: loss 0.000143\n",
      "iteration 18200 / 120000: loss 0.000146\n",
      "iteration 18300 / 120000: loss 0.000146\n",
      "iteration 18400 / 120000: loss 0.000146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 18500 / 120000: loss 0.000146\n",
      "iteration 18600 / 120000: loss 0.000144\n",
      "iteration 18700 / 120000: loss 0.000145\n",
      "iteration 18800 / 120000: loss 0.000146\n",
      "iteration 18900 / 120000: loss 0.000145\n",
      "iteration 19000 / 120000: loss 0.000147\n",
      "iteration 19100 / 120000: loss 72.899479\n",
      "iteration 19200 / 120000: loss 21.779759\n",
      "iteration 19300 / 120000: loss 67.583649\n",
      "iteration 19400 / 120000: loss 96.154171\n",
      "iteration 19500 / 120000: loss 0.000152\n",
      "iteration 19600 / 120000: loss 102.890217\n",
      "iteration 19700 / 120000: loss 187.291489\n",
      "iteration 19800 / 120000: loss 0.000155\n",
      "iteration 19900 / 120000: loss 0.000154\n",
      "iteration 20000 / 120000: loss 0.000155\n",
      "iteration 20100 / 120000: loss 0.000155\n",
      "iteration 20200 / 120000: loss 96.118463\n",
      "iteration 20300 / 120000: loss 0.000154\n",
      "iteration 20400 / 120000: loss 0.000156\n",
      "iteration 20500 / 120000: loss 0.000156\n",
      "iteration 20600 / 120000: loss 36.523174\n",
      "iteration 20700 / 120000: loss 0.000158\n",
      "iteration 20800 / 120000: loss 88.998395\n",
      "iteration 20900 / 120000: loss 0.000160\n",
      "iteration 21000 / 120000: loss 0.000161\n",
      "iteration 21100 / 120000: loss 0.000160\n",
      "iteration 21200 / 120000: loss 0.000161\n",
      "iteration 21300 / 120000: loss 0.000162\n",
      "iteration 21400 / 120000: loss 0.000162\n",
      "iteration 21500 / 120000: loss 0.000162\n",
      "iteration 21600 / 120000: loss 25.577331\n",
      "iteration 21700 / 120000: loss 78.029690\n",
      "iteration 21800 / 120000: loss 144.856620\n",
      "iteration 21900 / 120000: loss 0.000168\n",
      "iteration 22000 / 120000: loss 0.000167\n",
      "iteration 22100 / 120000: loss 0.000169\n",
      "iteration 22200 / 120000: loss 0.000170\n",
      "iteration 22300 / 120000: loss 0.000170\n",
      "iteration 22400 / 120000: loss 0.000171\n",
      "iteration 22500 / 120000: loss 0.000169\n",
      "iteration 22600 / 120000: loss 17.870504\n",
      "iteration 22700 / 120000: loss 0.000170\n",
      "iteration 22800 / 120000: loss 0.000169\n",
      "iteration 22900 / 120000: loss 0.000169\n",
      "iteration 23000 / 120000: loss 0.000169\n",
      "iteration 23100 / 120000: loss 0.000169\n",
      "iteration 23200 / 120000: loss 0.000169\n",
      "iteration 23300 / 120000: loss 0.000171\n",
      "iteration 23400 / 120000: loss 0.000172\n",
      "iteration 23500 / 120000: loss 0.000173\n",
      "iteration 23600 / 120000: loss 115.035577\n",
      "iteration 23700 / 120000: loss 158.997387\n",
      "iteration 23800 / 120000: loss 0.000173\n",
      "iteration 23900 / 120000: loss 16.580734\n",
      "iteration 24000 / 120000: loss 0.000175\n",
      "iteration 24100 / 120000: loss 0.000175\n",
      "iteration 24200 / 120000: loss 0.000176\n",
      "iteration 24300 / 120000: loss 0.000178\n",
      "iteration 24400 / 120000: loss 16.152425\n",
      "iteration 24500 / 120000: loss 0.000181\n",
      "iteration 24600 / 120000: loss 0.000184\n",
      "iteration 24700 / 120000: loss 0.000183\n",
      "iteration 24800 / 120000: loss 0.000184\n",
      "iteration 24900 / 120000: loss 0.000184\n",
      "iteration 25000 / 120000: loss 0.000186\n",
      "iteration 25100 / 120000: loss 0.000184\n",
      "iteration 25200 / 120000: loss 0.000185\n",
      "iteration 25300 / 120000: loss 0.000186\n",
      "iteration 25400 / 120000: loss 34.944231\n",
      "iteration 25500 / 120000: loss 0.000190\n",
      "iteration 25600 / 120000: loss 0.000194\n",
      "iteration 25700 / 120000: loss 0.000196\n",
      "iteration 25800 / 120000: loss 0.000197\n",
      "iteration 25900 / 120000: loss 0.000199\n",
      "iteration 26000 / 120000: loss 0.000198\n",
      "iteration 26100 / 120000: loss 0.000198\n",
      "iteration 26200 / 120000: loss 2.316744\n",
      "iteration 26300 / 120000: loss 0.000198\n",
      "iteration 26400 / 120000: loss 0.000198\n",
      "iteration 26500 / 120000: loss 0.000199\n",
      "iteration 26600 / 120000: loss 45.305349\n",
      "iteration 26700 / 120000: loss 0.000198\n",
      "iteration 26800 / 120000: loss 42.635536\n",
      "iteration 26900 / 120000: loss 0.000201\n",
      "iteration 27000 / 120000: loss 0.000201\n",
      "iteration 27100 / 120000: loss 0.000203\n",
      "iteration 27200 / 120000: loss 0.000201\n",
      "iteration 27300 / 120000: loss 0.000201\n",
      "iteration 27400 / 120000: loss 0.000199\n",
      "iteration 27500 / 120000: loss 0.000199\n",
      "iteration 27600 / 120000: loss 26.349450\n",
      "iteration 27700 / 120000: loss 0.000199\n",
      "iteration 27800 / 120000: loss 52.587342\n",
      "iteration 27900 / 120000: loss 0.000203\n",
      "iteration 28000 / 120000: loss 0.000204\n",
      "iteration 28100 / 120000: loss 0.000206\n",
      "iteration 28200 / 120000: loss 0.000205\n",
      "iteration 28300 / 120000: loss 0.000206\n",
      "iteration 28400 / 120000: loss 92.759159\n",
      "iteration 28500 / 120000: loss 0.000204\n",
      "iteration 28600 / 120000: loss 0.000204\n",
      "iteration 28700 / 120000: loss 0.000204\n",
      "iteration 28800 / 120000: loss 0.000205\n",
      "iteration 28900 / 120000: loss 0.000206\n",
      "iteration 29000 / 120000: loss 0.000206\n",
      "iteration 29100 / 120000: loss 6.053778\n",
      "iteration 29200 / 120000: loss 0.000208\n",
      "iteration 29300 / 120000: loss 0.000208\n",
      "iteration 29400 / 120000: loss 0.000210\n",
      "iteration 29500 / 120000: loss 0.000212\n",
      "iteration 29600 / 120000: loss 17.278355\n",
      "iteration 29700 / 120000: loss 0.000213\n",
      "iteration 29800 / 120000: loss 0.000215\n",
      "iteration 29900 / 120000: loss 0.000215\n",
      "iteration 30000 / 120000: loss 0.000216\n",
      "iteration 30100 / 120000: loss 65.959848\n",
      "iteration 30200 / 120000: loss 0.000214\n",
      "iteration 30300 / 120000: loss 0.000215\n",
      "iteration 30400 / 120000: loss 0.000216\n",
      "iteration 30500 / 120000: loss 0.000216\n",
      "iteration 30600 / 120000: loss 0.000217\n",
      "iteration 30700 / 120000: loss 50.864286\n",
      "iteration 30800 / 120000: loss 0.000220\n",
      "iteration 30900 / 120000: loss 0.000220\n",
      "iteration 31000 / 120000: loss 56.824015\n",
      "iteration 31100 / 120000: loss 0.000220\n",
      "iteration 31200 / 120000: loss 38.789345\n",
      "iteration 31300 / 120000: loss 0.000221\n",
      "iteration 31400 / 120000: loss 0.000222\n",
      "iteration 31500 / 120000: loss 0.000221\n",
      "iteration 31600 / 120000: loss 44.428617\n",
      "iteration 31700 / 120000: loss 0.000217\n",
      "iteration 31800 / 120000: loss 0.000219\n",
      "iteration 31900 / 120000: loss 9.702723\n",
      "iteration 32000 / 120000: loss 0.000221\n",
      "iteration 32100 / 120000: loss 0.000221\n",
      "iteration 32200 / 120000: loss 0.000221\n",
      "iteration 32300 / 120000: loss 0.000223\n",
      "iteration 32400 / 120000: loss 112.140903\n",
      "iteration 32500 / 120000: loss 0.000223\n",
      "iteration 32600 / 120000: loss 0.000225\n",
      "iteration 32700 / 120000: loss 7.378677\n",
      "iteration 32800 / 120000: loss 0.000226\n",
      "iteration 32900 / 120000: loss 0.703000\n",
      "iteration 33000 / 120000: loss 0.000224\n",
      "iteration 33100 / 120000: loss 0.000225\n",
      "iteration 33200 / 120000: loss 0.000225\n",
      "iteration 33300 / 120000: loss 0.000231\n",
      "iteration 33400 / 120000: loss 211.974935\n",
      "iteration 33500 / 120000: loss 0.000229\n",
      "iteration 33600 / 120000: loss 0.000229\n",
      "iteration 33700 / 120000: loss 0.000231\n",
      "iteration 33800 / 120000: loss 0.000233\n",
      "iteration 33900 / 120000: loss 0.000232\n",
      "iteration 34000 / 120000: loss 54.650815\n",
      "iteration 34100 / 120000: loss 0.000232\n",
      "iteration 34200 / 120000: loss 62.856875\n",
      "iteration 34300 / 120000: loss 0.000231\n",
      "iteration 34400 / 120000: loss 0.000232\n",
      "iteration 34500 / 120000: loss 0.000229\n",
      "iteration 34600 / 120000: loss 0.000230\n",
      "iteration 34700 / 120000: loss 31.352993\n",
      "iteration 34800 / 120000: loss 0.000230\n",
      "iteration 34900 / 120000: loss 0.000229\n",
      "iteration 35000 / 120000: loss 0.000230\n",
      "iteration 35100 / 120000: loss 0.000230\n",
      "iteration 35200 / 120000: loss 75.290787\n",
      "iteration 35300 / 120000: loss 0.000233\n",
      "iteration 35400 / 120000: loss 0.000233\n",
      "iteration 35500 / 120000: loss 0.000235\n",
      "iteration 35600 / 120000: loss 0.000234\n",
      "iteration 35700 / 120000: loss 0.000236\n",
      "iteration 35800 / 120000: loss 16.589614\n",
      "iteration 35900 / 120000: loss 0.000235\n",
      "iteration 36000 / 120000: loss 21.482193\n",
      "iteration 36100 / 120000: loss 0.000235\n",
      "iteration 36200 / 120000: loss 26.989004\n",
      "iteration 36300 / 120000: loss 0.000233\n",
      "iteration 36400 / 120000: loss 0.000234\n",
      "iteration 36500 / 120000: loss 0.000233\n",
      "iteration 36600 / 120000: loss 0.000233\n",
      "iteration 36700 / 120000: loss 0.000233\n",
      "iteration 36800 / 120000: loss 0.000234\n",
      "iteration 36900 / 120000: loss 0.000232\n",
      "iteration 37000 / 120000: loss 131.754329\n",
      "iteration 37100 / 120000: loss 0.000236\n",
      "iteration 37200 / 120000: loss 46.838251\n",
      "iteration 37300 / 120000: loss 132.428997\n",
      "iteration 37400 / 120000: loss 0.000239\n",
      "iteration 37500 / 120000: loss 0.000238\n",
      "iteration 37600 / 120000: loss 0.000238\n",
      "iteration 37700 / 120000: loss 0.000240\n",
      "iteration 37800 / 120000: loss 0.000243\n",
      "iteration 37900 / 120000: loss 130.636529\n",
      "iteration 38000 / 120000: loss 0.000243\n",
      "iteration 38100 / 120000: loss 0.000242\n",
      "iteration 38200 / 120000: loss 112.880424\n",
      "iteration 38300 / 120000: loss 0.000244\n",
      "iteration 38400 / 120000: loss 0.000244\n",
      "iteration 38500 / 120000: loss 0.000246\n",
      "iteration 38600 / 120000: loss 33.158015\n",
      "iteration 38700 / 120000: loss 0.000246\n",
      "iteration 38800 / 120000: loss 0.000246\n",
      "iteration 38900 / 120000: loss 62.488548\n",
      "iteration 39000 / 120000: loss 109.513646\n",
      "iteration 39100 / 120000: loss 0.000248\n",
      "iteration 39200 / 120000: loss 0.000249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 39300 / 120000: loss 0.000248\n",
      "iteration 39400 / 120000: loss 89.489608\n",
      "iteration 39500 / 120000: loss 5.153289\n",
      "iteration 39600 / 120000: loss 0.000255\n",
      "iteration 39700 / 120000: loss 0.000257\n",
      "iteration 39800 / 120000: loss 0.000259\n",
      "iteration 39900 / 120000: loss 0.000260\n",
      "iteration 40000 / 120000: loss 71.511512\n",
      "iteration 40100 / 120000: loss 0.000261\n",
      "iteration 40200 / 120000: loss 1.521610\n",
      "iteration 40300 / 120000: loss 108.908554\n",
      "iteration 40400 / 120000: loss 0.000268\n",
      "iteration 40500 / 120000: loss 0.000269\n",
      "iteration 40600 / 120000: loss 0.000272\n",
      "iteration 40700 / 120000: loss 0.000273\n",
      "iteration 40800 / 120000: loss 31.660609\n",
      "iteration 40900 / 120000: loss 0.000270\n",
      "iteration 41000 / 120000: loss 133.273805\n",
      "iteration 41100 / 120000: loss 0.000270\n",
      "iteration 41200 / 120000: loss 0.000270\n",
      "iteration 41300 / 120000: loss 0.000272\n",
      "iteration 41400 / 120000: loss 0.000271\n",
      "iteration 41500 / 120000: loss 25.565825\n",
      "iteration 41600 / 120000: loss 0.000272\n",
      "iteration 41700 / 120000: loss 0.000272\n",
      "iteration 41800 / 120000: loss 12.947384\n",
      "iteration 41900 / 120000: loss 66.500166\n",
      "iteration 42000 / 120000: loss 0.000273\n",
      "iteration 42100 / 120000: loss 0.000273\n",
      "iteration 42200 / 120000: loss 0.000275\n",
      "iteration 42300 / 120000: loss 0.000275\n",
      "iteration 42400 / 120000: loss 0.000274\n",
      "iteration 42500 / 120000: loss 0.000274\n",
      "iteration 42600 / 120000: loss 0.000275\n",
      "iteration 42700 / 120000: loss 0.000277\n",
      "iteration 42800 / 120000: loss 44.222315\n",
      "iteration 42900 / 120000: loss 245.630026\n",
      "iteration 43000 / 120000: loss 0.000278\n",
      "iteration 43100 / 120000: loss 0.000280\n",
      "iteration 43200 / 120000: loss 3.376556\n",
      "iteration 43300 / 120000: loss 77.804538\n",
      "iteration 43400 / 120000: loss 0.000282\n",
      "iteration 43500 / 120000: loss 63.010828\n",
      "iteration 43600 / 120000: loss 0.000286\n",
      "iteration 43700 / 120000: loss 0.000287\n",
      "iteration 43800 / 120000: loss 248.608548\n",
      "iteration 43900 / 120000: loss 0.000293\n",
      "iteration 44000 / 120000: loss 27.817399\n",
      "iteration 44100 / 120000: loss 0.000292\n",
      "iteration 44200 / 120000: loss 0.000293\n",
      "iteration 44300 / 120000: loss 0.000294\n",
      "iteration 44400 / 120000: loss 0.000295\n",
      "iteration 44500 / 120000: loss 0.000297\n",
      "iteration 44600 / 120000: loss 0.000298\n",
      "iteration 44700 / 120000: loss 96.118581\n",
      "iteration 44800 / 120000: loss 0.000300\n",
      "iteration 44900 / 120000: loss 6.626015\n",
      "iteration 45000 / 120000: loss 170.307516\n",
      "iteration 45100 / 120000: loss 0.000300\n",
      "iteration 45200 / 120000: loss 123.441335\n",
      "iteration 45300 / 120000: loss 0.000303\n",
      "iteration 45400 / 120000: loss 0.000305\n",
      "iteration 45500 / 120000: loss 0.000306\n",
      "iteration 45600 / 120000: loss 0.000307\n",
      "iteration 45700 / 120000: loss 83.997385\n",
      "iteration 45800 / 120000: loss 0.000307\n",
      "iteration 45900 / 120000: loss 0.000309\n",
      "iteration 46000 / 120000: loss 0.000309\n",
      "iteration 46100 / 120000: loss 0.000309\n",
      "iteration 46200 / 120000: loss 0.000309\n",
      "iteration 46300 / 120000: loss 0.000311\n",
      "iteration 46400 / 120000: loss 0.000311\n",
      "iteration 46500 / 120000: loss 7.538621\n",
      "iteration 46600 / 120000: loss 0.000310\n",
      "iteration 46700 / 120000: loss 0.000312\n",
      "iteration 46800 / 120000: loss 0.000313\n",
      "iteration 46900 / 120000: loss 0.000315\n",
      "iteration 47000 / 120000: loss 0.000318\n",
      "iteration 47100 / 120000: loss 0.000319\n",
      "iteration 47200 / 120000: loss 0.000321\n",
      "iteration 47300 / 120000: loss 0.000321\n",
      "iteration 47400 / 120000: loss 39.929410\n",
      "iteration 47500 / 120000: loss 0.000323\n",
      "iteration 47600 / 120000: loss 0.000324\n",
      "iteration 47700 / 120000: loss 0.000324\n",
      "iteration 47800 / 120000: loss 0.000324\n",
      "iteration 47900 / 120000: loss 0.000325\n",
      "iteration 48000 / 120000: loss 0.000326\n",
      "iteration 48100 / 120000: loss 0.000325\n",
      "iteration 48200 / 120000: loss 0.000326\n",
      "iteration 48300 / 120000: loss 67.412613\n",
      "iteration 48400 / 120000: loss 0.000329\n",
      "iteration 48500 / 120000: loss 0.000328\n",
      "iteration 48600 / 120000: loss 0.000329\n",
      "iteration 48700 / 120000: loss 61.762881\n",
      "iteration 48800 / 120000: loss 0.000329\n",
      "iteration 48900 / 120000: loss 75.913335\n",
      "iteration 49000 / 120000: loss 33.778519\n",
      "iteration 49100 / 120000: loss 0.000332\n",
      "iteration 49200 / 120000: loss 0.000333\n",
      "iteration 49300 / 120000: loss 9.260520\n",
      "iteration 49400 / 120000: loss 0.000335\n",
      "iteration 49500 / 120000: loss 0.000336\n",
      "iteration 49600 / 120000: loss 0.000337\n",
      "iteration 49700 / 120000: loss 18.571843\n",
      "iteration 49800 / 120000: loss 0.000337\n",
      "iteration 49900 / 120000: loss 0.000338\n",
      "iteration 50000 / 120000: loss 0.000336\n",
      "iteration 50100 / 120000: loss 0.000338\n",
      "iteration 50200 / 120000: loss 0.000338\n",
      "iteration 50300 / 120000: loss 86.682943\n",
      "iteration 50400 / 120000: loss 0.000339\n",
      "iteration 50500 / 120000: loss 0.000341\n",
      "iteration 50600 / 120000: loss 0.000339\n",
      "iteration 50700 / 120000: loss 0.000343\n",
      "iteration 50800 / 120000: loss 0.000342\n",
      "iteration 50900 / 120000: loss 0.000342\n",
      "iteration 51000 / 120000: loss 0.000341\n",
      "iteration 51100 / 120000: loss 16.416610\n",
      "iteration 51200 / 120000: loss 0.000340\n",
      "iteration 51300 / 120000: loss 0.000340\n",
      "iteration 51400 / 120000: loss 0.000343\n",
      "iteration 51500 / 120000: loss 106.901665\n",
      "iteration 51600 / 120000: loss 168.876443\n",
      "iteration 51700 / 120000: loss 17.924730\n",
      "iteration 51800 / 120000: loss 9.385147\n",
      "iteration 51900 / 120000: loss 35.153407\n",
      "iteration 52000 / 120000: loss 0.000341\n",
      "iteration 52100 / 120000: loss 0.000338\n",
      "iteration 52200 / 120000: loss 37.649913\n",
      "iteration 52300 / 120000: loss 0.000341\n",
      "iteration 52400 / 120000: loss 0.000343\n",
      "iteration 52500 / 120000: loss 0.000342\n",
      "iteration 52600 / 120000: loss 0.000342\n",
      "iteration 52700 / 120000: loss 0.000342\n",
      "iteration 52800 / 120000: loss 0.000342\n",
      "iteration 52900 / 120000: loss 41.416065\n",
      "iteration 53000 / 120000: loss 51.241337\n",
      "iteration 53100 / 120000: loss 59.634435\n",
      "iteration 53200 / 120000: loss 0.000344\n",
      "iteration 53300 / 120000: loss 0.000347\n",
      "iteration 53400 / 120000: loss 0.000346\n",
      "iteration 53500 / 120000: loss 0.000344\n",
      "iteration 53600 / 120000: loss 40.656622\n",
      "iteration 53700 / 120000: loss 0.000342\n",
      "iteration 53800 / 120000: loss 95.757236\n",
      "iteration 53900 / 120000: loss 0.000344\n",
      "iteration 54000 / 120000: loss 0.000346\n",
      "iteration 54100 / 120000: loss 0.000348\n",
      "iteration 54200 / 120000: loss 0.000348\n",
      "iteration 54300 / 120000: loss 10.502340\n",
      "iteration 54400 / 120000: loss 0.000349\n",
      "iteration 54500 / 120000: loss 0.000348\n",
      "iteration 54600 / 120000: loss 0.000349\n",
      "iteration 54700 / 120000: loss 0.000349\n",
      "iteration 54800 / 120000: loss 0.000349\n",
      "iteration 54900 / 120000: loss 0.000348\n",
      "iteration 55000 / 120000: loss 0.000350\n",
      "iteration 55100 / 120000: loss 0.000352\n",
      "iteration 55200 / 120000: loss 0.000351\n",
      "iteration 55300 / 120000: loss 7.191692\n",
      "iteration 55400 / 120000: loss 0.000355\n",
      "iteration 55500 / 120000: loss 0.000355\n",
      "iteration 55600 / 120000: loss 0.000353\n",
      "iteration 55700 / 120000: loss 53.958205\n",
      "iteration 55800 / 120000: loss 0.000354\n",
      "iteration 55900 / 120000: loss 13.647038\n",
      "iteration 56000 / 120000: loss 0.000354\n",
      "iteration 56100 / 120000: loss 0.000354\n",
      "iteration 56200 / 120000: loss 82.407117\n",
      "iteration 56300 / 120000: loss 0.000354\n",
      "iteration 56400 / 120000: loss 0.000354\n",
      "iteration 56500 / 120000: loss 113.180778\n",
      "iteration 56600 / 120000: loss 151.677242\n",
      "iteration 56700 / 120000: loss 0.000354\n",
      "iteration 56800 / 120000: loss 0.000356\n",
      "iteration 56900 / 120000: loss 68.010209\n",
      "iteration 57000 / 120000: loss 0.000357\n",
      "iteration 57100 / 120000: loss 0.000358\n",
      "iteration 57200 / 120000: loss 0.000360\n",
      "iteration 57300 / 120000: loss 0.000362\n",
      "iteration 57400 / 120000: loss 0.000362\n",
      "iteration 57500 / 120000: loss 0.000364\n",
      "iteration 57600 / 120000: loss 0.000362\n",
      "iteration 57700 / 120000: loss 0.000363\n",
      "iteration 57800 / 120000: loss 0.000367\n",
      "iteration 57900 / 120000: loss 30.495839\n",
      "iteration 58000 / 120000: loss 0.000365\n",
      "iteration 58100 / 120000: loss 0.000367\n",
      "iteration 58200 / 120000: loss 0.000368\n",
      "iteration 58300 / 120000: loss 0.000369\n",
      "iteration 58400 / 120000: loss 0.135638\n",
      "iteration 58500 / 120000: loss 0.000369\n",
      "iteration 58600 / 120000: loss 0.000370\n",
      "iteration 58700 / 120000: loss 0.000370\n",
      "iteration 58800 / 120000: loss 0.000371\n",
      "iteration 58900 / 120000: loss 162.647677\n",
      "iteration 59000 / 120000: loss 0.000368\n",
      "iteration 59100 / 120000: loss 0.000369\n",
      "iteration 59200 / 120000: loss 0.000367\n",
      "iteration 59300 / 120000: loss 0.000366\n",
      "iteration 59400 / 120000: loss 0.000366\n",
      "iteration 59500 / 120000: loss 0.000368\n",
      "iteration 59600 / 120000: loss 0.000369\n",
      "iteration 59700 / 120000: loss 57.540105\n",
      "iteration 59800 / 120000: loss 0.000370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 59900 / 120000: loss 0.000370\n",
      "iteration 60000 / 120000: loss 0.000368\n",
      "iteration 60100 / 120000: loss 0.000367\n",
      "iteration 60200 / 120000: loss 0.000366\n",
      "iteration 60300 / 120000: loss 22.921447\n",
      "iteration 60400 / 120000: loss 0.000366\n",
      "iteration 60500 / 120000: loss 50.423458\n",
      "iteration 60600 / 120000: loss 0.000367\n",
      "iteration 60700 / 120000: loss 0.000368\n",
      "iteration 60800 / 120000: loss 11.587037\n",
      "iteration 60900 / 120000: loss 62.848753\n",
      "iteration 61000 / 120000: loss 0.000372\n",
      "iteration 61100 / 120000: loss 0.000374\n",
      "iteration 61200 / 120000: loss 0.000375\n",
      "iteration 61300 / 120000: loss 0.000378\n",
      "iteration 61400 / 120000: loss 0.000378\n",
      "iteration 61500 / 120000: loss 0.000380\n",
      "iteration 61600 / 120000: loss 0.000380\n",
      "iteration 61700 / 120000: loss 0.000379\n",
      "iteration 61800 / 120000: loss 0.000378\n",
      "iteration 61900 / 120000: loss 0.000381\n",
      "iteration 62000 / 120000: loss 0.000378\n",
      "iteration 62100 / 120000: loss 0.000380\n",
      "iteration 62200 / 120000: loss 0.000379\n",
      "iteration 62300 / 120000: loss 0.000381\n",
      "iteration 62400 / 120000: loss 0.000383\n",
      "iteration 62500 / 120000: loss 48.383991\n",
      "iteration 62600 / 120000: loss 0.000385\n",
      "iteration 62700 / 120000: loss 0.000383\n",
      "iteration 62800 / 120000: loss 62.469112\n",
      "iteration 62900 / 120000: loss 0.000385\n",
      "iteration 63000 / 120000: loss 0.000386\n",
      "iteration 63100 / 120000: loss 47.606854\n",
      "iteration 63200 / 120000: loss 0.000386\n",
      "iteration 63300 / 120000: loss 0.000383\n",
      "iteration 63400 / 120000: loss 112.662782\n",
      "iteration 63500 / 120000: loss 0.000386\n",
      "iteration 63600 / 120000: loss 0.000387\n",
      "iteration 63700 / 120000: loss 0.000386\n",
      "iteration 63800 / 120000: loss 0.000387\n",
      "iteration 63900 / 120000: loss 0.000388\n",
      "iteration 64000 / 120000: loss 0.000389\n",
      "iteration 64100 / 120000: loss 0.000388\n",
      "iteration 64200 / 120000: loss 0.000391\n",
      "iteration 64300 / 120000: loss 1.587119\n",
      "iteration 64400 / 120000: loss 53.020528\n",
      "iteration 64500 / 120000: loss 0.000388\n",
      "iteration 64600 / 120000: loss 0.000389\n",
      "iteration 64700 / 120000: loss 0.000390\n",
      "iteration 64800 / 120000: loss 87.469508\n",
      "iteration 64900 / 120000: loss 19.638352\n",
      "iteration 65000 / 120000: loss 0.000394\n",
      "iteration 65100 / 120000: loss 0.000394\n",
      "iteration 65200 / 120000: loss 0.000395\n",
      "iteration 65300 / 120000: loss 0.000395\n",
      "iteration 65400 / 120000: loss 0.000395\n",
      "iteration 65500 / 120000: loss 0.000396\n",
      "iteration 65600 / 120000: loss 38.143993\n",
      "iteration 65700 / 120000: loss 0.000397\n",
      "iteration 65800 / 120000: loss 12.389874\n",
      "iteration 65900 / 120000: loss 0.000397\n",
      "iteration 66000 / 120000: loss 0.000397\n",
      "iteration 66100 / 120000: loss 0.000397\n",
      "iteration 66200 / 120000: loss 0.000396\n",
      "iteration 66300 / 120000: loss 0.000395\n",
      "iteration 66400 / 120000: loss 0.000394\n",
      "iteration 66500 / 120000: loss 0.000394\n",
      "iteration 66600 / 120000: loss 0.000393\n",
      "iteration 66700 / 120000: loss 0.000392\n",
      "iteration 66800 / 120000: loss 53.101677\n",
      "iteration 66900 / 120000: loss 0.000394\n",
      "iteration 67000 / 120000: loss 0.000394\n",
      "iteration 67100 / 120000: loss 0.000395\n",
      "iteration 67200 / 120000: loss 0.000394\n",
      "iteration 67300 / 120000: loss 10.670955\n",
      "iteration 67400 / 120000: loss 0.000397\n",
      "iteration 67500 / 120000: loss 0.000399\n",
      "iteration 67600 / 120000: loss 0.000398\n",
      "iteration 67700 / 120000: loss 0.000400\n",
      "iteration 67800 / 120000: loss 0.000403\n",
      "iteration 67900 / 120000: loss 0.000402\n",
      "iteration 68000 / 120000: loss 0.000403\n",
      "iteration 68100 / 120000: loss 0.000406\n",
      "iteration 68200 / 120000: loss 0.000407\n",
      "iteration 68300 / 120000: loss 0.000406\n",
      "iteration 68400 / 120000: loss 0.000408\n",
      "iteration 68500 / 120000: loss 0.000410\n",
      "iteration 68600 / 120000: loss 0.000409\n",
      "iteration 68700 / 120000: loss 0.000409\n",
      "iteration 68800 / 120000: loss 0.000408\n",
      "iteration 68900 / 120000: loss 0.972700\n",
      "iteration 69000 / 120000: loss 0.000409\n",
      "iteration 69100 / 120000: loss 0.000409\n",
      "iteration 69200 / 120000: loss 34.517289\n",
      "iteration 69300 / 120000: loss 0.000414\n",
      "iteration 69400 / 120000: loss 0.000414\n",
      "iteration 69500 / 120000: loss 14.792678\n",
      "iteration 69600 / 120000: loss 0.000413\n",
      "iteration 69700 / 120000: loss 0.000414\n",
      "iteration 69800 / 120000: loss 0.000416\n",
      "iteration 69900 / 120000: loss 65.953142\n",
      "iteration 70000 / 120000: loss 354.507665\n",
      "iteration 70100 / 120000: loss 49.618222\n",
      "iteration 70200 / 120000: loss 0.000421\n",
      "iteration 70300 / 120000: loss 0.000422\n",
      "iteration 70400 / 120000: loss 0.000423\n",
      "iteration 70500 / 120000: loss 0.000425\n",
      "iteration 70600 / 120000: loss 0.000427\n",
      "iteration 70700 / 120000: loss 0.000429\n",
      "iteration 70800 / 120000: loss 0.000429\n",
      "iteration 70900 / 120000: loss 0.000429\n",
      "iteration 71000 / 120000: loss 0.000430\n",
      "iteration 71100 / 120000: loss 0.000431\n",
      "iteration 71200 / 120000: loss 0.000430\n",
      "iteration 71300 / 120000: loss 0.000431\n",
      "iteration 71400 / 120000: loss 0.000433\n",
      "iteration 71500 / 120000: loss 118.351164\n",
      "iteration 71600 / 120000: loss 0.000434\n",
      "iteration 71700 / 120000: loss 0.000433\n",
      "iteration 71800 / 120000: loss 0.000433\n",
      "iteration 71900 / 120000: loss 0.000434\n",
      "iteration 72000 / 120000: loss 36.088763\n",
      "iteration 72100 / 120000: loss 13.741062\n",
      "iteration 72200 / 120000: loss 0.000430\n",
      "iteration 72300 / 120000: loss 0.000431\n",
      "iteration 72400 / 120000: loss 16.302787\n",
      "iteration 72500 / 120000: loss 0.000433\n",
      "iteration 72600 / 120000: loss 0.000434\n",
      "iteration 72700 / 120000: loss 97.294538\n",
      "iteration 72800 / 120000: loss 0.000434\n",
      "iteration 72900 / 120000: loss 0.000435\n",
      "iteration 73000 / 120000: loss 0.000433\n",
      "iteration 73100 / 120000: loss 0.000432\n",
      "iteration 73200 / 120000: loss 0.000433\n",
      "iteration 73300 / 120000: loss 54.698354\n",
      "iteration 73400 / 120000: loss 0.000435\n",
      "iteration 73500 / 120000: loss 0.000435\n",
      "iteration 73600 / 120000: loss 0.000435\n",
      "iteration 73700 / 120000: loss 0.000436\n",
      "iteration 73800 / 120000: loss 13.033706\n",
      "iteration 73900 / 120000: loss 45.900628\n",
      "iteration 74000 / 120000: loss 0.000441\n",
      "iteration 74100 / 120000: loss 0.000442\n",
      "iteration 74200 / 120000: loss 193.622156\n",
      "iteration 74300 / 120000: loss 0.000439\n",
      "iteration 74400 / 120000: loss 0.000441\n",
      "iteration 74500 / 120000: loss 0.000444\n",
      "iteration 74600 / 120000: loss 0.000445\n",
      "iteration 74700 / 120000: loss 0.000445\n",
      "iteration 74800 / 120000: loss 0.000446\n",
      "iteration 74900 / 120000: loss 0.000447\n",
      "iteration 75000 / 120000: loss 0.000448\n",
      "iteration 75100 / 120000: loss 38.598474\n",
      "iteration 75200 / 120000: loss 184.691090\n",
      "iteration 75300 / 120000: loss 0.000448\n",
      "iteration 75400 / 120000: loss 0.000447\n",
      "iteration 75500 / 120000: loss 0.000448\n",
      "iteration 75600 / 120000: loss 0.000448\n",
      "iteration 75700 / 120000: loss 0.000448\n",
      "iteration 75800 / 120000: loss 0.000449\n",
      "iteration 75900 / 120000: loss 187.721044\n",
      "iteration 76000 / 120000: loss 0.000446\n",
      "iteration 76100 / 120000: loss 0.000446\n",
      "iteration 76200 / 120000: loss 109.287285\n",
      "iteration 76300 / 120000: loss 142.053875\n",
      "iteration 76400 / 120000: loss 40.680895\n",
      "iteration 76500 / 120000: loss 0.000446\n",
      "iteration 76600 / 120000: loss 0.000446\n",
      "iteration 76700 / 120000: loss 79.598195\n",
      "iteration 76800 / 120000: loss 0.000450\n",
      "iteration 76900 / 120000: loss 63.898526\n",
      "iteration 77000 / 120000: loss 0.000450\n",
      "iteration 77100 / 120000: loss 0.000450\n",
      "iteration 77200 / 120000: loss 0.000450\n",
      "iteration 77300 / 120000: loss 0.000452\n",
      "iteration 77400 / 120000: loss 60.671484\n",
      "iteration 77500 / 120000: loss 0.000457\n",
      "iteration 77600 / 120000: loss 0.000454\n",
      "iteration 77700 / 120000: loss 80.054389\n",
      "iteration 77800 / 120000: loss 0.000454\n",
      "iteration 77900 / 120000: loss 0.000455\n",
      "iteration 78000 / 120000: loss 0.000458\n",
      "iteration 78100 / 120000: loss 0.000459\n",
      "iteration 78200 / 120000: loss 8.653428\n",
      "iteration 78300 / 120000: loss 0.000458\n",
      "iteration 78400 / 120000: loss 0.000458\n",
      "iteration 78500 / 120000: loss 0.000461\n",
      "iteration 78600 / 120000: loss 0.000463\n",
      "iteration 78700 / 120000: loss 20.890335\n",
      "iteration 78800 / 120000: loss 0.000466\n",
      "iteration 78900 / 120000: loss 58.730448\n",
      "iteration 79000 / 120000: loss 0.000468\n",
      "iteration 79100 / 120000: loss 0.000467\n",
      "iteration 79200 / 120000: loss 31.223477\n",
      "iteration 79300 / 120000: loss 0.000467\n",
      "iteration 79400 / 120000: loss 54.024095\n",
      "iteration 79500 / 120000: loss 9.106059\n",
      "iteration 79600 / 120000: loss 0.000467\n",
      "iteration 79700 / 120000: loss 0.000467\n",
      "iteration 79800 / 120000: loss 60.321059\n",
      "iteration 79900 / 120000: loss 0.000469\n",
      "iteration 80000 / 120000: loss 0.000468\n",
      "iteration 80100 / 120000: loss 0.000471\n",
      "iteration 80200 / 120000: loss 0.000472\n",
      "iteration 80300 / 120000: loss 0.000472\n",
      "iteration 80400 / 120000: loss 135.146161\n",
      "iteration 80500 / 120000: loss 64.366993\n",
      "iteration 80600 / 120000: loss 0.000473\n",
      "iteration 80700 / 120000: loss 0.000474\n",
      "iteration 80800 / 120000: loss 0.000474\n",
      "iteration 80900 / 120000: loss 0.000475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 81000 / 120000: loss 0.000475\n",
      "iteration 81100 / 120000: loss 0.000477\n",
      "iteration 81200 / 120000: loss 69.979151\n",
      "iteration 81300 / 120000: loss 29.880180\n",
      "iteration 81400 / 120000: loss 141.527956\n",
      "iteration 81500 / 120000: loss 0.000483\n",
      "iteration 81600 / 120000: loss 66.402928\n",
      "iteration 81700 / 120000: loss 0.000484\n",
      "iteration 81800 / 120000: loss 0.000486\n",
      "iteration 81900 / 120000: loss 27.171155\n",
      "iteration 82000 / 120000: loss 78.613104\n",
      "iteration 82100 / 120000: loss 0.000487\n",
      "iteration 82200 / 120000: loss 0.000488\n",
      "iteration 82300 / 120000: loss 77.330988\n",
      "iteration 82400 / 120000: loss 0.000491\n",
      "iteration 82500 / 120000: loss 94.313375\n",
      "iteration 82600 / 120000: loss 0.000493\n",
      "iteration 82700 / 120000: loss 0.000494\n",
      "iteration 82800 / 120000: loss 0.000495\n",
      "iteration 82900 / 120000: loss 0.000496\n",
      "iteration 83000 / 120000: loss 0.000497\n",
      "iteration 83100 / 120000: loss 0.000497\n",
      "iteration 83200 / 120000: loss 36.535419\n",
      "iteration 83300 / 120000: loss 0.000500\n",
      "iteration 83400 / 120000: loss 0.000501\n",
      "iteration 83500 / 120000: loss 0.000502\n",
      "iteration 83600 / 120000: loss 0.000504\n",
      "iteration 83700 / 120000: loss 0.000507\n",
      "iteration 83800 / 120000: loss 0.000508\n",
      "iteration 83900 / 120000: loss 0.000510\n",
      "iteration 84000 / 120000: loss 0.000510\n",
      "iteration 84100 / 120000: loss 0.000508\n",
      "iteration 84200 / 120000: loss 0.000510\n",
      "iteration 84300 / 120000: loss 0.000509\n",
      "iteration 84400 / 120000: loss 0.000509\n",
      "iteration 84500 / 120000: loss 0.000507\n",
      "iteration 84600 / 120000: loss 0.000508\n",
      "iteration 84700 / 120000: loss 0.000510\n",
      "iteration 84800 / 120000: loss 0.000511\n",
      "iteration 84900 / 120000: loss 0.000513\n",
      "iteration 85000 / 120000: loss 0.000511\n",
      "iteration 85100 / 120000: loss 0.000511\n",
      "iteration 85200 / 120000: loss 0.000511\n",
      "iteration 85300 / 120000: loss 0.000510\n",
      "iteration 85400 / 120000: loss 17.860083\n",
      "iteration 85500 / 120000: loss 42.078223\n",
      "iteration 85600 / 120000: loss 0.000511\n",
      "iteration 85700 / 120000: loss 0.000512\n",
      "iteration 85800 / 120000: loss 9.783406\n",
      "iteration 85900 / 120000: loss 0.000516\n",
      "iteration 86000 / 120000: loss 0.000518\n",
      "iteration 86100 / 120000: loss 0.000515\n",
      "iteration 86200 / 120000: loss 10.765991\n",
      "iteration 86300 / 120000: loss 0.000521\n",
      "iteration 86400 / 120000: loss 157.981664\n",
      "iteration 86500 / 120000: loss 72.768336\n",
      "iteration 86600 / 120000: loss 0.000520\n",
      "iteration 86700 / 120000: loss 0.000519\n",
      "iteration 86800 / 120000: loss 0.000519\n",
      "iteration 86900 / 120000: loss 0.000520\n",
      "iteration 87000 / 120000: loss 0.000521\n",
      "iteration 87100 / 120000: loss 43.122356\n",
      "iteration 87200 / 120000: loss 0.000521\n",
      "iteration 87300 / 120000: loss 0.000523\n",
      "iteration 87400 / 120000: loss 0.000525\n",
      "iteration 87500 / 120000: loss 0.000525\n",
      "iteration 87600 / 120000: loss 0.000523\n",
      "iteration 87700 / 120000: loss 0.000525\n",
      "iteration 87800 / 120000: loss 0.000528\n",
      "iteration 87900 / 120000: loss 145.706842\n",
      "iteration 88000 / 120000: loss 66.461569\n",
      "iteration 88100 / 120000: loss 0.000527\n",
      "iteration 88200 / 120000: loss 0.000526\n",
      "iteration 88300 / 120000: loss 0.000528\n",
      "iteration 88400 / 120000: loss 4.001877\n",
      "iteration 88500 / 120000: loss 63.101745\n",
      "iteration 88600 / 120000: loss 91.850512\n",
      "iteration 88700 / 120000: loss 0.000532\n",
      "iteration 88800 / 120000: loss 24.120479\n",
      "iteration 88900 / 120000: loss 0.000531\n",
      "iteration 89000 / 120000: loss 0.000532\n",
      "iteration 89100 / 120000: loss 0.000532\n",
      "iteration 89200 / 120000: loss 0.000533\n",
      "iteration 89300 / 120000: loss 0.000533\n",
      "iteration 89400 / 120000: loss 0.000536\n",
      "iteration 89500 / 120000: loss 7.775639\n",
      "iteration 89600 / 120000: loss 0.000537\n",
      "iteration 89700 / 120000: loss 0.000537\n",
      "iteration 89800 / 120000: loss 0.000540\n",
      "iteration 89900 / 120000: loss 0.000540\n",
      "iteration 90000 / 120000: loss 0.000540\n",
      "iteration 90100 / 120000: loss 0.000543\n",
      "iteration 90200 / 120000: loss 0.000545\n",
      "iteration 90300 / 120000: loss 0.000547\n",
      "iteration 90400 / 120000: loss 0.000548\n",
      "iteration 90500 / 120000: loss 0.000549\n",
      "iteration 90600 / 120000: loss 0.000548\n",
      "iteration 90700 / 120000: loss 0.000549\n",
      "iteration 90800 / 120000: loss 0.000549\n",
      "iteration 90900 / 120000: loss 43.211493\n",
      "iteration 91000 / 120000: loss 33.043639\n",
      "iteration 91100 / 120000: loss 0.000550\n",
      "iteration 91200 / 120000: loss 0.000549\n",
      "iteration 91300 / 120000: loss 0.000551\n",
      "iteration 91400 / 120000: loss 0.000550\n",
      "iteration 91500 / 120000: loss 0.000550\n",
      "iteration 91600 / 120000: loss 96.067583\n",
      "iteration 91700 / 120000: loss 0.000548\n",
      "iteration 91800 / 120000: loss 0.000548\n",
      "iteration 91900 / 120000: loss 0.000547\n",
      "iteration 92000 / 120000: loss 43.247501\n",
      "iteration 92100 / 120000: loss 110.406020\n",
      "iteration 92200 / 120000: loss 0.000551\n",
      "iteration 92300 / 120000: loss 0.000554\n",
      "iteration 92400 / 120000: loss 0.000554\n",
      "iteration 92500 / 120000: loss 0.000557\n",
      "iteration 92600 / 120000: loss 0.000555\n",
      "iteration 92700 / 120000: loss 73.683174\n",
      "iteration 92800 / 120000: loss 0.000555\n",
      "iteration 92900 / 120000: loss 112.906621\n",
      "iteration 93000 / 120000: loss 82.193988\n",
      "iteration 93100 / 120000: loss 21.007896\n",
      "iteration 93200 / 120000: loss 3.848078\n",
      "iteration 93300 / 120000: loss 0.000564\n",
      "iteration 93400 / 120000: loss 0.000565\n",
      "iteration 93500 / 120000: loss 97.119349\n",
      "iteration 93600 / 120000: loss 0.000567\n",
      "iteration 93700 / 120000: loss 0.000568\n",
      "iteration 93800 / 120000: loss 0.000568\n",
      "iteration 93900 / 120000: loss 0.000568\n",
      "iteration 94000 / 120000: loss 0.000568\n",
      "iteration 94100 / 120000: loss 0.000569\n",
      "iteration 94200 / 120000: loss 0.000573\n",
      "iteration 94300 / 120000: loss 48.187551\n",
      "iteration 94400 / 120000: loss 91.975852\n",
      "iteration 94500 / 120000: loss 0.000577\n",
      "iteration 94600 / 120000: loss 0.000577\n",
      "iteration 94700 / 120000: loss 83.059797\n",
      "iteration 94800 / 120000: loss 0.000578\n",
      "iteration 94900 / 120000: loss 0.000578\n",
      "iteration 95000 / 120000: loss 0.000578\n",
      "iteration 95100 / 120000: loss 0.000580\n",
      "iteration 95200 / 120000: loss 0.000577\n",
      "iteration 95300 / 120000: loss 0.000577\n",
      "iteration 95400 / 120000: loss 0.000577\n",
      "iteration 95500 / 120000: loss 20.513236\n",
      "iteration 95600 / 120000: loss 0.000577\n",
      "iteration 95700 / 120000: loss 0.000580\n",
      "iteration 95800 / 120000: loss 0.000580\n",
      "iteration 95900 / 120000: loss 0.000580\n",
      "iteration 96000 / 120000: loss 0.000581\n",
      "iteration 96100 / 120000: loss 0.000581\n",
      "iteration 96200 / 120000: loss 0.000581\n",
      "iteration 96300 / 120000: loss 0.000581\n",
      "iteration 96400 / 120000: loss 0.000581\n",
      "iteration 96500 / 120000: loss 0.000582\n",
      "iteration 96600 / 120000: loss 75.146626\n",
      "iteration 96700 / 120000: loss 0.000583\n",
      "iteration 96800 / 120000: loss 0.000585\n",
      "iteration 96900 / 120000: loss 0.000586\n",
      "iteration 97000 / 120000: loss 81.830425\n",
      "iteration 97100 / 120000: loss 0.000590\n",
      "iteration 97200 / 120000: loss 0.000589\n",
      "iteration 97300 / 120000: loss 0.000590\n",
      "iteration 97400 / 120000: loss 0.000590\n",
      "iteration 97500 / 120000: loss 0.000592\n",
      "iteration 97600 / 120000: loss 92.821957\n",
      "iteration 97700 / 120000: loss 0.000593\n",
      "iteration 97800 / 120000: loss 0.000594\n",
      "iteration 97900 / 120000: loss 0.000594\n",
      "iteration 98000 / 120000: loss 0.000594\n",
      "iteration 98100 / 120000: loss 46.020535\n",
      "iteration 98200 / 120000: loss 0.000594\n",
      "iteration 98300 / 120000: loss 0.000595\n",
      "iteration 98400 / 120000: loss 0.000597\n",
      "iteration 98500 / 120000: loss 0.000598\n",
      "iteration 98600 / 120000: loss 0.000600\n",
      "iteration 98700 / 120000: loss 0.000600\n",
      "iteration 98800 / 120000: loss 0.000603\n",
      "iteration 98900 / 120000: loss 0.000603\n",
      "iteration 99000 / 120000: loss 216.831526\n",
      "iteration 99100 / 120000: loss 68.309011\n",
      "iteration 99200 / 120000: loss 0.000601\n",
      "iteration 99300 / 120000: loss 116.661513\n",
      "iteration 99400 / 120000: loss 1.888996\n",
      "iteration 99500 / 120000: loss 0.000604\n",
      "iteration 99600 / 120000: loss 111.137617\n",
      "iteration 99700 / 120000: loss 0.000604\n",
      "iteration 99800 / 120000: loss 0.000604\n",
      "iteration 99900 / 120000: loss 0.000604\n",
      "iteration 100000 / 120000: loss 0.000603\n",
      "iteration 100100 / 120000: loss 0.000603\n",
      "iteration 100200 / 120000: loss 139.985764\n",
      "iteration 100300 / 120000: loss 17.285991\n",
      "iteration 100400 / 120000: loss 0.000608\n",
      "iteration 100500 / 120000: loss 0.000608\n",
      "iteration 100600 / 120000: loss 0.000610\n",
      "iteration 100700 / 120000: loss 0.000610\n",
      "iteration 100800 / 120000: loss 0.000613\n",
      "iteration 100900 / 120000: loss 0.000614\n",
      "iteration 101000 / 120000: loss 123.641938\n",
      "iteration 101100 / 120000: loss 0.000618\n",
      "iteration 101200 / 120000: loss 0.000619\n",
      "iteration 101300 / 120000: loss 0.000620\n",
      "iteration 101400 / 120000: loss 12.016135\n",
      "iteration 101500 / 120000: loss 0.000624\n",
      "iteration 101600 / 120000: loss 1.564764\n",
      "iteration 101700 / 120000: loss 0.000627\n",
      "iteration 101800 / 120000: loss 0.000629\n",
      "iteration 101900 / 120000: loss 1.697258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 102000 / 120000: loss 7.480998\n",
      "iteration 102100 / 120000: loss 122.270280\n",
      "iteration 102200 / 120000: loss 0.000627\n",
      "iteration 102300 / 120000: loss 15.890625\n",
      "iteration 102400 / 120000: loss 76.304410\n",
      "iteration 102500 / 120000: loss 0.000626\n",
      "iteration 102600 / 120000: loss 0.000628\n",
      "iteration 102700 / 120000: loss 0.000628\n",
      "iteration 102800 / 120000: loss 0.000627\n",
      "iteration 102900 / 120000: loss 0.000626\n",
      "iteration 103000 / 120000: loss 0.000625\n",
      "iteration 103100 / 120000: loss 0.000626\n",
      "iteration 103200 / 120000: loss 6.058259\n",
      "iteration 103300 / 120000: loss 0.000628\n",
      "iteration 103400 / 120000: loss 29.188538\n",
      "iteration 103500 / 120000: loss 107.860983\n",
      "iteration 103600 / 120000: loss 5.615782\n",
      "iteration 103700 / 120000: loss 0.000630\n",
      "iteration 103800 / 120000: loss 0.000630\n",
      "iteration 103900 / 120000: loss 0.000629\n",
      "iteration 104000 / 120000: loss 0.000630\n",
      "iteration 104100 / 120000: loss 0.000630\n",
      "iteration 104200 / 120000: loss 0.000630\n",
      "iteration 104300 / 120000: loss 0.000630\n",
      "iteration 104400 / 120000: loss 29.097882\n",
      "iteration 104500 / 120000: loss 0.000632\n",
      "iteration 104600 / 120000: loss 0.000632\n",
      "iteration 104700 / 120000: loss 0.000636\n",
      "iteration 104800 / 120000: loss 162.954334\n",
      "iteration 104900 / 120000: loss 0.000633\n",
      "iteration 105000 / 120000: loss 0.000633\n",
      "iteration 105100 / 120000: loss 15.899307\n",
      "iteration 105200 / 120000: loss 62.593809\n",
      "iteration 105300 / 120000: loss 0.000634\n",
      "iteration 105400 / 120000: loss 0.000635\n",
      "iteration 105500 / 120000: loss 28.647084\n",
      "iteration 105600 / 120000: loss 0.000638\n",
      "iteration 105700 / 120000: loss 0.000638\n",
      "iteration 105800 / 120000: loss 0.000637\n",
      "iteration 105900 / 120000: loss 0.000639\n",
      "iteration 106000 / 120000: loss 55.564252\n",
      "iteration 106100 / 120000: loss 0.000643\n",
      "iteration 106200 / 120000: loss 0.000644\n",
      "iteration 106300 / 120000: loss 0.000646\n",
      "iteration 106400 / 120000: loss 0.000648\n",
      "iteration 106500 / 120000: loss 0.000649\n",
      "iteration 106600 / 120000: loss 0.000650\n",
      "iteration 106700 / 120000: loss 28.873789\n",
      "iteration 106800 / 120000: loss 0.000652\n",
      "iteration 106900 / 120000: loss 0.000652\n",
      "iteration 107000 / 120000: loss 0.000654\n",
      "iteration 107100 / 120000: loss 0.000654\n",
      "iteration 107200 / 120000: loss 0.000656\n",
      "iteration 107300 / 120000: loss 0.000656\n",
      "iteration 107400 / 120000: loss 18.627179\n",
      "iteration 107500 / 120000: loss 63.029645\n",
      "iteration 107600 / 120000: loss 0.000657\n",
      "iteration 107700 / 120000: loss 5.952118\n",
      "iteration 107800 / 120000: loss 0.000656\n",
      "iteration 107900 / 120000: loss 0.000657\n",
      "iteration 108000 / 120000: loss 0.000660\n",
      "iteration 108100 / 120000: loss 0.000661\n",
      "iteration 108200 / 120000: loss 0.000660\n",
      "iteration 108300 / 120000: loss 0.000661\n",
      "iteration 108400 / 120000: loss 0.000661\n",
      "iteration 108500 / 120000: loss 0.000662\n",
      "iteration 108600 / 120000: loss 0.000660\n",
      "iteration 108700 / 120000: loss 0.000661\n",
      "iteration 108800 / 120000: loss 40.430864\n",
      "iteration 108900 / 120000: loss 29.591208\n",
      "iteration 109000 / 120000: loss 0.000661\n",
      "iteration 109100 / 120000: loss 0.000660\n",
      "iteration 109200 / 120000: loss 0.000659\n",
      "iteration 109300 / 120000: loss 0.000659\n",
      "iteration 109400 / 120000: loss 0.000660\n",
      "iteration 109500 / 120000: loss 0.000662\n",
      "iteration 109600 / 120000: loss 0.000663\n",
      "iteration 109700 / 120000: loss 46.801818\n",
      "iteration 109800 / 120000: loss 0.000664\n",
      "iteration 109900 / 120000: loss 0.000666\n",
      "iteration 110000 / 120000: loss 19.537947\n",
      "iteration 110100 / 120000: loss 15.388778\n",
      "iteration 110200 / 120000: loss 0.000668\n",
      "iteration 110300 / 120000: loss 0.000669\n",
      "iteration 110400 / 120000: loss 75.551299\n",
      "iteration 110500 / 120000: loss 0.000670\n",
      "iteration 110600 / 120000: loss 0.000670\n",
      "iteration 110700 / 120000: loss 0.000671\n",
      "iteration 110800 / 120000: loss 0.000672\n",
      "iteration 110900 / 120000: loss 0.000672\n",
      "iteration 111000 / 120000: loss 0.000673\n",
      "iteration 111100 / 120000: loss 73.657532\n",
      "iteration 111200 / 120000: loss 6.164371\n",
      "iteration 111300 / 120000: loss 0.000676\n",
      "iteration 111400 / 120000: loss 0.000676\n",
      "iteration 111500 / 120000: loss 0.000676\n",
      "iteration 111600 / 120000: loss 0.000674\n",
      "iteration 111700 / 120000: loss 0.000674\n",
      "iteration 111800 / 120000: loss 0.000675\n",
      "iteration 111900 / 120000: loss 0.000676\n",
      "iteration 112000 / 120000: loss 0.000677\n",
      "iteration 112100 / 120000: loss 6.986840\n",
      "iteration 112200 / 120000: loss 0.000677\n",
      "iteration 112300 / 120000: loss 0.000676\n",
      "iteration 112400 / 120000: loss 0.000677\n",
      "iteration 112500 / 120000: loss 188.950100\n",
      "iteration 112600 / 120000: loss 85.956011\n",
      "iteration 112700 / 120000: loss 0.000678\n",
      "iteration 112800 / 120000: loss 111.008314\n",
      "iteration 112900 / 120000: loss 0.000675\n",
      "iteration 113000 / 120000: loss 0.000676\n",
      "iteration 113100 / 120000: loss 0.000678\n",
      "iteration 113200 / 120000: loss 0.000681\n",
      "iteration 113300 / 120000: loss 0.000682\n",
      "iteration 113400 / 120000: loss 0.000683\n",
      "iteration 113500 / 120000: loss 0.000683\n",
      "iteration 113600 / 120000: loss 0.000681\n",
      "iteration 113700 / 120000: loss 0.000680\n",
      "iteration 113800 / 120000: loss 0.000679\n",
      "iteration 113900 / 120000: loss 4.139853\n",
      "iteration 114000 / 120000: loss 40.709269\n",
      "iteration 114100 / 120000: loss 0.000682\n",
      "iteration 114200 / 120000: loss 0.000683\n",
      "iteration 114300 / 120000: loss 0.000683\n",
      "iteration 114400 / 120000: loss 100.047994\n",
      "iteration 114500 / 120000: loss 0.000683\n",
      "iteration 114600 / 120000: loss 0.000682\n",
      "iteration 114700 / 120000: loss 0.000682\n",
      "iteration 114800 / 120000: loss 0.000680\n",
      "iteration 114900 / 120000: loss 105.637910\n",
      "iteration 115000 / 120000: loss 0.000680\n",
      "iteration 115100 / 120000: loss 0.000682\n",
      "iteration 115200 / 120000: loss 21.770731\n",
      "iteration 115300 / 120000: loss 0.000684\n",
      "iteration 115400 / 120000: loss 0.000684\n",
      "iteration 115500 / 120000: loss 69.191620\n",
      "iteration 115600 / 120000: loss 0.000687\n",
      "iteration 115700 / 120000: loss 0.000689\n",
      "iteration 115800 / 120000: loss 0.000689\n",
      "iteration 115900 / 120000: loss 0.000689\n",
      "iteration 116000 / 120000: loss 81.776237\n",
      "iteration 116100 / 120000: loss 0.000689\n",
      "iteration 116200 / 120000: loss 132.122819\n",
      "iteration 116300 / 120000: loss 0.000689\n",
      "iteration 116400 / 120000: loss 0.000690\n",
      "iteration 116500 / 120000: loss 0.000690\n",
      "iteration 116600 / 120000: loss 0.000690\n",
      "iteration 116700 / 120000: loss 20.884836\n",
      "iteration 116800 / 120000: loss 0.000693\n",
      "iteration 116900 / 120000: loss 43.791104\n",
      "iteration 117000 / 120000: loss 0.000694\n",
      "iteration 117100 / 120000: loss 0.000694\n",
      "iteration 117200 / 120000: loss 24.898981\n",
      "iteration 117300 / 120000: loss 32.114291\n",
      "iteration 117400 / 120000: loss 0.000700\n",
      "iteration 117500 / 120000: loss 0.000701\n",
      "iteration 117600 / 120000: loss 0.000703\n",
      "iteration 117700 / 120000: loss 0.000704\n",
      "iteration 117800 / 120000: loss 0.000702\n",
      "iteration 117900 / 120000: loss 0.000703\n",
      "iteration 118000 / 120000: loss 0.000704\n",
      "iteration 118100 / 120000: loss 0.000703\n",
      "iteration 118200 / 120000: loss 0.000705\n",
      "iteration 118300 / 120000: loss 157.154463\n",
      "iteration 118400 / 120000: loss 0.000706\n",
      "iteration 118500 / 120000: loss 0.000707\n",
      "iteration 118600 / 120000: loss 0.000707\n",
      "iteration 118700 / 120000: loss 0.000709\n",
      "iteration 118800 / 120000: loss 0.000708\n",
      "iteration 118900 / 120000: loss 0.000707\n",
      "iteration 119000 / 120000: loss 0.000709\n",
      "iteration 119100 / 120000: loss 0.000707\n",
      "iteration 119200 / 120000: loss 0.000707\n",
      "iteration 119300 / 120000: loss 0.000710\n",
      "iteration 119400 / 120000: loss 0.000711\n",
      "iteration 119500 / 120000: loss 0.000711\n",
      "iteration 119600 / 120000: loss 0.000712\n",
      "iteration 119700 / 120000: loss 0.000715\n",
      "iteration 119800 / 120000: loss 0.000714\n",
      "iteration 119900 / 120000: loss 0.000716\n",
      "lr=5e-06 bs=1 regularization_rate=0.0004\n",
      "iteration 0 / 120000: loss 0.843887\n",
      "iteration 100 / 120000: loss 0.000003\n",
      "iteration 200 / 120000: loss 0.000006\n",
      "iteration 300 / 120000: loss 0.000008\n",
      "iteration 400 / 120000: loss 0.000010\n",
      "iteration 500 / 120000: loss 10.038797\n",
      "iteration 600 / 120000: loss 0.000014\n",
      "iteration 700 / 120000: loss 0.000016\n",
      "iteration 800 / 120000: loss 53.244633\n",
      "iteration 900 / 120000: loss 0.000017\n",
      "iteration 1000 / 120000: loss 0.000019\n",
      "iteration 1100 / 120000: loss 111.247103\n",
      "iteration 1200 / 120000: loss 0.000020\n",
      "iteration 1300 / 120000: loss 0.000022\n",
      "iteration 1400 / 120000: loss 0.000023\n",
      "iteration 1500 / 120000: loss 47.474643\n",
      "iteration 1600 / 120000: loss 44.069015\n",
      "iteration 1700 / 120000: loss 0.000027\n",
      "iteration 1800 / 120000: loss 0.000027\n",
      "iteration 1900 / 120000: loss 126.322204\n",
      "iteration 2000 / 120000: loss 0.000030\n",
      "iteration 2100 / 120000: loss 0.000030\n",
      "iteration 2200 / 120000: loss 0.000031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 2300 / 120000: loss 0.000031\n",
      "iteration 2400 / 120000: loss 0.000031\n",
      "iteration 2500 / 120000: loss 0.000031\n",
      "iteration 2600 / 120000: loss 0.000032\n",
      "iteration 2700 / 120000: loss 0.000033\n",
      "iteration 2800 / 120000: loss 47.089200\n",
      "iteration 2900 / 120000: loss 0.000033\n",
      "iteration 3000 / 120000: loss 0.000035\n",
      "iteration 3100 / 120000: loss 36.277447\n",
      "iteration 3200 / 120000: loss 0.000037\n",
      "iteration 3300 / 120000: loss 0.000036\n",
      "iteration 3400 / 120000: loss 54.497924\n",
      "iteration 3500 / 120000: loss 73.566108\n",
      "iteration 3600 / 120000: loss 0.000038\n",
      "iteration 3700 / 120000: loss 0.000039\n",
      "iteration 3800 / 120000: loss 0.000042\n",
      "iteration 3900 / 120000: loss 0.000043\n",
      "iteration 4000 / 120000: loss 0.000042\n",
      "iteration 4100 / 120000: loss 39.266778\n",
      "iteration 4200 / 120000: loss 71.778961\n",
      "iteration 4300 / 120000: loss 60.472898\n",
      "iteration 4400 / 120000: loss 0.000048\n",
      "iteration 4500 / 120000: loss 0.000048\n",
      "iteration 4600 / 120000: loss 0.000048\n",
      "iteration 4700 / 120000: loss 9.403918\n",
      "iteration 4800 / 120000: loss 102.590252\n",
      "iteration 4900 / 120000: loss 0.000051\n",
      "iteration 5000 / 120000: loss 96.687486\n",
      "iteration 5100 / 120000: loss 0.000053\n",
      "iteration 5200 / 120000: loss 0.000054\n",
      "iteration 5300 / 120000: loss 0.000055\n",
      "iteration 5400 / 120000: loss 0.000058\n",
      "iteration 5500 / 120000: loss 0.000059\n",
      "iteration 5600 / 120000: loss 0.000060\n",
      "iteration 5700 / 120000: loss 0.000059\n",
      "iteration 5800 / 120000: loss 0.000059\n",
      "iteration 5900 / 120000: loss 0.000060\n",
      "iteration 6000 / 120000: loss 0.000058\n",
      "iteration 6100 / 120000: loss 0.000059\n",
      "iteration 6200 / 120000: loss 0.000060\n",
      "iteration 6300 / 120000: loss 0.000059\n",
      "iteration 6400 / 120000: loss 0.000059\n",
      "iteration 6500 / 120000: loss 0.000062\n",
      "iteration 6600 / 120000: loss 0.000062\n",
      "iteration 6700 / 120000: loss 0.000064\n",
      "iteration 6800 / 120000: loss 0.000065\n",
      "iteration 6900 / 120000: loss 0.000066\n",
      "iteration 7000 / 120000: loss 0.000064\n",
      "iteration 7100 / 120000: loss 0.000063\n",
      "iteration 7200 / 120000: loss 0.000064\n",
      "iteration 7300 / 120000: loss 0.000063\n",
      "iteration 7400 / 120000: loss 0.000066\n",
      "iteration 7500 / 120000: loss 51.868852\n",
      "iteration 7600 / 120000: loss 0.000065\n",
      "iteration 7700 / 120000: loss 0.000066\n",
      "iteration 7800 / 120000: loss 0.000066\n",
      "iteration 7900 / 120000: loss 0.000067\n",
      "iteration 8000 / 120000: loss 0.000068\n",
      "iteration 8100 / 120000: loss 19.642336\n",
      "iteration 8200 / 120000: loss 0.000069\n",
      "iteration 8300 / 120000: loss 0.000070\n",
      "iteration 8400 / 120000: loss 0.000070\n",
      "iteration 8500 / 120000: loss 47.861314\n",
      "iteration 8600 / 120000: loss 0.000071\n",
      "iteration 8700 / 120000: loss 0.000072\n",
      "iteration 8800 / 120000: loss 0.000072\n",
      "iteration 8900 / 120000: loss 0.000073\n",
      "iteration 9000 / 120000: loss 0.000074\n",
      "iteration 9100 / 120000: loss 0.000074\n",
      "iteration 9200 / 120000: loss 0.000073\n",
      "iteration 9300 / 120000: loss 0.000073\n",
      "iteration 9400 / 120000: loss 0.000073\n",
      "iteration 9500 / 120000: loss 16.974298\n",
      "iteration 9600 / 120000: loss 0.000077\n",
      "iteration 9700 / 120000: loss 0.000076\n",
      "iteration 9800 / 120000: loss 0.000076\n",
      "iteration 9900 / 120000: loss 45.198466\n",
      "iteration 10000 / 120000: loss 0.000077\n",
      "iteration 10100 / 120000: loss 0.000077\n",
      "iteration 10200 / 120000: loss 0.000077\n",
      "iteration 10300 / 120000: loss 0.000076\n",
      "iteration 10400 / 120000: loss 6.603586\n",
      "iteration 10500 / 120000: loss 0.000078\n",
      "iteration 10600 / 120000: loss 0.000080\n",
      "iteration 10700 / 120000: loss 23.791082\n",
      "iteration 10800 / 120000: loss 0.000079\n",
      "iteration 10900 / 120000: loss 15.703451\n",
      "iteration 11000 / 120000: loss 23.740950\n",
      "iteration 11100 / 120000: loss 0.000080\n",
      "iteration 11200 / 120000: loss 0.000081\n",
      "iteration 11300 / 120000: loss 33.059355\n",
      "iteration 11400 / 120000: loss 0.000081\n",
      "iteration 11500 / 120000: loss 1.664830\n",
      "iteration 11600 / 120000: loss 122.227292\n",
      "iteration 11700 / 120000: loss 0.000086\n",
      "iteration 11800 / 120000: loss 14.932482\n",
      "iteration 11900 / 120000: loss 0.000088\n",
      "iteration 12000 / 120000: loss 0.000089\n",
      "iteration 12100 / 120000: loss 100.842814\n",
      "iteration 12200 / 120000: loss 81.787824\n",
      "iteration 12300 / 120000: loss 7.638626\n",
      "iteration 12400 / 120000: loss 0.000094\n",
      "iteration 12500 / 120000: loss 0.000095\n",
      "iteration 12600 / 120000: loss 0.000095\n",
      "iteration 12700 / 120000: loss 54.384814\n",
      "iteration 12800 / 120000: loss 0.000097\n",
      "iteration 12900 / 120000: loss 0.000097\n",
      "iteration 13000 / 120000: loss 0.000100\n",
      "iteration 13100 / 120000: loss 0.000100\n",
      "iteration 13200 / 120000: loss 0.000100\n",
      "iteration 13300 / 120000: loss 0.000100\n",
      "iteration 13400 / 120000: loss 207.945258\n",
      "iteration 13500 / 120000: loss 0.000100\n",
      "iteration 13600 / 120000: loss 0.000102\n",
      "iteration 13700 / 120000: loss 0.000100\n",
      "iteration 13800 / 120000: loss 72.369804\n",
      "iteration 13900 / 120000: loss 78.805547\n",
      "iteration 14000 / 120000: loss 2.572255\n",
      "iteration 14100 / 120000: loss 0.000101\n",
      "iteration 14200 / 120000: loss 24.955534\n",
      "iteration 14300 / 120000: loss 0.000101\n",
      "iteration 14400 / 120000: loss 0.000102\n",
      "iteration 14500 / 120000: loss 0.000102\n",
      "iteration 14600 / 120000: loss 0.000102\n",
      "iteration 14700 / 120000: loss 0.000104\n",
      "iteration 14800 / 120000: loss 0.000104\n",
      "iteration 14900 / 120000: loss 0.000104\n",
      "iteration 15000 / 120000: loss 0.000103\n",
      "iteration 15100 / 120000: loss 0.000104\n",
      "iteration 15200 / 120000: loss 0.000103\n",
      "iteration 15300 / 120000: loss 0.000103\n",
      "iteration 15400 / 120000: loss 0.000105\n",
      "iteration 15500 / 120000: loss 0.000105\n",
      "iteration 15600 / 120000: loss 0.000105\n",
      "iteration 15700 / 120000: loss 0.000104\n",
      "iteration 15800 / 120000: loss 0.000103\n",
      "iteration 15900 / 120000: loss 0.000105\n",
      "iteration 16000 / 120000: loss 0.000106\n",
      "iteration 16100 / 120000: loss 2.927161\n",
      "iteration 16200 / 120000: loss 0.000107\n",
      "iteration 16300 / 120000: loss 0.000108\n",
      "iteration 16400 / 120000: loss 0.000109\n",
      "iteration 16500 / 120000: loss 0.000109\n",
      "iteration 16600 / 120000: loss 0.000110\n",
      "iteration 16700 / 120000: loss 0.000111\n",
      "iteration 16800 / 120000: loss 0.000111\n",
      "iteration 16900 / 120000: loss 0.000110\n",
      "iteration 17000 / 120000: loss 8.885697\n",
      "iteration 17100 / 120000: loss 0.000109\n",
      "iteration 17200 / 120000: loss 177.283337\n",
      "iteration 17300 / 120000: loss 0.000112\n",
      "iteration 17400 / 120000: loss 100.843200\n",
      "iteration 17500 / 120000: loss 0.849437\n",
      "iteration 17600 / 120000: loss 0.000117\n",
      "iteration 17700 / 120000: loss 0.000117\n",
      "iteration 17800 / 120000: loss 0.000118\n",
      "iteration 17900 / 120000: loss 0.000118\n",
      "iteration 18000 / 120000: loss 0.000119\n",
      "iteration 18100 / 120000: loss 0.000120\n",
      "iteration 18200 / 120000: loss 0.000120\n",
      "iteration 18300 / 120000: loss 0.000118\n",
      "iteration 18400 / 120000: loss 41.815880\n",
      "iteration 18500 / 120000: loss 102.273833\n",
      "iteration 18600 / 120000: loss 0.000119\n",
      "iteration 18700 / 120000: loss 0.000120\n",
      "iteration 18800 / 120000: loss 151.120027\n",
      "iteration 18900 / 120000: loss 6.704672\n",
      "iteration 19000 / 120000: loss 17.029965\n",
      "iteration 19100 / 120000: loss 0.000123\n",
      "iteration 19200 / 120000: loss 0.000124\n",
      "iteration 19300 / 120000: loss 0.000123\n",
      "iteration 19400 / 120000: loss 0.000123\n",
      "iteration 19500 / 120000: loss 0.000126\n",
      "iteration 19600 / 120000: loss 0.000125\n",
      "iteration 19700 / 120000: loss 0.000125\n",
      "iteration 19800 / 120000: loss 0.000124\n",
      "iteration 19900 / 120000: loss 0.000125\n",
      "iteration 20000 / 120000: loss 0.000126\n",
      "iteration 20100 / 120000: loss 0.000127\n",
      "iteration 20200 / 120000: loss 107.520981\n",
      "iteration 20300 / 120000: loss 73.723062\n",
      "iteration 20400 / 120000: loss 0.000126\n",
      "iteration 20500 / 120000: loss 0.000128\n",
      "iteration 20600 / 120000: loss 0.000129\n",
      "iteration 20700 / 120000: loss 0.000130\n",
      "iteration 20800 / 120000: loss 0.000130\n",
      "iteration 20900 / 120000: loss 0.000131\n",
      "iteration 21000 / 120000: loss 0.000130\n",
      "iteration 21100 / 120000: loss 0.000132\n",
      "iteration 21200 / 120000: loss 3.336438\n",
      "iteration 21300 / 120000: loss 85.544120\n",
      "iteration 21400 / 120000: loss 0.000133\n",
      "iteration 21500 / 120000: loss 88.716303\n",
      "iteration 21600 / 120000: loss 48.513617\n",
      "iteration 21700 / 120000: loss 0.000134\n",
      "iteration 21800 / 120000: loss 0.000134\n",
      "iteration 21900 / 120000: loss 0.000134\n",
      "iteration 22000 / 120000: loss 0.000135\n",
      "iteration 22100 / 120000: loss 0.000134\n",
      "iteration 22200 / 120000: loss 79.184274\n",
      "iteration 22300 / 120000: loss 0.000135\n",
      "iteration 22400 / 120000: loss 41.390700\n",
      "iteration 22500 / 120000: loss 0.000137\n",
      "iteration 22600 / 120000: loss 59.809340\n",
      "iteration 22700 / 120000: loss 0.000140\n",
      "iteration 22800 / 120000: loss 107.772745\n",
      "iteration 22900 / 120000: loss 0.000142\n",
      "iteration 23000 / 120000: loss 0.000143\n",
      "iteration 23100 / 120000: loss 0.000142\n",
      "iteration 23200 / 120000: loss 0.000142\n",
      "iteration 23300 / 120000: loss 0.000141\n",
      "iteration 23400 / 120000: loss 0.000141\n",
      "iteration 23500 / 120000: loss 0.000141\n",
      "iteration 23600 / 120000: loss 0.000141\n",
      "iteration 23700 / 120000: loss 77.897596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 23800 / 120000: loss 0.000147\n",
      "iteration 23900 / 120000: loss 0.000146\n",
      "iteration 24000 / 120000: loss 0.000144\n",
      "iteration 24100 / 120000: loss 28.778762\n",
      "iteration 24200 / 120000: loss 152.455684\n",
      "iteration 24300 / 120000: loss 0.000146\n",
      "iteration 24400 / 120000: loss 79.642099\n",
      "iteration 24500 / 120000: loss 0.000147\n",
      "iteration 24600 / 120000: loss 38.350472\n",
      "iteration 24700 / 120000: loss 0.000148\n",
      "iteration 24800 / 120000: loss 0.000148\n",
      "iteration 24900 / 120000: loss 16.796247\n",
      "iteration 25000 / 120000: loss 0.000148\n",
      "iteration 25100 / 120000: loss 0.000149\n",
      "iteration 25200 / 120000: loss 0.000149\n",
      "iteration 25300 / 120000: loss 0.000149\n",
      "iteration 25400 / 120000: loss 0.000152\n",
      "iteration 25500 / 120000: loss 0.000153\n",
      "iteration 25600 / 120000: loss 27.463400\n",
      "iteration 25700 / 120000: loss 84.472159\n",
      "iteration 25800 / 120000: loss 0.000154\n",
      "iteration 25900 / 120000: loss 0.000154\n",
      "iteration 26000 / 120000: loss 0.000155\n",
      "iteration 26100 / 120000: loss 0.000154\n",
      "iteration 26200 / 120000: loss 44.847792\n",
      "iteration 26300 / 120000: loss 0.000156\n",
      "iteration 26400 / 120000: loss 14.841856\n",
      "iteration 26500 / 120000: loss 0.000156\n",
      "iteration 26600 / 120000: loss 0.000157\n",
      "iteration 26700 / 120000: loss 0.000158\n",
      "iteration 26800 / 120000: loss 7.410327\n",
      "iteration 26900 / 120000: loss 0.000156\n",
      "iteration 27000 / 120000: loss 0.000157\n",
      "iteration 27100 / 120000: loss 0.000158\n",
      "iteration 27200 / 120000: loss 94.272119\n",
      "iteration 27300 / 120000: loss 0.000159\n",
      "iteration 27400 / 120000: loss 0.000159\n",
      "iteration 27500 / 120000: loss 0.000160\n",
      "iteration 27600 / 120000: loss 21.840446\n",
      "iteration 27700 / 120000: loss 0.000163\n",
      "iteration 27800 / 120000: loss 0.000160\n",
      "iteration 27900 / 120000: loss 0.000161\n",
      "iteration 28000 / 120000: loss 39.759004\n",
      "iteration 28100 / 120000: loss 0.000163\n",
      "iteration 28200 / 120000: loss 0.000165\n",
      "iteration 28300 / 120000: loss 0.000166\n",
      "iteration 28400 / 120000: loss 0.000167\n",
      "iteration 28500 / 120000: loss 0.000168\n",
      "iteration 28600 / 120000: loss 0.000168\n",
      "iteration 28700 / 120000: loss 136.981790\n",
      "iteration 28800 / 120000: loss 0.000168\n",
      "iteration 28900 / 120000: loss 0.000168\n",
      "iteration 29000 / 120000: loss 0.000168\n",
      "iteration 29100 / 120000: loss 0.000169\n",
      "iteration 29200 / 120000: loss 61.664943\n",
      "iteration 29300 / 120000: loss 0.000169\n",
      "iteration 29400 / 120000: loss 7.543935\n",
      "iteration 29500 / 120000: loss 0.000171\n",
      "iteration 29600 / 120000: loss 0.000171\n",
      "iteration 29700 / 120000: loss 140.194333\n",
      "iteration 29800 / 120000: loss 0.000172\n",
      "iteration 29900 / 120000: loss 22.131444\n",
      "iteration 30000 / 120000: loss 0.000173\n",
      "iteration 30100 / 120000: loss 0.000173\n",
      "iteration 30200 / 120000: loss 0.000173\n",
      "iteration 30300 / 120000: loss 0.000172\n",
      "iteration 30400 / 120000: loss 3.368022\n",
      "iteration 30500 / 120000: loss 0.000174\n",
      "iteration 30600 / 120000: loss 0.000173\n",
      "iteration 30700 / 120000: loss 16.777186\n",
      "iteration 30800 / 120000: loss 0.000175\n",
      "iteration 30900 / 120000: loss 0.000175\n",
      "iteration 31000 / 120000: loss 0.000176\n",
      "iteration 31100 / 120000: loss 34.608297\n",
      "iteration 31200 / 120000: loss 0.000175\n",
      "iteration 31300 / 120000: loss 14.771393\n",
      "iteration 31400 / 120000: loss 18.981669\n",
      "iteration 31500 / 120000: loss 0.000177\n",
      "iteration 31600 / 120000: loss 0.000177\n",
      "iteration 31700 / 120000: loss 0.000177\n",
      "iteration 31800 / 120000: loss 0.000178\n",
      "iteration 31900 / 120000: loss 0.000179\n",
      "iteration 32000 / 120000: loss 0.000182\n",
      "iteration 32100 / 120000: loss 0.000183\n",
      "iteration 32200 / 120000: loss 0.000184\n",
      "iteration 32300 / 120000: loss 25.694006\n",
      "iteration 32400 / 120000: loss 0.000188\n",
      "iteration 32500 / 120000: loss 0.000185\n",
      "iteration 32600 / 120000: loss 0.000187\n",
      "iteration 32700 / 120000: loss 0.000186\n",
      "iteration 32800 / 120000: loss 0.000185\n",
      "iteration 32900 / 120000: loss 0.000184\n",
      "iteration 33000 / 120000: loss 0.000184\n",
      "iteration 33100 / 120000: loss 0.000185\n",
      "iteration 33200 / 120000: loss 16.768906\n",
      "iteration 33300 / 120000: loss 0.000187\n",
      "iteration 33400 / 120000: loss 0.000187\n",
      "iteration 33500 / 120000: loss 0.000187\n",
      "iteration 33600 / 120000: loss 124.167678\n",
      "iteration 33700 / 120000: loss 0.000185\n",
      "iteration 33800 / 120000: loss 0.000184\n",
      "iteration 33900 / 120000: loss 0.000186\n",
      "iteration 34000 / 120000: loss 0.000186\n",
      "iteration 34100 / 120000: loss 0.000187\n",
      "iteration 34200 / 120000: loss 0.000187\n",
      "iteration 34300 / 120000: loss 0.000187\n",
      "iteration 34400 / 120000: loss 0.000188\n",
      "iteration 34500 / 120000: loss 0.000189\n",
      "iteration 34600 / 120000: loss 0.000188\n",
      "iteration 34700 / 120000: loss 0.000188\n",
      "iteration 34800 / 120000: loss 0.000188\n",
      "iteration 34900 / 120000: loss 0.000188\n",
      "iteration 35000 / 120000: loss 0.000190\n",
      "iteration 35100 / 120000: loss 0.000189\n",
      "iteration 35200 / 120000: loss 193.068382\n",
      "iteration 35300 / 120000: loss 11.993295\n",
      "iteration 35400 / 120000: loss 3.026484\n",
      "iteration 35500 / 120000: loss 0.000191\n",
      "iteration 35600 / 120000: loss 0.000191\n",
      "iteration 35700 / 120000: loss 0.000192\n",
      "iteration 35800 / 120000: loss 0.000193\n",
      "iteration 35900 / 120000: loss 26.796692\n",
      "iteration 36000 / 120000: loss 165.697642\n",
      "iteration 36100 / 120000: loss 44.235252\n",
      "iteration 36200 / 120000: loss 0.000197\n",
      "iteration 36300 / 120000: loss 0.000198\n",
      "iteration 36400 / 120000: loss 0.000199\n",
      "iteration 36500 / 120000: loss 0.000197\n",
      "iteration 36600 / 120000: loss 194.449911\n",
      "iteration 36700 / 120000: loss 0.000197\n",
      "iteration 36800 / 120000: loss 0.000198\n",
      "iteration 36900 / 120000: loss 0.000200\n",
      "iteration 37000 / 120000: loss 25.120404\n",
      "iteration 37100 / 120000: loss 39.004073\n",
      "iteration 37200 / 120000: loss 0.000202\n",
      "iteration 37300 / 120000: loss 0.000203\n",
      "iteration 37400 / 120000: loss 15.832724\n",
      "iteration 37500 / 120000: loss 247.715579\n",
      "iteration 37600 / 120000: loss 21.908615\n",
      "iteration 37700 / 120000: loss 0.000206\n",
      "iteration 37800 / 120000: loss 38.980297\n",
      "iteration 37900 / 120000: loss 8.873067\n",
      "iteration 38000 / 120000: loss 171.025086\n",
      "iteration 38100 / 120000: loss 0.000209\n",
      "iteration 38200 / 120000: loss 0.000209\n",
      "iteration 38300 / 120000: loss 0.000209\n",
      "iteration 38400 / 120000: loss 0.000211\n",
      "iteration 38500 / 120000: loss 0.000212\n",
      "iteration 38600 / 120000: loss 216.768632\n",
      "iteration 38700 / 120000: loss 1.913088\n",
      "iteration 38800 / 120000: loss 0.000212\n",
      "iteration 38900 / 120000: loss 0.000213\n",
      "iteration 39000 / 120000: loss 0.000213\n",
      "iteration 39100 / 120000: loss 151.497401\n",
      "iteration 39200 / 120000: loss 0.000217\n",
      "iteration 39300 / 120000: loss 193.831185\n",
      "iteration 39400 / 120000: loss 0.000218\n",
      "iteration 39500 / 120000: loss 0.000219\n",
      "iteration 39600 / 120000: loss 67.805214\n",
      "iteration 39700 / 120000: loss 0.000222\n",
      "iteration 39800 / 120000: loss 163.753419\n",
      "iteration 39900 / 120000: loss 150.464503\n",
      "iteration 40000 / 120000: loss 0.000223\n",
      "iteration 40100 / 120000: loss 0.000223\n",
      "iteration 40200 / 120000: loss 0.000222\n",
      "iteration 40300 / 120000: loss 0.000223\n",
      "iteration 40400 / 120000: loss 0.000222\n",
      "iteration 40500 / 120000: loss 0.000221\n",
      "iteration 40600 / 120000: loss 0.000222\n",
      "iteration 40700 / 120000: loss 0.000223\n",
      "iteration 40800 / 120000: loss 0.000224\n",
      "iteration 40900 / 120000: loss 0.000224\n",
      "iteration 41000 / 120000: loss 25.296710\n",
      "iteration 41100 / 120000: loss 0.594900\n",
      "iteration 41200 / 120000: loss 0.000227\n",
      "iteration 41300 / 120000: loss 8.209684\n",
      "iteration 41400 / 120000: loss 0.000228\n",
      "iteration 41500 / 120000: loss 0.000228\n",
      "iteration 41600 / 120000: loss 0.000228\n",
      "iteration 41700 / 120000: loss 0.000228\n",
      "iteration 41800 / 120000: loss 0.000227\n",
      "iteration 41900 / 120000: loss 11.666832\n",
      "iteration 42000 / 120000: loss 0.000228\n",
      "iteration 42100 / 120000: loss 0.000228\n",
      "iteration 42200 / 120000: loss 0.000228\n",
      "iteration 42300 / 120000: loss 0.000230\n",
      "iteration 42400 / 120000: loss 18.182034\n",
      "iteration 42500 / 120000: loss 0.000228\n",
      "iteration 42600 / 120000: loss 40.945575\n",
      "iteration 42700 / 120000: loss 0.000231\n",
      "iteration 42800 / 120000: loss 0.000230\n",
      "iteration 42900 / 120000: loss 0.000229\n",
      "iteration 43000 / 120000: loss 0.000230\n",
      "iteration 43100 / 120000: loss 0.000231\n",
      "iteration 43200 / 120000: loss 233.273069\n",
      "iteration 43300 / 120000: loss 0.000231\n",
      "iteration 43400 / 120000: loss 0.000233\n",
      "iteration 43500 / 120000: loss 0.000233\n",
      "iteration 43600 / 120000: loss 0.000234\n",
      "iteration 43700 / 120000: loss 0.000236\n",
      "iteration 43800 / 120000: loss 0.000237\n",
      "iteration 43900 / 120000: loss 0.000236\n",
      "iteration 44000 / 120000: loss 99.274764\n",
      "iteration 44100 / 120000: loss 0.000239\n",
      "iteration 44200 / 120000: loss 0.000238\n",
      "iteration 44300 / 120000: loss 0.000238\n",
      "iteration 44400 / 120000: loss 115.462634\n",
      "iteration 44500 / 120000: loss 0.000240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 44600 / 120000: loss 0.000240\n",
      "iteration 44700 / 120000: loss 0.000241\n",
      "iteration 44800 / 120000: loss 0.000242\n",
      "iteration 44900 / 120000: loss 0.000241\n",
      "iteration 45000 / 120000: loss 0.000241\n",
      "iteration 45100 / 120000: loss 0.000240\n",
      "iteration 45200 / 120000: loss 0.000241\n",
      "iteration 45300 / 120000: loss 0.000242\n",
      "iteration 45400 / 120000: loss 0.000243\n",
      "iteration 45500 / 120000: loss 0.000244\n",
      "iteration 45600 / 120000: loss 0.000245\n",
      "iteration 45700 / 120000: loss 0.000246\n",
      "iteration 45800 / 120000: loss 60.488678\n",
      "iteration 45900 / 120000: loss 0.000246\n",
      "iteration 46000 / 120000: loss 0.000247\n",
      "iteration 46100 / 120000: loss 0.000245\n",
      "iteration 46200 / 120000: loss 53.197430\n",
      "iteration 46300 / 120000: loss 0.000245\n",
      "iteration 46400 / 120000: loss 0.000247\n",
      "iteration 46500 / 120000: loss 6.149010\n",
      "iteration 46600 / 120000: loss 0.000250\n",
      "iteration 46700 / 120000: loss 4.422801\n",
      "iteration 46800 / 120000: loss 0.000251\n",
      "iteration 46900 / 120000: loss 0.000250\n",
      "iteration 47000 / 120000: loss 0.000250\n",
      "iteration 47100 / 120000: loss 3.908442\n",
      "iteration 47200 / 120000: loss 0.000251\n",
      "iteration 47300 / 120000: loss 0.000250\n",
      "iteration 47400 / 120000: loss 0.000250\n",
      "iteration 47500 / 120000: loss 0.000251\n",
      "iteration 47600 / 120000: loss 0.000251\n",
      "iteration 47700 / 120000: loss 121.746009\n",
      "iteration 47800 / 120000: loss 0.000253\n",
      "iteration 47900 / 120000: loss 0.000253\n",
      "iteration 48000 / 120000: loss 0.000254\n",
      "iteration 48100 / 120000: loss 105.512205\n",
      "iteration 48200 / 120000: loss 0.000257\n",
      "iteration 48300 / 120000: loss 0.000257\n",
      "iteration 48400 / 120000: loss 0.000256\n",
      "iteration 48500 / 120000: loss 0.000256\n",
      "iteration 48600 / 120000: loss 0.000258\n",
      "iteration 48700 / 120000: loss 0.000258\n",
      "iteration 48800 / 120000: loss 0.000258\n",
      "iteration 48900 / 120000: loss 0.000258\n",
      "iteration 49000 / 120000: loss 0.000259\n",
      "iteration 49100 / 120000: loss 8.157803\n",
      "iteration 49200 / 120000: loss 0.000261\n",
      "iteration 49300 / 120000: loss 0.000262\n",
      "iteration 49400 / 120000: loss 0.000262\n",
      "iteration 49500 / 120000: loss 0.000263\n",
      "iteration 49600 / 120000: loss 80.017528\n",
      "iteration 49700 / 120000: loss 0.000263\n",
      "iteration 49800 / 120000: loss 0.000264\n",
      "iteration 49900 / 120000: loss 106.199281\n",
      "iteration 50000 / 120000: loss 0.000265\n",
      "iteration 50100 / 120000: loss 0.000265\n",
      "iteration 50200 / 120000: loss 0.000263\n",
      "iteration 50300 / 120000: loss 0.000264\n",
      "iteration 50400 / 120000: loss 0.000265\n",
      "iteration 50500 / 120000: loss 0.000267\n",
      "iteration 50600 / 120000: loss 0.000268\n",
      "iteration 50700 / 120000: loss 0.000266\n",
      "iteration 50800 / 120000: loss 67.839814\n",
      "iteration 50900 / 120000: loss 34.231115\n",
      "iteration 51000 / 120000: loss 0.000270\n",
      "iteration 51100 / 120000: loss 0.000271\n",
      "iteration 51200 / 120000: loss 0.000273\n",
      "iteration 51300 / 120000: loss 0.000271\n",
      "iteration 51400 / 120000: loss 33.443171\n",
      "iteration 51500 / 120000: loss 6.438054\n",
      "iteration 51600 / 120000: loss 0.000270\n",
      "iteration 51700 / 120000: loss 0.000270\n",
      "iteration 51800 / 120000: loss 0.000270\n",
      "iteration 51900 / 120000: loss 177.223675\n",
      "iteration 52000 / 120000: loss 0.000271\n",
      "iteration 52100 / 120000: loss 86.265557\n",
      "iteration 52200 / 120000: loss 0.000275\n",
      "iteration 52300 / 120000: loss 0.000276\n",
      "iteration 52400 / 120000: loss 138.968229\n",
      "iteration 52500 / 120000: loss 0.000279\n",
      "iteration 52600 / 120000: loss 0.000278\n",
      "iteration 52700 / 120000: loss 0.000279\n",
      "iteration 52800 / 120000: loss 0.000281\n",
      "iteration 52900 / 120000: loss 0.000282\n",
      "iteration 53000 / 120000: loss 0.000281\n",
      "iteration 53100 / 120000: loss 0.000279\n",
      "iteration 53200 / 120000: loss 0.000280\n",
      "iteration 53300 / 120000: loss 0.000279\n",
      "iteration 53400 / 120000: loss 0.000278\n",
      "iteration 53500 / 120000: loss 0.000278\n",
      "iteration 53600 / 120000: loss 0.000278\n",
      "iteration 53700 / 120000: loss 0.000278\n",
      "iteration 53800 / 120000: loss 0.000278\n",
      "iteration 53900 / 120000: loss 0.000278\n",
      "iteration 54000 / 120000: loss 0.000278\n",
      "iteration 54100 / 120000: loss 0.000278\n",
      "iteration 54200 / 120000: loss 0.000279\n",
      "iteration 54300 / 120000: loss 0.000277\n",
      "iteration 54400 / 120000: loss 0.000278\n",
      "iteration 54500 / 120000: loss 0.000277\n",
      "iteration 54600 / 120000: loss 0.000279\n",
      "iteration 54700 / 120000: loss 0.000281\n",
      "iteration 54800 / 120000: loss 0.000281\n",
      "iteration 54900 / 120000: loss 0.000281\n",
      "iteration 55000 / 120000: loss 0.000282\n",
      "iteration 55100 / 120000: loss 38.566337\n",
      "iteration 55200 / 120000: loss 0.000282\n",
      "iteration 55300 / 120000: loss 74.585398\n",
      "iteration 55400 / 120000: loss 0.000282\n",
      "iteration 55500 / 120000: loss 0.000283\n",
      "iteration 55600 / 120000: loss 140.534567\n",
      "iteration 55700 / 120000: loss 2.304376\n",
      "iteration 55800 / 120000: loss 0.000282\n",
      "iteration 55900 / 120000: loss 0.000282\n",
      "iteration 56000 / 120000: loss 0.000281\n",
      "iteration 56100 / 120000: loss 0.000283\n",
      "iteration 56200 / 120000: loss 25.474992\n",
      "iteration 56300 / 120000: loss 0.000280\n",
      "iteration 56400 / 120000: loss 0.000280\n",
      "iteration 56500 / 120000: loss 0.000281\n",
      "iteration 56600 / 120000: loss 0.000281\n",
      "iteration 56700 / 120000: loss 50.182008\n",
      "iteration 56800 / 120000: loss 0.000283\n",
      "iteration 56900 / 120000: loss 3.010170\n",
      "iteration 57000 / 120000: loss 0.000284\n",
      "iteration 57100 / 120000: loss 34.290304\n",
      "iteration 57200 / 120000: loss 0.000283\n",
      "iteration 57300 / 120000: loss 0.000283\n",
      "iteration 57400 / 120000: loss 0.000284\n",
      "iteration 57500 / 120000: loss 195.728846\n",
      "iteration 57600 / 120000: loss 0.000285\n",
      "iteration 57700 / 120000: loss 0.000285\n",
      "iteration 57800 / 120000: loss 0.000284\n",
      "iteration 57900 / 120000: loss 0.000284\n",
      "iteration 58000 / 120000: loss 0.000285\n",
      "iteration 58100 / 120000: loss 0.000286\n",
      "iteration 58200 / 120000: loss 0.000286\n",
      "iteration 58300 / 120000: loss 0.000289\n",
      "iteration 58400 / 120000: loss 0.000288\n",
      "iteration 58500 / 120000: loss 0.000289\n",
      "iteration 58600 / 120000: loss 62.883230\n",
      "iteration 58700 / 120000: loss 0.000291\n",
      "iteration 58800 / 120000: loss 0.000291\n",
      "iteration 58900 / 120000: loss 0.000290\n",
      "iteration 59000 / 120000: loss 9.600995\n",
      "iteration 59100 / 120000: loss 0.000290\n",
      "iteration 59200 / 120000: loss 81.739322\n",
      "iteration 59300 / 120000: loss 0.000292\n",
      "iteration 59400 / 120000: loss 0.000292\n",
      "iteration 59500 / 120000: loss 0.000292\n",
      "iteration 59600 / 120000: loss 0.000293\n",
      "iteration 59700 / 120000: loss 111.369906\n",
      "iteration 59800 / 120000: loss 0.000294\n",
      "iteration 59900 / 120000: loss 7.406934\n",
      "iteration 60000 / 120000: loss 0.000295\n",
      "iteration 60100 / 120000: loss 50.669021\n",
      "iteration 60200 / 120000: loss 0.000296\n",
      "iteration 60300 / 120000: loss 0.000299\n",
      "iteration 60400 / 120000: loss 0.000300\n",
      "iteration 60500 / 120000: loss 0.000300\n",
      "iteration 60600 / 120000: loss 0.000299\n",
      "iteration 60700 / 120000: loss 0.000299\n",
      "iteration 60800 / 120000: loss 0.000300\n",
      "iteration 60900 / 120000: loss 0.000300\n",
      "iteration 61000 / 120000: loss 0.000301\n",
      "iteration 61100 / 120000: loss 0.000303\n",
      "iteration 61200 / 120000: loss 0.000305\n",
      "iteration 61300 / 120000: loss 48.182256\n",
      "iteration 61400 / 120000: loss 0.000305\n",
      "iteration 61500 / 120000: loss 42.751245\n",
      "iteration 61600 / 120000: loss 0.000306\n",
      "iteration 61700 / 120000: loss 115.950004\n",
      "iteration 61800 / 120000: loss 0.000304\n",
      "iteration 61900 / 120000: loss 164.603471\n",
      "iteration 62000 / 120000: loss 0.000305\n",
      "iteration 62100 / 120000: loss 0.000308\n",
      "iteration 62200 / 120000: loss 78.461905\n",
      "iteration 62300 / 120000: loss 0.000308\n",
      "iteration 62400 / 120000: loss 0.000311\n",
      "iteration 62500 / 120000: loss 0.000312\n",
      "iteration 62600 / 120000: loss 0.000312\n",
      "iteration 62700 / 120000: loss 0.588616\n",
      "iteration 62800 / 120000: loss 0.000312\n",
      "iteration 62900 / 120000: loss 0.000311\n",
      "iteration 63000 / 120000: loss 0.000311\n",
      "iteration 63100 / 120000: loss 0.000311\n",
      "iteration 63200 / 120000: loss 0.000313\n",
      "iteration 63300 / 120000: loss 0.000314\n",
      "iteration 63400 / 120000: loss 0.000315\n",
      "iteration 63500 / 120000: loss 0.000316\n",
      "iteration 63600 / 120000: loss 0.000315\n",
      "iteration 63700 / 120000: loss 0.000316\n",
      "iteration 63800 / 120000: loss 0.000315\n",
      "iteration 63900 / 120000: loss 0.000317\n",
      "iteration 64000 / 120000: loss 0.000319\n",
      "iteration 64100 / 120000: loss 0.000318\n",
      "iteration 64200 / 120000: loss 0.000320\n",
      "iteration 64300 / 120000: loss 0.000320\n",
      "iteration 64400 / 120000: loss 0.000320\n",
      "iteration 64500 / 120000: loss 0.000321\n",
      "iteration 64600 / 120000: loss 0.000321\n",
      "iteration 64700 / 120000: loss 0.000321\n",
      "iteration 64800 / 120000: loss 29.006631\n",
      "iteration 64900 / 120000: loss 0.000322\n",
      "iteration 65000 / 120000: loss 0.000323\n",
      "iteration 65100 / 120000: loss 0.000325\n",
      "iteration 65200 / 120000: loss 0.000325\n",
      "iteration 65300 / 120000: loss 0.000326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 65400 / 120000: loss 0.000328\n",
      "iteration 65500 / 120000: loss 0.000327\n",
      "iteration 65600 / 120000: loss 0.000327\n",
      "iteration 65700 / 120000: loss 0.000328\n",
      "iteration 65800 / 120000: loss 0.000329\n",
      "iteration 65900 / 120000: loss 0.000331\n",
      "iteration 66000 / 120000: loss 0.000332\n",
      "iteration 66100 / 120000: loss 0.000332\n",
      "iteration 66200 / 120000: loss 0.000333\n",
      "iteration 66300 / 120000: loss 0.000333\n",
      "iteration 66400 / 120000: loss 0.000334\n",
      "iteration 66500 / 120000: loss 0.000334\n",
      "iteration 66600 / 120000: loss 0.000335\n",
      "iteration 66700 / 120000: loss 113.227614\n",
      "iteration 66800 / 120000: loss 0.000336\n",
      "iteration 66900 / 120000: loss 0.000336\n",
      "iteration 67000 / 120000: loss 0.000337\n",
      "iteration 67100 / 120000: loss 0.000338\n",
      "iteration 67200 / 120000: loss 0.000339\n",
      "iteration 67300 / 120000: loss 0.000339\n",
      "iteration 67400 / 120000: loss 0.000338\n",
      "iteration 67500 / 120000: loss 0.000338\n",
      "iteration 67600 / 120000: loss 0.000340\n",
      "iteration 67700 / 120000: loss 0.000338\n",
      "iteration 67800 / 120000: loss 0.000339\n",
      "iteration 67900 / 120000: loss 0.000340\n",
      "iteration 68000 / 120000: loss 0.000339\n",
      "iteration 68100 / 120000: loss 59.839995\n",
      "iteration 68200 / 120000: loss 25.919648\n",
      "iteration 68300 / 120000: loss 0.000343\n",
      "iteration 68400 / 120000: loss 0.000342\n",
      "iteration 68500 / 120000: loss 0.000343\n",
      "iteration 68600 / 120000: loss 68.351406\n",
      "iteration 68700 / 120000: loss 53.105841\n",
      "iteration 68800 / 120000: loss 0.000344\n",
      "iteration 68900 / 120000: loss 0.000345\n",
      "iteration 69000 / 120000: loss 0.000347\n",
      "iteration 69100 / 120000: loss 0.000347\n",
      "iteration 69200 / 120000: loss 0.000347\n",
      "iteration 69300 / 120000: loss 0.000348\n",
      "iteration 69400 / 120000: loss 0.000346\n",
      "iteration 69500 / 120000: loss 0.000347\n",
      "iteration 69600 / 120000: loss 52.653330\n",
      "iteration 69700 / 120000: loss 0.000349\n",
      "iteration 69800 / 120000: loss 0.000348\n",
      "iteration 69900 / 120000: loss 7.681121\n",
      "iteration 70000 / 120000: loss 43.492197\n",
      "iteration 70100 / 120000: loss 0.000351\n",
      "iteration 70200 / 120000: loss 0.000351\n",
      "iteration 70300 / 120000: loss 0.000354\n",
      "iteration 70400 / 120000: loss 47.906626\n",
      "iteration 70500 / 120000: loss 0.000353\n",
      "iteration 70600 / 120000: loss 0.000354\n",
      "iteration 70700 / 120000: loss 0.000356\n",
      "iteration 70800 / 120000: loss 56.634892\n",
      "iteration 70900 / 120000: loss 0.000356\n",
      "iteration 71000 / 120000: loss 0.000358\n",
      "iteration 71100 / 120000: loss 0.000357\n",
      "iteration 71200 / 120000: loss 25.404233\n",
      "iteration 71300 / 120000: loss 0.000356\n",
      "iteration 71400 / 120000: loss 79.566669\n",
      "iteration 71500 / 120000: loss 63.877146\n",
      "iteration 71600 / 120000: loss 0.000356\n",
      "iteration 71700 / 120000: loss 22.446524\n",
      "iteration 71800 / 120000: loss 0.000357\n",
      "iteration 71900 / 120000: loss 0.000357\n",
      "iteration 72000 / 120000: loss 3.278750\n",
      "iteration 72100 / 120000: loss 0.000358\n",
      "iteration 72200 / 120000: loss 0.000356\n",
      "iteration 72300 / 120000: loss 0.000356\n",
      "iteration 72400 / 120000: loss 29.352403\n",
      "iteration 72500 / 120000: loss 0.000357\n",
      "iteration 72600 / 120000: loss 0.000359\n",
      "iteration 72700 / 120000: loss 0.000358\n",
      "iteration 72800 / 120000: loss 0.000358\n",
      "iteration 72900 / 120000: loss 0.000359\n",
      "iteration 73000 / 120000: loss 32.317288\n",
      "iteration 73100 / 120000: loss 0.000362\n",
      "iteration 73200 / 120000: loss 80.315108\n",
      "iteration 73300 / 120000: loss 0.000362\n",
      "iteration 73400 / 120000: loss 0.000360\n",
      "iteration 73500 / 120000: loss 0.000359\n",
      "iteration 73600 / 120000: loss 0.000359\n",
      "iteration 73700 / 120000: loss 0.000360\n",
      "iteration 73800 / 120000: loss 166.482425\n",
      "iteration 73900 / 120000: loss 0.000363\n",
      "iteration 74000 / 120000: loss 0.000363\n",
      "iteration 74100 / 120000: loss 0.000365\n",
      "iteration 74200 / 120000: loss 0.000366\n",
      "iteration 74300 / 120000: loss 0.000367\n",
      "iteration 74400 / 120000: loss 0.000366\n",
      "iteration 74500 / 120000: loss 0.000365\n",
      "iteration 74600 / 120000: loss 0.000366\n",
      "iteration 74700 / 120000: loss 59.457884\n",
      "iteration 74800 / 120000: loss 73.517828\n",
      "iteration 74900 / 120000: loss 63.314033\n",
      "iteration 75000 / 120000: loss 0.000366\n",
      "iteration 75100 / 120000: loss 0.000367\n",
      "iteration 75200 / 120000: loss 0.000367\n",
      "iteration 75300 / 120000: loss 0.000367\n",
      "iteration 75400 / 120000: loss 0.000368\n",
      "iteration 75500 / 120000: loss 0.000368\n",
      "iteration 75600 / 120000: loss 0.000369\n",
      "iteration 75700 / 120000: loss 0.000371\n",
      "iteration 75800 / 120000: loss 0.000370\n",
      "iteration 75900 / 120000: loss 0.000370\n",
      "iteration 76000 / 120000: loss 12.019732\n",
      "iteration 76100 / 120000: loss 6.206758\n",
      "iteration 76200 / 120000: loss 0.000374\n",
      "iteration 76300 / 120000: loss 0.000374\n",
      "iteration 76400 / 120000: loss 0.000377\n",
      "iteration 76500 / 120000: loss 0.000375\n",
      "iteration 76600 / 120000: loss 0.000375\n",
      "iteration 76700 / 120000: loss 95.873412\n",
      "iteration 76800 / 120000: loss 0.000376\n",
      "iteration 76900 / 120000: loss 0.000375\n",
      "iteration 77000 / 120000: loss 0.000376\n",
      "iteration 77100 / 120000: loss 0.000376\n",
      "iteration 77200 / 120000: loss 0.000377\n",
      "iteration 77300 / 120000: loss 0.000377\n",
      "iteration 77400 / 120000: loss 0.000379\n",
      "iteration 77500 / 120000: loss 0.000379\n",
      "iteration 77600 / 120000: loss 56.311027\n",
      "iteration 77700 / 120000: loss 0.000382\n",
      "iteration 77800 / 120000: loss 0.000383\n",
      "iteration 77900 / 120000: loss 0.000384\n",
      "iteration 78000 / 120000: loss 0.000384\n",
      "iteration 78100 / 120000: loss 0.000384\n",
      "iteration 78200 / 120000: loss 0.000385\n",
      "iteration 78300 / 120000: loss 0.000386\n",
      "iteration 78400 / 120000: loss 0.000388\n",
      "iteration 78500 / 120000: loss 134.570141\n",
      "iteration 78600 / 120000: loss 0.000389\n",
      "iteration 78700 / 120000: loss 0.000390\n",
      "iteration 78800 / 120000: loss 17.623659\n",
      "iteration 78900 / 120000: loss 3.232022\n",
      "iteration 79000 / 120000: loss 0.000392\n",
      "iteration 79100 / 120000: loss 0.000396\n",
      "iteration 79200 / 120000: loss 0.000396\n",
      "iteration 79300 / 120000: loss 0.000396\n",
      "iteration 79400 / 120000: loss 0.000395\n",
      "iteration 79500 / 120000: loss 72.505773\n",
      "iteration 79600 / 120000: loss 0.000396\n",
      "iteration 79700 / 120000: loss 0.000396\n",
      "iteration 79800 / 120000: loss 36.209124\n",
      "iteration 79900 / 120000: loss 0.000395\n",
      "iteration 80000 / 120000: loss 0.000395\n",
      "iteration 80100 / 120000: loss 39.479324\n",
      "iteration 80200 / 120000: loss 30.541405\n",
      "iteration 80300 / 120000: loss 100.838060\n",
      "iteration 80400 / 120000: loss 0.000397\n",
      "iteration 80500 / 120000: loss 0.000399\n",
      "iteration 80600 / 120000: loss 0.000399\n",
      "iteration 80700 / 120000: loss 0.000400\n",
      "iteration 80800 / 120000: loss 47.425829\n",
      "iteration 80900 / 120000: loss 0.000399\n",
      "iteration 81000 / 120000: loss 0.000399\n",
      "iteration 81100 / 120000: loss 0.000400\n",
      "iteration 81200 / 120000: loss 0.000401\n",
      "iteration 81300 / 120000: loss 6.390362\n",
      "iteration 81400 / 120000: loss 0.000403\n",
      "iteration 81500 / 120000: loss 0.000402\n",
      "iteration 81600 / 120000: loss 148.136986\n",
      "iteration 81700 / 120000: loss 0.000401\n",
      "iteration 81800 / 120000: loss 0.000404\n",
      "iteration 81900 / 120000: loss 10.796267\n",
      "iteration 82000 / 120000: loss 35.148723\n",
      "iteration 82100 / 120000: loss 0.000405\n",
      "iteration 82200 / 120000: loss 128.797087\n",
      "iteration 82300 / 120000: loss 58.403494\n",
      "iteration 82400 / 120000: loss 0.000408\n",
      "iteration 82500 / 120000: loss 0.000408\n",
      "iteration 82600 / 120000: loss 126.846493\n",
      "iteration 82700 / 120000: loss 0.000408\n",
      "iteration 82800 / 120000: loss 0.000405\n",
      "iteration 82900 / 120000: loss 22.847659\n",
      "iteration 83000 / 120000: loss 0.000406\n",
      "iteration 83100 / 120000: loss 35.863815\n",
      "iteration 83200 / 120000: loss 0.000407\n",
      "iteration 83300 / 120000: loss 99.692119\n",
      "iteration 83400 / 120000: loss 0.000408\n",
      "iteration 83500 / 120000: loss 0.000407\n",
      "iteration 83600 / 120000: loss 0.000408\n",
      "iteration 83700 / 120000: loss 0.000412\n",
      "iteration 83800 / 120000: loss 0.000410\n",
      "iteration 83900 / 120000: loss 0.000410\n",
      "iteration 84000 / 120000: loss 0.000409\n",
      "iteration 84100 / 120000: loss 0.000409\n",
      "iteration 84200 / 120000: loss 0.000409\n",
      "iteration 84300 / 120000: loss 0.000409\n",
      "iteration 84400 / 120000: loss 55.746125\n",
      "iteration 84500 / 120000: loss 0.000408\n",
      "iteration 84600 / 120000: loss 0.000409\n",
      "iteration 84700 / 120000: loss 0.000409\n",
      "iteration 84800 / 120000: loss 0.000411\n",
      "iteration 84900 / 120000: loss 0.000413\n",
      "iteration 85000 / 120000: loss 31.430086\n",
      "iteration 85100 / 120000: loss 99.152944\n",
      "iteration 85200 / 120000: loss 180.656862\n",
      "iteration 85300 / 120000: loss 0.000413\n",
      "iteration 85400 / 120000: loss 0.000414\n",
      "iteration 85500 / 120000: loss 0.000414\n",
      "iteration 85600 / 120000: loss 0.000413\n",
      "iteration 85700 / 120000: loss 0.000413\n",
      "iteration 85800 / 120000: loss 83.016899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 85900 / 120000: loss 0.000411\n",
      "iteration 86000 / 120000: loss 0.000411\n",
      "iteration 86100 / 120000: loss 183.443695\n",
      "iteration 86200 / 120000: loss 0.000412\n",
      "iteration 86300 / 120000: loss 110.563631\n",
      "iteration 86400 / 120000: loss 78.796249\n",
      "iteration 86500 / 120000: loss 0.000416\n",
      "iteration 86600 / 120000: loss 27.050748\n",
      "iteration 86700 / 120000: loss 0.000417\n",
      "iteration 86800 / 120000: loss 0.000417\n",
      "iteration 86900 / 120000: loss 45.384147\n",
      "iteration 87000 / 120000: loss 0.000419\n",
      "iteration 87100 / 120000: loss 0.000420\n",
      "iteration 87200 / 120000: loss 0.000419\n",
      "iteration 87300 / 120000: loss 0.000420\n",
      "iteration 87400 / 120000: loss 0.000422\n",
      "iteration 87500 / 120000: loss 0.000425\n",
      "iteration 87600 / 120000: loss 0.000428\n",
      "iteration 87700 / 120000: loss 0.000427\n",
      "iteration 87800 / 120000: loss 0.000429\n",
      "iteration 87900 / 120000: loss 0.000429\n",
      "iteration 88000 / 120000: loss 1.679710\n",
      "iteration 88100 / 120000: loss 31.243126\n",
      "iteration 88200 / 120000: loss 0.000431\n",
      "iteration 88300 / 120000: loss 0.000430\n",
      "iteration 88400 / 120000: loss 0.000430\n",
      "iteration 88500 / 120000: loss 0.000433\n",
      "iteration 88600 / 120000: loss 0.000432\n",
      "iteration 88700 / 120000: loss 0.000432\n",
      "iteration 88800 / 120000: loss 0.000433\n",
      "iteration 88900 / 120000: loss 0.000434\n",
      "iteration 89000 / 120000: loss 87.474390\n",
      "iteration 89100 / 120000: loss 0.000436\n",
      "iteration 89200 / 120000: loss 17.903721\n",
      "iteration 89300 / 120000: loss 0.000437\n",
      "iteration 89400 / 120000: loss 0.000437\n",
      "iteration 89500 / 120000: loss 0.000439\n",
      "iteration 89600 / 120000: loss 6.837455\n",
      "iteration 89700 / 120000: loss 0.000439\n",
      "iteration 89800 / 120000: loss 0.000441\n",
      "iteration 89900 / 120000: loss 30.053891\n",
      "iteration 90000 / 120000: loss 55.346080\n",
      "iteration 90100 / 120000: loss 111.283019\n",
      "iteration 90200 / 120000: loss 0.000441\n",
      "iteration 90300 / 120000: loss 0.000442\n",
      "iteration 90400 / 120000: loss 0.000441\n",
      "iteration 90500 / 120000: loss 0.000442\n",
      "iteration 90600 / 120000: loss 0.000441\n",
      "iteration 90700 / 120000: loss 0.000444\n",
      "iteration 90800 / 120000: loss 19.088667\n",
      "iteration 90900 / 120000: loss 0.000443\n",
      "iteration 91000 / 120000: loss 64.230705\n",
      "iteration 91100 / 120000: loss 0.000445\n",
      "iteration 91200 / 120000: loss 0.000448\n",
      "iteration 91300 / 120000: loss 0.000448\n",
      "iteration 91400 / 120000: loss 0.000448\n",
      "iteration 91500 / 120000: loss 0.000447\n",
      "iteration 91600 / 120000: loss 127.671346\n",
      "iteration 91700 / 120000: loss 0.000449\n",
      "iteration 91800 / 120000: loss 0.000449\n",
      "iteration 91900 / 120000: loss 0.000450\n",
      "iteration 92000 / 120000: loss 0.000452\n",
      "iteration 92100 / 120000: loss 0.000452\n",
      "iteration 92200 / 120000: loss 0.000451\n",
      "iteration 92300 / 120000: loss 0.000451\n",
      "iteration 92400 / 120000: loss 190.105246\n",
      "iteration 92500 / 120000: loss 0.000452\n",
      "iteration 92600 / 120000: loss 0.000453\n",
      "iteration 92700 / 120000: loss 0.000453\n",
      "iteration 92800 / 120000: loss 10.769482\n",
      "iteration 92900 / 120000: loss 0.000454\n",
      "iteration 93000 / 120000: loss 0.000453\n",
      "iteration 93100 / 120000: loss 0.000453\n",
      "iteration 93200 / 120000: loss 0.000454\n",
      "iteration 93300 / 120000: loss 0.000454\n",
      "iteration 93400 / 120000: loss 0.000455\n",
      "iteration 93500 / 120000: loss 0.000456\n",
      "iteration 93600 / 120000: loss 0.000456\n",
      "iteration 93700 / 120000: loss 0.000456\n",
      "iteration 93800 / 120000: loss 0.000457\n",
      "iteration 93900 / 120000: loss 0.000458\n",
      "iteration 94000 / 120000: loss 64.886031\n",
      "iteration 94100 / 120000: loss 0.000458\n",
      "iteration 94200 / 120000: loss 0.000458\n",
      "iteration 94300 / 120000: loss 69.634093\n",
      "iteration 94400 / 120000: loss 0.000457\n",
      "iteration 94500 / 120000: loss 115.325834\n",
      "iteration 94600 / 120000: loss 0.000456\n",
      "iteration 94700 / 120000: loss 0.000457\n",
      "iteration 94800 / 120000: loss 8.498803\n",
      "iteration 94900 / 120000: loss 0.000459\n",
      "iteration 95000 / 120000: loss 0.000460\n",
      "iteration 95100 / 120000: loss 102.550575\n",
      "iteration 95200 / 120000: loss 0.000461\n",
      "iteration 95300 / 120000: loss 12.265180\n",
      "iteration 95400 / 120000: loss 0.000464\n",
      "iteration 95500 / 120000: loss 0.000465\n",
      "iteration 95600 / 120000: loss 0.000466\n",
      "iteration 95700 / 120000: loss 0.000465\n",
      "iteration 95800 / 120000: loss 0.000467\n",
      "iteration 95900 / 120000: loss 0.000468\n",
      "iteration 96000 / 120000: loss 0.000468\n",
      "iteration 96100 / 120000: loss 160.158618\n",
      "iteration 96200 / 120000: loss 0.000469\n",
      "iteration 96300 / 120000: loss 0.000469\n",
      "iteration 96400 / 120000: loss 0.000470\n",
      "iteration 96500 / 120000: loss 0.000469\n",
      "iteration 96600 / 120000: loss 0.000470\n",
      "iteration 96700 / 120000: loss 0.000470\n",
      "iteration 96800 / 120000: loss 0.000471\n",
      "iteration 96900 / 120000: loss 0.000473\n",
      "iteration 97000 / 120000: loss 0.000472\n",
      "iteration 97100 / 120000: loss 0.000474\n",
      "iteration 97200 / 120000: loss 19.488626\n",
      "iteration 97300 / 120000: loss 0.000476\n",
      "iteration 97400 / 120000: loss 46.980116\n",
      "iteration 97500 / 120000: loss 0.000478\n",
      "iteration 97600 / 120000: loss 90.062077\n",
      "iteration 97700 / 120000: loss 0.000479\n",
      "iteration 97800 / 120000: loss 0.000479\n",
      "iteration 97900 / 120000: loss 0.000479\n",
      "iteration 98000 / 120000: loss 3.975057\n",
      "iteration 98100 / 120000: loss 0.000481\n",
      "iteration 98200 / 120000: loss 90.732796\n",
      "iteration 98300 / 120000: loss 0.000483\n",
      "iteration 98400 / 120000: loss 0.000483\n",
      "iteration 98500 / 120000: loss 0.000483\n",
      "iteration 98600 / 120000: loss 0.000485\n",
      "iteration 98700 / 120000: loss 0.000487\n",
      "iteration 98800 / 120000: loss 0.000486\n",
      "iteration 98900 / 120000: loss 0.000486\n",
      "iteration 99000 / 120000: loss 95.901368\n",
      "iteration 99100 / 120000: loss 37.710786\n",
      "iteration 99200 / 120000: loss 133.186375\n",
      "iteration 99300 / 120000: loss 0.000483\n",
      "iteration 99400 / 120000: loss 10.138422\n",
      "iteration 99500 / 120000: loss 0.000485\n",
      "iteration 99600 / 120000: loss 0.000485\n",
      "iteration 99700 / 120000: loss 0.000483\n",
      "iteration 99800 / 120000: loss 0.000483\n",
      "iteration 99900 / 120000: loss 218.060597\n",
      "iteration 100000 / 120000: loss 0.000482\n",
      "iteration 100100 / 120000: loss 0.000482\n",
      "iteration 100200 / 120000: loss 0.000484\n",
      "iteration 100300 / 120000: loss 69.723338\n",
      "iteration 100400 / 120000: loss 0.000484\n",
      "iteration 100500 / 120000: loss 62.514605\n",
      "iteration 100600 / 120000: loss 0.000486\n",
      "iteration 100700 / 120000: loss 0.000485\n",
      "iteration 100800 / 120000: loss 0.000488\n",
      "iteration 100900 / 120000: loss 23.631153\n",
      "iteration 101000 / 120000: loss 0.000489\n",
      "iteration 101100 / 120000: loss 42.467208\n",
      "iteration 101200 / 120000: loss 0.000490\n",
      "iteration 101300 / 120000: loss 0.000491\n",
      "iteration 101400 / 120000: loss 201.883710\n",
      "iteration 101500 / 120000: loss 0.000490\n",
      "iteration 101600 / 120000: loss 0.000490\n",
      "iteration 101700 / 120000: loss 0.000487\n",
      "iteration 101800 / 120000: loss 0.000487\n",
      "iteration 101900 / 120000: loss 275.607403\n",
      "iteration 102000 / 120000: loss 0.000486\n",
      "iteration 102100 / 120000: loss 0.000487\n",
      "iteration 102200 / 120000: loss 0.000487\n",
      "iteration 102300 / 120000: loss 2.383050\n",
      "iteration 102400 / 120000: loss 0.000490\n",
      "iteration 102500 / 120000: loss 0.000490\n",
      "iteration 102600 / 120000: loss 0.000489\n",
      "iteration 102700 / 120000: loss 2.497023\n",
      "iteration 102800 / 120000: loss 0.000489\n",
      "iteration 102900 / 120000: loss 0.000489\n",
      "iteration 103000 / 120000: loss 0.000488\n",
      "iteration 103100 / 120000: loss 0.000488\n",
      "iteration 103200 / 120000: loss 4.770705\n",
      "iteration 103300 / 120000: loss 0.000491\n",
      "iteration 103400 / 120000: loss 0.000490\n",
      "iteration 103500 / 120000: loss 0.000491\n",
      "iteration 103600 / 120000: loss 0.000493\n",
      "iteration 103700 / 120000: loss 0.000493\n",
      "iteration 103800 / 120000: loss 0.000494\n",
      "iteration 103900 / 120000: loss 0.000494\n",
      "iteration 104000 / 120000: loss 0.000493\n",
      "iteration 104100 / 120000: loss 0.000494\n",
      "iteration 104200 / 120000: loss 0.000494\n",
      "iteration 104300 / 120000: loss 0.000494\n",
      "iteration 104400 / 120000: loss 0.000494\n",
      "iteration 104500 / 120000: loss 0.000494\n",
      "iteration 104600 / 120000: loss 0.000493\n",
      "iteration 104700 / 120000: loss 0.000493\n",
      "iteration 104800 / 120000: loss 0.000494\n",
      "iteration 104900 / 120000: loss 0.000495\n",
      "iteration 105000 / 120000: loss 0.000496\n",
      "iteration 105100 / 120000: loss 0.000498\n",
      "iteration 105200 / 120000: loss 0.000498\n",
      "iteration 105300 / 120000: loss 0.000500\n",
      "iteration 105400 / 120000: loss 40.982950\n",
      "iteration 105500 / 120000: loss 0.000501\n",
      "iteration 105600 / 120000: loss 0.000500\n",
      "iteration 105700 / 120000: loss 0.000500\n",
      "iteration 105800 / 120000: loss 0.000502\n",
      "iteration 105900 / 120000: loss 0.000501\n",
      "iteration 106000 / 120000: loss 9.602261\n",
      "iteration 106100 / 120000: loss 0.000502\n",
      "iteration 106200 / 120000: loss 22.275701\n",
      "iteration 106300 / 120000: loss 0.000502\n",
      "iteration 106400 / 120000: loss 36.464488\n",
      "iteration 106500 / 120000: loss 0.000503\n",
      "iteration 106600 / 120000: loss 6.191075\n",
      "iteration 106700 / 120000: loss 0.000502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 106800 / 120000: loss 14.615480\n",
      "iteration 106900 / 120000: loss 20.130049\n",
      "iteration 107000 / 120000: loss 0.000498\n",
      "iteration 107100 / 120000: loss 15.065096\n",
      "iteration 107200 / 120000: loss 0.000502\n",
      "iteration 107300 / 120000: loss 199.340006\n",
      "iteration 107400 / 120000: loss 9.440092\n",
      "iteration 107500 / 120000: loss 0.000503\n",
      "iteration 107600 / 120000: loss 0.000504\n",
      "iteration 107700 / 120000: loss 59.763695\n",
      "iteration 107800 / 120000: loss 0.000504\n",
      "iteration 107900 / 120000: loss 75.128364\n",
      "iteration 108000 / 120000: loss 17.368425\n",
      "iteration 108100 / 120000: loss 0.000507\n",
      "iteration 108200 / 120000: loss 0.000509\n",
      "iteration 108300 / 120000: loss 0.000508\n",
      "iteration 108400 / 120000: loss 7.175179\n",
      "iteration 108500 / 120000: loss 0.000508\n",
      "iteration 108600 / 120000: loss 164.167062\n",
      "iteration 108700 / 120000: loss 0.000507\n",
      "iteration 108800 / 120000: loss 0.000507\n",
      "iteration 108900 / 120000: loss 0.000507\n",
      "iteration 109000 / 120000: loss 0.000509\n",
      "iteration 109100 / 120000: loss 16.353811\n",
      "iteration 109200 / 120000: loss 116.276087\n",
      "iteration 109300 / 120000: loss 0.000511\n",
      "iteration 109400 / 120000: loss 0.000512\n",
      "iteration 109500 / 120000: loss 0.000511\n",
      "iteration 109600 / 120000: loss 0.000511\n",
      "iteration 109700 / 120000: loss 0.000511\n",
      "iteration 109800 / 120000: loss 0.000514\n",
      "iteration 109900 / 120000: loss 0.000513\n",
      "iteration 110000 / 120000: loss 0.000514\n",
      "iteration 110100 / 120000: loss 70.861912\n",
      "iteration 110200 / 120000: loss 0.000513\n",
      "iteration 110300 / 120000: loss 0.000514\n",
      "iteration 110400 / 120000: loss 0.000514\n",
      "iteration 110500 / 120000: loss 8.430608\n",
      "iteration 110600 / 120000: loss 0.000514\n",
      "iteration 110700 / 120000: loss 0.000516\n",
      "iteration 110800 / 120000: loss 0.000517\n",
      "iteration 110900 / 120000: loss 0.000518\n",
      "iteration 111000 / 120000: loss 0.000520\n",
      "iteration 111100 / 120000: loss 0.000521\n",
      "iteration 111200 / 120000: loss 0.000522\n",
      "iteration 111300 / 120000: loss 0.000522\n",
      "iteration 111400 / 120000: loss 0.000522\n",
      "iteration 111500 / 120000: loss 0.000520\n",
      "iteration 111600 / 120000: loss 0.000521\n",
      "iteration 111700 / 120000: loss 104.360272\n",
      "iteration 111800 / 120000: loss 0.000523\n",
      "iteration 111900 / 120000: loss 0.000523\n",
      "iteration 112000 / 120000: loss 0.000524\n",
      "iteration 112100 / 120000: loss 0.000523\n",
      "iteration 112200 / 120000: loss 0.000524\n",
      "iteration 112300 / 120000: loss 0.000525\n",
      "iteration 112400 / 120000: loss 3.800763\n",
      "iteration 112500 / 120000: loss 0.000527\n",
      "iteration 112600 / 120000: loss 0.000529\n",
      "iteration 112700 / 120000: loss 0.000529\n",
      "iteration 112800 / 120000: loss 0.000530\n",
      "iteration 112900 / 120000: loss 0.000533\n",
      "iteration 113000 / 120000: loss 0.000534\n",
      "iteration 113100 / 120000: loss 0.000533\n",
      "iteration 113200 / 120000: loss 0.000534\n",
      "iteration 113300 / 120000: loss 0.000535\n",
      "iteration 113400 / 120000: loss 0.000536\n",
      "iteration 113500 / 120000: loss 0.000536\n",
      "iteration 113600 / 120000: loss 0.000538\n",
      "iteration 113700 / 120000: loss 0.000537\n",
      "iteration 113800 / 120000: loss 0.000539\n",
      "iteration 113900 / 120000: loss 0.000539\n",
      "iteration 114000 / 120000: loss 24.027104\n",
      "iteration 114100 / 120000: loss 0.000536\n",
      "iteration 114200 / 120000: loss 0.000536\n",
      "iteration 114300 / 120000: loss 0.000536\n",
      "iteration 114400 / 120000: loss 0.000538\n",
      "iteration 114500 / 120000: loss 0.000537\n",
      "iteration 114600 / 120000: loss 65.889251\n",
      "iteration 114700 / 120000: loss 28.437987\n",
      "iteration 114800 / 120000: loss 0.000542\n",
      "iteration 114900 / 120000: loss 0.000543\n",
      "iteration 115000 / 120000: loss 0.000543\n",
      "iteration 115100 / 120000: loss 0.000546\n",
      "iteration 115200 / 120000: loss 0.000547\n",
      "iteration 115300 / 120000: loss 0.000546\n",
      "iteration 115400 / 120000: loss 0.000546\n",
      "iteration 115500 / 120000: loss 0.000546\n",
      "iteration 115600 / 120000: loss 0.000546\n",
      "iteration 115700 / 120000: loss 0.000547\n",
      "iteration 115800 / 120000: loss 0.000547\n",
      "iteration 115900 / 120000: loss 11.061138\n",
      "iteration 116000 / 120000: loss 151.595202\n",
      "iteration 116100 / 120000: loss 0.000547\n",
      "iteration 116200 / 120000: loss 0.000548\n",
      "iteration 116300 / 120000: loss 0.000548\n",
      "iteration 116400 / 120000: loss 0.000548\n",
      "iteration 116500 / 120000: loss 0.000549\n",
      "iteration 116600 / 120000: loss 45.360599\n",
      "iteration 116700 / 120000: loss 0.000550\n",
      "iteration 116800 / 120000: loss 0.000552\n",
      "iteration 116900 / 120000: loss 23.319852\n",
      "iteration 117000 / 120000: loss 0.000553\n",
      "iteration 117100 / 120000: loss 0.000554\n",
      "iteration 117200 / 120000: loss 0.000555\n",
      "iteration 117300 / 120000: loss 0.000555\n",
      "iteration 117400 / 120000: loss 0.000555\n",
      "iteration 117500 / 120000: loss 0.000555\n",
      "iteration 117600 / 120000: loss 0.000556\n",
      "iteration 117700 / 120000: loss 38.357904\n",
      "iteration 117800 / 120000: loss 8.680259\n",
      "iteration 117900 / 120000: loss 0.000558\n",
      "iteration 118000 / 120000: loss 0.000559\n",
      "iteration 118100 / 120000: loss 0.000560\n",
      "iteration 118200 / 120000: loss 5.561684\n",
      "iteration 118300 / 120000: loss 0.000560\n",
      "iteration 118400 / 120000: loss 0.000562\n",
      "iteration 118500 / 120000: loss 0.000563\n",
      "iteration 118600 / 120000: loss 0.000562\n",
      "iteration 118700 / 120000: loss 7.242581\n",
      "iteration 118800 / 120000: loss 0.000566\n",
      "iteration 118900 / 120000: loss 0.000567\n",
      "iteration 119000 / 120000: loss 0.000567\n",
      "iteration 119100 / 120000: loss 0.000569\n",
      "iteration 119200 / 120000: loss 0.000568\n",
      "iteration 119300 / 120000: loss 215.688633\n",
      "iteration 119400 / 120000: loss 0.000568\n",
      "iteration 119500 / 120000: loss 89.112973\n",
      "iteration 119600 / 120000: loss 0.000567\n",
      "iteration 119700 / 120000: loss 0.000568\n",
      "iteration 119800 / 120000: loss 64.791106\n",
      "iteration 119900 / 120000: loss 0.000570\n",
      "lr=5e-06 bs=1 regularization_rate=0.0003\n",
      "iteration 0 / 120000: loss 0.976790\n",
      "iteration 100 / 120000: loss 0.000004\n",
      "iteration 200 / 120000: loss 0.000005\n",
      "iteration 300 / 120000: loss 0.000008\n",
      "iteration 400 / 120000: loss 0.000009\n",
      "iteration 500 / 120000: loss 0.000009\n",
      "iteration 600 / 120000: loss 0.000010\n",
      "iteration 700 / 120000: loss 0.000011\n",
      "iteration 800 / 120000: loss 0.000013\n",
      "iteration 900 / 120000: loss 0.000013\n",
      "iteration 1000 / 120000: loss 0.000014\n",
      "iteration 1100 / 120000: loss 27.459709\n",
      "iteration 1200 / 120000: loss 0.000017\n",
      "iteration 1300 / 120000: loss 0.000017\n",
      "iteration 1400 / 120000: loss 0.000017\n",
      "iteration 1500 / 120000: loss 0.000019\n",
      "iteration 1600 / 120000: loss 35.760622\n",
      "iteration 1700 / 120000: loss 0.000020\n",
      "iteration 1800 / 120000: loss 0.000020\n",
      "iteration 1900 / 120000: loss 10.114587\n",
      "iteration 2000 / 120000: loss 9.367351\n",
      "iteration 2100 / 120000: loss 133.935028\n",
      "iteration 2200 / 120000: loss 48.322547\n",
      "iteration 2300 / 120000: loss 0.000023\n",
      "iteration 2400 / 120000: loss 0.000024\n",
      "iteration 2500 / 120000: loss 90.641641\n",
      "iteration 2600 / 120000: loss 34.497779\n",
      "iteration 2700 / 120000: loss 0.000026\n",
      "iteration 2800 / 120000: loss 83.329920\n",
      "iteration 2900 / 120000: loss 0.000027\n",
      "iteration 3000 / 120000: loss 0.000027\n",
      "iteration 3100 / 120000: loss 0.000029\n",
      "iteration 3200 / 120000: loss 0.000029\n",
      "iteration 3300 / 120000: loss 0.000030\n",
      "iteration 3400 / 120000: loss 0.000030\n",
      "iteration 3500 / 120000: loss 0.000030\n",
      "iteration 3600 / 120000: loss 20.010565\n",
      "iteration 3700 / 120000: loss 71.450382\n",
      "iteration 3800 / 120000: loss 36.326612\n",
      "iteration 3900 / 120000: loss 0.000033\n",
      "iteration 4000 / 120000: loss 219.994680\n",
      "iteration 4100 / 120000: loss 4.038104\n",
      "iteration 4200 / 120000: loss 225.730539\n",
      "iteration 4300 / 120000: loss 0.000033\n",
      "iteration 4400 / 120000: loss 0.000034\n",
      "iteration 4500 / 120000: loss 0.000034\n",
      "iteration 4600 / 120000: loss 17.996158\n",
      "iteration 4700 / 120000: loss 0.000036\n",
      "iteration 4800 / 120000: loss 0.000035\n",
      "iteration 4900 / 120000: loss 16.703744\n",
      "iteration 5000 / 120000: loss 0.000036\n",
      "iteration 5100 / 120000: loss 0.000037\n",
      "iteration 5200 / 120000: loss 0.000037\n",
      "iteration 5300 / 120000: loss 0.000037\n",
      "iteration 5400 / 120000: loss 0.000038\n",
      "iteration 5500 / 120000: loss 0.000040\n",
      "iteration 5600 / 120000: loss 31.304695\n",
      "iteration 5700 / 120000: loss 0.000042\n",
      "iteration 5800 / 120000: loss 0.000041\n",
      "iteration 5900 / 120000: loss 0.000043\n",
      "iteration 6000 / 120000: loss 0.000044\n",
      "iteration 6100 / 120000: loss 0.000044\n",
      "iteration 6200 / 120000: loss 3.580949\n",
      "iteration 6300 / 120000: loss 0.000045\n",
      "iteration 6400 / 120000: loss 0.000045\n",
      "iteration 6500 / 120000: loss 4.928703\n",
      "iteration 6600 / 120000: loss 0.000047\n",
      "iteration 6700 / 120000: loss 71.235137\n",
      "iteration 6800 / 120000: loss 0.000047\n",
      "iteration 6900 / 120000: loss 0.000048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 7000 / 120000: loss 0.000048\n",
      "iteration 7100 / 120000: loss 0.000050\n",
      "iteration 7200 / 120000: loss 0.000049\n",
      "iteration 7300 / 120000: loss 0.000049\n",
      "iteration 7400 / 120000: loss 153.961771\n",
      "iteration 7500 / 120000: loss 0.000050\n",
      "iteration 7600 / 120000: loss 14.151069\n",
      "iteration 7700 / 120000: loss 0.000051\n",
      "iteration 7800 / 120000: loss 0.000051\n",
      "iteration 7900 / 120000: loss 0.000052\n",
      "iteration 8000 / 120000: loss 0.000053\n",
      "iteration 8100 / 120000: loss 0.000052\n",
      "iteration 8200 / 120000: loss 27.025107\n",
      "iteration 8300 / 120000: loss 28.178999\n",
      "iteration 8400 / 120000: loss 48.801949\n",
      "iteration 8500 / 120000: loss 0.000053\n",
      "iteration 8600 / 120000: loss 0.000053\n",
      "iteration 8700 / 120000: loss 1.352622\n",
      "iteration 8800 / 120000: loss 0.000053\n",
      "iteration 8900 / 120000: loss 0.000053\n",
      "iteration 9000 / 120000: loss 35.143863\n",
      "iteration 9100 / 120000: loss 0.000054\n",
      "iteration 9200 / 120000: loss 0.000054\n",
      "iteration 9300 / 120000: loss 0.000054\n",
      "iteration 9400 / 120000: loss 20.597953\n",
      "iteration 9500 / 120000: loss 0.000052\n",
      "iteration 9600 / 120000: loss 0.000054\n",
      "iteration 9700 / 120000: loss 0.000055\n",
      "iteration 9800 / 120000: loss 90.558139\n",
      "iteration 9900 / 120000: loss 0.000055\n",
      "iteration 10000 / 120000: loss 25.723358\n",
      "iteration 10100 / 120000: loss 0.000057\n",
      "iteration 10200 / 120000: loss 0.000059\n",
      "iteration 10300 / 120000: loss 0.000060\n",
      "iteration 10400 / 120000: loss 36.408429\n",
      "iteration 10500 / 120000: loss 0.000060\n",
      "iteration 10600 / 120000: loss 0.000060\n",
      "iteration 10700 / 120000: loss 0.000062\n",
      "iteration 10800 / 120000: loss 12.886333\n",
      "iteration 10900 / 120000: loss 0.000063\n",
      "iteration 11000 / 120000: loss 0.000063\n",
      "iteration 11100 / 120000: loss 0.000064\n",
      "iteration 11200 / 120000: loss 0.000064\n",
      "iteration 11300 / 120000: loss 0.000064\n",
      "iteration 11400 / 120000: loss 0.000064\n",
      "iteration 11500 / 120000: loss 0.000066\n",
      "iteration 11600 / 120000: loss 0.000066\n",
      "iteration 11700 / 120000: loss 0.000066\n",
      "iteration 11800 / 120000: loss 0.000066\n",
      "iteration 11900 / 120000: loss 42.133963\n",
      "iteration 12000 / 120000: loss 0.000066\n",
      "iteration 12100 / 120000: loss 0.000066\n",
      "iteration 12200 / 120000: loss 0.000067\n",
      "iteration 12300 / 120000: loss 72.678860\n",
      "iteration 12400 / 120000: loss 184.860764\n",
      "iteration 12500 / 120000: loss 0.000068\n",
      "iteration 12600 / 120000: loss 0.000068\n",
      "iteration 12700 / 120000: loss 0.000068\n",
      "iteration 12800 / 120000: loss 0.000069\n",
      "iteration 12900 / 120000: loss 0.000070\n",
      "iteration 13000 / 120000: loss 0.000069\n",
      "iteration 13100 / 120000: loss 0.000070\n",
      "iteration 13200 / 120000: loss 0.000069\n",
      "iteration 13300 / 120000: loss 31.710787\n",
      "iteration 13400 / 120000: loss 0.000072\n",
      "iteration 13500 / 120000: loss 0.000070\n",
      "iteration 13600 / 120000: loss 0.000073\n",
      "iteration 13700 / 120000: loss 0.000072\n",
      "iteration 13800 / 120000: loss 0.000073\n",
      "iteration 13900 / 120000: loss 0.000074\n",
      "iteration 14000 / 120000: loss 0.000075\n",
      "iteration 14100 / 120000: loss 0.000077\n",
      "iteration 14200 / 120000: loss 0.000076\n",
      "iteration 14300 / 120000: loss 0.000075\n",
      "iteration 14400 / 120000: loss 0.000075\n",
      "iteration 14500 / 120000: loss 0.000077\n",
      "iteration 14600 / 120000: loss 0.000078\n",
      "iteration 14700 / 120000: loss 62.437180\n",
      "iteration 14800 / 120000: loss 0.000079\n",
      "iteration 14900 / 120000: loss 0.000078\n",
      "iteration 15000 / 120000: loss 0.000078\n",
      "iteration 15100 / 120000: loss 0.000079\n",
      "iteration 15200 / 120000: loss 0.000079\n",
      "iteration 15300 / 120000: loss 0.000080\n",
      "iteration 15400 / 120000: loss 0.000079\n",
      "iteration 15500 / 120000: loss 0.000080\n",
      "iteration 15600 / 120000: loss 106.993002\n",
      "iteration 15700 / 120000: loss 0.000080\n",
      "iteration 15800 / 120000: loss 0.000080\n",
      "iteration 15900 / 120000: loss 0.000080\n",
      "iteration 16000 / 120000: loss 0.000080\n",
      "iteration 16100 / 120000: loss 0.000081\n",
      "iteration 16200 / 120000: loss 0.000083\n",
      "iteration 16300 / 120000: loss 0.000082\n",
      "iteration 16400 / 120000: loss 76.998084\n",
      "iteration 16500 / 120000: loss 0.000083\n",
      "iteration 16600 / 120000: loss 0.000083\n",
      "iteration 16700 / 120000: loss 0.000082\n",
      "iteration 16800 / 120000: loss 0.000082\n",
      "iteration 16900 / 120000: loss 0.000082\n",
      "iteration 17000 / 120000: loss 0.000082\n",
      "iteration 17100 / 120000: loss 52.416412\n",
      "iteration 17200 / 120000: loss 0.000083\n",
      "iteration 17300 / 120000: loss 0.000082\n",
      "iteration 17400 / 120000: loss 0.000084\n",
      "iteration 17500 / 120000: loss 0.000084\n",
      "iteration 17600 / 120000: loss 0.000086\n",
      "iteration 17700 / 120000: loss 0.000087\n",
      "iteration 17800 / 120000: loss 0.000087\n",
      "iteration 17900 / 120000: loss 0.000088\n",
      "iteration 18000 / 120000: loss 0.000088\n",
      "iteration 18100 / 120000: loss 0.000087\n",
      "iteration 18200 / 120000: loss 0.000088\n",
      "iteration 18300 / 120000: loss 0.000088\n",
      "iteration 18400 / 120000: loss 0.000089\n",
      "iteration 18500 / 120000: loss 0.000089\n",
      "iteration 18600 / 120000: loss 10.983079\n",
      "iteration 18700 / 120000: loss 0.000089\n",
      "iteration 18800 / 120000: loss 55.136190\n",
      "iteration 18900 / 120000: loss 0.000092\n",
      "iteration 19000 / 120000: loss 0.000090\n",
      "iteration 19100 / 120000: loss 16.624262\n",
      "iteration 19200 / 120000: loss 0.000092\n",
      "iteration 19300 / 120000: loss 0.000093\n",
      "iteration 19400 / 120000: loss 0.000092\n",
      "iteration 19500 / 120000: loss 0.000091\n",
      "iteration 19600 / 120000: loss 0.000093\n",
      "iteration 19700 / 120000: loss 0.000092\n",
      "iteration 19800 / 120000: loss 0.000092\n",
      "iteration 19900 / 120000: loss 0.000094\n",
      "iteration 20000 / 120000: loss 0.000096\n",
      "iteration 20100 / 120000: loss 51.173291\n",
      "iteration 20200 / 120000: loss 55.189031\n",
      "iteration 20300 / 120000: loss 60.460155\n",
      "iteration 20400 / 120000: loss 0.000098\n",
      "iteration 20500 / 120000: loss 0.000099\n",
      "iteration 20600 / 120000: loss 0.000099\n",
      "iteration 20700 / 120000: loss 50.089297\n",
      "iteration 20800 / 120000: loss 0.000101\n",
      "iteration 20900 / 120000: loss 0.000100\n",
      "iteration 21000 / 120000: loss 0.000100\n",
      "iteration 21100 / 120000: loss 0.000101\n",
      "iteration 21200 / 120000: loss 0.000101\n",
      "iteration 21300 / 120000: loss 0.000100\n",
      "iteration 21400 / 120000: loss 80.205864\n",
      "iteration 21500 / 120000: loss 0.000104\n",
      "iteration 21600 / 120000: loss 0.000104\n",
      "iteration 21700 / 120000: loss 0.000104\n",
      "iteration 21800 / 120000: loss 0.000104\n",
      "iteration 21900 / 120000: loss 0.393876\n",
      "iteration 22000 / 120000: loss 0.000105\n",
      "iteration 22100 / 120000: loss 0.000104\n",
      "iteration 22200 / 120000: loss 114.898940\n",
      "iteration 22300 / 120000: loss 0.000105\n",
      "iteration 22400 / 120000: loss 0.000104\n",
      "iteration 22500 / 120000: loss 25.967349\n",
      "iteration 22600 / 120000: loss 36.759865\n",
      "iteration 22700 / 120000: loss 0.000102\n",
      "iteration 22800 / 120000: loss 150.452471\n",
      "iteration 22900 / 120000: loss 0.000102\n",
      "iteration 23000 / 120000: loss 67.985819\n",
      "iteration 23100 / 120000: loss 46.205764\n",
      "iteration 23200 / 120000: loss 0.000104\n",
      "iteration 23300 / 120000: loss 0.000105\n",
      "iteration 23400 / 120000: loss 0.000104\n",
      "iteration 23500 / 120000: loss 267.290565\n",
      "iteration 23600 / 120000: loss 75.100802\n",
      "iteration 23700 / 120000: loss 45.663406\n",
      "iteration 23800 / 120000: loss 0.000107\n",
      "iteration 23900 / 120000: loss 109.738864\n",
      "iteration 24000 / 120000: loss 0.000108\n",
      "iteration 24100 / 120000: loss 0.000109\n",
      "iteration 24200 / 120000: loss 150.094722\n",
      "iteration 24300 / 120000: loss 0.000109\n",
      "iteration 24400 / 120000: loss 0.842090\n",
      "iteration 24500 / 120000: loss 0.000107\n",
      "iteration 24600 / 120000: loss 0.000107\n",
      "iteration 24700 / 120000: loss 0.000108\n",
      "iteration 24800 / 120000: loss 0.000107\n",
      "iteration 24900 / 120000: loss 299.312951\n",
      "iteration 25000 / 120000: loss 0.000107\n",
      "iteration 25100 / 120000: loss 0.000108\n",
      "iteration 25200 / 120000: loss 0.000109\n",
      "iteration 25300 / 120000: loss 0.000110\n",
      "iteration 25400 / 120000: loss 282.299503\n",
      "iteration 25500 / 120000: loss 0.000112\n",
      "iteration 25600 / 120000: loss 31.208165\n",
      "iteration 25700 / 120000: loss 91.873326\n",
      "iteration 25800 / 120000: loss 55.758503\n",
      "iteration 25900 / 120000: loss 0.000115\n",
      "iteration 26000 / 120000: loss 79.981503\n",
      "iteration 26100 / 120000: loss 17.204386\n",
      "iteration 26200 / 120000: loss 0.000117\n",
      "iteration 26300 / 120000: loss 0.000117\n",
      "iteration 26400 / 120000: loss 75.907391\n",
      "iteration 26500 / 120000: loss 0.000119\n",
      "iteration 26600 / 120000: loss 39.284270\n",
      "iteration 26700 / 120000: loss 0.000118\n",
      "iteration 26800 / 120000: loss 0.000118\n",
      "iteration 26900 / 120000: loss 0.000118\n",
      "iteration 27000 / 120000: loss 0.000119\n",
      "iteration 27100 / 120000: loss 0.000120\n",
      "iteration 27200 / 120000: loss 0.000121\n",
      "iteration 27300 / 120000: loss 0.000120\n",
      "iteration 27400 / 120000: loss 0.000119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 27500 / 120000: loss 0.000120\n",
      "iteration 27600 / 120000: loss 12.006281\n",
      "iteration 27700 / 120000: loss 0.000121\n",
      "iteration 27800 / 120000: loss 0.000121\n",
      "iteration 27900 / 120000: loss 0.000122\n",
      "iteration 28000 / 120000: loss 3.836960\n",
      "iteration 28100 / 120000: loss 0.000123\n",
      "iteration 28200 / 120000: loss 0.000124\n",
      "iteration 28300 / 120000: loss 0.000125\n",
      "iteration 28400 / 120000: loss 0.000125\n",
      "iteration 28500 / 120000: loss 0.000125\n",
      "iteration 28600 / 120000: loss 0.000126\n",
      "iteration 28700 / 120000: loss 44.563072\n",
      "iteration 28800 / 120000: loss 0.000127\n",
      "iteration 28900 / 120000: loss 0.000126\n",
      "iteration 29000 / 120000: loss 0.000127\n",
      "iteration 29100 / 120000: loss 0.000126\n",
      "iteration 29200 / 120000: loss 0.000127\n",
      "iteration 29300 / 120000: loss 0.000126\n",
      "iteration 29400 / 120000: loss 4.966638\n",
      "iteration 29500 / 120000: loss 0.000128\n",
      "iteration 29600 / 120000: loss 65.579453\n",
      "iteration 29700 / 120000: loss 0.000128\n",
      "iteration 29800 / 120000: loss 0.000127\n",
      "iteration 29900 / 120000: loss 0.000128\n",
      "iteration 30000 / 120000: loss 0.000128\n",
      "iteration 30100 / 120000: loss 0.220521\n",
      "iteration 30200 / 120000: loss 0.000128\n",
      "iteration 30300 / 120000: loss 0.000129\n",
      "iteration 30400 / 120000: loss 0.000129\n",
      "iteration 30500 / 120000: loss 0.000130\n",
      "iteration 30600 / 120000: loss 83.809947\n",
      "iteration 30700 / 120000: loss 41.368645\n",
      "iteration 30800 / 120000: loss 0.000132\n",
      "iteration 30900 / 120000: loss 0.000132\n",
      "iteration 31000 / 120000: loss 0.000134\n",
      "iteration 31100 / 120000: loss 0.000134\n",
      "iteration 31200 / 120000: loss 103.923513\n",
      "iteration 31300 / 120000: loss 0.000135\n",
      "iteration 31400 / 120000: loss 0.000136\n",
      "iteration 31500 / 120000: loss 0.000136\n",
      "iteration 31600 / 120000: loss 0.000136\n",
      "iteration 31700 / 120000: loss 0.000136\n",
      "iteration 31800 / 120000: loss 65.876334\n",
      "iteration 31900 / 120000: loss 0.000136\n",
      "iteration 32000 / 120000: loss 0.000137\n",
      "iteration 32100 / 120000: loss 0.000138\n",
      "iteration 32200 / 120000: loss 0.000139\n",
      "iteration 32300 / 120000: loss 0.000140\n",
      "iteration 32400 / 120000: loss 0.000141\n",
      "iteration 32500 / 120000: loss 0.000141\n",
      "iteration 32600 / 120000: loss 0.000141\n",
      "iteration 32700 / 120000: loss 37.482743\n",
      "iteration 32800 / 120000: loss 69.695748\n",
      "iteration 32900 / 120000: loss 0.000142\n",
      "iteration 33000 / 120000: loss 116.179978\n",
      "iteration 33100 / 120000: loss 12.898708\n",
      "iteration 33200 / 120000: loss 0.000142\n",
      "iteration 33300 / 120000: loss 0.000142\n",
      "iteration 33400 / 120000: loss 0.000143\n",
      "iteration 33500 / 120000: loss 0.000143\n",
      "iteration 33600 / 120000: loss 0.000144\n",
      "iteration 33700 / 120000: loss 0.000144\n",
      "iteration 33800 / 120000: loss 20.642702\n",
      "iteration 33900 / 120000: loss 0.000145\n",
      "iteration 34000 / 120000: loss 0.000144\n",
      "iteration 34100 / 120000: loss 0.000142\n",
      "iteration 34200 / 120000: loss 0.000143\n",
      "iteration 34300 / 120000: loss 0.000143\n",
      "iteration 34400 / 120000: loss 0.000143\n",
      "iteration 34500 / 120000: loss 0.000144\n",
      "iteration 34600 / 120000: loss 0.000143\n",
      "iteration 34700 / 120000: loss 0.000144\n",
      "iteration 34800 / 120000: loss 0.000144\n",
      "iteration 34900 / 120000: loss 0.000144\n",
      "iteration 35000 / 120000: loss 0.000145\n",
      "iteration 35100 / 120000: loss 0.000145\n",
      "iteration 35200 / 120000: loss 0.000146\n",
      "iteration 35300 / 120000: loss 0.000145\n",
      "iteration 35400 / 120000: loss 0.000145\n",
      "iteration 35500 / 120000: loss 81.683490\n",
      "iteration 35600 / 120000: loss 0.000146\n",
      "iteration 35700 / 120000: loss 0.000146\n",
      "iteration 35800 / 120000: loss 0.000148\n",
      "iteration 35900 / 120000: loss 0.000149\n",
      "iteration 36000 / 120000: loss 0.000149\n",
      "iteration 36100 / 120000: loss 0.000148\n",
      "iteration 36200 / 120000: loss 79.973270\n",
      "iteration 36300 / 120000: loss 116.001597\n",
      "iteration 36400 / 120000: loss 0.000151\n",
      "iteration 36500 / 120000: loss 0.000151\n",
      "iteration 36600 / 120000: loss 0.000151\n",
      "iteration 36700 / 120000: loss 0.000150\n",
      "iteration 36800 / 120000: loss 0.000150\n",
      "iteration 36900 / 120000: loss 0.000150\n",
      "iteration 37000 / 120000: loss 0.000151\n",
      "iteration 37100 / 120000: loss 20.617344\n",
      "iteration 37200 / 120000: loss 0.000151\n",
      "iteration 37300 / 120000: loss 0.000152\n",
      "iteration 37400 / 120000: loss 27.153588\n",
      "iteration 37500 / 120000: loss 0.000153\n",
      "iteration 37600 / 120000: loss 0.000153\n",
      "iteration 37700 / 120000: loss 0.000152\n",
      "iteration 37800 / 120000: loss 0.000153\n",
      "iteration 37900 / 120000: loss 0.000153\n",
      "iteration 38000 / 120000: loss 0.000154\n",
      "iteration 38100 / 120000: loss 0.000154\n",
      "iteration 38200 / 120000: loss 0.000155\n",
      "iteration 38300 / 120000: loss 0.000155\n",
      "iteration 38400 / 120000: loss 0.000155\n",
      "iteration 38500 / 120000: loss 12.768360\n",
      "iteration 38600 / 120000: loss 0.000157\n",
      "iteration 38700 / 120000: loss 0.000157\n",
      "iteration 38800 / 120000: loss 0.000157\n",
      "iteration 38900 / 120000: loss 0.000156\n",
      "iteration 39000 / 120000: loss 0.000156\n",
      "iteration 39100 / 120000: loss 0.000157\n",
      "iteration 39200 / 120000: loss 0.000157\n",
      "iteration 39300 / 120000: loss 0.000157\n",
      "iteration 39400 / 120000: loss 0.000157\n",
      "iteration 39500 / 120000: loss 0.000159\n",
      "iteration 39600 / 120000: loss 0.000159\n",
      "iteration 39700 / 120000: loss 2.017800\n",
      "iteration 39800 / 120000: loss 18.758695\n",
      "iteration 39900 / 120000: loss 0.000160\n",
      "iteration 40000 / 120000: loss 0.000161\n",
      "iteration 40100 / 120000: loss 0.000162\n",
      "iteration 40200 / 120000: loss 176.016563\n",
      "iteration 40300 / 120000: loss 0.000162\n",
      "iteration 40400 / 120000: loss 0.000162\n",
      "iteration 40500 / 120000: loss 0.000163\n",
      "iteration 40600 / 120000: loss 0.000164\n",
      "iteration 40700 / 120000: loss 0.000165\n",
      "iteration 40800 / 120000: loss 0.000165\n",
      "iteration 40900 / 120000: loss 0.000165\n",
      "iteration 41000 / 120000: loss 0.000165\n",
      "iteration 41100 / 120000: loss 0.000165\n",
      "iteration 41200 / 120000: loss 0.000165\n",
      "iteration 41300 / 120000: loss 0.000164\n",
      "iteration 41400 / 120000: loss 0.000164\n",
      "iteration 41500 / 120000: loss 0.000163\n",
      "iteration 41600 / 120000: loss 0.000163\n",
      "iteration 41700 / 120000: loss 0.000164\n",
      "iteration 41800 / 120000: loss 0.000164\n",
      "iteration 41900 / 120000: loss 0.000165\n",
      "iteration 42000 / 120000: loss 40.430154\n",
      "iteration 42100 / 120000: loss 0.000166\n",
      "iteration 42200 / 120000: loss 188.484702\n",
      "iteration 42300 / 120000: loss 0.000168\n",
      "iteration 42400 / 120000: loss 0.000168\n",
      "iteration 42500 / 120000: loss 0.000168\n",
      "iteration 42600 / 120000: loss 0.000168\n",
      "iteration 42700 / 120000: loss 0.000168\n",
      "iteration 42800 / 120000: loss 0.000168\n",
      "iteration 42900 / 120000: loss 0.000169\n",
      "iteration 43000 / 120000: loss 0.000168\n",
      "iteration 43100 / 120000: loss 0.000169\n",
      "iteration 43200 / 120000: loss 0.000169\n",
      "iteration 43300 / 120000: loss 0.000167\n",
      "iteration 43400 / 120000: loss 0.000167\n",
      "iteration 43500 / 120000: loss 0.000167\n",
      "iteration 43600 / 120000: loss 0.000169\n",
      "iteration 43700 / 120000: loss 0.000170\n",
      "iteration 43800 / 120000: loss 0.000169\n",
      "iteration 43900 / 120000: loss 0.000169\n",
      "iteration 44000 / 120000: loss 54.993369\n",
      "iteration 44100 / 120000: loss 29.223969\n",
      "iteration 44200 / 120000: loss 0.000169\n",
      "iteration 44300 / 120000: loss 0.000171\n",
      "iteration 44400 / 120000: loss 0.000172\n",
      "iteration 44500 / 120000: loss 0.000172\n",
      "iteration 44600 / 120000: loss 116.510608\n",
      "iteration 44700 / 120000: loss 0.000172\n",
      "iteration 44800 / 120000: loss 0.000172\n",
      "iteration 44900 / 120000: loss 0.000172\n",
      "iteration 45000 / 120000: loss 0.000172\n",
      "iteration 45100 / 120000: loss 0.000171\n",
      "iteration 45200 / 120000: loss 0.000172\n",
      "iteration 45300 / 120000: loss 0.000173\n",
      "iteration 45400 / 120000: loss 0.000173\n",
      "iteration 45500 / 120000: loss 0.000173\n",
      "iteration 45600 / 120000: loss 0.000173\n",
      "iteration 45700 / 120000: loss 0.000173\n",
      "iteration 45800 / 120000: loss 0.000173\n",
      "iteration 45900 / 120000: loss 24.043138\n",
      "iteration 46000 / 120000: loss 0.000174\n",
      "iteration 46100 / 120000: loss 0.000175\n",
      "iteration 46200 / 120000: loss 0.000175\n",
      "iteration 46300 / 120000: loss 0.000175\n",
      "iteration 46400 / 120000: loss 13.233278\n",
      "iteration 46500 / 120000: loss 0.000178\n",
      "iteration 46600 / 120000: loss 0.000177\n",
      "iteration 46700 / 120000: loss 73.516523\n",
      "iteration 46800 / 120000: loss 0.000180\n",
      "iteration 46900 / 120000: loss 0.000180\n",
      "iteration 47000 / 120000: loss 0.000180\n",
      "iteration 47100 / 120000: loss 0.000181\n",
      "iteration 47200 / 120000: loss 0.000182\n",
      "iteration 47300 / 120000: loss 77.102866\n",
      "iteration 47400 / 120000: loss 59.585873\n",
      "iteration 47500 / 120000: loss 0.000182\n",
      "iteration 47600 / 120000: loss 0.000183\n",
      "iteration 47700 / 120000: loss 94.200333\n",
      "iteration 47800 / 120000: loss 10.699635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 47900 / 120000: loss 0.000184\n",
      "iteration 48000 / 120000: loss 62.181281\n",
      "iteration 48100 / 120000: loss 0.000183\n",
      "iteration 48200 / 120000: loss 0.000184\n",
      "iteration 48300 / 120000: loss 75.500384\n",
      "iteration 48400 / 120000: loss 0.000184\n",
      "iteration 48500 / 120000: loss 0.000185\n",
      "iteration 48600 / 120000: loss 0.000184\n",
      "iteration 48700 / 120000: loss 0.000183\n",
      "iteration 48800 / 120000: loss 0.000183\n",
      "iteration 48900 / 120000: loss 0.000184\n",
      "iteration 49000 / 120000: loss 0.000184\n",
      "iteration 49100 / 120000: loss 0.000186\n",
      "iteration 49200 / 120000: loss 80.461583\n",
      "iteration 49300 / 120000: loss 0.000187\n",
      "iteration 49400 / 120000: loss 0.000187\n",
      "iteration 49500 / 120000: loss 0.000188\n",
      "iteration 49600 / 120000: loss 0.000187\n",
      "iteration 49700 / 120000: loss 0.000188\n",
      "iteration 49800 / 120000: loss 0.000188\n",
      "iteration 49900 / 120000: loss 0.000188\n",
      "iteration 50000 / 120000: loss 0.000188\n",
      "iteration 50100 / 120000: loss 7.641420\n",
      "iteration 50200 / 120000: loss 0.000187\n",
      "iteration 50300 / 120000: loss 0.000187\n",
      "iteration 50400 / 120000: loss 11.070685\n",
      "iteration 50500 / 120000: loss 0.000187\n",
      "iteration 50600 / 120000: loss 32.371249\n",
      "iteration 50700 / 120000: loss 0.000188\n",
      "iteration 50800 / 120000: loss 0.000188\n",
      "iteration 50900 / 120000: loss 0.000189\n",
      "iteration 51000 / 120000: loss 35.762076\n",
      "iteration 51100 / 120000: loss 0.000191\n",
      "iteration 51200 / 120000: loss 24.049826\n",
      "iteration 51300 / 120000: loss 0.000191\n",
      "iteration 51400 / 120000: loss 0.000192\n",
      "iteration 51500 / 120000: loss 0.000193\n",
      "iteration 51600 / 120000: loss 0.000192\n",
      "iteration 51700 / 120000: loss 77.085005\n",
      "iteration 51800 / 120000: loss 0.000194\n",
      "iteration 51900 / 120000: loss 0.000194\n",
      "iteration 52000 / 120000: loss 0.000193\n",
      "iteration 52100 / 120000: loss 0.000193\n",
      "iteration 52200 / 120000: loss 0.000194\n",
      "iteration 52300 / 120000: loss 0.000195\n",
      "iteration 52400 / 120000: loss 0.000194\n",
      "iteration 52500 / 120000: loss 29.802088\n",
      "iteration 52600 / 120000: loss 0.000197\n",
      "iteration 52700 / 120000: loss 0.000196\n",
      "iteration 52800 / 120000: loss 33.648978\n",
      "iteration 52900 / 120000: loss 55.356264\n",
      "iteration 53000 / 120000: loss 0.000197\n",
      "iteration 53100 / 120000: loss 0.000197\n",
      "iteration 53200 / 120000: loss 0.000198\n",
      "iteration 53300 / 120000: loss 0.000199\n",
      "iteration 53400 / 120000: loss 0.000200\n",
      "iteration 53500 / 120000: loss 0.000199\n",
      "iteration 53600 / 120000: loss 0.000199\n",
      "iteration 53700 / 120000: loss 0.000200\n",
      "iteration 53800 / 120000: loss 35.588582\n",
      "iteration 53900 / 120000: loss 0.000201\n",
      "iteration 54000 / 120000: loss 0.000201\n",
      "iteration 54100 / 120000: loss 0.000202\n",
      "iteration 54200 / 120000: loss 0.000203\n",
      "iteration 54300 / 120000: loss 0.000203\n",
      "iteration 54400 / 120000: loss 0.000202\n",
      "iteration 54500 / 120000: loss 0.000203\n",
      "iteration 54600 / 120000: loss 0.000203\n",
      "iteration 54700 / 120000: loss 5.179689\n",
      "iteration 54800 / 120000: loss 0.000204\n",
      "iteration 54900 / 120000: loss 27.162937\n",
      "iteration 55000 / 120000: loss 0.000205\n",
      "iteration 55100 / 120000: loss 0.000205\n",
      "iteration 55200 / 120000: loss 0.000205\n",
      "iteration 55300 / 120000: loss 0.000205\n",
      "iteration 55400 / 120000: loss 7.115963\n",
      "iteration 55500 / 120000: loss 92.742435\n",
      "iteration 55600 / 120000: loss 0.000207\n",
      "iteration 55700 / 120000: loss 0.000207\n",
      "iteration 55800 / 120000: loss 0.000206\n",
      "iteration 55900 / 120000: loss 0.000207\n",
      "iteration 56000 / 120000: loss 0.000208\n",
      "iteration 56100 / 120000: loss 0.000207\n",
      "iteration 56200 / 120000: loss 0.000208\n",
      "iteration 56300 / 120000: loss 0.000207\n",
      "iteration 56400 / 120000: loss 0.000207\n",
      "iteration 56500 / 120000: loss 73.729663\n",
      "iteration 56600 / 120000: loss 0.000208\n",
      "iteration 56700 / 120000: loss 59.033994\n",
      "iteration 56800 / 120000: loss 0.000211\n",
      "iteration 56900 / 120000: loss 0.000212\n",
      "iteration 57000 / 120000: loss 0.000211\n",
      "iteration 57100 / 120000: loss 0.000212\n",
      "iteration 57200 / 120000: loss 0.000212\n",
      "iteration 57300 / 120000: loss 0.000213\n",
      "iteration 57400 / 120000: loss 0.000213\n",
      "iteration 57500 / 120000: loss 0.000214\n",
      "iteration 57600 / 120000: loss 0.000214\n",
      "iteration 57700 / 120000: loss 17.592065\n",
      "iteration 57800 / 120000: loss 0.000213\n",
      "iteration 57900 / 120000: loss 0.000214\n",
      "iteration 58000 / 120000: loss 0.000212\n",
      "iteration 58100 / 120000: loss 1.970052\n",
      "iteration 58200 / 120000: loss 15.307299\n",
      "iteration 58300 / 120000: loss 0.000214\n",
      "iteration 58400 / 120000: loss 0.000214\n",
      "iteration 58500 / 120000: loss 68.909270\n",
      "iteration 58600 / 120000: loss 0.000214\n",
      "iteration 58700 / 120000: loss 193.051556\n",
      "iteration 58800 / 120000: loss 0.000214\n",
      "iteration 58900 / 120000: loss 0.000215\n",
      "iteration 59000 / 120000: loss 0.000215\n",
      "iteration 59100 / 120000: loss 11.437874\n",
      "iteration 59200 / 120000: loss 20.896375\n",
      "iteration 59300 / 120000: loss 16.171759\n",
      "iteration 59400 / 120000: loss 0.000220\n",
      "iteration 59500 / 120000: loss 0.000220\n",
      "iteration 59600 / 120000: loss 0.000219\n",
      "iteration 59700 / 120000: loss 179.759860\n",
      "iteration 59800 / 120000: loss 0.000221\n",
      "iteration 59900 / 120000: loss 0.000221\n",
      "iteration 60000 / 120000: loss 0.000222\n",
      "iteration 60100 / 120000: loss 0.000222\n",
      "iteration 60200 / 120000: loss 0.000223\n",
      "iteration 60300 / 120000: loss 304.372785\n",
      "iteration 60400 / 120000: loss 0.000225\n",
      "iteration 60500 / 120000: loss 0.000225\n",
      "iteration 60600 / 120000: loss 4.608614\n",
      "iteration 60700 / 120000: loss 0.000226\n",
      "iteration 60800 / 120000: loss 0.000226\n",
      "iteration 60900 / 120000: loss 0.000227\n",
      "iteration 61000 / 120000: loss 0.000227\n",
      "iteration 61100 / 120000: loss 52.605151\n",
      "iteration 61200 / 120000: loss 0.000226\n",
      "iteration 61300 / 120000: loss 0.000227\n",
      "iteration 61400 / 120000: loss 7.882788\n",
      "iteration 61500 / 120000: loss 0.000226\n",
      "iteration 61600 / 120000: loss 0.000227\n",
      "iteration 61700 / 120000: loss 37.210343\n",
      "iteration 61800 / 120000: loss 0.000227\n",
      "iteration 61900 / 120000: loss 0.000227\n",
      "iteration 62000 / 120000: loss 0.000228\n",
      "iteration 62100 / 120000: loss 145.264237\n",
      "iteration 62200 / 120000: loss 0.000230\n",
      "iteration 62300 / 120000: loss 65.919203\n",
      "iteration 62400 / 120000: loss 0.000232\n",
      "iteration 62500 / 120000: loss 0.000231\n",
      "iteration 62600 / 120000: loss 44.261268\n",
      "iteration 62700 / 120000: loss 7.079883\n",
      "iteration 62800 / 120000: loss 0.000232\n",
      "iteration 62900 / 120000: loss 0.000231\n",
      "iteration 63000 / 120000: loss 0.000231\n",
      "iteration 63100 / 120000: loss 56.744133\n",
      "iteration 63200 / 120000: loss 0.000231\n",
      "iteration 63300 / 120000: loss 66.884398\n",
      "iteration 63400 / 120000: loss 19.042818\n",
      "iteration 63500 / 120000: loss 0.000232\n",
      "iteration 63600 / 120000: loss 0.000232\n",
      "iteration 63700 / 120000: loss 0.000233\n",
      "iteration 63800 / 120000: loss 12.074034\n",
      "iteration 63900 / 120000: loss 0.000234\n",
      "iteration 64000 / 120000: loss 0.000234\n",
      "iteration 64100 / 120000: loss 0.000235\n",
      "iteration 64200 / 120000: loss 0.000235\n",
      "iteration 64300 / 120000: loss 0.000234\n",
      "iteration 64400 / 120000: loss 0.000234\n",
      "iteration 64500 / 120000: loss 0.000235\n",
      "iteration 64600 / 120000: loss 0.000235\n",
      "iteration 64700 / 120000: loss 0.000235\n",
      "iteration 64800 / 120000: loss 106.616007\n",
      "iteration 64900 / 120000: loss 0.000234\n",
      "iteration 65000 / 120000: loss 0.000234\n",
      "iteration 65100 / 120000: loss 0.000233\n",
      "iteration 65200 / 120000: loss 0.000233\n",
      "iteration 65300 / 120000: loss 0.000234\n",
      "iteration 65400 / 120000: loss 55.287813\n",
      "iteration 65500 / 120000: loss 2.570270\n",
      "iteration 65600 / 120000: loss 0.000235\n",
      "iteration 65700 / 120000: loss 0.000237\n",
      "iteration 65800 / 120000: loss 0.000238\n",
      "iteration 65900 / 120000: loss 0.000239\n",
      "iteration 66000 / 120000: loss 94.436329\n",
      "iteration 66100 / 120000: loss 0.000240\n",
      "iteration 66200 / 120000: loss 0.000239\n",
      "iteration 66300 / 120000: loss 0.000240\n",
      "iteration 66400 / 120000: loss 33.037143\n",
      "iteration 66500 / 120000: loss 0.000241\n",
      "iteration 66600 / 120000: loss 0.000241\n",
      "iteration 66700 / 120000: loss 0.000242\n",
      "iteration 66800 / 120000: loss 14.528925\n",
      "iteration 66900 / 120000: loss 0.000243\n",
      "iteration 67000 / 120000: loss 0.000243\n",
      "iteration 67100 / 120000: loss 0.000244\n",
      "iteration 67200 / 120000: loss 0.000243\n",
      "iteration 67300 / 120000: loss 3.081218\n",
      "iteration 67400 / 120000: loss 86.859924\n",
      "iteration 67500 / 120000: loss 0.000246\n",
      "iteration 67600 / 120000: loss 0.000247\n",
      "iteration 67700 / 120000: loss 0.000247\n",
      "iteration 67800 / 120000: loss 38.030107\n",
      "iteration 67900 / 120000: loss 0.000248\n",
      "iteration 68000 / 120000: loss 0.000249\n",
      "iteration 68100 / 120000: loss 0.000249\n",
      "iteration 68200 / 120000: loss 0.000248\n",
      "iteration 68300 / 120000: loss 0.000248\n",
      "iteration 68400 / 120000: loss 53.453990\n",
      "iteration 68500 / 120000: loss 6.101760\n",
      "iteration 68600 / 120000: loss 0.000250\n",
      "iteration 68700 / 120000: loss 0.000249\n",
      "iteration 68800 / 120000: loss 0.000249\n",
      "iteration 68900 / 120000: loss 23.142010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 69000 / 120000: loss 280.303609\n",
      "iteration 69100 / 120000: loss 0.000251\n",
      "iteration 69200 / 120000: loss 0.000252\n",
      "iteration 69300 / 120000: loss 0.000254\n",
      "iteration 69400 / 120000: loss 0.000253\n",
      "iteration 69500 / 120000: loss 0.000253\n",
      "iteration 69600 / 120000: loss 137.442342\n",
      "iteration 69700 / 120000: loss 0.000253\n",
      "iteration 69800 / 120000: loss 0.000254\n",
      "iteration 69900 / 120000: loss 0.000253\n",
      "iteration 70000 / 120000: loss 0.000253\n",
      "iteration 70100 / 120000: loss 0.000254\n",
      "iteration 70200 / 120000: loss 0.000253\n",
      "iteration 70300 / 120000: loss 0.000253\n",
      "iteration 70400 / 120000: loss 16.387363\n",
      "iteration 70500 / 120000: loss 0.000255\n",
      "iteration 70600 / 120000: loss 0.000256\n",
      "iteration 70700 / 120000: loss 0.000255\n",
      "iteration 70800 / 120000: loss 0.000256\n",
      "iteration 70900 / 120000: loss 0.000256\n",
      "iteration 71000 / 120000: loss 94.671756\n",
      "iteration 71100 / 120000: loss 0.000258\n",
      "iteration 71200 / 120000: loss 0.000259\n",
      "iteration 71300 / 120000: loss 0.000261\n",
      "iteration 71400 / 120000: loss 0.000261\n",
      "iteration 71500 / 120000: loss 0.000261\n",
      "iteration 71600 / 120000: loss 0.000262\n",
      "iteration 71700 / 120000: loss 101.845630\n",
      "iteration 71800 / 120000: loss 0.000261\n",
      "iteration 71900 / 120000: loss 0.000261\n",
      "iteration 72000 / 120000: loss 0.000261\n",
      "iteration 72100 / 120000: loss 0.000261\n",
      "iteration 72200 / 120000: loss 0.000262\n",
      "iteration 72300 / 120000: loss 0.000261\n",
      "iteration 72400 / 120000: loss 0.000262\n",
      "iteration 72500 / 120000: loss 0.000263\n",
      "iteration 72600 / 120000: loss 0.000263\n",
      "iteration 72700 / 120000: loss 0.000263\n",
      "iteration 72800 / 120000: loss 0.000263\n",
      "iteration 72900 / 120000: loss 0.000264\n",
      "iteration 73000 / 120000: loss 136.824852\n",
      "iteration 73100 / 120000: loss 0.000265\n",
      "iteration 73200 / 120000: loss 111.845342\n",
      "iteration 73300 / 120000: loss 0.000265\n",
      "iteration 73400 / 120000: loss 0.000265\n",
      "iteration 73500 / 120000: loss 0.000265\n",
      "iteration 73600 / 120000: loss 22.170405\n",
      "iteration 73700 / 120000: loss 121.632730\n",
      "iteration 73800 / 120000: loss 0.000267\n",
      "iteration 73900 / 120000: loss 0.000267\n",
      "iteration 74000 / 120000: loss 0.000267\n",
      "iteration 74100 / 120000: loss 0.000268\n",
      "iteration 74200 / 120000: loss 0.000269\n",
      "iteration 74300 / 120000: loss 0.000268\n",
      "iteration 74400 / 120000: loss 0.000268\n",
      "iteration 74500 / 120000: loss 0.000267\n",
      "iteration 74600 / 120000: loss 0.000269\n",
      "iteration 74700 / 120000: loss 0.000268\n",
      "iteration 74800 / 120000: loss 0.000269\n",
      "iteration 74900 / 120000: loss 0.000270\n",
      "iteration 75000 / 120000: loss 24.288856\n",
      "iteration 75100 / 120000: loss 0.000271\n",
      "iteration 75200 / 120000: loss 174.585962\n",
      "iteration 75300 / 120000: loss 0.000272\n",
      "iteration 75400 / 120000: loss 0.000272\n",
      "iteration 75500 / 120000: loss 26.207443\n",
      "iteration 75600 / 120000: loss 0.000274\n",
      "iteration 75700 / 120000: loss 0.000273\n",
      "iteration 75800 / 120000: loss 0.000273\n",
      "iteration 75900 / 120000: loss 0.000274\n",
      "iteration 76000 / 120000: loss 0.000274\n",
      "iteration 76100 / 120000: loss 0.000274\n",
      "iteration 76200 / 120000: loss 0.000274\n",
      "iteration 76300 / 120000: loss 0.000275\n",
      "iteration 76400 / 120000: loss 0.000276\n",
      "iteration 76500 / 120000: loss 0.000277\n",
      "iteration 76600 / 120000: loss 0.000279\n",
      "iteration 76700 / 120000: loss 0.000279\n",
      "iteration 76800 / 120000: loss 0.000279\n",
      "iteration 76900 / 120000: loss 0.000279\n",
      "iteration 77000 / 120000: loss 146.821470\n",
      "iteration 77100 / 120000: loss 0.000280\n",
      "iteration 77200 / 120000: loss 53.985602\n",
      "iteration 77300 / 120000: loss 0.000281\n",
      "iteration 77400 / 120000: loss 0.000280\n",
      "iteration 77500 / 120000: loss 0.000281\n",
      "iteration 77600 / 120000: loss 0.000281\n",
      "iteration 77700 / 120000: loss 136.129522\n",
      "iteration 77800 / 120000: loss 0.000281\n",
      "iteration 77900 / 120000: loss 0.000281\n",
      "iteration 78000 / 120000: loss 58.913217\n",
      "iteration 78100 / 120000: loss 0.000284\n",
      "iteration 78200 / 120000: loss 75.013350\n",
      "iteration 78300 / 120000: loss 0.000284\n",
      "iteration 78400 / 120000: loss 21.666577\n",
      "iteration 78500 / 120000: loss 26.837904\n",
      "iteration 78600 / 120000: loss 28.077024\n",
      "iteration 78700 / 120000: loss 0.000285\n",
      "iteration 78800 / 120000: loss 0.000286\n",
      "iteration 78900 / 120000: loss 0.000286\n",
      "iteration 79000 / 120000: loss 0.000287\n",
      "iteration 79100 / 120000: loss 0.000287\n",
      "iteration 79200 / 120000: loss 0.000287\n",
      "iteration 79300 / 120000: loss 240.281890\n",
      "iteration 79400 / 120000: loss 0.000287\n",
      "iteration 79500 / 120000: loss 0.000288\n",
      "iteration 79600 / 120000: loss 54.634932\n",
      "iteration 79700 / 120000: loss 0.000287\n",
      "iteration 79800 / 120000: loss 37.598115\n",
      "iteration 79900 / 120000: loss 0.000290\n",
      "iteration 80000 / 120000: loss 33.842888\n",
      "iteration 80100 / 120000: loss 0.000291\n",
      "iteration 80200 / 120000: loss 0.000290\n",
      "iteration 80300 / 120000: loss 0.000290\n",
      "iteration 80400 / 120000: loss 0.000292\n",
      "iteration 80500 / 120000: loss 0.000292\n",
      "iteration 80600 / 120000: loss 0.000293\n",
      "iteration 80700 / 120000: loss 17.687869\n",
      "iteration 80800 / 120000: loss 0.000294\n",
      "iteration 80900 / 120000: loss 0.000293\n",
      "iteration 81000 / 120000: loss 0.000294\n",
      "iteration 81100 / 120000: loss 0.000295\n",
      "iteration 81200 / 120000: loss 0.000294\n",
      "iteration 81300 / 120000: loss 0.000295\n",
      "iteration 81400 / 120000: loss 0.000295\n",
      "iteration 81500 / 120000: loss 0.000296\n",
      "iteration 81600 / 120000: loss 118.165995\n",
      "iteration 81700 / 120000: loss 0.000295\n",
      "iteration 81800 / 120000: loss 0.000294\n",
      "iteration 81900 / 120000: loss 0.000294\n",
      "iteration 82000 / 120000: loss 66.452053\n",
      "iteration 82100 / 120000: loss 113.272289\n",
      "iteration 82200 / 120000: loss 0.000296\n",
      "iteration 82300 / 120000: loss 0.000297\n",
      "iteration 82400 / 120000: loss 42.289200\n",
      "iteration 82500 / 120000: loss 0.000297\n",
      "iteration 82600 / 120000: loss 0.000297\n",
      "iteration 82700 / 120000: loss 0.000298\n",
      "iteration 82800 / 120000: loss 0.000298\n",
      "iteration 82900 / 120000: loss 114.190396\n",
      "iteration 83000 / 120000: loss 0.000297\n",
      "iteration 83100 / 120000: loss 0.000297\n",
      "iteration 83200 / 120000: loss 0.000297\n",
      "iteration 83300 / 120000: loss 0.000298\n",
      "iteration 83400 / 120000: loss 0.000299\n",
      "iteration 83500 / 120000: loss 0.000299\n",
      "iteration 83600 / 120000: loss 0.000300\n",
      "iteration 83700 / 120000: loss 0.000299\n",
      "iteration 83800 / 120000: loss 0.000300\n",
      "iteration 83900 / 120000: loss 0.000299\n",
      "iteration 84000 / 120000: loss 0.000301\n",
      "iteration 84100 / 120000: loss 0.000301\n",
      "iteration 84200 / 120000: loss 0.000301\n",
      "iteration 84300 / 120000: loss 0.000303\n",
      "iteration 84400 / 120000: loss 5.818986\n",
      "iteration 84500 / 120000: loss 59.286110\n",
      "iteration 84600 / 120000: loss 0.000302\n",
      "iteration 84700 / 120000: loss 0.000302\n",
      "iteration 84800 / 120000: loss 0.000304\n",
      "iteration 84900 / 120000: loss 0.000305\n",
      "iteration 85000 / 120000: loss 0.000305\n",
      "iteration 85100 / 120000: loss 0.000305\n",
      "iteration 85200 / 120000: loss 0.000304\n",
      "iteration 85300 / 120000: loss 0.000304\n",
      "iteration 85400 / 120000: loss 21.771429\n",
      "iteration 85500 / 120000: loss 20.189865\n",
      "iteration 85600 / 120000: loss 0.000304\n",
      "iteration 85700 / 120000: loss 0.000305\n",
      "iteration 85800 / 120000: loss 0.000305\n",
      "iteration 85900 / 120000: loss 0.000307\n",
      "iteration 86000 / 120000: loss 0.000308\n",
      "iteration 86100 / 120000: loss 118.217096\n",
      "iteration 86200 / 120000: loss 0.000310\n",
      "iteration 86300 / 120000: loss 0.000309\n",
      "iteration 86400 / 120000: loss 0.000309\n",
      "iteration 86500 / 120000: loss 7.984867\n",
      "iteration 86600 / 120000: loss 0.000310\n",
      "iteration 86700 / 120000: loss 0.000311\n",
      "iteration 86800 / 120000: loss 0.000311\n",
      "iteration 86900 / 120000: loss 53.210255\n",
      "iteration 87000 / 120000: loss 41.770097\n",
      "iteration 87100 / 120000: loss 127.684990\n",
      "iteration 87200 / 120000: loss 0.000310\n",
      "iteration 87300 / 120000: loss 0.000310\n",
      "iteration 87400 / 120000: loss 88.948193\n",
      "iteration 87500 / 120000: loss 0.000311\n",
      "iteration 87600 / 120000: loss 0.000311\n",
      "iteration 87700 / 120000: loss 29.736178\n",
      "iteration 87800 / 120000: loss 0.000312\n",
      "iteration 87900 / 120000: loss 0.000314\n",
      "iteration 88000 / 120000: loss 53.723818\n",
      "iteration 88100 / 120000: loss 11.610420\n",
      "iteration 88200 / 120000: loss 0.000315\n",
      "iteration 88300 / 120000: loss 42.381380\n",
      "iteration 88400 / 120000: loss 0.000314\n",
      "iteration 88500 / 120000: loss 0.000315\n",
      "iteration 88600 / 120000: loss 0.000316\n",
      "iteration 88700 / 120000: loss 0.000317\n",
      "iteration 88800 / 120000: loss 17.254332\n",
      "iteration 88900 / 120000: loss 0.000317\n",
      "iteration 89000 / 120000: loss 0.000318\n",
      "iteration 89100 / 120000: loss 18.654199\n",
      "iteration 89200 / 120000: loss 81.287605\n",
      "iteration 89300 / 120000: loss 83.768375\n",
      "iteration 89400 / 120000: loss 0.000318\n",
      "iteration 89500 / 120000: loss 0.000319\n",
      "iteration 89600 / 120000: loss 0.000321\n",
      "iteration 89700 / 120000: loss 0.000320\n",
      "iteration 89800 / 120000: loss 0.000320\n",
      "iteration 89900 / 120000: loss 0.000321\n",
      "iteration 90000 / 120000: loss 0.000321\n",
      "iteration 90100 / 120000: loss 11.517436\n",
      "iteration 90200 / 120000: loss 0.000321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 90300 / 120000: loss 0.000322\n",
      "iteration 90400 / 120000: loss 33.912676\n",
      "iteration 90500 / 120000: loss 0.000322\n",
      "iteration 90600 / 120000: loss 207.223783\n",
      "iteration 90700 / 120000: loss 0.000323\n",
      "iteration 90800 / 120000: loss 0.000323\n",
      "iteration 90900 / 120000: loss 0.000324\n",
      "iteration 91000 / 120000: loss 0.000324\n",
      "iteration 91100 / 120000: loss 0.000325\n",
      "iteration 91200 / 120000: loss 85.682161\n",
      "iteration 91300 / 120000: loss 0.000325\n",
      "iteration 91400 / 120000: loss 0.000327\n",
      "iteration 91500 / 120000: loss 0.000327\n",
      "iteration 91600 / 120000: loss 0.000327\n",
      "iteration 91700 / 120000: loss 71.174523\n",
      "iteration 91800 / 120000: loss 0.000329\n",
      "iteration 91900 / 120000: loss 0.000330\n",
      "iteration 92000 / 120000: loss 99.543517\n",
      "iteration 92100 / 120000: loss 0.000331\n",
      "iteration 92200 / 120000: loss 87.936480\n",
      "iteration 92300 / 120000: loss 0.000331\n",
      "iteration 92400 / 120000: loss 0.000333\n",
      "iteration 92500 / 120000: loss 0.000335\n",
      "iteration 92600 / 120000: loss 29.329488\n",
      "iteration 92700 / 120000: loss 0.000334\n",
      "iteration 92800 / 120000: loss 23.101922\n",
      "iteration 92900 / 120000: loss 0.000334\n",
      "iteration 93000 / 120000: loss 0.000334\n",
      "iteration 93100 / 120000: loss 24.876711\n",
      "iteration 93200 / 120000: loss 0.000334\n",
      "iteration 93300 / 120000: loss 0.000336\n",
      "iteration 93400 / 120000: loss 0.000336\n",
      "iteration 93500 / 120000: loss 0.000336\n",
      "iteration 93600 / 120000: loss 0.000337\n",
      "iteration 93700 / 120000: loss 76.217990\n",
      "iteration 93800 / 120000: loss 0.000336\n",
      "iteration 93900 / 120000: loss 0.000336\n",
      "iteration 94000 / 120000: loss 0.000337\n",
      "iteration 94100 / 120000: loss 0.000336\n",
      "iteration 94200 / 120000: loss 0.000337\n",
      "iteration 94300 / 120000: loss 0.000336\n",
      "iteration 94400 / 120000: loss 0.000336\n",
      "iteration 94500 / 120000: loss 0.000338\n",
      "iteration 94600 / 120000: loss 0.000338\n",
      "iteration 94700 / 120000: loss 0.000338\n",
      "iteration 94800 / 120000: loss 161.270805\n",
      "iteration 94900 / 120000: loss 127.720743\n",
      "iteration 95000 / 120000: loss 0.000340\n",
      "iteration 95100 / 120000: loss 42.232214\n",
      "iteration 95200 / 120000: loss 0.000342\n",
      "iteration 95300 / 120000: loss 0.000342\n",
      "iteration 95400 / 120000: loss 73.151990\n",
      "iteration 95500 / 120000: loss 0.000341\n",
      "iteration 95600 / 120000: loss 0.000341\n",
      "iteration 95700 / 120000: loss 0.000342\n",
      "iteration 95800 / 120000: loss 0.000342\n",
      "iteration 95900 / 120000: loss 0.000343\n",
      "iteration 96000 / 120000: loss 0.000344\n",
      "iteration 96100 / 120000: loss 0.000344\n",
      "iteration 96200 / 120000: loss 0.000344\n",
      "iteration 96300 / 120000: loss 0.000345\n",
      "iteration 96400 / 120000: loss 0.000344\n",
      "iteration 96500 / 120000: loss 0.000346\n",
      "iteration 96600 / 120000: loss 0.000347\n",
      "iteration 96700 / 120000: loss 0.000347\n",
      "iteration 96800 / 120000: loss 198.795028\n",
      "iteration 96900 / 120000: loss 0.000348\n",
      "iteration 97000 / 120000: loss 0.000348\n",
      "iteration 97100 / 120000: loss 0.000348\n",
      "iteration 97200 / 120000: loss 0.000348\n",
      "iteration 97300 / 120000: loss 0.000349\n",
      "iteration 97400 / 120000: loss 0.000350\n",
      "iteration 97500 / 120000: loss 0.000349\n",
      "iteration 97600 / 120000: loss 31.423725\n",
      "iteration 97700 / 120000: loss 0.000350\n",
      "iteration 97800 / 120000: loss 0.000349\n",
      "iteration 97900 / 120000: loss 0.000349\n",
      "iteration 98000 / 120000: loss 0.000350\n",
      "iteration 98100 / 120000: loss 0.000351\n",
      "iteration 98200 / 120000: loss 2.784381\n",
      "iteration 98300 / 120000: loss 0.000352\n",
      "iteration 98400 / 120000: loss 0.000353\n",
      "iteration 98500 / 120000: loss 0.000353\n",
      "iteration 98600 / 120000: loss 0.000353\n",
      "iteration 98700 / 120000: loss 0.000354\n",
      "iteration 98800 / 120000: loss 0.000354\n",
      "iteration 98900 / 120000: loss 0.000355\n",
      "iteration 99000 / 120000: loss 0.000357\n",
      "iteration 99100 / 120000: loss 96.785737\n",
      "iteration 99200 / 120000: loss 0.000357\n",
      "iteration 99300 / 120000: loss 0.000359\n",
      "iteration 99400 / 120000: loss 0.000358\n",
      "iteration 99500 / 120000: loss 0.000359\n",
      "iteration 99600 / 120000: loss 0.000358\n",
      "iteration 99700 / 120000: loss 0.000359\n",
      "iteration 99800 / 120000: loss 0.000360\n",
      "iteration 99900 / 120000: loss 0.000361\n",
      "iteration 100000 / 120000: loss 0.000362\n",
      "iteration 100100 / 120000: loss 0.000361\n",
      "iteration 100200 / 120000: loss 0.000363\n",
      "iteration 100300 / 120000: loss 0.000363\n",
      "iteration 100400 / 120000: loss 0.000363\n",
      "iteration 100500 / 120000: loss 0.000364\n",
      "iteration 100600 / 120000: loss 0.000364\n",
      "iteration 100700 / 120000: loss 0.000364\n",
      "iteration 100800 / 120000: loss 0.000363\n",
      "iteration 100900 / 120000: loss 0.000363\n",
      "iteration 101000 / 120000: loss 0.000363\n",
      "iteration 101100 / 120000: loss 110.572479\n",
      "iteration 101200 / 120000: loss 0.000364\n",
      "iteration 101300 / 120000: loss 98.695170\n",
      "iteration 101400 / 120000: loss 0.000365\n",
      "iteration 101500 / 120000: loss 3.594173\n",
      "iteration 101600 / 120000: loss 0.000365\n",
      "iteration 101700 / 120000: loss 0.000366\n",
      "iteration 101800 / 120000: loss 0.000365\n",
      "iteration 101900 / 120000: loss 0.000366\n",
      "iteration 102000 / 120000: loss 22.395490\n",
      "iteration 102100 / 120000: loss 0.000368\n",
      "iteration 102200 / 120000: loss 0.000367\n",
      "iteration 102300 / 120000: loss 0.000367\n",
      "iteration 102400 / 120000: loss 32.534815\n",
      "iteration 102500 / 120000: loss 0.000368\n",
      "iteration 102600 / 120000: loss 0.000369\n",
      "iteration 102700 / 120000: loss 0.000369\n",
      "iteration 102800 / 120000: loss 0.000370\n",
      "iteration 102900 / 120000: loss 0.000370\n",
      "iteration 103000 / 120000: loss 0.000370\n",
      "iteration 103100 / 120000: loss 0.000370\n",
      "iteration 103200 / 120000: loss 0.000369\n",
      "iteration 103300 / 120000: loss 73.087666\n",
      "iteration 103400 / 120000: loss 0.000371\n",
      "iteration 103500 / 120000: loss 0.000370\n",
      "iteration 103600 / 120000: loss 0.000370\n",
      "iteration 103700 / 120000: loss 0.000371\n",
      "iteration 103800 / 120000: loss 0.000372\n",
      "iteration 103900 / 120000: loss 0.000372\n",
      "iteration 104000 / 120000: loss 0.000370\n",
      "iteration 104100 / 120000: loss 0.000371\n",
      "iteration 104200 / 120000: loss 0.000370\n",
      "iteration 104300 / 120000: loss 0.000369\n",
      "iteration 104400 / 120000: loss 0.000370\n",
      "iteration 104500 / 120000: loss 0.000371\n",
      "iteration 104600 / 120000: loss 72.490454\n",
      "iteration 104700 / 120000: loss 0.000373\n",
      "iteration 104800 / 120000: loss 0.000374\n",
      "iteration 104900 / 120000: loss 0.000374\n",
      "iteration 105000 / 120000: loss 19.262194\n",
      "iteration 105100 / 120000: loss 0.000374\n",
      "iteration 105200 / 120000: loss 0.000376\n",
      "iteration 105300 / 120000: loss 0.000376\n",
      "iteration 105400 / 120000: loss 0.000376\n",
      "iteration 105500 / 120000: loss 0.000376\n",
      "iteration 105600 / 120000: loss 0.000376\n",
      "iteration 105700 / 120000: loss 0.000377\n",
      "iteration 105800 / 120000: loss 0.000378\n",
      "iteration 105900 / 120000: loss 0.000378\n",
      "iteration 106000 / 120000: loss 0.000379\n",
      "iteration 106100 / 120000: loss 0.000378\n",
      "iteration 106200 / 120000: loss 0.000378\n",
      "iteration 106300 / 120000: loss 0.000379\n",
      "iteration 106400 / 120000: loss 0.000380\n",
      "iteration 106500 / 120000: loss 0.000381\n",
      "iteration 106600 / 120000: loss 102.534783\n",
      "iteration 106700 / 120000: loss 15.437414\n",
      "iteration 106800 / 120000: loss 0.000383\n",
      "iteration 106900 / 120000: loss 0.000382\n",
      "iteration 107000 / 120000: loss 0.000383\n",
      "iteration 107100 / 120000: loss 0.000384\n",
      "iteration 107200 / 120000: loss 0.000385\n",
      "iteration 107300 / 120000: loss 0.000384\n",
      "iteration 107400 / 120000: loss 0.000385\n",
      "iteration 107500 / 120000: loss 0.000385\n",
      "iteration 107600 / 120000: loss 33.484454\n",
      "iteration 107700 / 120000: loss 0.000384\n",
      "iteration 107800 / 120000: loss 0.000385\n",
      "iteration 107900 / 120000: loss 0.000385\n",
      "iteration 108000 / 120000: loss 0.000384\n",
      "iteration 108100 / 120000: loss 0.000383\n",
      "iteration 108200 / 120000: loss 0.000382\n",
      "iteration 108300 / 120000: loss 31.792364\n",
      "iteration 108400 / 120000: loss 0.000383\n",
      "iteration 108500 / 120000: loss 0.000384\n",
      "iteration 108600 / 120000: loss 0.000383\n",
      "iteration 108700 / 120000: loss 0.000383\n",
      "iteration 108800 / 120000: loss 0.000383\n",
      "iteration 108900 / 120000: loss 0.000385\n",
      "iteration 109000 / 120000: loss 78.874756\n",
      "iteration 109100 / 120000: loss 16.895720\n",
      "iteration 109200 / 120000: loss 0.000386\n",
      "iteration 109300 / 120000: loss 0.000386\n",
      "iteration 109400 / 120000: loss 0.000386\n",
      "iteration 109500 / 120000: loss 0.000387\n",
      "iteration 109600 / 120000: loss 0.000388\n",
      "iteration 109700 / 120000: loss 0.000390\n",
      "iteration 109800 / 120000: loss 0.000390\n",
      "iteration 109900 / 120000: loss 0.000390\n",
      "iteration 110000 / 120000: loss 0.000391\n",
      "iteration 110100 / 120000: loss 0.000391\n",
      "iteration 110200 / 120000: loss 106.451180\n",
      "iteration 110300 / 120000: loss 0.000390\n",
      "iteration 110400 / 120000: loss 0.000391\n",
      "iteration 110500 / 120000: loss 0.000390\n",
      "iteration 110600 / 120000: loss 0.000391\n",
      "iteration 110700 / 120000: loss 0.980434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 110800 / 120000: loss 10.374239\n",
      "iteration 110900 / 120000: loss 0.000392\n",
      "iteration 111000 / 120000: loss 0.000392\n",
      "iteration 111100 / 120000: loss 23.449846\n",
      "iteration 111200 / 120000: loss 73.798518\n",
      "iteration 111300 / 120000: loss 0.000392\n",
      "iteration 111400 / 120000: loss 15.775114\n",
      "iteration 111500 / 120000: loss 0.000394\n",
      "iteration 111600 / 120000: loss 0.000394\n",
      "iteration 111700 / 120000: loss 0.000395\n",
      "iteration 111800 / 120000: loss 1.170651\n",
      "iteration 111900 / 120000: loss 0.000396\n",
      "iteration 112000 / 120000: loss 16.016945\n",
      "iteration 112100 / 120000: loss 0.000396\n",
      "iteration 112200 / 120000: loss 0.000397\n",
      "iteration 112300 / 120000: loss 50.592554\n",
      "iteration 112400 / 120000: loss 0.000396\n",
      "iteration 112500 / 120000: loss 0.000396\n",
      "iteration 112600 / 120000: loss 0.000395\n",
      "iteration 112700 / 120000: loss 24.653248\n",
      "iteration 112800 / 120000: loss 0.000396\n",
      "iteration 112900 / 120000: loss 7.056489\n",
      "iteration 113000 / 120000: loss 0.000397\n",
      "iteration 113100 / 120000: loss 0.000397\n",
      "iteration 113200 / 120000: loss 0.000397\n",
      "iteration 113300 / 120000: loss 0.000398\n",
      "iteration 113400 / 120000: loss 0.000399\n",
      "iteration 113500 / 120000: loss 0.000399\n",
      "iteration 113600 / 120000: loss 0.000400\n",
      "iteration 113700 / 120000: loss 0.000400\n",
      "iteration 113800 / 120000: loss 0.000400\n",
      "iteration 113900 / 120000: loss 78.339593\n",
      "iteration 114000 / 120000: loss 0.000401\n",
      "iteration 114100 / 120000: loss 0.000401\n",
      "iteration 114200 / 120000: loss 0.000401\n",
      "iteration 114300 / 120000: loss 0.000402\n",
      "iteration 114400 / 120000: loss 0.000405\n",
      "iteration 114500 / 120000: loss 0.000405\n",
      "iteration 114600 / 120000: loss 0.000405\n",
      "iteration 114700 / 120000: loss 0.000404\n",
      "iteration 114800 / 120000: loss 0.000404\n",
      "iteration 114900 / 120000: loss 0.000404\n",
      "iteration 115000 / 120000: loss 0.000403\n",
      "iteration 115100 / 120000: loss 0.000404\n",
      "iteration 115200 / 120000: loss 0.000405\n",
      "iteration 115300 / 120000: loss 0.000406\n",
      "iteration 115400 / 120000: loss 66.045159\n",
      "iteration 115500 / 120000: loss 0.000406\n",
      "iteration 115600 / 120000: loss 0.000407\n",
      "iteration 115700 / 120000: loss 0.000408\n",
      "iteration 115800 / 120000: loss 0.000408\n",
      "iteration 115900 / 120000: loss 114.081999\n",
      "iteration 116000 / 120000: loss 0.000407\n",
      "iteration 116100 / 120000: loss 0.000408\n",
      "iteration 116200 / 120000: loss 0.000409\n",
      "iteration 116300 / 120000: loss 0.000410\n",
      "iteration 116400 / 120000: loss 20.606031\n",
      "iteration 116500 / 120000: loss 0.000410\n",
      "iteration 116600 / 120000: loss 0.000411\n",
      "iteration 116700 / 120000: loss 0.000411\n",
      "iteration 116800 / 120000: loss 0.000411\n",
      "iteration 116900 / 120000: loss 43.405804\n",
      "iteration 117000 / 120000: loss 0.000413\n",
      "iteration 117100 / 120000: loss 0.000414\n",
      "iteration 117200 / 120000: loss 0.000414\n",
      "iteration 117300 / 120000: loss 90.615655\n",
      "iteration 117400 / 120000: loss 0.000414\n",
      "iteration 117500 / 120000: loss 148.924246\n",
      "iteration 117600 / 120000: loss 0.000417\n",
      "iteration 117700 / 120000: loss 0.000418\n",
      "iteration 117800 / 120000: loss 0.000419\n",
      "iteration 117900 / 120000: loss 0.000420\n",
      "iteration 118000 / 120000: loss 55.523277\n",
      "iteration 118100 / 120000: loss 0.000420\n",
      "iteration 118200 / 120000: loss 14.175540\n",
      "iteration 118300 / 120000: loss 93.950571\n",
      "iteration 118400 / 120000: loss 0.000418\n",
      "iteration 118500 / 120000: loss 74.600708\n",
      "iteration 118600 / 120000: loss 0.000418\n",
      "iteration 118700 / 120000: loss 0.000420\n",
      "iteration 118800 / 120000: loss 0.000420\n",
      "iteration 118900 / 120000: loss 56.524129\n",
      "iteration 119000 / 120000: loss 0.000419\n",
      "iteration 119100 / 120000: loss 0.000418\n",
      "iteration 119200 / 120000: loss 0.000419\n",
      "iteration 119300 / 120000: loss 26.342240\n",
      "iteration 119400 / 120000: loss 0.000420\n",
      "iteration 119500 / 120000: loss 62.060682\n",
      "iteration 119600 / 120000: loss 0.000421\n",
      "iteration 119700 / 120000: loss 0.000420\n",
      "iteration 119800 / 120000: loss 0.000421\n",
      "iteration 119900 / 120000: loss 0.000421\n",
      "lr=5e-06 bs=100 regularization_rate=0.0006\n",
      "iteration 0 / 1200: loss 0.935070\n",
      "iteration 100 / 1200: loss 0.767402\n",
      "iteration 200 / 1200: loss 1.457276\n",
      "iteration 300 / 1200: loss 1.008247\n",
      "iteration 400 / 1200: loss 0.703816\n",
      "iteration 500 / 1200: loss 0.776359\n",
      "iteration 600 / 1200: loss 0.725599\n",
      "iteration 700 / 1200: loss 1.219549\n",
      "iteration 800 / 1200: loss 1.194784\n",
      "iteration 900 / 1200: loss 1.285114\n",
      "iteration 1000 / 1200: loss 0.854389\n",
      "iteration 1100 / 1200: loss 0.981193\n",
      "lr=5e-06 bs=100 regularization_rate=0.0005\n",
      "iteration 0 / 1200: loss 0.976810\n",
      "iteration 100 / 1200: loss 1.136326\n",
      "iteration 200 / 1200: loss 0.878458\n",
      "iteration 300 / 1200: loss 0.493386\n",
      "iteration 400 / 1200: loss 0.962936\n",
      "iteration 500 / 1200: loss 0.821171\n",
      "iteration 600 / 1200: loss 0.656461\n",
      "iteration 700 / 1200: loss 0.543831\n",
      "iteration 800 / 1200: loss 1.150977\n",
      "iteration 900 / 1200: loss 0.840503\n",
      "iteration 1000 / 1200: loss 4.229173\n",
      "iteration 1100 / 1200: loss 1.304015\n",
      "lr=5e-06 bs=100 regularization_rate=0.0004\n",
      "iteration 0 / 1200: loss 1.051410\n",
      "iteration 100 / 1200: loss 2.647973\n",
      "iteration 200 / 1200: loss 1.054743\n",
      "iteration 300 / 1200: loss 1.000193\n",
      "iteration 400 / 1200: loss 0.751667\n",
      "iteration 500 / 1200: loss 0.559339\n",
      "iteration 600 / 1200: loss 0.978316\n",
      "iteration 700 / 1200: loss 1.410829\n",
      "iteration 800 / 1200: loss 0.814359\n",
      "iteration 900 / 1200: loss 0.798753\n",
      "iteration 1000 / 1200: loss 0.550079\n",
      "iteration 1100 / 1200: loss 0.859266\n",
      "lr=5e-06 bs=100 regularization_rate=0.0003\n",
      "iteration 0 / 1200: loss 0.971809\n",
      "iteration 100 / 1200: loss 0.636149\n",
      "iteration 200 / 1200: loss 0.584625\n",
      "iteration 300 / 1200: loss 2.455581\n",
      "iteration 400 / 1200: loss 1.369959\n",
      "iteration 500 / 1200: loss 0.867207\n",
      "iteration 600 / 1200: loss 1.137957\n",
      "iteration 700 / 1200: loss 0.666263\n",
      "iteration 800 / 1200: loss 0.647596\n",
      "iteration 900 / 1200: loss 1.363107\n",
      "iteration 1000 / 1200: loss 0.877531\n",
      "iteration 1100 / 1200: loss 1.393170\n",
      "lr=5e-06 bs=200 regularization_rate=0.0006\n",
      "iteration 0 / 600: loss 1.009495\n",
      "iteration 100 / 600: loss 0.681811\n",
      "iteration 200 / 600: loss 1.262908\n",
      "iteration 300 / 600: loss 0.694770\n",
      "iteration 400 / 600: loss 3.800885\n",
      "iteration 500 / 600: loss 0.710683\n",
      "lr=5e-06 bs=200 regularization_rate=0.0005\n",
      "iteration 0 / 600: loss 1.065315\n",
      "iteration 100 / 600: loss 0.623920\n",
      "iteration 200 / 600: loss 1.041750\n",
      "iteration 300 / 600: loss 0.853082\n",
      "iteration 400 / 600: loss 0.431086\n",
      "iteration 500 / 600: loss 0.576769\n",
      "lr=5e-06 bs=200 regularization_rate=0.0004\n",
      "iteration 0 / 600: loss 1.004998\n",
      "iteration 100 / 600: loss 2.051210\n",
      "iteration 200 / 600: loss 0.695352\n",
      "iteration 300 / 600: loss 0.761590\n",
      "iteration 400 / 600: loss 2.785124\n",
      "iteration 500 / 600: loss 1.808917\n",
      "lr=5e-06 bs=200 regularization_rate=0.0003\n",
      "iteration 0 / 600: loss 0.982150\n",
      "iteration 100 / 600: loss 1.906728\n",
      "iteration 200 / 600: loss 1.895581\n",
      "iteration 300 / 600: loss 0.682478\n",
      "iteration 400 / 600: loss 0.755188\n",
      "iteration 500 / 600: loss 2.509990\n",
      "lr=5e-06 bs=500 regularization_rate=0.0006\n",
      "iteration 0 / 240: loss 1.054905\n",
      "iteration 100 / 240: loss 0.746337\n",
      "iteration 200 / 240: loss 2.444017\n",
      "lr=5e-06 bs=500 regularization_rate=0.0005\n",
      "iteration 0 / 240: loss 0.992969\n",
      "iteration 100 / 240: loss 0.898304\n",
      "iteration 200 / 240: loss 1.472064\n",
      "lr=5e-06 bs=500 regularization_rate=0.0004\n",
      "iteration 0 / 240: loss 0.970910\n",
      "iteration 100 / 240: loss 0.962124\n",
      "iteration 200 / 240: loss 0.574750\n",
      "lr=5e-06 bs=500 regularization_rate=0.0003\n",
      "iteration 0 / 240: loss 0.956634\n",
      "iteration 100 / 240: loss 0.588824\n",
      "iteration 200 / 240: loss 0.599011\n",
      "lr=5e-06 bs=10000 regularization_rate=0.0006\n",
      "iteration 0 / 12: loss 0.980307\n",
      "lr=5e-06 bs=10000 regularization_rate=0.0005\n",
      "iteration 0 / 12: loss 0.988792\n",
      "lr=5e-06 bs=10000 regularization_rate=0.0004\n",
      "iteration 0 / 12: loss 0.947431\n",
      "lr=5e-06 bs=10000 regularization_rate=0.0003\n",
      "iteration 0 / 12: loss 0.982200\n",
      "lr 1.000000e-07 batch_size 1.000000e+00 regularization_rate 3.000000e-04 train accuracy: 0.793400 val accuracy: 0.352000\n",
      "lr 1.000000e-07 batch_size 1.000000e+00 regularization_rate 4.000000e-04 train accuracy: 0.830700 val accuracy: 0.389000\n",
      "lr 1.000000e-07 batch_size 1.000000e+00 regularization_rate 5.000000e-04 train accuracy: 0.804700 val accuracy: 0.357000\n",
      "lr 1.000000e-07 batch_size 1.000000e+00 regularization_rate 6.000000e-04 train accuracy: 0.821500 val accuracy: 0.412000\n",
      "lr 1.000000e-07 batch_size 1.000000e+02 regularization_rate 3.000000e-04 train accuracy: 0.827300 val accuracy: 0.411000\n",
      "lr 1.000000e-07 batch_size 1.000000e+02 regularization_rate 4.000000e-04 train accuracy: 0.826400 val accuracy: 0.400000\n",
      "lr 1.000000e-07 batch_size 1.000000e+02 regularization_rate 5.000000e-04 train accuracy: 0.829100 val accuracy: 0.405000\n",
      "lr 1.000000e-07 batch_size 1.000000e+02 regularization_rate 6.000000e-04 train accuracy: 0.826700 val accuracy: 0.407000\n",
      "lr 1.000000e-07 batch_size 2.000000e+02 regularization_rate 3.000000e-04 train accuracy: 0.821300 val accuracy: 0.407000\n",
      "lr 1.000000e-07 batch_size 2.000000e+02 regularization_rate 4.000000e-04 train accuracy: 0.822900 val accuracy: 0.408000\n",
      "lr 1.000000e-07 batch_size 2.000000e+02 regularization_rate 5.000000e-04 train accuracy: 0.821800 val accuracy: 0.405000\n",
      "lr 1.000000e-07 batch_size 2.000000e+02 regularization_rate 6.000000e-04 train accuracy: 0.822100 val accuracy: 0.409000\n",
      "lr 1.000000e-07 batch_size 5.000000e+02 regularization_rate 3.000000e-04 train accuracy: 0.810700 val accuracy: 0.405000\n",
      "lr 1.000000e-07 batch_size 5.000000e+02 regularization_rate 4.000000e-04 train accuracy: 0.811500 val accuracy: 0.406000\n",
      "lr 1.000000e-07 batch_size 5.000000e+02 regularization_rate 5.000000e-04 train accuracy: 0.814300 val accuracy: 0.410000\n",
      "lr 1.000000e-07 batch_size 5.000000e+02 regularization_rate 6.000000e-04 train accuracy: 0.813100 val accuracy: 0.411000\n",
      "lr 1.000000e-07 batch_size 1.000000e+04 regularization_rate 3.000000e-04 train accuracy: 0.757000 val accuracy: 0.391000\n",
      "lr 1.000000e-07 batch_size 1.000000e+04 regularization_rate 4.000000e-04 train accuracy: 0.757900 val accuracy: 0.395000\n",
      "lr 1.000000e-07 batch_size 1.000000e+04 regularization_rate 5.000000e-04 train accuracy: 0.754300 val accuracy: 0.396000\n",
      "lr 1.000000e-07 batch_size 1.000000e+04 regularization_rate 6.000000e-04 train accuracy: 0.755700 val accuracy: 0.390000\n",
      "lr 5.000000e-06 batch_size 1.000000e+00 regularization_rate 3.000000e-04 train accuracy: 0.799700 val accuracy: 0.374000\n",
      "lr 5.000000e-06 batch_size 1.000000e+00 regularization_rate 4.000000e-04 train accuracy: 0.805100 val accuracy: 0.383000\n",
      "lr 5.000000e-06 batch_size 1.000000e+00 regularization_rate 5.000000e-04 train accuracy: 0.784600 val accuracy: 0.390000\n",
      "lr 5.000000e-06 batch_size 1.000000e+00 regularization_rate 6.000000e-04 train accuracy: 0.674500 val accuracy: 0.288000\n",
      "lr 5.000000e-06 batch_size 1.000000e+02 regularization_rate 3.000000e-04 train accuracy: 0.825300 val accuracy: 0.401000\n",
      "lr 5.000000e-06 batch_size 1.000000e+02 regularization_rate 4.000000e-04 train accuracy: 0.828200 val accuracy: 0.417000\n",
      "lr 5.000000e-06 batch_size 1.000000e+02 regularization_rate 5.000000e-04 train accuracy: 0.821000 val accuracy: 0.382000\n",
      "lr 5.000000e-06 batch_size 1.000000e+02 regularization_rate 6.000000e-04 train accuracy: 0.798600 val accuracy: 0.396000\n",
      "lr 5.000000e-06 batch_size 2.000000e+02 regularization_rate 3.000000e-04 train accuracy: 0.819900 val accuracy: 0.385000\n",
      "lr 5.000000e-06 batch_size 2.000000e+02 regularization_rate 4.000000e-04 train accuracy: 0.831300 val accuracy: 0.389000\n",
      "lr 5.000000e-06 batch_size 2.000000e+02 regularization_rate 5.000000e-04 train accuracy: 0.821300 val accuracy: 0.411000\n",
      "lr 5.000000e-06 batch_size 2.000000e+02 regularization_rate 6.000000e-04 train accuracy: 0.830000 val accuracy: 0.412000\n",
      "lr 5.000000e-06 batch_size 5.000000e+02 regularization_rate 3.000000e-04 train accuracy: 0.731800 val accuracy: 0.336000\n",
      "lr 5.000000e-06 batch_size 5.000000e+02 regularization_rate 4.000000e-04 train accuracy: 0.801300 val accuracy: 0.363000\n",
      "lr 5.000000e-06 batch_size 5.000000e+02 regularization_rate 5.000000e-04 train accuracy: 0.704200 val accuracy: 0.323000\n",
      "lr 5.000000e-06 batch_size 5.000000e+02 regularization_rate 6.000000e-04 train accuracy: 0.773400 val accuracy: 0.396000\n",
      "lr 5.000000e-06 batch_size 1.000000e+04 regularization_rate 3.000000e-04 train accuracy: 0.710600 val accuracy: 0.330000\n",
      "lr 5.000000e-06 batch_size 1.000000e+04 regularization_rate 4.000000e-04 train accuracy: 0.722800 val accuracy: 0.336000\n",
      "lr 5.000000e-06 batch_size 1.000000e+04 regularization_rate 5.000000e-04 train accuracy: 0.688200 val accuracy: 0.319000\n",
      "lr 5.000000e-06 batch_size 1.000000e+04 regularization_rate 6.000000e-04 train accuracy: 0.688200 val accuracy: 0.317000\n",
      "best validation accuracy achieved during cross-validation: 0.417000\n",
      "linear perceptron regularized on raw pixels final test set accuracy: 0.815000\n"
     ]
    }
   ],
   "source": [
    "from functions.classifier import LinearPerceptronRegularization\n",
    "from functions.losses import perceptron_loss_vectorized_with_regularization\n",
    "\n",
    "learning_rates = [1e-7, 5e-6]\n",
    "batch_sizes = [1, 100, 200, 500, 10000]\n",
    "regularizarion_rates = [6e-4, 5e-4, 4e-4, 3e-4]\n",
    "\n",
    "results = {}\n",
    "best_val = -1   \n",
    "best_perceptron_regularized = None \n",
    "\n",
    "################################################################################\n",
    "#                            START OF YOUR CODE                                #\n",
    "################################################################################\n",
    "epochs = 200*600/X_train.shape[0]\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        for regularization_rate in regularizarion_rates:\n",
    "            print('lr={} bs={} regularization_rate={}'.format(lr, bs, regularization_rate))\n",
    "            num_iters = int(epochs*X_train.shape[0]/bs)\n",
    "            lpr = LinearPerceptronRegularization(X_train, y_train, regularization_rate)\n",
    "            _ = lpr.train(X_train, y_train, learning_rate=lr, num_iters=num_iters,batch_size=bs,verbose=True)\n",
    "            val_accuracy = lpr.calc_accuracy(X_val, y_val)\n",
    "            train_accuracy = lpr.calc_accuracy(X_train, y_train)\n",
    "            results[(lr, bs, regularization_rate)] = (train_accuracy,val_accuracy)\n",
    "\n",
    "            if val_accuracy > best_val:\n",
    "                best_val = val_accuracy\n",
    "                best_perceptron_regularized = lpr\n",
    "            \n",
    "################################################################################\n",
    "#                              END OF YOUR CODE                                #\n",
    "################################################################################\n",
    "    \n",
    "# Print out results.\n",
    "for lr, batch_size, regularization_rate in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, batch_size, regularization_rate)]\n",
    "    print ('lr %e batch_size %e regularization_rate %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, batch_size, regularization_rate, train_accuracy, val_accuracy))\n",
    "\n",
    "\n",
    "print ('best validation accuracy achieved during cross-validation: %f' % best_val)\n",
    "\n",
    "test_accuracy = best_perceptron_regularized.calc_accuracy(X_test, y_test)\n",
    "print ('linear perceptron regularized on raw pixels final test set accuracy: %f' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
