{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_word_embedding_assignment-checkpoint.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "k_CaLtyMRXae",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Word Embedding - Home Assigment\n",
        "## Dr. Omri Allouche 2018. YData Deep Learning Course\n",
        "\n",
        "[Open in Google Colab](https://colab.research.google.com/github/omriallouche/deep_learning_course/blob/master/DL_word_embedding_assignment.ipynb)\n",
        "    \n",
        "    \n",
        "In this exercise, you'll use word vectors trained on a corpus of 380,000 lyrics of songs from MetroLyrics (https://www.kaggle.com/gyani95/380000-lyrics-from-metrolyrics).  \n",
        "The dataset contains these fields for each song, in CSV format:\n",
        "1. index\n",
        "1. song\n",
        "1. year\n",
        "1. artist\n",
        "1. genre\n",
        "1. lyrics\n",
        "\n",
        "Before doing this exercise, we recommend that you go over the \"Bag of words meets bag of popcorn\" tutorial (https://www.kaggle.com/c/word2vec-nlp-tutorial)\n",
        "\n",
        "Other recommended resources:\n",
        "- https://rare-technologies.com/word2vec-tutorial/\n",
        "- https://www.kaggle.com/pierremegret/gensim-word2vec-tutorial"
      ]
    },
    {
      "metadata": {
        "id": "Ykb9T-R6RXaj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train word vectors\n",
        "Train word vectors using the Skipgram Word2vec algorithm and the gensim package.\n",
        "Make sure you perform the following:\n",
        "- Tokenize words\n",
        "- Lowercase all words\n",
        "- Remove punctuation marks\n",
        "- Remove rare words\n",
        "- Remove stopwords\n",
        "\n",
        "Use 300 as the dimension of the word vectors. Try different context sizes."
      ]
    },
    {
      "metadata": {
        "id": "AfpKNFzCRXak",
        "colab_type": "code",
        "outputId": "bcfbfb27-f7a5-4870-ee5c-3ee1d7a16116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B8VR2krpRXap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "ebda3752-17bf-4b5c-ee8a-fa91e3548ac2"
      },
      "cell_type": "code",
      "source": [
        "import pandas  as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "5Aq5UnrgRuIE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tNxQ6Kk4RXas",
        "colab_type": "code",
        "outputId": "b7946b6f-516a-4da2-d699-94cc97ffb988",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "MIN_OCCURENCES = 5\n",
        "lyrics_df = pd.read_csv(\"/content/drive/My Drive/lyrics.csv\")\n",
        "#lyrics_df = pd.read_csv('../lyrics.csv', header=0, encoding='utf-8')\n",
        "# converters={'lyrics': lambda x: str(x)},\n",
        "# lyrics_df = pd.read_csv('../lyrics.csv', header=0)\n",
        "# lyrics_df['Collyricsumn'] =lyrics_df['lyrics'].astype(str)\n",
        "lyrics_df.sample(10)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>song</th>\n",
              "      <th>year</th>\n",
              "      <th>artist</th>\n",
              "      <th>genre</th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>223114</th>\n",
              "      <td>223114</td>\n",
              "      <td>while-i-still-got-the-time</td>\n",
              "      <td>2008</td>\n",
              "      <td>darius-rucker</td>\n",
              "      <td>Country</td>\n",
              "      <td>Thirty nine candles burnt out on a cake\\nEach ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39186</th>\n",
              "      <td>39186</td>\n",
              "      <td>f-m-l</td>\n",
              "      <td>2014</td>\n",
              "      <td>the-amity-affliction</td>\n",
              "      <td>Not Available</td>\n",
              "      <td>There are parts of me\\nThat have been lost at ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239845</th>\n",
              "      <td>239845</td>\n",
              "      <td>pantie-lover</td>\n",
              "      <td>2014</td>\n",
              "      <td>asap-ferg</td>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>[Hook]\\nEvery time I walk up in the club, I go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137019</th>\n",
              "      <td>137019</td>\n",
              "      <td>chocolate-brown</td>\n",
              "      <td>2001</td>\n",
              "      <td>cranberries</td>\n",
              "      <td>Rock</td>\n",
              "      <td>But I tried and I sighed\\nhe didn't listen to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354490</th>\n",
              "      <td>354490</td>\n",
              "      <td>i-m-good</td>\n",
              "      <td>2015</td>\n",
              "      <td>amir-obe</td>\n",
              "      <td>Other</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75862</th>\n",
              "      <td>75862</td>\n",
              "      <td>falling-out-of-love-at-this-volume</td>\n",
              "      <td>2000</td>\n",
              "      <td>bright-eyes</td>\n",
              "      <td>Rock</td>\n",
              "      <td>Tell me what you wanted to hear\\nLet me do the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194927</th>\n",
              "      <td>194927</td>\n",
              "      <td>peking-hooligan</td>\n",
              "      <td>2007</td>\n",
              "      <td>buzzcocks</td>\n",
              "      <td>Rock</td>\n",
              "      <td>You know me cos I hang around the bicycle shed...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68991</th>\n",
              "      <td>68991</td>\n",
              "      <td>thumb</td>\n",
              "      <td>2006</td>\n",
              "      <td>dinosaur-jr</td>\n",
              "      <td>Rock</td>\n",
              "      <td>There never really is a good time\\nThere's alw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28682</th>\n",
              "      <td>28682</td>\n",
              "      <td>you-treat-me-like-a-secret</td>\n",
              "      <td>2014</td>\n",
              "      <td>candi-staton</td>\n",
              "      <td>Electronic</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343370</th>\n",
              "      <td>343370</td>\n",
              "      <td>love-has-finally-come-at-last</td>\n",
              "      <td>2009</td>\n",
              "      <td>bobby-womack</td>\n",
              "      <td>R&amp;B</td>\n",
              "      <td>Love has finally come at last\\nAnd I'm never g...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         index                                song  year  \\\n",
              "223114  223114          while-i-still-got-the-time  2008   \n",
              "39186    39186                               f-m-l  2014   \n",
              "239845  239845                        pantie-lover  2014   \n",
              "137019  137019                     chocolate-brown  2001   \n",
              "354490  354490                            i-m-good  2015   \n",
              "75862    75862  falling-out-of-love-at-this-volume  2000   \n",
              "194927  194927                     peking-hooligan  2007   \n",
              "68991    68991                               thumb  2006   \n",
              "28682    28682          you-treat-me-like-a-secret  2014   \n",
              "343370  343370       love-has-finally-come-at-last  2009   \n",
              "\n",
              "                      artist          genre  \\\n",
              "223114         darius-rucker        Country   \n",
              "39186   the-amity-affliction  Not Available   \n",
              "239845             asap-ferg        Hip-Hop   \n",
              "137019           cranberries           Rock   \n",
              "354490              amir-obe          Other   \n",
              "75862            bright-eyes           Rock   \n",
              "194927             buzzcocks           Rock   \n",
              "68991            dinosaur-jr           Rock   \n",
              "28682           candi-staton     Electronic   \n",
              "343370          bobby-womack            R&B   \n",
              "\n",
              "                                                   lyrics  \n",
              "223114  Thirty nine candles burnt out on a cake\\nEach ...  \n",
              "39186   There are parts of me\\nThat have been lost at ...  \n",
              "239845  [Hook]\\nEvery time I walk up in the club, I go...  \n",
              "137019  But I tried and I sighed\\nhe didn't listen to ...  \n",
              "354490                                                NaN  \n",
              "75862   Tell me what you wanted to hear\\nLet me do the...  \n",
              "194927  You know me cos I hang around the bicycle shed...  \n",
              "68991   There never really is a good time\\nThere's alw...  \n",
              "28682                                                 NaN  \n",
              "343370  Love has finally come at last\\nAnd I'm never g...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "Crg1j1LbRXaz",
        "colab_type": "code",
        "outputId": "ccc4f4eb-c446-4386-fd69-e0ed3d5ae1a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "cell_type": "code",
      "source": [
        "lyrics_df.info()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 362237 entries, 0 to 362236\n",
            "Data columns (total 6 columns):\n",
            "index     362237 non-null int64\n",
            "song      362235 non-null object\n",
            "year      362237 non-null int64\n",
            "artist    362237 non-null object\n",
            "genre     362237 non-null object\n",
            "lyrics    266557 non-null object\n",
            "dtypes: int64(2), object(4)\n",
            "memory usage: 16.6+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AnZc7UE5RXa3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hOOSfY5ZRXa7",
        "colab_type": "code",
        "outputId": "860b30e2-30ee-4538-b8fd-78c8140b212b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "lyrics_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>song</th>\n",
              "      <th>year</th>\n",
              "      <th>artist</th>\n",
              "      <th>genre</th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ego-remix</td>\n",
              "      <td>2009</td>\n",
              "      <td>beyonce-knowles</td>\n",
              "      <td>Pop</td>\n",
              "      <td>Oh baby, how you doing?\\nYou know I'm gonna cu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>then-tell-me</td>\n",
              "      <td>2009</td>\n",
              "      <td>beyonce-knowles</td>\n",
              "      <td>Pop</td>\n",
              "      <td>playin' everything so easy,\\nit's like you see...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>honesty</td>\n",
              "      <td>2009</td>\n",
              "      <td>beyonce-knowles</td>\n",
              "      <td>Pop</td>\n",
              "      <td>If you search\\nFor tenderness\\nIt isn't hard t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>you-are-my-rock</td>\n",
              "      <td>2009</td>\n",
              "      <td>beyonce-knowles</td>\n",
              "      <td>Pop</td>\n",
              "      <td>Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>black-culture</td>\n",
              "      <td>2009</td>\n",
              "      <td>beyonce-knowles</td>\n",
              "      <td>Pop</td>\n",
              "      <td>Party the people, the people the party it's po...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index             song  year           artist genre  \\\n",
              "0      0        ego-remix  2009  beyonce-knowles   Pop   \n",
              "1      1     then-tell-me  2009  beyonce-knowles   Pop   \n",
              "2      2          honesty  2009  beyonce-knowles   Pop   \n",
              "3      3  you-are-my-rock  2009  beyonce-knowles   Pop   \n",
              "4      4    black-culture  2009  beyonce-knowles   Pop   \n",
              "\n",
              "                                              lyrics  \n",
              "0  Oh baby, how you doing?\\nYou know I'm gonna cu...  \n",
              "1  playin' everything so easy,\\nit's like you see...  \n",
              "2  If you search\\nFor tenderness\\nIt isn't hard t...  \n",
              "3  Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...  \n",
              "4  Party the people, the people the party it's po...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "tv_6aJn0RXa-",
        "colab_type": "code",
        "outputId": "057c8f8f-42ea-4862-b712-f78964a4fe82",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "cell_type": "code",
      "source": [
        "lyrics_df.describe(include = 'all')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>song</th>\n",
              "      <th>year</th>\n",
              "      <th>artist</th>\n",
              "      <th>genre</th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>362237.000000</td>\n",
              "      <td>362235</td>\n",
              "      <td>362237.000000</td>\n",
              "      <td>362237</td>\n",
              "      <td>362237</td>\n",
              "      <td>266557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>NaN</td>\n",
              "      <td>250472</td>\n",
              "      <td>NaN</td>\n",
              "      <td>18231</td>\n",
              "      <td>12</td>\n",
              "      <td>244873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>NaN</td>\n",
              "      <td>intro</td>\n",
              "      <td>NaN</td>\n",
              "      <td>dolly-parton</td>\n",
              "      <td>Rock</td>\n",
              "      <td>INSTRUMENTAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>NaN</td>\n",
              "      <td>366</td>\n",
              "      <td>NaN</td>\n",
              "      <td>755</td>\n",
              "      <td>131377</td>\n",
              "      <td>1369</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>181118.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2008.537596</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>104568.959068</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.908024</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>90559.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2006.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>181118.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2008.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>271677.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2014.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>362236.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2038.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                index    song           year        artist   genre  \\\n",
              "count   362237.000000  362235  362237.000000        362237  362237   \n",
              "unique            NaN  250472            NaN         18231      12   \n",
              "top               NaN   intro            NaN  dolly-parton    Rock   \n",
              "freq              NaN     366            NaN           755  131377   \n",
              "mean    181118.000000     NaN    2008.537596           NaN     NaN   \n",
              "std     104568.959068     NaN       9.908024           NaN     NaN   \n",
              "min          0.000000     NaN      67.000000           NaN     NaN   \n",
              "25%      90559.000000     NaN    2006.000000           NaN     NaN   \n",
              "50%     181118.000000     NaN    2008.000000           NaN     NaN   \n",
              "75%     271677.000000     NaN    2014.000000           NaN     NaN   \n",
              "max     362236.000000     NaN    2038.000000           NaN     NaN   \n",
              "\n",
              "              lyrics  \n",
              "count         266557  \n",
              "unique        244873  \n",
              "top     INSTRUMENTAL  \n",
              "freq            1369  \n",
              "mean             NaN  \n",
              "std              NaN  \n",
              "min              NaN  \n",
              "25%              NaN  \n",
              "50%              NaN  \n",
              "75%              NaN  \n",
              "max              NaN  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "t2ykUs6gRXbC",
        "colab_type": "code",
        "outputId": "a09fa9e0-d669-4b42-f908-0e26ce159b18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "cell_type": "code",
      "source": [
        "lyrics_df = lyrics_df[lyrics_df.lyrics.notnull()]\n",
        "lyrics_df.sample(10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>song</th>\n",
              "      <th>year</th>\n",
              "      <th>artist</th>\n",
              "      <th>genre</th>\n",
              "      <th>lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>225641</th>\n",
              "      <td>225641</td>\n",
              "      <td>summer-rain</td>\n",
              "      <td>2008</td>\n",
              "      <td>anna-ternheim</td>\n",
              "      <td>Indie</td>\n",
              "      <td>Last summer was mad, remember the rain\\nI know...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19677</th>\n",
              "      <td>19677</td>\n",
              "      <td>love-club</td>\n",
              "      <td>2009</td>\n",
              "      <td>big-bang</td>\n",
              "      <td>Pop</td>\n",
              "      <td>We gettin down in the club\\nAll my fella all m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93346</th>\n",
              "      <td>93346</td>\n",
              "      <td>when-papa-played-the-dobro</td>\n",
              "      <td>2007</td>\n",
              "      <td>flatt-and-scruggs</td>\n",
              "      <td>Country</td>\n",
              "      <td>My papa was a hobo when they delivered me\\nWe ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230134</th>\n",
              "      <td>230134</td>\n",
              "      <td>up-to-my-neck-in-you</td>\n",
              "      <td>2006</td>\n",
              "      <td>ac-dc</td>\n",
              "      <td>Rock</td>\n",
              "      <td>Well I've been up to my neck in trouble\\nUp to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81330</th>\n",
              "      <td>81330</td>\n",
              "      <td>we-will-meet-again</td>\n",
              "      <td>2001</td>\n",
              "      <td>bosson</td>\n",
              "      <td>Pop</td>\n",
              "      <td>It's hard to say goodbye, it hurts to be alone...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266356</th>\n",
              "      <td>266356</td>\n",
              "      <td>pre-approved</td>\n",
              "      <td>2012</td>\n",
              "      <td>classes-of-dynamo</td>\n",
              "      <td>Not Available</td>\n",
              "      <td>Im coming with the news\\nIm coming with the ne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116995</th>\n",
              "      <td>116995</td>\n",
              "      <td>no-control</td>\n",
              "      <td>2006</td>\n",
              "      <td>david-bowie</td>\n",
              "      <td>Rock</td>\n",
              "      <td>Stay away from the future\\nBack away from the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240934</th>\n",
              "      <td>240934</td>\n",
              "      <td>addio-fioritoi-asil</td>\n",
              "      <td>2007</td>\n",
              "      <td>andrea-bocelli</td>\n",
              "      <td>Not Available</td>\n",
              "      <td>(Giacomo Puccini - MADAMA BUTTERFLY)\\nAddio, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36431</th>\n",
              "      <td>36431</td>\n",
              "      <td>master-of-disguise</td>\n",
              "      <td>2006</td>\n",
              "      <td>arcturus</td>\n",
              "      <td>Metal</td>\n",
              "      <td>(\"No! this face is only a mask a wicked orname...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120533</th>\n",
              "      <td>120533</td>\n",
              "      <td>holla-at-me</td>\n",
              "      <td>2010</td>\n",
              "      <td>chris-brown</td>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>Uh, Boom, Boom\\nWe ballin' in the room\\nSweepi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         index                        song  year             artist  \\\n",
              "225641  225641                 summer-rain  2008      anna-ternheim   \n",
              "19677    19677                   love-club  2009           big-bang   \n",
              "93346    93346  when-papa-played-the-dobro  2007  flatt-and-scruggs   \n",
              "230134  230134        up-to-my-neck-in-you  2006              ac-dc   \n",
              "81330    81330          we-will-meet-again  2001             bosson   \n",
              "266356  266356                pre-approved  2012  classes-of-dynamo   \n",
              "116995  116995                  no-control  2006        david-bowie   \n",
              "240934  240934         addio-fioritoi-asil  2007     andrea-bocelli   \n",
              "36431    36431          master-of-disguise  2006           arcturus   \n",
              "120533  120533                 holla-at-me  2010        chris-brown   \n",
              "\n",
              "                genre                                             lyrics  \n",
              "225641          Indie  Last summer was mad, remember the rain\\nI know...  \n",
              "19677             Pop  We gettin down in the club\\nAll my fella all m...  \n",
              "93346         Country  My papa was a hobo when they delivered me\\nWe ...  \n",
              "230134           Rock  Well I've been up to my neck in trouble\\nUp to...  \n",
              "81330             Pop  It's hard to say goodbye, it hurts to be alone...  \n",
              "266356  Not Available  Im coming with the news\\nIm coming with the ne...  \n",
              "116995           Rock  Stay away from the future\\nBack away from the ...  \n",
              "240934  Not Available  (Giacomo Puccini - MADAMA BUTTERFLY)\\nAddio, f...  \n",
              "36431           Metal  (\"No! this face is only a mask a wicked orname...  \n",
              "120533        Hip-Hop  Uh, Boom, Boom\\nWe ballin' in the room\\nSweepi...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "NZMzR2VXRXbG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "texts = lyrics_df[\"lyrics\"].tolist()\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "flat_list =  [word for word in [tokenizer.tokenize(text.lower()) for text  in texts]]\n",
        "all_text = [item for sublist in flat_list for item in sublist]\n",
        "req_dist = nltk.FreqDist(all_text)\n",
        "rare_words = {word for (word, count) in req_dist.items() if count < MIN_OCCURENCES}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3uXCLl53RXbI",
        "colab_type": "code",
        "outputId": "e145feec-8e0f-4189-e234-7020989f99e3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '/home/gabib3b/anaconda2/lib/python27.zip',\n",
              " '/home/gabib3b/anaconda2/lib/python2.7',\n",
              " '/home/gabib3b/anaconda2/lib/python2.7/plat-linux2',\n",
              " '/home/gabib3b/anaconda2/lib/python2.7/lib-tk',\n",
              " '/home/gabib3b/anaconda2/lib/python2.7/lib-old',\n",
              " '/home/gabib3b/anaconda2/lib/python2.7/lib-dynload',\n",
              " '/home/gabib3b/anaconda2/lib/python2.7/site-packages',\n",
              " '/home/gabib3b/anaconda2/lib/python2.7/site-packages/setuptools-40.6.3-py2.7.egg',\n",
              " '/home/gabib3b/anaconda2/lib/python2.7/site-packages/IPython/extensions',\n",
              " '/home/gabib3b/.ipython']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "_SW31k8TRXbL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string \n",
        "\n",
        "def cleanText(text, rare_words=None):\n",
        "    \n",
        "        #text = text1.translate(string.punctuation)\n",
        "  table = str.maketrans({key: None for key in string.punctuation})\n",
        "  text = text.translate(table)  \n",
        "        \n",
        "  tokens = word_tokenize(text)\n",
        "  tokens = [w.lower() for w in tokens]\n",
        "\n",
        "  stops = set(stopwords.words(\"english\"))\n",
        "\n",
        "  words = [word for word in tokens if word not in stops and (rare_words is None or word not in rare_words)]\n",
        "  if len(words) == 0:\n",
        "    return None\n",
        "\n",
        "  return words\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VEkrD8wpRXbN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5b33a76f-27cc-476c-e1d2-2eecc82a23bd"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'string With Punctuation'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "fhMq6Tj0RXbP",
        "colab_type": "code",
        "outputId": "40fd671a-f019-490a-c73b-d023dec2f020",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        }
      },
      "cell_type": "code",
      "source": [
        "lyrics_df[\"clean_lyrics\"] = lyrics_df[\"lyrics\"].map(lambda text: cleanText(text, rare_words))\n",
        "lyrics_df.sample(10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>song</th>\n",
              "      <th>year</th>\n",
              "      <th>artist</th>\n",
              "      <th>genre</th>\n",
              "      <th>lyrics</th>\n",
              "      <th>clean_lyrics</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>133661</th>\n",
              "      <td>133661</td>\n",
              "      <td>como-fingir-unplugged</td>\n",
              "      <td>2008</td>\n",
              "      <td>elvis-crespo</td>\n",
              "      <td>Pop</td>\n",
              "      <td>Â¿CÃ³mo fingir que te olvide?\\nSi por mas que ...</td>\n",
              "      <td>[â¿cã³mo, fingir, que, te, olvide, si, por, ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302550</th>\n",
              "      <td>302550</td>\n",
              "      <td>wild-wild-west</td>\n",
              "      <td>2006</td>\n",
              "      <td>escape-club</td>\n",
              "      <td>Rock</td>\n",
              "      <td>Forty-seven dead beats living in the back stre...</td>\n",
              "      <td>[fortyseven, dead, beats, living, back, street...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241658</th>\n",
              "      <td>241658</td>\n",
              "      <td>arc-of-the-sun</td>\n",
              "      <td>2009</td>\n",
              "      <td>assembly-of-dust</td>\n",
              "      <td>Rock</td>\n",
              "      <td>make yourself at home we've been expecting you...</td>\n",
              "      <td>[make, home, weve, expecting, weve, waiting, a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280387</th>\n",
              "      <td>280387</td>\n",
              "      <td>one-step-ahead</td>\n",
              "      <td>2009</td>\n",
              "      <td>beres-hammond</td>\n",
              "      <td>Rock</td>\n",
              "      <td>One step ahead and you're up\\nOne step behind ...</td>\n",
              "      <td>[one, step, ahead, youre, one, step, behind, y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122470</th>\n",
              "      <td>122470</td>\n",
              "      <td>one-day</td>\n",
              "      <td>2008</td>\n",
              "      <td>dave-mason</td>\n",
              "      <td>Rock</td>\n",
              "      <td>I know it's unbelievable\\nAnd I know it seems ...</td>\n",
              "      <td>[know, unbelievable, know, seems, unthinkable,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46030</th>\n",
              "      <td>46030</td>\n",
              "      <td>take-me-to-your-heart</td>\n",
              "      <td>2007</td>\n",
              "      <td>bananarama</td>\n",
              "      <td>Pop</td>\n",
              "      <td>[Chorus]\\nTake me to your heart now, baby\\nTak...</td>\n",
              "      <td>[chorus, take, heart, baby, take, heart, come,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199895</th>\n",
              "      <td>199895</td>\n",
              "      <td>chloroform</td>\n",
              "      <td>2015</td>\n",
              "      <td>belasco</td>\n",
              "      <td>Rock</td>\n",
              "      <td>Thought she was the most important person in t...</td>\n",
              "      <td>[thought, important, person, world, dressed, c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344241</th>\n",
              "      <td>344241</td>\n",
              "      <td>excited</td>\n",
              "      <td>2013</td>\n",
              "      <td>avant</td>\n",
              "      <td>Hip-Hop</td>\n",
              "      <td>This feels good, hm\\nMmm,\\nYeah yeah\\nAh, uh u...</td>\n",
              "      <td>[feels, good, hm, mmm, yeah, yeah, ah, uh, uh,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166437</th>\n",
              "      <td>166437</td>\n",
              "      <td>shackles-and-chains</td>\n",
              "      <td>2007</td>\n",
              "      <td>arlo-guthrie</td>\n",
              "      <td>Rock</td>\n",
              "      <td>On a long lonesome journey I'm going\\nOh darli...</td>\n",
              "      <td>[long, lonesome, journey, im, going, oh, darli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177860</th>\n",
              "      <td>177860</td>\n",
              "      <td>assemble</td>\n",
              "      <td>2012</td>\n",
              "      <td>avengers</td>\n",
              "      <td>Rock</td>\n",
              "      <td>Verse 1\\n(Thor)\\nI'm mighty Thor\\nAnd this is ...</td>\n",
              "      <td>[verse, 1, thor, im, mighty, thor, war, see, h...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         index                   song  year            artist    genre  \\\n",
              "133661  133661  como-fingir-unplugged  2008      elvis-crespo      Pop   \n",
              "302550  302550         wild-wild-west  2006       escape-club     Rock   \n",
              "241658  241658         arc-of-the-sun  2009  assembly-of-dust     Rock   \n",
              "280387  280387         one-step-ahead  2009     beres-hammond     Rock   \n",
              "122470  122470                one-day  2008        dave-mason     Rock   \n",
              "46030    46030  take-me-to-your-heart  2007        bananarama      Pop   \n",
              "199895  199895             chloroform  2015           belasco     Rock   \n",
              "344241  344241                excited  2013             avant  Hip-Hop   \n",
              "166437  166437    shackles-and-chains  2007      arlo-guthrie     Rock   \n",
              "177860  177860               assemble  2012          avengers     Rock   \n",
              "\n",
              "                                                   lyrics  \\\n",
              "133661  Â¿CÃ³mo fingir que te olvide?\\nSi por mas que ...   \n",
              "302550  Forty-seven dead beats living in the back stre...   \n",
              "241658  make yourself at home we've been expecting you...   \n",
              "280387  One step ahead and you're up\\nOne step behind ...   \n",
              "122470  I know it's unbelievable\\nAnd I know it seems ...   \n",
              "46030   [Chorus]\\nTake me to your heart now, baby\\nTak...   \n",
              "199895  Thought she was the most important person in t...   \n",
              "344241  This feels good, hm\\nMmm,\\nYeah yeah\\nAh, uh u...   \n",
              "166437  On a long lonesome journey I'm going\\nOh darli...   \n",
              "177860  Verse 1\\n(Thor)\\nI'm mighty Thor\\nAnd this is ...   \n",
              "\n",
              "                                             clean_lyrics  \n",
              "133661  [â¿cã³mo, fingir, que, te, olvide, si, por, ma...  \n",
              "302550  [fortyseven, dead, beats, living, back, street...  \n",
              "241658  [make, home, weve, expecting, weve, waiting, a...  \n",
              "280387  [one, step, ahead, youre, one, step, behind, y...  \n",
              "122470  [know, unbelievable, know, seems, unthinkable,...  \n",
              "46030   [chorus, take, heart, baby, take, heart, come,...  \n",
              "199895  [thought, important, person, world, dressed, c...  \n",
              "344241  [feels, good, hm, mmm, yeah, yeah, ah, uh, uh,...  \n",
              "166437  [long, lonesome, journey, im, going, oh, darli...  \n",
              "177860  [verse, 1, thor, im, mighty, thor, war, see, h...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "-9RTqtm6RXbV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lyrics_df = lyrics_df[lyrics_df.clean_lyrics.notnull()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "13GsRZKhRXba",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "FEATURE_VECTOR_SIZE = 300 \n",
        "WINDOW_SIZE = 2\n",
        "all_sentenses = lyrics_df[\"clean_lyrics\"].tolist()\n",
        "wevec_model = Word2Vec(all_sentenses, size=FEATURE_VECTOR_SIZE, window=WINDOW_SIZE, workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L1wosSO7RXbd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clean_text = lyrics_df[\"clean_lyrics\"].tolist()\n",
        "flat_list = [item for sublist in clean_text for item in sublist]\n",
        "clean_req_dist = nltk.FreqDist(flat_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8N-oKf2LRXbg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vEMcasRaRXbo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Review most similar words\n",
        "Get initial evaluation of the word vectors by analyzing the most similar words for a few interesting words in the text. \n",
        "\n",
        "Choose words yourself, and find the most similar words to them."
      ]
    },
    {
      "metadata": {
        "id": "szI-y5dYRXbp",
        "colab_type": "code",
        "outputId": "905091a2-39bb-43f9-ec61-a6594a2f1a0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8739
        }
      },
      "cell_type": "code",
      "source": [
        "word_similars = {}\n",
        "for word, _ in clean_req_dist.most_common(50):\n",
        "  \n",
        "    similar = wevec_model.wv.most_similar(word)\n",
        "    word_similars[word] = similar\n",
        "\n",
        "    \n",
        "word_similars"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'aint': [('im', 0.5663697719573975),\n",
              "  ('cause', 0.5653460025787354),\n",
              "  ('wasnt', 0.5467410087585449),\n",
              "  ('theres', 0.5248292684555054),\n",
              "  ('youre', 0.5246023535728455),\n",
              "  ('thats', 0.5171744227409363),\n",
              "  ('isnt', 0.5135149955749512),\n",
              "  ('got', 0.5108820796012878),\n",
              "  ('know', 0.5038890838623047),\n",
              "  ('never', 0.5014824867248535)],\n",
              " 'away': [('let', 0.48832565546035767),\n",
              "  ('well', 0.4859676957130432),\n",
              "  ('cause', 0.4832591116428375),\n",
              "  ('time', 0.47816771268844604),\n",
              "  ('gone', 0.47182345390319824),\n",
              "  ('love', 0.46732097864151),\n",
              "  ('aside', 0.4666703939437866),\n",
              "  ('home', 0.4637254774570465),\n",
              "  ('back', 0.46354684233665466),\n",
              "  ('know', 0.46338358521461487)],\n",
              " 'baby': [('girl', 0.7120827436447144),\n",
              "  ('babe', 0.6995776891708374),\n",
              "  ('love', 0.6694008111953735),\n",
              "  ('want', 0.669062614440918),\n",
              "  ('yeah', 0.6660323143005371),\n",
              "  ('ooh', 0.6635637879371643),\n",
              "  ('oh', 0.658881425857544),\n",
              "  ('know', 0.6534972190856934),\n",
              "  ('cause', 0.6385881900787354),\n",
              "  ('darlin', 0.6360634565353394)],\n",
              " 'back': [('home', 0.5887631773948669),\n",
              "  ('way', 0.5375089049339294),\n",
              "  ('cause', 0.534113883972168),\n",
              "  ('right', 0.5337236523628235),\n",
              "  ('see', 0.5279619693756104),\n",
              "  ('baby', 0.5206151008605957),\n",
              "  ('come', 0.517545223236084),\n",
              "  ('let', 0.5158803462982178),\n",
              "  ('well', 0.5132509469985962),\n",
              "  ('around', 0.5107855200767517)],\n",
              " 'cant': [('couldnt', 0.723799467086792),\n",
              "  ('wont', 0.6827356815338135),\n",
              "  ('dont', 0.6429269313812256),\n",
              "  ('could', 0.5928511023521423),\n",
              "  ('cause', 0.5852749347686768),\n",
              "  ('want', 0.5851738452911377),\n",
              "  ('try', 0.5682271718978882),\n",
              "  ('ill', 0.5536952614784241),\n",
              "  ('trying', 0.5535484552383423),\n",
              "  ('let', 0.5384676456451416)],\n",
              " 'cause': [('cuz', 0.8079079389572144),\n",
              "  ('know', 0.7568197250366211),\n",
              "  ('dont', 0.6842511296272278),\n",
              "  ('think', 0.6820630431175232),\n",
              "  ('coz', 0.6806420683860779),\n",
              "  ('cos', 0.6762710809707642),\n",
              "  ('see', 0.6516028642654419),\n",
              "  ('want', 0.6489353775978088),\n",
              "  ('well', 0.6399257779121399),\n",
              "  ('baby', 0.6385882496833801)],\n",
              " 'come': [('go', 0.5892999172210693),\n",
              "  ('want', 0.5771645307540894),\n",
              "  ('comes', 0.5771149396896362),\n",
              "  ('baby', 0.5739448666572571),\n",
              "  ('coming', 0.5721402764320374),\n",
              "  ('bring', 0.5704269409179688),\n",
              "  ('take', 0.5619875192642212),\n",
              "  ('came', 0.5561540722846985),\n",
              "  ('know', 0.5531078577041626),\n",
              "  ('get', 0.5523031949996948)],\n",
              " 'could': [('would', 0.7875112891197205),\n",
              "  ('id', 0.6750789880752563),\n",
              "  ('youd', 0.6632087826728821),\n",
              "  ('couldnt', 0.6516528725624084),\n",
              "  ('wanted', 0.6168656349182129),\n",
              "  ('knew', 0.6155462861061096),\n",
              "  ('never', 0.5967786312103271),\n",
              "  ('didnt', 0.5935608744621277),\n",
              "  ('cant', 0.5928511023521423),\n",
              "  ('theyd', 0.5885814428329468)],\n",
              " 'day': [('time', 0.6266740560531616),\n",
              "  ('night', 0.620597243309021),\n",
              "  ('everyday', 0.5926679372787476),\n",
              "  ('morning', 0.5725794434547424),\n",
              "  ('today', 0.5702868103981018),\n",
              "  ('days', 0.5561830997467041),\n",
              "  ('year', 0.5419521331787109),\n",
              "  ('moment', 0.5355156660079956),\n",
              "  ('life', 0.5351184606552124),\n",
              "  ('way', 0.528084933757782)],\n",
              " 'dont': [('wont', 0.7109542489051819),\n",
              "  ('want', 0.7036983370780945),\n",
              "  ('know', 0.6930184364318848),\n",
              "  ('cause', 0.6842511296272278),\n",
              "  ('cant', 0.6429269313812256),\n",
              "  ('didnt', 0.6421318054199219),\n",
              "  ('need', 0.637547492980957),\n",
              "  ('really', 0.6214883923530579),\n",
              "  ('baby', 0.6191330552101135),\n",
              "  ('wan', 0.6145753264427185)],\n",
              " 'feel': [('feels', 0.6957604885101318),\n",
              "  ('feeling', 0.6490216851234436),\n",
              "  ('felt', 0.6391104459762573),\n",
              "  ('know', 0.6178280711174011),\n",
              "  ('love', 0.5935261249542236),\n",
              "  ('feelin', 0.5934211015701294),\n",
              "  ('cause', 0.583661675453186),\n",
              "  ('see', 0.5764236450195312),\n",
              "  ('want', 0.5746220350265503),\n",
              "  ('youre', 0.5606571435928345)],\n",
              " 'get': [('cause', 0.6193242073059082),\n",
              "  ('getting', 0.6016655564308167),\n",
              "  ('gettin', 0.60112464427948),\n",
              "  ('go', 0.5989205837249756),\n",
              "  ('take', 0.5849828720092773),\n",
              "  ('know', 0.580410361289978),\n",
              "  ('gets', 0.5779247283935547),\n",
              "  ('want', 0.5702115297317505),\n",
              "  ('got', 0.5650511384010315),\n",
              "  ('make', 0.5644965767860413)],\n",
              " 'girl': [('baby', 0.7120828032493591),\n",
              "  ('boy', 0.6803402900695801),\n",
              "  ('woman', 0.6568160653114319),\n",
              "  ('cause', 0.6033686399459839),\n",
              "  ('know', 0.6025257110595703),\n",
              "  ('girls', 0.5924623608589172),\n",
              "  ('love', 0.5923222303390503),\n",
              "  ('guy', 0.56671541929245),\n",
              "  ('want', 0.5658198595046997),\n",
              "  ('youre', 0.5556005239486694)],\n",
              " 'give': [('gave', 0.6301363706588745),\n",
              "  ('giving', 0.6272382140159607),\n",
              "  ('want', 0.6095423102378845),\n",
              "  ('take', 0.6091717481613159),\n",
              "  ('givin', 0.607517421245575),\n",
              "  ('need', 0.5857858657836914),\n",
              "  ('gives', 0.5840538144111633),\n",
              "  ('know', 0.5719672441482544),\n",
              "  ('love', 0.5648506283760071),\n",
              "  ('tell', 0.5558071136474609)],\n",
              " 'go': [('know', 0.6292890310287476),\n",
              "  ('get', 0.5989205837249756),\n",
              "  ('let', 0.5972548723220825),\n",
              "  ('take', 0.5954945683479309),\n",
              "  ('come', 0.5892997980117798),\n",
              "  ('going', 0.5669206380844116),\n",
              "  ('see', 0.566895604133606),\n",
              "  ('baby', 0.5636709332466125),\n",
              "  ('stay', 0.5594096779823303),\n",
              "  ('run', 0.5550017952919006)],\n",
              " 'gon': [('gunna', 0.6702015399932861),\n",
              "  ('na', 0.641385018825531),\n",
              "  ('going', 0.6007109880447388),\n",
              "  ('ill', 0.5698465704917908),\n",
              "  ('well', 0.567378044128418),\n",
              "  ('cause', 0.5619683265686035),\n",
              "  ('supposed', 0.5501289367675781),\n",
              "  ('wont', 0.5465490221977234),\n",
              "  ('finna', 0.5457605719566345),\n",
              "  ('ready', 0.5377052426338196)],\n",
              " 'got': [('gots', 0.6333959102630615),\n",
              "  ('cause', 0.5777989625930786),\n",
              "  ('get', 0.5650511980056763),\n",
              "  ('ta', 0.5491036772727966),\n",
              "  ('know', 0.546208381652832),\n",
              "  ('want', 0.539495050907135),\n",
              "  ('yeah', 0.5387946367263794),\n",
              "  ('thats', 0.5239390134811401),\n",
              "  ('dont', 0.5151320099830627),\n",
              "  ('give', 0.5109987854957581)],\n",
              " 'heart': [('hearts', 0.7298710346221924),\n",
              "  ('love', 0.588991641998291),\n",
              "  ('soul', 0.5500480532646179),\n",
              "  ('know', 0.5164538621902466),\n",
              "  ('inside', 0.5137538909912109),\n",
              "  ('cause', 0.5082606077194214),\n",
              "  ('heartbeat', 0.5049100518226624),\n",
              "  ('never', 0.4928109049797058),\n",
              "  ('always', 0.4922381043434143),\n",
              "  ('world', 0.49043673276901245)],\n",
              " 'ill': [('youll', 0.7906038165092468),\n",
              "  ('theyll', 0.6921430826187134),\n",
              "  ('wont', 0.6675747632980347),\n",
              "  ('shell', 0.6480000019073486),\n",
              "  ('well', 0.6321897506713867),\n",
              "  ('want', 0.6252074837684631),\n",
              "  ('dont', 0.6104179620742798),\n",
              "  ('itll', 0.6056602001190186),\n",
              "  ('could', 0.5753991603851318),\n",
              "  ('let', 0.573877215385437)],\n",
              " 'im': [('youre', 0.7951192259788513),\n",
              "  ('shes', 0.6149190664291382),\n",
              "  ('cause', 0.6073265075683594),\n",
              "  ('hes', 0.6066488027572632),\n",
              "  ('theyre', 0.6063071489334106),\n",
              "  ('aint', 0.5663697719573975),\n",
              "  ('know', 0.5533913969993591),\n",
              "  ('whos', 0.5532470941543579),\n",
              "  ('keep', 0.5532059669494629),\n",
              "  ('still', 0.5525389909744263)],\n",
              " 'ive': [('youve', 0.8494142889976501),\n",
              "  ('weve', 0.7705097198486328),\n",
              "  ('theyve', 0.6924443244934082),\n",
              "  ('havent', 0.665094256401062),\n",
              "  ('hasnt', 0.5550329685211182),\n",
              "  ('ever', 0.5350263118743896),\n",
              "  ('shes', 0.5289801955223083),\n",
              "  ('cause', 0.5165167450904846),\n",
              "  ('time', 0.5134604573249817),\n",
              "  ('never', 0.512916088104248)],\n",
              " 'know': [('cause', 0.7568197846412659),\n",
              "  ('want', 0.7267005443572998),\n",
              "  ('really', 0.7230163812637329),\n",
              "  ('think', 0.7154723405838013),\n",
              "  ('tell', 0.710807740688324),\n",
              "  ('love', 0.703856885433197),\n",
              "  ('dont', 0.6930185556411743),\n",
              "  ('see', 0.6789946556091309),\n",
              "  ('say', 0.6764810681343079),\n",
              "  ('need', 0.6620960831642151)],\n",
              " 'la': [('lunera', 0.4549947679042816),\n",
              "  ('dansante', 0.4386948347091675),\n",
              "  ('misma', 0.43413081765174866),\n",
              "  ('sagrada', 0.43020665645599365),\n",
              "  ('una', 0.42894047498703003),\n",
              "  ('consecuencia', 0.4165678024291992),\n",
              "  ('esa', 0.4152718484401703),\n",
              "  ('¿qu', 0.41011980175971985),\n",
              "  ('lavande', 0.4020920395851135),\n",
              "  ('cierres', 0.40122872591018677)],\n",
              " 'let': [('know', 0.6446177959442139),\n",
              "  ('want', 0.6414936780929565),\n",
              "  ('letting', 0.6391526460647583),\n",
              "  ('wont', 0.6141812205314636),\n",
              "  ('dont', 0.6048920750617981),\n",
              "  ('tell', 0.6014602780342102),\n",
              "  ('cause', 0.598921537399292),\n",
              "  ('go', 0.5972549915313721),\n",
              "  ('ill', 0.573877215385437),\n",
              "  ('baby', 0.572147011756897)],\n",
              " 'life': [('lives', 0.6302896738052368),\n",
              "  ('lifes', 0.6211806535720825),\n",
              "  ('world', 0.6065423488616943),\n",
              "  ('time', 0.590988278388977),\n",
              "  ('love', 0.580857515335083),\n",
              "  ('cause', 0.5533379316329956),\n",
              "  ('lifetime', 0.5480563044548035),\n",
              "  ('way', 0.5441443920135498),\n",
              "  ('day', 0.5351184606552124),\n",
              "  ('everything', 0.5279898047447205)],\n",
              " 'like': [('cause', 0.5786993503570557),\n",
              "  ('know', 0.5543126463890076),\n",
              "  ('see', 0.5328645706176758),\n",
              "  ('im', 0.5068784952163696),\n",
              "  ('want', 0.5050586462020874),\n",
              "  ('yeah', 0.5039310455322266),\n",
              "  ('way', 0.5003045797348022),\n",
              "  ('think', 0.49599847197532654),\n",
              "  ('love', 0.495656818151474),\n",
              "  ('still', 0.48556092381477356)],\n",
              " 'love': [('know', 0.703856885433197),\n",
              "  ('baby', 0.6694008111953735),\n",
              "  ('want', 0.6463333368301392),\n",
              "  ('cause', 0.6367230415344238),\n",
              "  ('oh', 0.6207993030548096),\n",
              "  ('way', 0.6070366501808167),\n",
              "  ('yeah', 0.6021788120269775),\n",
              "  ('feel', 0.5935261249542236),\n",
              "  ('girl', 0.5923221111297607),\n",
              "  ('true', 0.5918528437614441)],\n",
              " 'make': [('making', 0.6535421013832092),\n",
              "  ('made', 0.6340877413749695),\n",
              "  ('makin', 0.617367148399353),\n",
              "  ('makes', 0.6135274171829224),\n",
              "  ('cause', 0.5745468735694885),\n",
              "  ('know', 0.5661117434501648),\n",
              "  ('get', 0.5644965767860413),\n",
              "  ('want', 0.5560566186904907),\n",
              "  ('see', 0.5551841259002686),\n",
              "  ('take', 0.540411114692688)],\n",
              " 'man': [('woman', 0.6006616353988647),\n",
              "  ('mans', 0.5478818416595459),\n",
              "  ('guy', 0.5173032879829407),\n",
              "  ('boy', 0.5142313241958618),\n",
              "  ('girl', 0.5050415992736816),\n",
              "  ('men', 0.4962606728076935),\n",
              "  ('cause', 0.48690277338027954),\n",
              "  ('know', 0.4852979779243469),\n",
              "  ('love', 0.4747278690338135),\n",
              "  ('yeah', 0.4739295244216919)],\n",
              " 'na': [('gon', 0.6413849592208862),\n",
              "  ('wan', 0.5280660390853882),\n",
              "  ('gunna', 0.5145276188850403),\n",
              "  ('tonight', 0.4739684760570526),\n",
              "  ('baby', 0.4660261273384094),\n",
              "  ('alright', 0.46176600456237793),\n",
              "  ('dont', 0.4602188467979431),\n",
              "  ('know', 0.46007010340690613),\n",
              "  ('cause', 0.45844516158103943),\n",
              "  ('make', 0.4494374990463257)],\n",
              " 'need': [('want', 0.7807939052581787),\n",
              "  ('know', 0.6620961427688599),\n",
              "  ('dont', 0.637547492980957),\n",
              "  ('cause', 0.6278640031814575),\n",
              "  ('baby', 0.6054514646530151),\n",
              "  ('needed', 0.6052317023277283),\n",
              "  ('give', 0.5857858657836914),\n",
              "  ('love', 0.5779235363006592),\n",
              "  ('needs', 0.5719714164733887),\n",
              "  ('wan', 0.5645575523376465)],\n",
              " 'never': [('ever', 0.7096387147903442),\n",
              "  ('always', 0.6546244621276855),\n",
              "  ('could', 0.5967786312103271),\n",
              "  ('know', 0.588390052318573),\n",
              "  ('knew', 0.5791223049163818),\n",
              "  ('love', 0.576082706451416),\n",
              "  ('cause', 0.5672125816345215),\n",
              "  ('well', 0.5636934041976929),\n",
              "  ('thought', 0.5613229274749756),\n",
              "  ('would', 0.5610820651054382)],\n",
              " 'night': [('day', 0.620597243309021),\n",
              "  ('nights', 0.6172021627426147),\n",
              "  ('time', 0.5884141325950623),\n",
              "  ('evening', 0.5767116546630859),\n",
              "  ('afternoon', 0.5756338238716125),\n",
              "  ('tonight', 0.5662292242050171),\n",
              "  ('nite', 0.5570229291915894),\n",
              "  ('weekend', 0.5565205216407776),\n",
              "  ('nighttime', 0.5194175839424133),\n",
              "  ('summer', 0.5161288976669312)],\n",
              " 'oh': [('yeah', 0.7748574018478394),\n",
              "  ('whoa', 0.7129714488983154),\n",
              "  ('baby', 0.6588814854621887),\n",
              "  ('ooh', 0.6564612984657288),\n",
              "  ('woah', 0.6291455030441284),\n",
              "  ('yes', 0.6258177757263184),\n",
              "  ('love', 0.6207993030548096),\n",
              "  ('know', 0.5790987610816956),\n",
              "  ('darling', 0.5760760307312012),\n",
              "  ('ohh', 0.5730686187744141)],\n",
              " 'one': [('another', 0.6051348447799683),\n",
              "  ('cause', 0.5914093255996704),\n",
              "  ('love', 0.568797767162323),\n",
              "  ('know', 0.5633056163787842),\n",
              "  ('every', 0.5606702566146851),\n",
              "  ('time', 0.5503772497177124),\n",
              "  ('someone', 0.5471892356872559),\n",
              "  ('last', 0.5466698408126831),\n",
              "  ('always', 0.5435311794281006),\n",
              "  ('well', 0.5433189272880554)],\n",
              " 'que': [('mã\\x83â¡s', 0.6337242722511292),\n",
              "  ('quien', 0.6313324570655823),\n",
              "  ('porque', 0.6303075551986694),\n",
              "  ('aunque', 0.62865149974823),\n",
              "  ('cuando', 0.6285561919212341),\n",
              "  ('qu', 0.6151500344276428),\n",
              "  ('cual', 0.5977753400802612),\n",
              "  ('mejor', 0.5970975160598755),\n",
              "  ('paque', 0.5955273509025574),\n",
              "  ('porke', 0.5945683717727661)],\n",
              " 'right': [('baby', 0.6145572662353516),\n",
              "  ('cause', 0.6105897426605225),\n",
              "  ('know', 0.6094638109207153),\n",
              "  ('wrong', 0.6082954406738281),\n",
              "  ('alright', 0.6081950664520264),\n",
              "  ('well', 0.6019836664199829),\n",
              "  ('yeah', 0.5907764434814453),\n",
              "  ('way', 0.5891772508621216),\n",
              "  ('tonight', 0.5732190608978271),\n",
              "  ('good', 0.5686466693878174)],\n",
              " 'say': [('said', 0.7043707370758057),\n",
              "  ('saying', 0.6875754594802856),\n",
              "  ('know', 0.6764810681343079),\n",
              "  ('tell', 0.6654198169708252),\n",
              "  ('cause', 0.6353148221969604),\n",
              "  ('think', 0.6316874027252197),\n",
              "  ('believe', 0.5998356342315674),\n",
              "  ('sayin', 0.5923376083374023),\n",
              "  ('love', 0.5898576974868774),\n",
              "  ('want', 0.5881849527359009)],\n",
              " 'see': [('know', 0.6789946556091309),\n",
              "  ('cause', 0.6516028642654419),\n",
              "  ('look', 0.6393704414367676),\n",
              "  ('tell', 0.6289917230606079),\n",
              "  ('believe', 0.6015256643295288),\n",
              "  ('want', 0.5817187428474426),\n",
              "  ('show', 0.5816184878349304),\n",
              "  ('love', 0.5811706185340881),\n",
              "  ('feel', 0.5764236450195312),\n",
              "  ('say', 0.5756902694702148)],\n",
              " 'take': [('taking', 0.6640574932098389),\n",
              "  ('took', 0.6429004669189453),\n",
              "  ('give', 0.6091718077659607),\n",
              "  ('takes', 0.6030418276786804),\n",
              "  ('takin', 0.5957764387130737),\n",
              "  ('go', 0.5954946279525757),\n",
              "  ('get', 0.5849829912185669),\n",
              "  ('come', 0.561987578868866),\n",
              "  ('taken', 0.5551919341087341),\n",
              "  ('hold', 0.5466718673706055)],\n",
              " 'tell': [('know', 0.7108076810836792),\n",
              "  ('say', 0.6654196977615356),\n",
              "  ('cause', 0.6292158961296082),\n",
              "  ('see', 0.6289917230606079),\n",
              "  ('told', 0.626566469669342),\n",
              "  ('telling', 0.6056089997291565),\n",
              "  ('think', 0.603791356086731),\n",
              "  ('let', 0.6014602184295654),\n",
              "  ('want', 0.6003217101097107),\n",
              "  ('baby', 0.5981444120407104)],\n",
              " 'thats': [('cause', 0.6241044998168945),\n",
              "  ('know', 0.6176583766937256),\n",
              "  ('yeah', 0.5936315655708313),\n",
              "  ('love', 0.5855806469917297),\n",
              "  ('right', 0.5539908409118652),\n",
              "  ('always', 0.5513325929641724),\n",
              "  ('youre', 0.5446222424507141),\n",
              "  ('baby', 0.5372949838638306),\n",
              "  ('see', 0.5365058779716492),\n",
              "  ('well', 0.5356206297874451)],\n",
              " 'time': [('day', 0.6266740560531616),\n",
              "  ('cause', 0.6036513447761536),\n",
              "  ('life', 0.590988278388977),\n",
              "  ('moment', 0.5907822847366333),\n",
              "  ('night', 0.5884141325950623),\n",
              "  ('well', 0.584812581539154),\n",
              "  ('way', 0.5622592568397522),\n",
              "  ('know', 0.5599384307861328),\n",
              "  ('love', 0.5585645437240601),\n",
              "  ('always', 0.5522359609603882)],\n",
              " 'wan': [('want', 0.7341502904891968),\n",
              "  ('know', 0.6156445145606995),\n",
              "  ('dont', 0.6145753264427185),\n",
              "  ('let', 0.5673102140426636),\n",
              "  ('need', 0.5645575523376465),\n",
              "  ('baby', 0.5471823215484619),\n",
              "  ('cause', 0.5291971564292908),\n",
              "  ('na', 0.5280660390853882),\n",
              "  ('gon', 0.5278910398483276),\n",
              "  ('love', 0.5155688524246216)],\n",
              " 'want': [('need', 0.7807939052581787),\n",
              "  ('wan', 0.7341503500938416),\n",
              "  ('know', 0.7267005443572998),\n",
              "  ('dont', 0.7036983370780945),\n",
              "  ('baby', 0.6690627336502075),\n",
              "  ('cause', 0.6489353775978088),\n",
              "  ('love', 0.6463333368301392),\n",
              "  ('let', 0.6414936780929565),\n",
              "  ('ill', 0.6252074837684631),\n",
              "  ('really', 0.6111565828323364)],\n",
              " 'way': [('know', 0.6079506278038025),\n",
              "  ('love', 0.6070366501808167),\n",
              "  ('cause', 0.604371190071106),\n",
              "  ('right', 0.5891772508621216),\n",
              "  ('well', 0.579102635383606),\n",
              "  ('always', 0.5624393224716187),\n",
              "  ('time', 0.5622591972351074),\n",
              "  ('want', 0.557675838470459),\n",
              "  ('baby', 0.5499564409255981),\n",
              "  ('never', 0.5465573072433472)],\n",
              " 'well': [('cause', 0.6399258375167847),\n",
              "  ('ill', 0.6321898698806763),\n",
              "  ('know', 0.6043914556503296),\n",
              "  ('right', 0.6019837856292725),\n",
              "  ('baby', 0.5851708650588989),\n",
              "  ('time', 0.5848126411437988),\n",
              "  ('yeah', 0.5812807083129883),\n",
              "  ('way', 0.579102635383606),\n",
              "  ('love', 0.5765088796615601),\n",
              "  ('might', 0.5735976696014404)],\n",
              " 'world': [('worlds', 0.6187469959259033),\n",
              "  ('life', 0.6065423488616943),\n",
              "  ('universe', 0.5605000257492065),\n",
              "  ('cause', 0.5398502349853516),\n",
              "  ('love', 0.5355241894721985),\n",
              "  ('everything', 0.5216445326805115),\n",
              "  ('see', 0.513755202293396),\n",
              "  ('know', 0.5069876313209534),\n",
              "  ('way', 0.5036863088607788),\n",
              "  ('us', 0.495491623878479)],\n",
              " 'yeah': [('oh', 0.7748572826385498),\n",
              "  ('baby', 0.6660322546958923),\n",
              "  ('ooh', 0.661824107170105),\n",
              "  ('whoa', 0.6573215126991272),\n",
              "  ('know', 0.635951578617096),\n",
              "  ('cause', 0.6170056462287903),\n",
              "  ('love', 0.602178692817688),\n",
              "  ('thats', 0.5936315059661865),\n",
              "  ('aw', 0.5924257636070251),\n",
              "  ('right', 0.5907763838768005)],\n",
              " 'youre': [('im', 0.7951191663742065),\n",
              "  ('shes', 0.6412957906723022),\n",
              "  ('theyre', 0.6320570707321167),\n",
              "  ('cause', 0.6316495537757874),\n",
              "  ('know', 0.6124160885810852),\n",
              "  ('baby', 0.5995012521743774),\n",
              "  ('always', 0.5830700397491455),\n",
              "  ('hes', 0.5745923519134521),\n",
              "  ('think', 0.5686862468719482),\n",
              "  ('youll', 0.5623116493225098)]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "1W3GUhLPRXbr",
        "colab_type": "code",
        "outputId": "56a1ac3b-4120-4835-8fdd-435dd20e2c3c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wevec_model.wv.most_similar('fire')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('fires', 0.6295726895332336),\n",
              " ('flames', 0.6074615120887756),\n",
              " ('flame', 0.6055196523666382),\n",
              " ('ablaze', 0.5413768887519836),\n",
              " ('desire', 0.5156161785125732),\n",
              " ('alight', 0.5122188329696655),\n",
              " ('gasoline', 0.4977535903453827),\n",
              " ('burning', 0.49690544605255127),\n",
              " ('spark', 0.4928058683872223),\n",
              " ('aflame', 0.4832827150821686)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "metadata": {
        "id": "ab9S8xOnRXbt",
        "colab_type": "code",
        "outputId": "efbf0b19-5a06-4b89-cd27-344e2751e865",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wevec_model.wv.most_similar('kiss')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('kissed', 0.5996934771537781),\n",
              " ('touch', 0.5846958160400391),\n",
              " ('kisses', 0.5504751205444336),\n",
              " ('hug', 0.5244470834732056),\n",
              " ('caress', 0.5160906314849854),\n",
              " ('kissing', 0.4945163130760193),\n",
              " ('love', 0.4940756559371948),\n",
              " ('baby', 0.4696815013885498),\n",
              " ('kissin', 0.46546944975852966),\n",
              " ('taste', 0.4626149833202362)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "metadata": {
        "id": "zdeUfR_aRXbw",
        "colab_type": "code",
        "outputId": "c3f46683-7aeb-4deb-a1c0-a3d05e7e2cc9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wevec_model.wv.most_similar('girl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('baby', 0.7139131426811218),\n",
              " ('boy', 0.7059749960899353),\n",
              " ('woman', 0.6433032751083374),\n",
              " ('know', 0.6125483512878418),\n",
              " ('cause', 0.5841875672340393),\n",
              " ('love', 0.5832270383834839),\n",
              " ('girls', 0.5812261700630188),\n",
              " ('yeah', 0.5732951164245605),\n",
              " ('want', 0.5672628879547119),\n",
              " ('youre', 0.5650014877319336)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "doTUjmQ1RXbz",
        "colab_type": "code",
        "outputId": "a3a65284-8718-41ee-b663-7d4b6c4d0dfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "cell_type": "code",
      "source": [
        "wevec_model.wv.most_similar('day')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('time', 0.6266740560531616),\n",
              " ('night', 0.620597243309021),\n",
              " ('everyday', 0.5926679372787476),\n",
              " ('morning', 0.5725794434547424),\n",
              " ('today', 0.5702868103981018),\n",
              " ('days', 0.5561830997467041),\n",
              " ('year', 0.5419521331787109),\n",
              " ('moment', 0.5355156660079956),\n",
              " ('life', 0.5351184606552124),\n",
              " ('way', 0.528084933757782)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "_BaSE8w0RXb2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Word Vectors Algebra\n",
        "We've seen in class examples of algebraic games on the word vectors (e.g. man - woman + king = queen ). \n",
        "\n",
        "Try a few vector algebra terms, and evaluate how well they work. Try to use the Cosine distance and compare it to the Euclidean distance."
      ]
    },
    {
      "metadata": {
        "id": "oDyT5JtPRXb3",
        "colab_type": "code",
        "outputId": "e1acf3bf-8773-47e6-bfa3-070c4d4aa189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "cell_type": "code",
      "source": [
        "v1 = wevec_model.wv['man'] \n",
        "v2 = wevec_model.wv['woman'] \n",
        "v3 = wevec_model.wv['king'] \n",
        "\n",
        "res =  v1 - v2 + v3\n",
        "wevec_model.wv.similar_by_vector(res)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('king', 0.7882822155952454),\n",
              " ('man', 0.47769367694854736),\n",
              " ('kings', 0.4146175682544708),\n",
              " ('queens', 0.37266281247138977),\n",
              " ('ruler', 0.37229782342910767),\n",
              " ('hail', 0.36218011379241943),\n",
              " ('prophet', 0.3618967533111572),\n",
              " ('chief', 0.3597838878631592),\n",
              " ('throne', 0.35767027735710144),\n",
              " ('kumbia', 0.35489657521247864)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "LeYCRYwxRXb8",
        "colab_type": "code",
        "outputId": "f0245365-d10f-43a1-d66a-98e06a70e62a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "cell_type": "code",
      "source": [
        "v1 = wevec_model.wv['girl'] \n",
        "v2 = wevec_model.wv['baby'] \n",
        "\n",
        "res =  v1 + v2 \n",
        "wevec_model.wv.similar_by_vector(res)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('girl', 0.9318497180938721),\n",
              " ('baby', 0.9183056354522705),\n",
              " ('boy', 0.7003820538520813),\n",
              " ('love', 0.6799249649047852),\n",
              " ('know', 0.6774591207504272),\n",
              " ('cause', 0.6702293157577515),\n",
              " ('want', 0.6648070216178894),\n",
              " ('babe', 0.6564757823944092),\n",
              " ('yeah', 0.6520112752914429),\n",
              " ('woman', 0.6502894163131714)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "-YaIx-p5RXcA",
        "colab_type": "code",
        "outputId": "9843eb37-72b6-4a77-d3ef-d56e9e082d27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "cell_type": "code",
      "source": [
        "v1 = wevec_model.wv['lover'] \n",
        "v2 = wevec_model.wv['man'] \n",
        "v3 = wevec_model.wv['woman'] \n",
        "\n",
        "res =  v1 - v2  + v3\n",
        "wevec_model.wv.similar_by_vector(res)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('lover', 0.7886897921562195),\n",
              " ('woman', 0.6719876527786255),\n",
              " ('girl', 0.48289191722869873),\n",
              " ('baby', 0.441474586725235),\n",
              " ('lovin', 0.4390641152858734),\n",
              " ('friend', 0.4284239411354065),\n",
              " ('love', 0.4250537157058716),\n",
              " ('mine', 0.40829527378082275),\n",
              " ('shes', 0.39532506465911865),\n",
              " ('affection', 0.3907325863838196)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "FU3sAwZERXcF",
        "colab_type": "code",
        "outputId": "0b5f67df-369c-4984-e3c9-db05812343e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "cell_type": "code",
      "source": [
        "v1 = wevec_model.wv['love'] \n",
        "v2 = wevec_model.wv['woman'] \n",
        "\n",
        "res =  v1 + v2\n",
        "wevec_model.wv.similar_by_vector(res)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('woman', 0.8862682580947876),\n",
              " ('love', 0.8674317598342896),\n",
              " ('girl', 0.7133291959762573),\n",
              " ('baby', 0.6877225637435913),\n",
              " ('know', 0.6840402483940125),\n",
              " ('cause', 0.637723445892334),\n",
              " ('want', 0.6223989725112915),\n",
              " ('lovin', 0.6200134754180908),\n",
              " ('man', 0.6155452728271484),\n",
              " ('way', 0.6130156517028809)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "cG4bL0g4RXcJ",
        "colab_type": "code",
        "outputId": "c5c9a036-24c7-47ce-8a23-80302d52ab9f",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "v1 = wevec_model.wv['love'] \n",
        "v2 = wevec_model.wv['woman'] \n",
        "\n",
        "res =  v1 + v2\n",
        "wevec_model.wv.similar_by_vector(res)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('woman', 0.877863347530365),\n",
              " ('love', 0.8622276782989502),\n",
              " ('girl', 0.7056551575660706),\n",
              " ('baby', 0.6891446709632874),\n",
              " ('know', 0.6853798627853394),\n",
              " ('cause', 0.6328531503677368),\n",
              " ('lovin', 0.6304674744606018),\n",
              " ('want', 0.6176474094390869),\n",
              " ('man', 0.615849494934082),\n",
              " ('way', 0.6060291528701782)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "OJov8FhCRXcL",
        "colab_type": "code",
        "outputId": "07215033-68a9-4c31-c1ca-b3a715c6b96d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "cell_type": "code",
      "source": [
        "v1 = wevec_model.wv['baby'] \n",
        "v2 = wevec_model.wv['girl'] \n",
        "v3 = wevec_model.wv['man'] \n",
        "\n",
        "res =  v1 - v2 + v3\n",
        "wevec_model.wv.similar_by_vector(res)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('man', 0.7545353770256042),\n",
              " ('baby', 0.5510138273239136),\n",
              " ('yeah', 0.46613001823425293),\n",
              " ('oh', 0.4390658438205719),\n",
              " ('love', 0.42743343114852905),\n",
              " ('yes', 0.42291349172592163),\n",
              " ('well', 0.42170244455337524),\n",
              " ('know', 0.41399848461151123),\n",
              " ('lord', 0.4125754237174988),\n",
              " ('babe', 0.41126126050949097)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "6GXrv02MRXcN",
        "colab_type": "code",
        "outputId": "9e6c6fbc-6052-43d9-b915-1763585eece8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "v2 = wevec_model.wv['love'] \n",
        "v2 = wevec_model.wv['woman'] \n",
        "\n",
        "res =  v1 + v2\n",
        "wevec_model.wv.similar_by_vector(res)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('woman', 0.886969268321991),\n",
              " ('baby', 0.8707532286643982),\n",
              " ('girl', 0.7706629037857056),\n",
              " ('babe', 0.6707208752632141),\n",
              " ('love', 0.6638684868812561),\n",
              " ('know', 0.6623520255088806),\n",
              " ('want', 0.630240261554718),\n",
              " ('yeah', 0.6264259815216064),\n",
              " ('cause', 0.6246328353881836),\n",
              " ('honey', 0.6214901208877563)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "metadata": {
        "id": "uiHCl_FjRXcP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IV41Rzd-RXcR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Sentiment Analysis\n",
        "Estimate sentiment of words using word vectors.  \n",
        "In this section, we'll use the SemEval-2015 English Twitter Sentiment Lexicon.  \n",
        "The lexicon was used as an official test set in the SemEval-2015 shared Task #10: Subtask E, and contains a polarity score for words in range -1 (negative) to 1 (positive) - http://saifmohammad.com/WebPages/SCL.html#OPP"
      ]
    },
    {
      "metadata": {
        "id": "2xZFSPXIRXcR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build a classifier for the sentiment of a word given its word vector. Split the data to a train and test sets, and report the model performance on both sets."
      ]
    },
    {
      "metadata": {
        "id": "nPyYXUApRXcS",
        "colab_type": "code",
        "outputId": "b5011f36-9d3b-4636-c66a-d036be90da5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "cell_type": "code",
      "source": [
        "twitter_lex_df = pd.read_csv('/content/drive/My Drive/SemEval2015-English-Twitter-Lexicon.txt', sep='\\t',  names =['polarity', 'word'])\n",
        "twitter_lex_df.describe(include = 'all')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>polarity</th>\n",
              "      <th>word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1515.000000</td>\n",
              "      <td>1515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>NaN</td>\n",
              "      <td>can't bring</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.000319</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.502247</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-0.984000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.422000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.031000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.406000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.984000</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           polarity         word\n",
              "count   1515.000000         1515\n",
              "unique          NaN         1515\n",
              "top             NaN  can't bring\n",
              "freq            NaN            1\n",
              "mean       0.000319          NaN\n",
              "std        0.502247          NaN\n",
              "min       -0.984000          NaN\n",
              "25%       -0.422000          NaN\n",
              "50%        0.031000          NaN\n",
              "75%        0.406000          NaN\n",
              "max        0.984000          NaN"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "gvIxpK4ARXcY",
        "colab_type": "code",
        "outputId": "bf9a498f-3db1-475e-8ad5-34706fa698f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "cell_type": "code",
      "source": [
        "twitter_lex_df.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>polarity</th>\n",
              "      <th>word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.984</td>\n",
              "      <td>loves</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.984</td>\n",
              "      <td>#inspirational</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.969</td>\n",
              "      <td>amazing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.969</td>\n",
              "      <td>#peaceful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.953</td>\n",
              "      <td>#greatness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   polarity            word\n",
              "0     0.984           loves\n",
              "1     0.984  #inspirational\n",
              "2     0.969         amazing\n",
              "3     0.969       #peaceful\n",
              "4     0.953      #greatness"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "3gFx_-0pRXcb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "twitter_lex_df['vector'] = twitter_lex_df[\"word\"].map(lambda word: wevec_model.wv[word].reshape(1,-1) if word in wevec_model.wv else None)\n",
        "twitter_lex_df = twitter_lex_df[twitter_lex_df.vector.notnull()]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1qhm9PFZRXcd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(twitter_lex_df, test_size=0.2, random_state=999)\n",
        "X_train = train['vector'].values\n",
        "y_train = train['polarity'].values\n",
        "X_test = test['vector'].values\n",
        "y_test = test['polarity'].values\n",
        "\n",
        "X_train = np.concatenate(X_train).reshape(X_train.shape[0], X_train[0].shape[1])\n",
        "\n",
        "shape = list(X_test[0].shape)\n",
        "X_test = np.concatenate(X_test).reshape(X_test.shape[0],X_test[0].shape[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JTajK9JHRXce",
        "colab_type": "code",
        "outputId": "9e559f90-8710-45d3-ab07-64c81e96d1e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier,XGBRegressor\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model = XGBRegressor()\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
              "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
              "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
              "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "       silent=True, subsample=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "A6CXEYhWRXch",
        "colab_type": "code",
        "outputId": "43418142-8ce7-4bf6-a830-d17152635aa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "model.score(X_test, y_test)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4206103424734679"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "32oVBSJGRXcl",
        "colab_type": "code",
        "outputId": "7a6c6490-8ddc-4f6f-f561-719920ad9140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "regr = RandomForestRegressor(max_depth=3, random_state=999, n_estimators=150, min_samples_leaf=3)\n",
        "regr.fit(X_train, y_train)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
              "           max_features='auto', max_leaf_nodes=None,\n",
              "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "           min_samples_leaf=3, min_samples_split=2,\n",
              "           min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=None,\n",
              "           oob_score=False, random_state=999, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "XnrL0bUmRXcp",
        "colab_type": "code",
        "outputId": "b01db6c0-3b25-4d31-ceaf-d8c665fef68c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "regr.score(X_test, y_test)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.26720810779396953"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "tq9k0rF4RXcs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.utils.data as utils_data\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0ZPQpE1YRXcx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = y_train.reshape(-1, 1)\n",
        "yy = y_test.reshape(-1, 1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gSZsh-cbRXc1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "training_samples = utils_data.TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y))\n",
        "data_loader = utils_data.DataLoader(training_samples, batch_size=5, shuffle=False)\t\n",
        "\n",
        "test_samples = utils_data.TensorDataset(torch.from_numpy(X_test), torch.from_numpy(yy))\n",
        "test_data_loader = utils_data.DataLoader(test_samples, batch_size=len(X_test), shuffle=False)\t\n",
        "test_data_loader_1 = utils_data.DataLoader(test_samples, batch_size=1, shuffle=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IMah6XckRXc5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4Od1vn9wRXc8",
        "colab_type": "code",
        "outputId": "200e121b-5ec7-4a35-bd04-a47ba3633cb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, n_feature, n_hidden, n_output):\n",
        "        super(Net, self).__init__()\n",
        "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
        "        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n",
        "        self.dropout1 = nn.Dropout(p=0.1)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
        "        x = self.dropout1(x)\n",
        "        x = self.predict(x)             # linear output\n",
        "        return x\n",
        "    \n",
        "net = Net(n_feature=300, n_hidden=20, n_output=1)     # define the network\n",
        "print(net)  # net architecture\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.001)\n",
        "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n",
        "\n",
        "plt.ion()   # something about plotting\n",
        "\n",
        "for t in range(100):\n",
        "    for batch_idx, (data, target) in enumerate(data_loader):\n",
        "  \n",
        "        data, target = Variable(data).float(), Variable(target).float()\n",
        "        optimizer.zero_grad()\n",
        "        prediction = net(data)\n",
        "        loss = loss_func(prediction, target) \n",
        "        \n",
        "        loss.backward() \n",
        "        optimizer.step()\n",
        "        \n",
        "\n",
        "print('score')\n",
        "def score(model, data_loader, criterion):\n",
        "    \n",
        "  running_loss = 0.\n",
        "  calc_count =0.\n",
        "  \n",
        "  model.eval()\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for images, labels in data_loader:\n",
        "\n",
        "      images = Variable(images)  \n",
        "      labels = Variable(labels)\n",
        "      \n",
        "      outputs = model(images.float())\n",
        "      #(outputs.shape, labels.shape)\n",
        "      loss = criterion(outputs, labels.float())\n",
        "      print(loss)\n",
        "\n",
        "score(net, test_data_loader, loss_func )  "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (hidden): Linear(in_features=300, out_features=20, bias=True)\n",
            "  (predict): Linear(in_features=20, out_features=1, bias=True)\n",
            "  (dropout1): Dropout(p=0.1)\n",
            ")\n",
            "score\n",
            "tensor(0.1255)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "onaHnQPXRXc-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "        \n",
        "       \n",
        "\n",
        "     \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LZT1RIAyRXdB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r4oCCXA1RXdE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Goi1mSRQRXdG",
        "colab_type": "code",
        "outputId": "f19acd0f-b38c-4b9d-f28c-95774ef9defe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1733
        }
      },
      "cell_type": "code",
      "source": [
        "model = Net(n_feature=300, n_hidden=10, n_output=1)  \n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "model.train()\n",
        "loss_list = []\n",
        "for epoch in range(100):\n",
        "  for batch_idx, (data, target) in enumerate(data_loader):\n",
        "    data, target = Variable(data), Variable(target)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data.float())       \n",
        "    \n",
        "    \n",
        "    loss = criterion(output, target.float())\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch >2:\n",
        "      if batch_idx % 200 == 0:\n",
        "        loss_list.append(loss.data)\n",
        "        print(loss.data)\n",
        "      \n",
        "    \n",
        "#     if epoch >2:\n",
        "#       if batch_idx % 200 == 0:\n",
        "#         loss_list.append(loss.data[0])\n",
        "#       if batch_idx % 800 == 0:\n",
        "#         print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "#         epoch, batch_idx * len(data), len(data_loader.dataset), 100. * batch_idx / len(data_loader), loss.data[0]))\n",
        "        \n",
        "\n",
        "print('score')\n",
        "def score(model, data_loader, criterion):\n",
        "    \n",
        "  running_loss = 0.\n",
        "  calc_count =0.\n",
        "  \n",
        "  model.eval()\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for images, labels in data_loader:\n",
        "\n",
        "      images = Variable(images)  \n",
        "      labels = Variable(labels)\n",
        "      \n",
        "      outputs = model(images.float())\n",
        "      #(outputs.shape, labels.shape)\n",
        "      loss = criterion(outputs, labels.float())\n",
        "      print(loss)\n",
        "\n",
        "score(model, test_data_loader, criterion )        \n",
        "            \n",
        "            \n",
        "            \n",
        "            "
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.0486)\n",
            "tensor(0.0358)\n",
            "tensor(0.0211)\n",
            "tensor(0.0190)\n",
            "tensor(0.0182)\n",
            "tensor(0.0420)\n",
            "tensor(0.0616)\n",
            "tensor(0.0608)\n",
            "tensor(0.0225)\n",
            "tensor(0.0551)\n",
            "tensor(0.0334)\n",
            "tensor(0.0327)\n",
            "tensor(0.0398)\n",
            "tensor(0.0519)\n",
            "tensor(0.0318)\n",
            "tensor(0.0217)\n",
            "tensor(0.0559)\n",
            "tensor(0.0118)\n",
            "tensor(0.0537)\n",
            "tensor(0.0363)\n",
            "tensor(0.0190)\n",
            "tensor(0.0081)\n",
            "tensor(0.0091)\n",
            "tensor(0.0034)\n",
            "tensor(0.0315)\n",
            "tensor(0.0278)\n",
            "tensor(0.0344)\n",
            "tensor(0.0113)\n",
            "tensor(0.0452)\n",
            "tensor(0.0581)\n",
            "tensor(0.0312)\n",
            "tensor(0.0321)\n",
            "tensor(0.0366)\n",
            "tensor(0.0077)\n",
            "tensor(0.0204)\n",
            "tensor(0.1066)\n",
            "tensor(0.0089)\n",
            "tensor(0.0187)\n",
            "tensor(0.0158)\n",
            "tensor(0.0044)\n",
            "tensor(0.0120)\n",
            "tensor(0.0264)\n",
            "tensor(0.0027)\n",
            "tensor(0.0184)\n",
            "tensor(0.0252)\n",
            "tensor(0.0961)\n",
            "tensor(0.0317)\n",
            "tensor(0.0114)\n",
            "tensor(0.0044)\n",
            "tensor(0.0089)\n",
            "tensor(0.0257)\n",
            "tensor(0.0188)\n",
            "tensor(0.0579)\n",
            "tensor(0.0127)\n",
            "tensor(0.0006)\n",
            "tensor(0.0761)\n",
            "tensor(0.0483)\n",
            "tensor(0.0279)\n",
            "tensor(0.0301)\n",
            "tensor(0.0013)\n",
            "tensor(0.0023)\n",
            "tensor(0.0093)\n",
            "tensor(0.0054)\n",
            "tensor(0.0104)\n",
            "tensor(0.0269)\n",
            "tensor(0.0071)\n",
            "tensor(0.0662)\n",
            "tensor(0.0484)\n",
            "tensor(0.0013)\n",
            "tensor(0.0125)\n",
            "tensor(0.0063)\n",
            "tensor(0.0042)\n",
            "tensor(0.0176)\n",
            "tensor(0.0036)\n",
            "tensor(0.0189)\n",
            "tensor(0.0158)\n",
            "tensor(0.0040)\n",
            "tensor(0.0515)\n",
            "tensor(0.0052)\n",
            "tensor(0.0268)\n",
            "tensor(0.0311)\n",
            "tensor(0.0045)\n",
            "tensor(0.0218)\n",
            "tensor(0.0217)\n",
            "tensor(0.0176)\n",
            "tensor(0.0018)\n",
            "tensor(0.0031)\n",
            "tensor(0.0088)\n",
            "tensor(0.0739)\n",
            "tensor(0.0278)\n",
            "tensor(0.0317)\n",
            "tensor(0.0852)\n",
            "tensor(0.0532)\n",
            "tensor(0.0174)\n",
            "tensor(0.0603)\n",
            "tensor(0.0011)\n",
            "tensor(0.0398)\n",
            "score\n",
            "tensor(0.2408)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uXH77-NnRXdM",
        "colab_type": "code",
        "outputId": "7e037845-28b6-40b1-daa1-c50919b06904",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def valid(model,x_valid,y_valid,criterion):\n",
        "#     model.eval()\n",
        "#     data, target = Variable(x_valid), Variable(y_valid)\n",
        "#     y_pred = model(data)\n",
        "#     loss = criterion(y_pred, target)\n",
        "# #     print('test-loss {0}'.format(loss.item())\n",
        "#     return loss.item()\n",
        "\n",
        "# valid(model, X_test, y_test.reshape(-1, 1), criterion )\n",
        "\n",
        "def score(model, data_loader, criterion):\n",
        "    \n",
        "  running_loss = 0.\n",
        "  calc_count =0.\n",
        "  \n",
        "  model.eval()\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    for images, labels in data_loader:\n",
        "\n",
        "      images = Variable(images)  \n",
        "      labels = Variable(labels)\n",
        "      \n",
        "      outputs = model(images.float())\n",
        "      #(outputs.shape, labels.shape)\n",
        "      loss = criterion(outputs, labels.float())\n",
        "      print(loss)\n",
        "\n",
        "score(model, test_data_loader, criterion )        \n",
        "\n",
        "#       running_correct +=torch.sum(pred==labels.data).cpu().numpy().item()\n",
        "#       calc_count+=outputs.data.shape[0]\n",
        "#       running_loss += loss.item()\n",
        "#       confusion_matrix.add(pred, labels)\n",
        "  \n",
        "#   return round(running_loss/calc_count, 4), round(running_correct/calc_count, 4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.2898)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ViJvZQ0lRXdP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Use your trained model from the previous question to predict the sentiment score of words in the lyrics corpus that are not part of the original sentiment dataset. Review the words with the highest positive and negative sentiment. Do the results make sense?"
      ]
    },
    {
      "metadata": {
        "id": "Rg8p9R5wRXdQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "02nUNxJ1RXdR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualize Word Vectors\n",
        "In this section, you'll plot words on a 2D grid based on their inner similarity. We'll use the tSNE transformation to reduce dimensions from 300 to 2. You can get sample code from https://www.kaggle.com/pierremegret/gensim-word2vec-tutorial or other tutorials online.\n",
        "\n",
        "Perform the following:\n",
        "- Keep only the 3,000 most frequent words (after removing stopwords)\n",
        "- For this list, compute for each word its relative abundance in each of the genres\n",
        "- Compute the ratio between the proportion of each word in each genre and the proportion of the word in the entire corpus (the background distribution)\n",
        "- Pick the top 50 words for each genre. These words give good indication for that genre. Join the words from all genres into a single list of top significant words. \n",
        "- Compute tSNE transformation to 2D for all words, based on their word vectors\n",
        "- Plot the list of the top significant words in 2D. Next to each word output its text. The color of each point should indicate the genre for which it is most significant.\n",
        "\n",
        "You might prefer to use a different number of points or a slightly different methodology for improved results.  \n",
        "Analyze the results."
      ]
    },
    {
      "metadata": {
        "id": "B1p05fLZRXdS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "texts = lyrics_df[\"clean_lyrics\"].tolist()\n",
        "\n",
        "all_text = [item for sublist in texts for item in sublist]\n",
        "req_dist = nltk.FreqDist(all_text)\n",
        "words_couter = [(word, count) for (word, count) in req_dist.items()]\n",
        "words_couter.sort(key=lambda tup: tup[1], reverse=True) \n",
        "top_words = words_couter[0:3000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VQoMlRKhRXdT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "geners = lyrics_df['genre'].unique()\n",
        "word_gener_counter = np.zeros(shape=(3000, len(geners)))\n",
        "word_total_counter = np.zeros(len(geners))\n",
        "word_index = {word: index for index, (word,counter) in enumerate(top_words)}\n",
        "index_word = {index:word for index, (word,counter) in enumerate(top_words)}\n",
        "\n",
        "genere_index = {genere: index for index, genere in enumerate(geners)}\n",
        "index_genere = {index:genere  for index, genere in enumerate(geners)}\n",
        "\n",
        "for index, row in lyrics_df.iterrows():\n",
        "    genre = row['genre']\n",
        "    words = row['clean_lyrics']\n",
        "    \n",
        "    current_genere_index = genere_index[genre]\n",
        "     \n",
        "    \n",
        "    for word in words:\n",
        "        if word in word_index:\n",
        "            word_total_counter[current_genere_index] += 1\n",
        "            current_word_index = word_index[word]\n",
        "            word_gener_counter[current_word_index][current_genere_index]  += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sArcPgdvRXdU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ratios = word_gener_counter / word_total_counter.reshape(12)\n",
        "(ratios[1, 10],word_gener_counter[1, 10]/ word_total_counter[10])\n",
        "\n",
        "ratios_sorted = np.argsort(ratios, axis=0, kind='quicksort')\n",
        "top_ineces = ratios_sorted[0:50, :]\n",
        "\n",
        "\n",
        "ratios = word_gener_counter / word_total_counter.reshape(12)\n",
        "(ratios[1, 10],word_gener_counter[1, 10]/ word_total_counter[10])\n",
        "genget_top_words = {}\n",
        "for row in top_ineces:\n",
        "    for column, val in enumerate(row):\n",
        "        genre = index_genere[column]\n",
        "        if genre not in genget_top_words:\n",
        "            genget_top_words[genre] = []\n",
        "        \n",
        "        word =index_word[val]\n",
        "        genget_top_words[genre].append(word)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bS32v78YRXdW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        " \n",
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def tsnescatterplot(model, word, list_names):\n",
        "    \"\"\" Plot in seaborn the results from the t-SNE dimensionality reduction algorithm of the vectors of a query word,\n",
        "    its list of most similar words, and a list of words.\n",
        "    \"\"\"\n",
        "    arrays = np.empty((0, 300), dtype='f')\n",
        "#     word_labels = [word]\n",
        "    word_labels = [word]\n",
        "    color_list  = ['red']\n",
        "    \n",
        "\n",
        "    # adds the vector of the query word\n",
        "    arrays = np.append(arrays, model.wv.__getitem__([word]), axis=0)\n",
        "    \n",
        "    # gets list of most similar words\n",
        "    close_words = model.wv.most_similar([word])\n",
        "    \n",
        "    # adds the vector for each of the closest words to the array\n",
        "    for wrd_score in close_words:\n",
        "        wrd_vector = model.wv.__getitem__([wrd_score[0]])\n",
        "        word_labels.append(wrd_score[0])\n",
        "        color_list.append('blue')\n",
        "        arrays = np.append(arrays, wrd_vector, axis=0)\n",
        "    \n",
        "    # adds the vector for each of the words from list_names to the array\n",
        "    for wrd in list_names:\n",
        "        wrd_vector = model.wv.__getitem__([wrd])\n",
        "        word_labels.append(wrd)\n",
        "        color_list.append('green')\n",
        "        arrays = np.append(arrays, wrd_vector, axis=0)\n",
        "        \n",
        "    # Reduces the dimensionality from 300 to 50 dimensions with PCA\n",
        "    reduc = PCA(n_components=50).fit_transform(arrays)\n",
        "    \n",
        "    # Finds t-SNE coordinates for 2 dimensions\n",
        "    np.set_printoptions(suppress=True)\n",
        "    \n",
        "    Y = TSNE(n_components=2, random_state=0, perplexity=15).fit_transform(reduc)\n",
        "    \n",
        "    # Sets everything up to plot\n",
        "    df = pd.DataFrame({'x': [x for x in Y[:, 0]],\n",
        "                       'y': [y for y in Y[:, 1]],\n",
        "                       'words': word_labels,\n",
        "                       'color': color_list})\n",
        "    \n",
        "    fig, _ = plt.subplots()\n",
        "    fig.set_size_inches(9, 9)\n",
        "    \n",
        "    # Basic plot\n",
        "    p1 = sns.regplot(data=df,\n",
        "                     x=\"x\",\n",
        "                     y=\"y\",\n",
        "                     fit_reg=False,\n",
        "                     marker=\"o\",\n",
        "                     scatter_kws={'s': 40,\n",
        "                                  'facecolors': df['color']\n",
        "                                 }\n",
        "                    )\n",
        "    \n",
        "    # Adds annotations one by one with a loop\n",
        "    for line in range(0, df.shape[0]):\n",
        "         p1.text(df[\"x\"][line],\n",
        "                 df['y'][line],\n",
        "                 '  ' + df[\"words\"][line].title(),\n",
        "                 horizontalalignment='left',\n",
        "                 verticalalignment='bottom', size='medium',\n",
        "                 color=df['color'][line],\n",
        "                 weight='normal'\n",
        "                ).set_size(15)\n",
        "\n",
        "    \n",
        "    plt.xlim(Y[:, 0].min()-50, Y[:, 0].max()+50)\n",
        "    plt.ylim(Y[:, 1].min()-50, Y[:, 1].max()+50)\n",
        "            \n",
        "    plt.title('t-SNE visualization for {}'.format(word.title()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XOXibTX6RXdY",
        "colab_type": "code",
        "outputId": "28d755fc-fe40-4707-df82-7b732906a536",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tsnescatterplot(wevec_model, 'lady', ['winter', 'song'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "bKjUU5QYRXda",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        " \n",
        "import seaborn as sns\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def tsnescatterplot(model, genere_words):\n",
        "    \"\"\" Plot in seaborn the results from the t-SNE dimensionality reduction algorithm of the vectors of a query word,\n",
        "    its list of most similar words, and a list of words.\n",
        "    \"\"\"\n",
        "    num_of_geners = len(genere_words.keys()) * 50\n",
        "    arrays = np.empty((0, 300), dtype='f')\n",
        "    #arrays = np.empty((0,num_of_geners)  , dtype='f')\n",
        "                      \n",
        "#     word_labels = [word]\n",
        "    word_labels = []\n",
        "\n",
        "#     color_list  = ['red']\n",
        "    color_list_ptions = ['white',  'green', 'purple', 'black',  'blue', 'yellow', 'orange', 'red', 'olive', \n",
        "                  'pink', 'cyan', 'brown']\n",
        "    \n",
        "\n",
        "    color_list = []                  \n",
        "    for index, (genere, list_names) in  enumerate(genere_words.items()):\n",
        "        color = color_list_ptions[index]\n",
        "        for wrd in list_names:\n",
        "            wrd_vector = model.wv.__getitem__([wrd])   \n",
        "            word_labels.append(wrd)\n",
        "            color_list.append(color)\n",
        "            arrays = np.append(arrays, wrd_vector, axis=0)\n",
        "                      \n",
        "         \n",
        "                    \n",
        "        \n",
        "    # Reduces the dimensionality from 300 to 50 dimensions with PCA\n",
        "    reduc = PCA(n_components=50).fit_transform(arrays)\n",
        "    \n",
        "    # Finds t-SNE coordinates for 2 dimensions\n",
        "    np.set_printoptions(suppress=True)\n",
        "    \n",
        "    Y = TSNE(n_components=2, random_state=0, perplexity=15).fit_transform(reduc)\n",
        "    \n",
        "    # Sets everything up to plot\n",
        "    df = pd.DataFrame({'x': [x for x in Y[:, 0]],\n",
        "                       'y': [y for y in Y[:, 1]],\n",
        "                       'words': word_labels,\n",
        "                       'color': color_list})\n",
        "    \n",
        "    fig, _ = plt.subplots()\n",
        "    fig.set_size_inches(9, 9)\n",
        "    \n",
        "    # Basic plot\n",
        "    p1 = sns.regplot(data=df,\n",
        "                     x=\"x\",\n",
        "                     y=\"y\",\n",
        "                     fit_reg=False,\n",
        "                     marker=\"o\",\n",
        "                     scatter_kws={'s': 40,\n",
        "                                  'facecolors': df['color']\n",
        "                                 }\n",
        "                    )\n",
        "    \n",
        "    # Adds annotations one by one with a loop\n",
        "    for line in range(0, df.shape[0]):\n",
        "         p1.text(df[\"x\"][line],\n",
        "                 df['y'][line],\n",
        "                 '  ' + df[\"words\"][line].title(),\n",
        "                 horizontalalignment='left',\n",
        "                 verticalalignment='bottom', size='medium',\n",
        "                 color=df['color'][line],\n",
        "                 weight='normal'\n",
        "                ).set_size(15)\n",
        "\n",
        "    \n",
        "    plt.xlim(Y[:, 0].min()-50, Y[:, 0].max()+50)\n",
        "    plt.ylim(Y[:, 1].min()-50, Y[:, 1].max()+50)\n",
        "            \n",
        "    plt.title('t-SNE visualization for {}'.format(word.title()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DVRJZ5M5RXdd",
        "colab_type": "code",
        "outputId": "407a943f-8680-4c35-d429-29073d98eea3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tsnescatterplot(wevec_model, genget_top_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error in callback <function post_execute at 0x7fe270cc72a8> (for post_execute):\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "matplotlib display text must have all code points < 128 or use Unicode strings",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mpost_execute\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mpost_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_interactive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                     \u001b[0mdraw_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;31m# IPython >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/_pylab_helpers.pyc\u001b[0m in \u001b[0;36mdraw_all\u001b[0;34m(cls, force)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf_mgr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mforce\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mf_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                 \u001b[0mf_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0matexit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroy_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/backend_bases.pyc\u001b[0m in \u001b[0;36mdraw_idle\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2053\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_idle_drawing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2054\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idle_draw_cntx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2055\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdraw_cursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/backends/backend_agg.pyc\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;31m# if toolbar:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m#     toolbar.set_cursor(cursors.WAIT)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/artist.pyc\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/figure.pyc\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1475\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/image.pyc\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/artist.pyc\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2605\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2607\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2609\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/image.pyc\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/artist.pyc\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/text.pyc\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_wrap_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtextobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m             \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             \u001b[0mtrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/text.pyc\u001b[0m in \u001b[0;36m_get_layout\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mbaseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0mclean_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mismath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_math_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_usetex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclean_line\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 w, h, d = renderer.get_text_width_height_descent(clean_line,\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/text.pyc\u001b[0m in \u001b[0;36mis_math_text\u001b[0;34m(s, usetex)\u001b[0m\n\u001b[1;32m   1186\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TeX'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_math_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/cbook/__init__.pyc\u001b[0m in \u001b[0;36mis_math_text\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m   2031\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2032\u001b[0m         raise ValueError(\n\u001b[0;32m-> 2033\u001b[0;31m             \u001b[0;34m\"matplotlib display text must have all code points < 128 or use \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2034\u001b[0m             \"Unicode strings\")\n\u001b[1;32m   2035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: matplotlib display text must have all code points < 128 or use Unicode strings"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "matplotlib display text must have all code points < 128 or use Unicode strings",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/IPython/core/formatters.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/IPython/core/pylabtools.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/IPython/core/pylabtools.pyc\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/backend_bases.pyc\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2210\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m                     \u001b[0mdryrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2212\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2213\u001b[0m                 \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cachedRenderer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m                 \u001b[0mbbox_inches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/backends/backend_agg.pyc\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m         \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0moriginal_dpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/backends/backend_agg.pyc\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;31m# if toolbar:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m#     toolbar.set_cursor(cursors.WAIT)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/artist.pyc\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/figure.pyc\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1475\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/image.pyc\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/artist.pyc\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/axes/_base.pyc\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2605\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2607\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2609\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/image.pyc\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/artist.pyc\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/text.pyc\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_wrap_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtextobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m             \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m             \u001b[0mtrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtextobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/text.pyc\u001b[0m in \u001b[0;36m_get_layout\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mbaseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0mclean_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mismath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_math_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_usetex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclean_line\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 w, h, d = renderer.get_text_width_height_descent(clean_line,\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/text.pyc\u001b[0m in \u001b[0;36mis_math_text\u001b[0;34m(s, usetex)\u001b[0m\n\u001b[1;32m   1186\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TeX'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_math_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/matplotlib/cbook/__init__.pyc\u001b[0m in \u001b[0;36mis_math_text\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m   2031\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2032\u001b[0m         raise ValueError(\n\u001b[0;32m-> 2033\u001b[0;31m             \u001b[0;34m\"matplotlib display text must have all code points < 128 or use \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2034\u001b[0m             \"Unicode strings\")\n\u001b[1;32m   2035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: matplotlib display text must have all code points < 128 or use Unicode strings"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 648x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "4WJDq0L_RXdf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Text Classification\n",
        "In this section, you'll build a text classifier, determining the genre of a song based on its lyrics."
      ]
    },
    {
      "metadata": {
        "id": "r7r2gGPNRXdg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Text classification using Bag-of-Words\n",
        "Build a Naive Bayes classifier based on the bag of Words.  \n",
        "You will need to divide your dataset into a train and test sets."
      ]
    },
    {
      "metadata": {
        "id": "m7_TWU0MRXdg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "lyrics_df['clean_sentense'] = lyrics_df['clean_lyrics'].map(lambda words: ' '.join(words)) \n",
        "train, test = train_test_split(lyrics_df, test_size=0.2, random_state=999)\n",
        "\n",
        "\n",
        "#X_train = train['lyrics'].tolist()\n",
        "X_train = train['clean_sentense'].tolist()\n",
        "y_train = train['genre'].tolist()\n",
        "\n",
        "#X_test = test['lyrics']\n",
        "X_test = test['clean_sentense']\n",
        "y_test = test['genre']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dbqc1AeARXdk",
        "colab_type": "code",
        "outputId": "c3bccfd9-53f3-4eaa-ce61-0e711f9be263",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vect = CountVectorizer()\n",
        "X_train_dtm = vect.fit_transform(X_train)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "'utf8' codec can't decode byte 0xc2 in position 735: invalid continuation byte",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-92e402d7272d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train_dtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 869\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 266\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/gabib3b/anaconda2/lib/python2.7/encodings/utf_8.pyc\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(input, errors)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'strict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutf_8_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mIncrementalEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementalEncoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf8' codec can't decode byte 0xc2 in position 735: invalid continuation byte"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "gQTfWo3PRXdn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train_dtm, y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a3Lg6fv_RXdp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test_dtm = vect.transform(X_test)\n",
        "y_pred_class = nb.predict(X_test_dtm)\n",
        "accuracy_score = accuracy_score(y_test, y_pred_class)\n",
        "accuracy_score\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uVMOr9T8RXdr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "geners = lyrics_df['genre'].unique()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f7vRLIjhRXdt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "geners = lyrics_df['genre'].unique()\n",
        "conf_mat = confusion_matrix(\n",
        "        y_test, y_pred_class, labels = geners)\n",
        "\n",
        "acc_score = accuracy_score(y_test, y_pred_class)\n",
        "\n",
        "print(acc_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UeYY3BYyRXdu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "def plt_confusion_matrix(cm, class_names, normalize =False):\n",
        "  \n",
        "  if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "      \n",
        "  \n",
        "  df_cm = pd.DataFrame(cm, index = [i for i in class_names],\n",
        "                    columns = class_names)\n",
        "  \n",
        "  plt.figure(figsize = (20,14))\n",
        "  sns.heatmap(df_cm, annot=True)\n",
        "\n",
        "plt_confusion_matrix(conf_mat, geners)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u3OJnG3-RXdv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Show the classification report - precision, recall, f1 for each class."
      ]
    },
    {
      "metadata": {
        "id": "MCHuOuKBRXdv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred_class))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KuT0hps4RXdx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Text classification using Word Vectors\n",
        "#### Average word vectors\n",
        "Do the same, using a classifier that averages the word vectors of words in the document."
      ]
    },
    {
      "metadata": {
        "id": "2WPbc8BIRXdx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#lyrics_df['t1'] = lyrics_df['clean_lyrics'].map(lambda words: ' '.join(words)) \n",
        "def avg_sentense(sentense_words):\n",
        "    vectors = []\n",
        "    for word in sentense_words:\n",
        "        vectors.append(wevec_model.wv[word].reshape(1,-1))\n",
        "    \n",
        "    if len(vectors) > 1:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return vectors[0]\n",
        "\n",
        "lyrics_df = lyrics_df[lyrics_df.clean_lyrics.notnull()]\n",
        "lyrics_df['avg_vector'] = lyrics_df[\"clean_lyrics\"].map(lambda sentense: (avg_sentense(sentense)))\n",
        "train, test = train_test_split(lyrics_df, test_size=0.2, random_state=999)\n",
        "\n",
        "#X_train = train['lyrics'].tolist()\n",
        "X_train = train['avg_vector'].tolist()\n",
        "y_train = train['genre'].tolist()\n",
        "\n",
        "#X_test = test['lyrics']\n",
        "X_test = test['avg_vector'].tolist()\n",
        "y_test = test['genre']\n",
        "\n",
        "#avg_sentense(lyrics_df['clean_lyrics'][0])\n",
        "#twitter_lex_df['vector'] = twitter_lex_df[\"word\"].map(lambda word: wevec_model.wv[word].reshape(1,-1) if word in wevec_model.wv else None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B5-GdId2RXdy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# nb = MultinomialNB()\n",
        "# # nb.fit([[1,2,3], [2,3,4]], [1,2])\n",
        "# train, test = train_test_split(lyrics_df, test_size=0.2, random_state=999)\n",
        "# train_x_data = train['avg_vector'].tolist()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kBWyIDskRXd1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "X_train = np.asanyarray(X_train)\n",
        "X_train = X_train.reshape((212318,300))\n",
        "\n",
        "X_test1 = np.asanyarray(X_test)\n",
        "X_test1 = X_test1.reshape((-1, 300))\n",
        "\n",
        "\n",
        "# # X_train[0.shape\n",
        "# nb = MultinomialNB()\n",
        "# nb.fit(xx, y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NuFvKc8IRXd2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test1.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7FgbClY3RXd9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_scaled = scaler.transform(X_train)\n",
        "X_test1 = scaler.transform(X_test1)\n",
        "#X_scaled = preprocessing.scale(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2714gf9ERXd-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "translator = {}\n",
        "translator2 = {}\n",
        "for index, y in  enumerate(set(y_train)):\n",
        "    translator[index] = y\n",
        "    translator2[y] = index\n",
        "    \n",
        "# (X_train.shape, len(y_train))\n",
        "# nb = MultinomialNB()\n",
        "# nb.fit(X_scaled, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LDe4CVX5RXd_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_train_numbers = [translator2[y] for y in y_train]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TJ0MkF9bRXeA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# (X_train.shape, len(y_train))\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_scaled, y_train_numbers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PTx6dg-gRXeD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred_class = nb.predict(X_test1)\n",
        "res = [translator[y1] for y1 in y_pred_class]\n",
        "acc_score = accuracy_score(y_test, res)\n",
        "acc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vy2GTuIiRXeE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### TfIdf Weighting\n",
        "Do the same, using a classifier that averages the word vectors of words in the document, weighting each word by its TfIdf.\n"
      ]
    },
    {
      "metadata": {
        "id": "_svSV6f1RXeG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EzLU6-qKRXeH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Text classification using ConvNet\n",
        "Do the same, using a ConvNet.  \n",
        "The ConvNet should get as input a 2D matrix where each column is an embedding vector of a single word, and words are in order. Use zero padding so that all matrices have a similar length.  \n",
        "Some songs might be very long. Trim them so you keep a maximum of 128 words (after cleaning stop words and rare words).  \n",
        "Initialize the embedding layer using the word vectors that you've trained before, but allow them to change during training.  \n",
        "\n",
        "Extra: Try training the ConvNet with 2 slight modifications:\n",
        "1. freezing the the weights trained using Word2vec (preventing it from updating)\n",
        "1. random initialization of the embedding layer"
      ]
    },
    {
      "metadata": {
        "id": "8FjeeWcfRXeH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You are encouraged to try this question on your own.  \n",
        "\n",
        "You might prefer to get ideas from the paper \"Convolutional Neural Networks for Sentence Classification\" (Kim 2014, [link](https://arxiv.org/abs/1408.5882)).\n",
        "\n",
        "There are several implementations of the paper code in PyTorch online (see for example [this repo](https://github.com/prakashpandey9/Text-Classification-Pytorch) for a PyTorch implementation of CNN and other architectures for text classification). If you get stuck, they might provide you with a reference for your own code."
      ]
    },
    {
      "metadata": {
        "id": "rvOBQ3TzRXeI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}